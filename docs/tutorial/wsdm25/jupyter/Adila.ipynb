{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is `Adila`?\n",
    "\n",
    "`Adila` is an extension of the `OpeNTF` framework, focusing on improving the fairness of neural team formation methods.\n",
    "\n",
    "In particular, `Adila` attempts to mitigate popularity bias (and other forms of bias) through the application of greedy re-ranking algorithms when training neural team formation methods. The algorithms include:\n",
    "- [Score maximizing greedy mitigation algorithm](https://dl.acm.org/doi/10.1145/3292500.3330691)\n",
    "- [Greedy conservative mitigation algorithm](https://dl.acm.org/doi/10.1145/3292500.3330691)\n",
    "- [Relaxed variant of greedy conservative algorithm](https://dl.acm.org/doi/10.1145/3292500.3330691)\n",
    "- [Probabilistic greedy re-ranking algorithm](https://dl.acm.org/doi/10.1145/3132847.3132938)\n",
    "\n",
    "<img src=\"https://github.com/fani-lab/Adila/raw/main/misc/flow.png\" height=300px />\n",
    "\n",
    "# Quickstart\n",
    "\n",
    "`OpeNTF` has the following required arguments:\n",
    "\n",
    "- `-data`: the path of the input datasets.\n",
    "- `-domain`: the domain the input dataset belongs in.\n",
    "- `-model`: the neural team formation models to be used in the run.\n",
    "\n",
    "For `Adila`, other optional arguments include:\n",
    "- `-attribute`: the set of our sensitive attributes (e.g., popularity).\n",
    "- `-fairness`: fairness metrics for reranking algorithms, used to minimize different bias.\n",
    "- `-np-ratio`: desired ratio of non-popular experts after reranking.\n",
    "- `-k_max`: cutoff for the reranking algorithms.\n",
    "- `-filter`: remove outliers, if needed.\n",
    "- `-future`: predict future, if needed.\n",
    "- `-exp_id`: ID of the experiment.\n",
    "- `-output`: path of the baseline output.\n",
    "\n",
    "The following is a sample run of the `OpeNTF` codebase using a toy dataset `toy.dblp.v12.json`, which is modelled after the DBLP dataset: a dataset consisting of authorship and skill information on more than 4 million Computer Science research publications. Two neural models (`feedforward` and `Bayesian`) are used in this quickstart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Documents\\JS_Projects\\OpeNTF\\src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Documents\\Pycharm_Projects\\venvs\\opentf_base\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/Owner/Documents/JS_Projects/OpeNTF/src\n"
     ]
    }
   ],
   "source": [
    "%cd ../../../../src/\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
      "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
      "It took 0.008003473281860352 seconds to load from the pickles.\n",
      "It took 0.01700305938720703 seconds to load the sparse matrices.\n",
      "Running for (dataset, model): (dblp, fnn) ... \n",
      "Fold 0/2, Epoch 0/9, Minibatch 0/0, Phase train, Running Loss train 0.6056249141693115, Time 0.11439990997314453, Overall 2.0763325691223145 \n",
      "Fold 0/2, Epoch 0/9, Running Loss train 0.03562499495113597, Time 0.11439990997314453, Overall 2.0763325691223145 \n",
      "Fold 0/2, Epoch 0/9, Minibatch 0/0, Phase valid, Running Loss valid 0.5972533226013184, Time 0.11742401123046875, Overall 2.0793566703796387 \n",
      "Fold 0/2, Epoch 0/9, Running Loss valid 0.06636148028903538, Time 0.11742401123046875, Overall 2.0793566703796387 \n",
      "Fold 0/2, Epoch 1/9, Minibatch 0/0, Phase train, Running Loss train 0.5991436243057251, Time 0.13058924674987793, Overall 2.092521905899048 \n",
      "Fold 0/2, Epoch 1/9, Running Loss train 0.035243742606219125, Time 0.13058924674987793, Overall 2.092521905899048 \n",
      "Fold 0/2, Epoch 1/9, Minibatch 0/0, Phase valid, Running Loss valid 0.5923084616661072, Time 0.13258051872253418, Overall 2.094513177871704 \n",
      "Fold 0/2, Epoch 1/9, Running Loss valid 0.06581205129623413, Time 0.13258051872253418, Overall 2.094513177871704 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 0/2, Epoch 2/9, Minibatch 0/0, Phase train, Running Loss train 0.592818021774292, Time 0.1396188735961914, Overall 2.1015515327453613 \n",
      "Fold 0/2, Epoch 2/9, Running Loss train 0.03487164833966423, Time 0.1396188735961914, Overall 2.1015515327453613 \n",
      "Fold 0/2, Epoch 2/9, Minibatch 0/0, Phase valid, Running Loss valid 0.5874701738357544, Time 0.14061689376831055, Overall 2.1025495529174805 \n",
      "Fold 0/2, Epoch 2/9, Running Loss valid 0.06527446375952826, Time 0.1416165828704834, Overall 2.1035492420196533 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 0/2, Epoch 3/9, Minibatch 0/0, Phase train, Running Loss train 0.5866307020187378, Time 0.1473398208618164, Overall 2.1092724800109863 \n",
      "Fold 0/2, Epoch 3/9, Running Loss train 0.0345076883540434, Time 0.1473398208618164, Overall 2.1092724800109863 \n",
      "Fold 0/2, Epoch 3/9, Minibatch 0/0, Phase valid, Running Loss valid 0.5827431082725525, Time 0.1493387222290039, Overall 2.111271381378174 \n",
      "Fold 0/2, Epoch 3/9, Running Loss valid 0.06474923425250584, Time 0.1493387222290039, Overall 2.111271381378174 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Fold 0/2, Epoch 4/9, Minibatch 0/0, Phase train, Running Loss train 0.5805637240409851, Time 0.15434002876281738, Overall 2.1162726879119873 \n",
      "Fold 0/2, Epoch 4/9, Running Loss train 0.034150807296528536, Time 0.15434002876281738, Overall 2.1162726879119873 \n",
      "Fold 0/2, Epoch 4/9, Minibatch 0/0, Phase valid, Running Loss valid 0.5781247019767761, Time 0.15633869171142578, Overall 2.1182713508605957 \n",
      "Fold 0/2, Epoch 4/9, Running Loss valid 0.06423607799741957, Time 0.15633869171142578, Overall 2.1182713508605957 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Fold 0/2, Epoch 5/9, Minibatch 0/0, Phase train, Running Loss train 0.574617326259613, Time 0.16161012649536133, Overall 2.1235427856445312 \n",
      "Fold 0/2, Epoch 5/9, Running Loss train 0.03380101919174194, Time 0.16260933876037598, Overall 2.124541997909546 \n",
      "Fold 0/2, Epoch 5/9, Minibatch 0/0, Phase valid, Running Loss valid 0.573630690574646, Time 0.16460824012756348, Overall 2.1265408992767334 \n",
      "Fold 0/2, Epoch 5/9, Running Loss valid 0.06373674339718288, Time 0.16460824012756348, Overall 2.1265408992767334 \n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early Stopping Triggered at epoch: 5\n",
      "Fold 1/2, Epoch 0/9, Minibatch 0/0, Phase train, Running Loss train 0.6933990716934204, Time 0.0049991607666015625, Overall 2.13354229927063 \n",
      "Fold 1/2, Epoch 0/9, Running Loss train 0.04078818068784826, Time 0.0049991607666015625, Overall 2.13354229927063 \n",
      "Fold 1/2, Epoch 0/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6659319996833801, Time 0.006998777389526367, Overall 2.1355419158935547 \n",
      "Fold 1/2, Epoch 0/9, Running Loss valid 0.07399244440926446, Time 0.006998777389526367, Overall 2.1355419158935547 \n",
      "Fold 1/2, Epoch 1/9, Minibatch 0/0, Phase train, Running Loss train 0.6839163899421692, Time 0.013229846954345703, Overall 2.141772985458374 \n",
      "Fold 1/2, Epoch 1/9, Running Loss train 0.040230375878951126, Time 0.013229846954345703, Overall 2.141772985458374 \n",
      "Fold 1/2, Epoch 1/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6573002338409424, Time 0.015229463577270508, Overall 2.143772602081299 \n",
      "Fold 1/2, Epoch 1/9, Running Loss valid 0.07303335931566027, Time 0.015229463577270508, Overall 2.143772602081299 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 1/2, Epoch 2/9, Minibatch 0/0, Phase train, Running Loss train 0.6747457981109619, Time 0.020233631134033203, Overall 2.1487767696380615 \n",
      "Fold 1/2, Epoch 2/9, Running Loss train 0.03969092930064482, Time 0.02122950553894043, Overall 2.1497726440429688 \n",
      "Fold 1/2, Epoch 2/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6489450335502625, Time 0.02222895622253418, Overall 2.1507720947265625 \n",
      "Fold 1/2, Epoch 2/9, Running Loss valid 0.07210500372780694, Time 0.02222895622253418, Overall 2.1507720947265625 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 1/2, Epoch 3/9, Minibatch 0/0, Phase train, Running Loss train 0.6658795475959778, Time 0.02722930908203125, Overall 2.1557724475860596 \n",
      "Fold 1/2, Epoch 3/9, Running Loss train 0.03916938515270457, Time 0.02722930908203125, Overall 2.1557724475860596 \n",
      "Fold 1/2, Epoch 3/9, Minibatch 0/0, Phase valid, Running Loss valid 0.640863835811615, Time 0.029228925704956055, Overall 2.1577720642089844 \n",
      "Fold 1/2, Epoch 3/9, Running Loss valid 0.07120709286795722, Time 0.03022933006286621, Overall 2.1587724685668945 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Fold 1/2, Epoch 4/9, Minibatch 0/0, Phase train, Running Loss train 0.6573038697242737, Time 0.03422904014587402, Overall 2.1627721786499023 \n",
      "Fold 1/2, Epoch 4/9, Running Loss train 0.03866493351319257, Time 0.03422904014587402, Overall 2.1627721786499023 \n",
      "Fold 1/2, Epoch 4/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6330206394195557, Time 0.03722953796386719, Overall 2.1657726764678955 \n",
      "Fold 1/2, Epoch 4/9, Running Loss valid 0.07033562660217285, Time 0.03722953796386719, Overall 2.1657726764678955 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Fold 1/2, Epoch 5/9, Minibatch 0/0, Phase train, Running Loss train 0.6490036845207214, Time 0.042229652404785156, Overall 2.1707727909088135 \n",
      "Fold 1/2, Epoch 5/9, Running Loss train 0.03817668732474832, Time 0.042229652404785156, Overall 2.1707727909088135 \n",
      "Fold 1/2, Epoch 5/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6254642009735107, Time 0.04422903060913086, Overall 2.172772169113159 \n",
      "Fold 1/2, Epoch 5/9, Running Loss valid 0.06949602233039008, Time 0.04422903060913086, Overall 2.172772169113159 \n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early Stopping Triggered at epoch: 5\n",
      "Fold 2/2, Epoch 0/9, Minibatch 0/0, Phase train, Running Loss train 0.6977599263191223, Time 0.00500178337097168, Overall 2.180774211883545 \n",
      "Fold 2/2, Epoch 0/9, Running Loss train 0.03876444035106235, Time 0.00500178337097168, Overall 2.180774211883545 \n",
      "Fold 2/2, Epoch 0/9, Minibatch 0/0, Phase valid, Running Loss valid 0.7054514288902283, Time 0.006999969482421875, Overall 2.182772397994995 \n",
      "Fold 2/2, Epoch 0/9, Running Loss valid 0.08818142861127853, Time 0.006999969482421875, Overall 2.182772397994995 \n",
      "Fold 2/2, Epoch 1/9, Minibatch 0/0, Phase train, Running Loss train 0.687987744808197, Time 0.013000011444091797, Overall 2.188772439956665 \n",
      "Fold 2/2, Epoch 1/9, Running Loss train 0.038221541378233165, Time 0.013000011444091797, Overall 2.188772439956665 \n",
      "Fold 2/2, Epoch 1/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6971001029014587, Time 0.015000343322753906, Overall 2.190772771835327 \n",
      "Fold 2/2, Epoch 1/9, Running Loss valid 0.08713751286268234, Time 0.015000343322753906, Overall 2.190772771835327 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 2/2, Epoch 2/9, Minibatch 0/0, Phase train, Running Loss train 0.678523600101471, Time 0.021015405654907227, Overall 2.1967878341674805 \n",
      "Fold 2/2, Epoch 2/9, Running Loss train 0.03769575556119283, Time 0.021015405654907227, Overall 2.1967878341674805 \n",
      "Fold 2/2, Epoch 2/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6890474557876587, Time 0.023000478744506836, Overall 2.19877290725708 \n",
      "Fold 2/2, Epoch 2/9, Running Loss valid 0.08613093197345734, Time 0.023000478744506836, Overall 2.19877290725708 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 2/2, Epoch 3/9, Minibatch 0/0, Phase train, Running Loss train 0.6693738698959351, Time 0.026999950408935547, Overall 2.202772378921509 \n",
      "Fold 2/2, Epoch 3/9, Running Loss train 0.037187437216440834, Time 0.026999950408935547, Overall 2.202772378921509 \n",
      "Fold 2/2, Epoch 3/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6812991499900818, Time 0.029000043869018555, Overall 2.204772472381592 \n",
      "Fold 2/2, Epoch 3/9, Running Loss valid 0.08516239374876022, Time 0.029000043869018555, Overall 2.204772472381592 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Fold 2/2, Epoch 4/9, Minibatch 0/0, Phase train, Running Loss train 0.6605099439620972, Time 0.03399944305419922, Overall 2.2097718715667725 \n",
      "Fold 2/2, Epoch 4/9, Running Loss train 0.036694996886783175, Time 0.034999847412109375, Overall 2.2107722759246826 \n",
      "Fold 2/2, Epoch 4/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6738382577896118, Time 0.03600001335144043, Overall 2.2117724418640137 \n",
      "Fold 2/2, Epoch 4/9, Running Loss valid 0.08422978222370148, Time 0.037000179290771484, Overall 2.2127726078033447 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Fold 2/2, Epoch 5/9, Minibatch 0/0, Phase train, Running Loss train 0.6519139409065247, Time 0.04199981689453125, Overall 2.2177722454071045 \n",
      "Fold 2/2, Epoch 5/9, Running Loss train 0.036217441161473594, Time 0.04199981689453125, Overall 2.2177722454071045 \n",
      "Fold 2/2, Epoch 5/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6666646599769592, Time 0.0429995059967041, Overall 2.2187719345092773 \n",
      "Fold 2/2, Epoch 5/9, Running Loss valid 0.0833330824971199, Time 0.0429995059967041, Overall 2.2187719345092773 \n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early Stopping Triggered at epoch: 5\n",
      "It took 2.2217726707458496 to train the model.\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'P_2,5,10'} ...\n",
      "Averaging ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'P_2,5,10'} ...\n",
      "Averaging ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'P_2,5,10'} ...\n",
      "Averaging ...\n",
      "Running for (dataset, model): (dblp, bnn) ... \n",
      "Fold 0/2, Epoch 0/4, Minibatch 0/0, Phase train, Running Loss train 9.701826095581055, Time 0.031192779541015625, Overall 0.04186081886291504 \n",
      "Fold 0/2, Epoch 0/4, Running Loss train 0.5706956526812386, Time 0.031192779541015625, Overall 0.04186081886291504 \n",
      "Fold 0/2, Epoch 0/4, Minibatch 0/0, Phase valid, Running Loss valid 6.872168064117432, Time 0.0375819206237793, Overall 0.04824995994567871 \n",
      "Fold 0/2, Epoch 0/4, Running Loss valid 0.7635742293463813, Time 0.0375819206237793, Overall 0.04824995994567871 \n",
      "Fold 0/2, Epoch 1/4, Minibatch 0/0, Phase train, Running Loss train 7.5233869552612305, Time 0.04979133605957031, Overall 0.06045937538146973 \n",
      "Fold 0/2, Epoch 1/4, Running Loss train 0.4425521738388959, Time 0.05079174041748047, Overall 0.06145977973937988 \n",
      "Fold 0/2, Epoch 1/4, Minibatch 0/0, Phase valid, Running Loss valid 5.3721466064453125, Time 0.05479097366333008, Overall 0.06545901298522949 \n",
      "Fold 0/2, Epoch 1/4, Running Loss valid 0.5969051784939237, Time 0.05479097366333008, Overall 0.06545901298522949 \n",
      "Fold 0/2, Epoch 2/4, Minibatch 0/0, Phase train, Running Loss train 8.192793846130371, Time 0.06479120254516602, Overall 0.07545924186706543 \n",
      "Fold 0/2, Epoch 2/4, Running Loss train 0.4819290497723748, Time 0.06579184532165527, Overall 0.07645988464355469 \n",
      "Fold 0/2, Epoch 2/4, Minibatch 0/0, Phase valid, Running Loss valid 3.3596651554107666, Time 0.06979179382324219, Overall 0.0804598331451416 \n",
      "Fold 0/2, Epoch 2/4, Running Loss valid 0.3732961283789741, Time 0.06979179382324219, Overall 0.0804598331451416 \n",
      "Fold 0/2, Epoch 3/4, Minibatch 0/0, Phase train, Running Loss train 8.646368980407715, Time 0.0809173583984375, Overall 0.09158539772033691 \n",
      "Fold 0/2, Epoch 3/4, Running Loss train 0.5086099400239832, Time 0.0809173583984375, Overall 0.09158539772033691 \n",
      "Fold 0/2, Epoch 3/4, Minibatch 0/0, Phase valid, Running Loss valid 10.32580280303955, Time 0.08491730690002441, Overall 0.09558534622192383 \n",
      "Fold 0/2, Epoch 3/4, Running Loss valid 1.1473114225599501, Time 0.08591723442077637, Overall 0.09658527374267578 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 0/2, Epoch 4/4, Minibatch 0/0, Phase train, Running Loss train 8.802574157714844, Time 0.09553670883178711, Overall 0.10620474815368652 \n",
      "Fold 0/2, Epoch 4/4, Running Loss train 0.517798479865579, Time 0.09553670883178711, Overall 0.10620474815368652 \n",
      "Fold 0/2, Epoch 4/4, Minibatch 0/0, Phase valid, Running Loss valid 6.550690650939941, Time 0.09953689575195312, Overall 0.11020493507385254 \n",
      "Fold 0/2, Epoch 4/4, Running Loss valid 0.7278545167711046, Time 0.10053706169128418, Overall 0.1112051010131836 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 1/2, Epoch 0/4, Minibatch 0/0, Phase train, Running Loss train 8.19212818145752, Time 0.008999347686767578, Overall 0.12320470809936523 \n",
      "Fold 1/2, Epoch 0/4, Running Loss train 0.48188989302691293, Time 0.008999347686767578, Overall 0.12320470809936523 \n",
      "Fold 1/2, Epoch 0/4, Minibatch 0/0, Phase valid, Running Loss valid 10.479596138000488, Time 0.01299905776977539, Overall 0.12720441818237305 \n",
      "Fold 1/2, Epoch 0/4, Running Loss valid 1.1643995708889432, Time 0.013999700546264648, Overall 0.1282050609588623 \n",
      "Fold 1/2, Epoch 1/4, Minibatch 0/0, Phase train, Running Loss train 7.664950370788574, Time 0.023999691009521484, Overall 0.13820505142211914 \n",
      "Fold 1/2, Epoch 1/4, Running Loss train 0.45087943357579846, Time 0.023999691009521484, Overall 0.13820505142211914 \n",
      "Fold 1/2, Epoch 1/4, Minibatch 0/0, Phase valid, Running Loss valid 5.143964767456055, Time 0.029000043869018555, Overall 0.1432054042816162 \n",
      "Fold 1/2, Epoch 1/4, Running Loss valid 0.5715516408284506, Time 0.029000043869018555, Overall 0.1432054042816162 \n",
      "Fold 1/2, Epoch 2/4, Minibatch 0/0, Phase train, Running Loss train 7.0461907386779785, Time 0.03899955749511719, Overall 0.15320491790771484 \n",
      "Fold 1/2, Epoch 2/4, Running Loss train 0.41448180815752816, Time 0.03899955749511719, Overall 0.15320491790771484 \n",
      "Fold 1/2, Epoch 2/4, Minibatch 0/0, Phase valid, Running Loss valid 5.6814775466918945, Time 0.04399919509887695, Overall 0.1582045555114746 \n",
      "Fold 1/2, Epoch 2/4, Running Loss valid 0.6312752829657661, Time 0.04399919509887695, Overall 0.1582045555114746 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 1/2, Epoch 3/4, Minibatch 0/0, Phase train, Running Loss train 9.323131561279297, Time 0.052999019622802734, Overall 0.1672043800354004 \n",
      "Fold 1/2, Epoch 3/4, Running Loss train 0.5484195036046645, Time 0.0540006160736084, Overall 0.16820597648620605 \n",
      "Fold 1/2, Epoch 3/4, Minibatch 0/0, Phase valid, Running Loss valid 5.8487043380737305, Time 0.0579986572265625, Overall 0.17220401763916016 \n",
      "Fold 1/2, Epoch 3/4, Running Loss valid 0.6498560375637479, Time 0.0579986572265625, Overall 0.17220401763916016 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 1/2, Epoch 4/4, Minibatch 0/0, Phase train, Running Loss train 8.630220413208008, Time 0.06699919700622559, Overall 0.18120455741882324 \n",
      "Fold 1/2, Epoch 4/4, Running Loss train 0.5076600243063534, Time 0.06699919700622559, Overall 0.18120455741882324 \n",
      "Fold 1/2, Epoch 4/4, Minibatch 0/0, Phase valid, Running Loss valid 6.0534820556640625, Time 0.07200026512145996, Overall 0.18620562553405762 \n",
      "Fold 1/2, Epoch 4/4, Running Loss valid 0.6726091172960069, Time 0.07200026512145996, Overall 0.18620562553405762 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Fold 2/2, Epoch 0/4, Minibatch 0/0, Phase train, Running Loss train 13.120939254760742, Time 0.008000373840332031, Overall 0.19820547103881836 \n",
      "Fold 2/2, Epoch 0/4, Running Loss train 0.7289410697089301, Time 0.008000373840332031, Overall 0.19820547103881836 \n",
      "Fold 2/2, Epoch 0/4, Minibatch 0/0, Phase valid, Running Loss valid 7.2940826416015625, Time 0.012000322341918945, Overall 0.20220541954040527 \n",
      "Fold 2/2, Epoch 0/4, Running Loss valid 0.9117603302001953, Time 0.012000322341918945, Overall 0.20220541954040527 \n",
      "Fold 2/2, Epoch 1/4, Minibatch 0/0, Phase train, Running Loss train 6.706620693206787, Time 0.026009082794189453, Overall 0.21621417999267578 \n",
      "Fold 2/2, Epoch 1/4, Running Loss train 0.3725900385114882, Time 0.026009082794189453, Overall 0.21621417999267578 \n",
      "Fold 2/2, Epoch 1/4, Minibatch 0/0, Phase valid, Running Loss valid 5.9946818351745605, Time 0.03200340270996094, Overall 0.22220849990844727 \n",
      "Fold 2/2, Epoch 1/4, Running Loss valid 0.7493352293968201, Time 0.03200340270996094, Overall 0.22220849990844727 \n",
      "Fold 2/2, Epoch 2/4, Minibatch 0/0, Phase train, Running Loss train 6.208798408508301, Time 0.04400157928466797, Overall 0.2342066764831543 \n",
      "Fold 2/2, Epoch 2/4, Running Loss train 0.34493324491712785, Time 0.04400157928466797, Overall 0.2342066764831543 \n",
      "Fold 2/2, Epoch 2/4, Minibatch 0/0, Phase valid, Running Loss valid 6.477299213409424, Time 0.04900002479553223, Overall 0.23920512199401855 \n",
      "Fold 2/2, Epoch 2/4, Running Loss valid 0.809662401676178, Time 0.04900002479553223, Overall 0.23920512199401855 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 2/2, Epoch 3/4, Minibatch 0/0, Phase train, Running Loss train 6.142395973205566, Time 0.06000041961669922, Overall 0.25020551681518555 \n",
      "Fold 2/2, Epoch 3/4, Running Loss train 0.3412442207336426, Time 0.06000041961669922, Overall 0.25020551681518555 \n",
      "Fold 2/2, Epoch 3/4, Minibatch 0/0, Phase valid, Running Loss valid 6.238161563873291, Time 0.06600022315979004, Overall 0.25620532035827637 \n",
      "Fold 2/2, Epoch 3/4, Running Loss valid 0.7797701954841614, Time 0.06600022315979004, Overall 0.25620532035827637 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 2/2, Epoch 4/4, Minibatch 0/0, Phase train, Running Loss train 5.860939979553223, Time 0.07599925994873047, Overall 0.2662043571472168 \n",
      "Fold 2/2, Epoch 4/4, Running Loss train 0.3256077766418457, Time 0.07599925994873047, Overall 0.2662043571472168 \n",
      "Fold 2/2, Epoch 4/4, Minibatch 0/0, Phase valid, Running Loss valid 6.935448169708252, Time 0.08000016212463379, Overall 0.2702052593231201 \n",
      "Fold 2/2, Epoch 4/4, Running Loss valid 0.8669310212135315, Time 0.08000016212463379, Overall 0.2702052593231201 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "It took 0.2732059955596924 to train the model.\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'P_2,5,10'} ...\n",
      "Averaging ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'P_2,5,10'} ...\n",
      "Averaging ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'P_2,5,10'} ...\n",
      "Averaging ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Documents\\Pycharm_Projects\\venvs\\opentf_base\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Owner\\Documents\\JS_Projects\\OpeNTF\\src\\mdl\\fnn.py:306: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(modelfile))\n",
      "C:\\Users\\Owner\\Documents\\JS_Projects\\OpeNTF\\src\\mdl\\ntf.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Y_ = torch.load(f'{model_path}/f{foldidx}.{pred_set}.{epoch}pred')\n",
      "C:\\Users\\Owner\\Documents\\JS_Projects\\OpeNTF\\src\\mdl\\ntf.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Y_ = torch.load(f'{model_path}/f{foldidx}.{pred_set}.{epoch}pred')\n",
      "C:\\Users\\Owner\\Documents\\JS_Projects\\OpeNTF\\src\\mdl\\ntf.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Y_ = torch.load(f'{model_path}/f{foldidx}.{pred_set}.{epoch}pred')\n",
      "C:\\Users\\Owner\\Documents\\Pycharm_Projects\\venvs\\opentf_base\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Owner\\Documents\\JS_Projects\\OpeNTF\\src\\mdl\\bnn.py:248: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(modelfile))\n",
      "C:\\Users\\Owner\\Documents\\JS_Projects\\OpeNTF\\src\\mdl\\ntf.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Y_ = torch.load(f'{model_path}/f{foldidx}.{pred_set}.{epoch}pred')\n",
      "C:\\Users\\Owner\\Documents\\JS_Projects\\OpeNTF\\src\\mdl\\ntf.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Y_ = torch.load(f'{model_path}/f{foldidx}.{pred_set}.{epoch}pred')\n",
      "C:\\Users\\Owner\\Documents\\JS_Projects\\OpeNTF\\src\\mdl\\ntf.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Y_ = torch.load(f'{model_path}/f{foldidx}.{pred_set}.{epoch}pred')\n"
     ]
    }
   ],
   "source": [
    "!python -u main.py -data ../data/raw/dblp/toy.dblp.v12.json -domain dblp -model fnn bnn -fairness det_greedy -attribute popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Resources\n",
    "- [`OpeNTF` codebase](https://github.com/fani-lab/OpeNTF/tree/main)\n",
    "- [`Adila` codebase](https://github.com/fani-lab/adila)\n",
    "- [`vivaFemme` codebase](https://github.com/fani-lab/OpeNTF/tree/vivaFemme)\n",
    "- [Streaming Training Strategy codebase](https://github.com/fani-lab/OpeNTF/tree/ecir24)\n",
    "- [Tutorial Website and Materials](https://fani-lab.github.io/OpeNTF/tutorial/umap24/)\n",
    "    - [`OpeNTF` paper](https://doi.org/10.1145/3511808.3557526)\n",
    "    - [`Adila` paper](https://doi.org/10.1007/978-3-031-37249-0_9)\n",
    "    - [`vivaFemme` paper](https://hosseinfani.github.io/res/papers/2024_BIAS_SIGIR_vivaFemme_Mitigating_Gender_Bias_in_Neural_Team_Recommendation_via_Female-Advocate_Loss_Regularization.pdf)\n",
    "    - [Streaming Training Strategy paper](https://link.springer.com/chapter/10.1007/978-3-031-56027-9_20)\n",
    "\n",
    "<img src=\"./qr-code.png\" height=300px />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opentf_base",
   "language": "python",
   "name": "opentf_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
