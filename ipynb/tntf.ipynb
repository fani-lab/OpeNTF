{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fani-lab/OpeNTF/blob/main/ipynb/tntf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QGHFtvGnTLJ"
      },
      "source": [
        "<p align=\"center\"><img src='https://raw.githubusercontent.com/fani-lab/OpeNTF/refs/heads/main/docs/figs/temporal.jpg' width=\"500\" ></p>\n",
        "\n",
        "`OpeNTF` via `Temporal (Streaming)` Training Strategy\n",
        "\n",
        "Inspired by [`curriculum learning`](https://doi.org/10.1109/TPAMI.2021.3069908) and [`temporal latent space`](https://doi.org/10.1109/TKDE.2016.2591009) inference, we developed a temporal training strategy to consume time information as an aspect of experts' skills and collaboration ties in teams, as opposed to an extra numeric input feature, while being model-agnostic and with `no modification` to the models' architectures. In contrast to the `i.i.d` assumption (`bag of teams`) during model training on a shuffled dataset, we organize the teams based on time intervals (e.g., `yearly`) and train a neural model incrementally on streamed subsets of teams, as shown above. We randomly initialize a model's parameters at `t=0` and train the model on the subset of teams in the first time interval for a certain number of epochs. We then continue training on the subsequent time intervals, using the learned parameters from the previous time interval. This process is repeated until we complete the training on the subset of teams in the last time interval. Via temporal training, models capture the evolution of experts' skills and collaborative ties over time."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dE7D-VfK3Fla"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4tk12X-nTLK"
      },
      "source": [
        "**Temporal (Streaming) Team Recommendation [`[ECIR24]`](https://doi.org/10.1007/978-3-031-56027-9\\_20)**\n",
        "\n",
        "To run `OpeNTF` in temporal mode, the model instance should be set to `mdl.tntf.tNtf_{mdl.rnd.Rnd,mdl.fnn.Fnn,mdl.bnn.Bnn}` in [`src/__config__.yaml#L65`](https://github.com/fani-lab/OpeNTF/blob/main/src/__config__.yaml#L65) like:\n",
        "\n",
        "Random model: `\"models.instances=[mdl.tntf.tNtf_mdl.rnd.Rnd]\"`\n",
        "\n",
        "Non-variational feedforward model: `\"models.instances=[mdl.tntf.tNtf_mdl.fnn.Fnn]\"`\n",
        "\n",
        "Variational Bayesian model: `\"models.instances=[mdl.tntf.tNtf_mdl.bnn.Bnn]\"`\n",
        "\n",
        "All models: `\"models.instances=[mdl.tntf.tNtf_mdl.rnd.Rnd,mdl.tntf.tNtf_mdl.fnn.Fnn,mdl.tntf.tNtf_mdl.bnn.Bnn]\"`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "U3bXSGQC3Lic"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "0Uiz41tPnTLK"
      },
      "source": [
        "**Hyperparameters**\n",
        "\n",
        "`OpeNTF` leverage [`hydra`](https://hydra.cc/) to manage models hyperparameters in hierarchy:\n",
        "\n",
        "*   [`src/__config__.yaml`](https://github.com/fani-lab/OpeNTF/blob/main/src/__config__.yaml): `OpeNTF`'s main settings for the pipeline execution like `data.*`, `models.*`, `train.*`, `test.*`, `eval.*`\n",
        "    *   [`src/mdl/__config__.yaml`](https://github.com/fani-lab/OpeNTF/blob/main/src/mdl/__config__.yaml): models' training hyperparameters like `fnn.*`, `bnn.*`, `lr`, `batch_size`, ...\n",
        "\n",
        "To set these hyperparameters,\n",
        "\n",
        "- `Override` them in the running commands (recommended), or\n",
        "- Change the defaults in the `__config__.yaml` files\n",
        "\n",
        "\n",
        "> An imortant config for the temporal training is `train.step_ahead` that must be set in to order the training set ascending in time and split the last `step_ahead` number of time steps as the `test` and all the previous time intervals for the per-time-interval training sets:\n",
        "\n",
        "```\n",
        "python main.py  \"cmd=[prep,train,test,eval]\" \\\n",
        "                \"models.instances=[mdl.tntf.tNtf_mdl.fnn.Fnn,mdl.tntf.tNtf_mdl.bnn.Bnn]\" \\\n",
        "                train.step_ahead=1 \\\n",
        "                data.domain=cmn.publication.Publication \\\n",
        "                data.source=../data/dblp/toy.dblp.v12.json \\\n",
        "                data.output=../output/dblp/toy.dblp.v12.json \\\n",
        "                ~data.filter \\\n",
        "                +models.batch_size=2 \\\n",
        "                +models.nsd=unigram_b \\\n",
        "                \"+models.h=[128]\"\n",
        "```\n",
        "\n",
        "(see default settings for common models in [`src/mdl/__config__.yaml`](https://github.com/fani-lab/OpeNTF/blob/main/src/mdl/__config__.yaml))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rEqgd5eO95eD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwEN1xLDnTLK"
      },
      "source": [
        "**Setup & Quickstart**\n",
        "\n",
        "From the [`quickstart`](https://colab.research.google.com/github/fani-lab/OpeNTF/blob/main/ipynb/quickstart.ipynb) script:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mZln-_cnnTLM",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60138db9-4a94-490a-9fa7-eb8064014b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.92.23)] [Waiting for headers] [1 I\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:3 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.8 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://cli.github.com/packages stable/main amd64 Packages [356 B]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,648 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [61.5 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,640 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,292 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,881 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,486 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,604 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,971 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [86.7 kB]\n",
            "Fetched 30.3 MB in 6s (4,995 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  javascript-common libjs-sphinxdoc libjs-underscore libpython3.8-minimal\n",
            "  libpython3.8-stdlib python3-dev python3-pkg-resources python3-setuptools\n",
            "  python3-wheel python3.10-dev python3.8-lib2to3 python3.8-minimal\n",
            "Suggested packages:\n",
            "  apache2 | lighttpd | httpd python-setuptools-doc binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  javascript-common libjs-sphinxdoc libjs-underscore libpython3.8-minimal\n",
            "  libpython3.8-stdlib python3-dev python3-pip python3-setuptools python3-wheel\n",
            "  python3.10-dev python3.8 python3.8-distutils python3.8-lib2to3\n",
            "  python3.8-minimal python3.8-venv\n",
            "The following packages will be upgraded:\n",
            "  python3-pkg-resources\n",
            "1 upgraded, 15 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 10.8 MB of archives.\n",
            "After this operation, 33.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5,936 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.13 [508 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.7 [1,306 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-pkg-resources all 68.1.2-2~jammy3 [216 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-setuptools all 68.1.2-2~jammy3 [465 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.20-1+jammy1 [126 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.20-1+jammy1 [193 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-venv amd64 3.8.20-1+jammy1 [2,618 kB]\n",
            "Fetched 10.8 MB in 1s (7,932 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 16.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 117540 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../01-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../02-javascript-common_11+nmu1_all.deb ...\n",
            "Unpacking javascript-common (11+nmu1) ...\n",
            "Selecting previously unselected package libjs-underscore.\n",
            "Preparing to unpack .../03-libjs-underscore_1.13.2~dfsg-2_all.deb ...\n",
            "Unpacking libjs-underscore (1.13.2~dfsg-2) ...\n",
            "Selecting previously unselected package libjs-sphinxdoc.\n",
            "Preparing to unpack .../04-libjs-sphinxdoc_4.3.2-1_all.deb ...\n",
            "Unpacking libjs-sphinxdoc (4.3.2-1) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../05-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.10-dev.\n",
            "Preparing to unpack .../06-python3.10-dev_3.10.12-1~22.04.13_amd64.deb ...\n",
            "Unpacking python3.10-dev (3.10.12-1~22.04.13) ...\n",
            "Selecting previously unselected package python3-dev.\n",
            "Preparing to unpack .../07-python3-dev_3.10.6-1~22.04.1_amd64.deb ...\n",
            "Unpacking python3-dev (3.10.6-1~22.04.1) ...\n",
            "Preparing to unpack .../08-python3-pkg-resources_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-pkg-resources (68.1.2-2~jammy3) over (59.6.0-1.2ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../09-python3-setuptools_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-setuptools (68.1.2-2~jammy3) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../10-python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../11-python3-pip_22.0.2+dfsg-1ubuntu0.7_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../12-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "Preparing to unpack .../13-python3.8-lib2to3_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../14-python3.8-distutils_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-venv.\n",
            "Preparing to unpack .../15-python3.8-venv_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Setting up python3-pkg-resources (68.1.2-2~jammy3) ...\n",
            "Setting up javascript-common (11+nmu1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3-setuptools (68.1.2-2~jammy3) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Setting up python3.10-dev (3.10.12-1~22.04.13) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Setting up libjs-underscore (1.13.2~dfsg-2) ...\n",
            "Setting up python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Setting up libjs-sphinxdoc (4.3.2-1) ...\n",
            "Setting up python3-dev (3.10.6-1~22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.8.20\n"
          ]
        }
      ],
      "source": [
        "# set up python 3.8\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y python3.8 python3.8-venv python3.8-distutils python3-pip\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 10\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get OpeNTF\n",
        "!rm -R opentf/\n",
        "!git clone https://github.com/Fani-Lab/opentf\n",
        "!pip install --upgrade pip setuptools\n",
        "!pip install -r opentf/requirements.txt"
      ],
      "metadata": {
        "id": "95eDgj3AAInL",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "366575be-7fa0-4d19-dbcc-d21b480664e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'opentf/': No such file or directory\n",
            "Cloning into 'opentf'...\n",
            "remote: Enumerating objects: 27098, done.\u001b[K\n",
            "remote: Counting objects: 100% (273/273), done.\u001b[K\n",
            "remote: Compressing objects: 100% (208/208), done.\u001b[K\n",
            "remote: Total 27098 (delta 121), reused 157 (delta 64), pack-reused 26825 (from 3)\u001b[K\n",
            "Receiving objects: 100% (27098/27098), 1.32 GiB | 24.85 MiB/s, done.\n",
            "Resolving deltas: 100% (13393/13393), done.\n",
            "Updating files: 100% (4379/4379), done.\n",
            "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (68.1.2)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-75.3.3-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 68.1.2\n",
            "    Not uninstalling setuptools at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'setuptools'. No files were found to uninstall.\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.2\n",
            "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'pip'. No files were found to uninstall.\n",
            "Successfully installed pip-25.0.1 setuptools-75.3.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "bb8f20f4dbe14f309d7a6bb47f4cb645"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hydra-core==1.3.2 (from -r opentf/requirements.txt (line 3))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting scipy==1.10.1 (from -r opentf/requirements.txt (line 4))\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Collecting numpy==1.24.4 (from -r opentf/requirements.txt (line 5))\n",
            "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting importlib-resources (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting PyYAML>=5.1.0 (from omegaconf<2.4,>=2.2->hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading PyYAML-6.0.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting zipp>=3.1.0 (from importlib-resources->hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m150.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Downloading packaging-26.0-py3-none-any.whl (74 kB)\n",
            "Downloading PyYAML-6.0.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.0/806.0 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144553 sha256=aceffbdf4ca2ac8938f274ecd60f3043a6223014ee72d6dcd2d8d0b6fce752c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, zipp, PyYAML, packaging, numpy, scipy, omegaconf, importlib-resources, hydra-core\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 1.0.0\n",
            "    Uninstalling zipp-1.0.0:\n",
            "      Successfully uninstalled zipp-1.0.0\n",
            "Successfully installed PyYAML-6.0.3 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 importlib-resources-6.4.5 numpy-1.24.4 omegaconf-2.3.0 packaging-26.0 scipy-1.10.1 zipp-3.20.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging",
                  "pydevd_plugins"
                ]
              },
              "id": "2b8e12a87ccb475f8459df5a59751391"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd opentf/src/\n",
        "!python main.py \"cmd=[prep,train,test,eval]\" \"models.instances=[mdl.tntf.tNtf_mdl.bnn.Bnn]\" train.step_ahead=1 data.domain=cmn.publication.Publication data.source=../data/dblp/toy.dblp.v12.json data.output=../output/dblp/toy.dblp.v12.json ~data.filter +models.batch_size=2 +models.nsd=unigram_b \"+models.h=[128]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDdbvZnWATUw",
        "outputId": "34840d01-9579-4c32-c2f1-91039ddf7e49",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/opentf/src\n",
            "[2026-01-24 05:46:54,280][cmn.team][INFO] - Loading teamsvecs matrices from ../output/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "[2026-01-24 05:46:54,281][pkgmgr][INFO] - tqdm not found.\n",
            "[2026-01-24 05:46:54,281][pkgmgr][INFO] - Installing tqdm...\n",
            "[2026-01-24 05:46:55,482][pkgmgr][INFO] - Collecting tqdm==4.65.0\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
            "Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.65.0\n",
            "\n",
            "[2026-01-24 05:46:55,487][cmn.team][INFO] - Loading indexes pickle from ../output/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "[2026-01-24 05:46:55,487][cmn.team][INFO] - Indexes pickle is loaded.\n",
            "[2026-01-24 05:46:55,487][cmn.team][INFO] - Teamsvecs matrices and indexes for skills (31, 10), members (31, 13), and locations (31, 29) are loaded.\n",
            "[2026-01-24 05:46:55,488][__main__][INFO] - Loading splits from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1.pkl ...\n",
            "[2026-01-24 05:46:55,488][pkgmgr][INFO] - sklearn.model_selection not found.\n",
            "[2026-01-24 05:46:55,488][pkgmgr][INFO] - Installing scikit-learn...\n",
            "[2026-01-24 05:47:00,562][pkgmgr][INFO] - Collecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (1.10.1)\n",
            "Collecting joblib>=1.1.1 (from scikit-learn==1.2.2)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn==1.2.2)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.8/9.8 MB 60.1 MB/s eta 0:00:00\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
            "Successfully installed joblib-1.4.2 scikit-learn-1.2.2 threadpoolctl-3.5.0\n",
            "\n",
            "[2026-01-24 05:47:01,154][__main__][INFO] - Splits file not found! Generating ...\n",
            "[2026-01-24 05:47:01,156][cmn.team][INFO] - Loading member-skill co-occurrence matrix (13, 10) from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/skillcoverage.pkl ...\n",
            "[2026-01-24 05:47:01,156][cmn.team][INFO] - Member-skill co-occurrence matrix not found! Generating ...\n",
            "[2026-01-24 05:47:01,159][cmn.team][INFO] - Member-skill co-occurrence matrix (13, 10) saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/skillcoverage.pkl.\n",
            "[2026-01-24 05:47:01,223][pkgmgr][INFO] - torch not found.\n",
            "[2026-01-24 05:47:01,223][pkgmgr][INFO] - Installing torch...\n",
            "[2026-01-24 05:49:35,835][pkgmgr][INFO] - Collecting torch==2.4.1\n",
            "  Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting filelock (from torch==2.4.1)\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch==2.4.1)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch==2.4.1)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.4.1)\n",
            "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting jinja2 (from torch==2.4.1)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.4.1)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.1)\n",
            "  Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.4.1) (2.0.1)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.1)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 797.1/797.1 MB 36.3 MB/s eta 0:00:00\n",
            "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 55.5 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 99.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 139.4 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 32.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 16.3 MB/s eta 0:00:00\n",
            "Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 60.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 60.1 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 60.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 67.1 MB/s eta 0:00:00\n",
            "Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.2/176.2 MB 64.3 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.4/209.4 MB 59.5 MB/s eta 0:00:00\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 53.6 MB/s eta 0:00:00\n",
            "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 119.6 MB/s eta 0:00:00\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 20.3 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.7/39.7 MB 45.8 MB/s eta 0:00:00\n",
            "Installing collected packages: mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, jinja2, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "Successfully installed filelock-3.16.1 fsspec-2025.3.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.1 triton-3.0.0 typing-extensions-4.13.2\n",
            "\n",
            "[2026-01-24 05:49:38,818][pkgmgr][INFO] - tensorboardX not found.\n",
            "[2026-01-24 05:49:38,819][pkgmgr][INFO] - Installing tensorboardX...\n",
            "[2026-01-24 05:49:49,759][pkgmgr][INFO] - Collecting tensorboardX==2.6.2.2\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting tensorboard==2.14.0\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting protobuf==3.20\n",
            "  Downloading protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (698 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX==2.6.2.2) (1.24.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX==2.6.2.2) (26.0)\n",
            "Collecting absl-py>=0.4 (from tensorboard==2.14.0)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard==2.14.0)\n",
            "  Downloading grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard==2.14.0)\n",
            "  Downloading google_auth-2.47.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard==2.14.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard==2.14.0) (3.3.6)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard==2.14.0)\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.14.0) (75.3.3)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard==2.14.0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard==2.14.0)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard==2.14.0) (0.37.1)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard==2.14.0)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard==2.14.0)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard==2.14.0)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/lib/python3/dist-packages (from markdown>=2.6.8->tensorboard==2.14.0) (4.6.4)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard==2.14.0)\n",
            "  Downloading charset_normalizer-3.4.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard==2.14.0)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard==2.14.0)\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard==2.14.0)\n",
            "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard==2.14.0)\n",
            "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.14.0)\n",
            "  Downloading pyasn1-0.6.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard==2.14.0) (3.2.0)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 77.6 MB/s eta 0:00:00\n",
            "Downloading protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 46.6 MB/s eta 0:00:00\n",
            "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Downloading google_auth-2.47.0-py3-none-any.whl (234 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 92.4 MB/s eta 0:00:00\n",
            "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 132.6 MB/s eta 0:00:00\n",
            "Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (147 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Downloading pyasn1-0.6.2-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: urllib3, tensorboard-data-server, pyasn1, protobuf, MarkupSafe, idna, grpcio, charset_normalizer, certifi, absl-py, werkzeug, tensorboardX, rsa, requests, pyasn1-modules, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "Successfully installed MarkupSafe-2.1.5 absl-py-2.3.1 certifi-2026.1.4 charset_normalizer-3.4.4 google-auth-2.47.0 google-auth-oauthlib-1.0.0 grpcio-1.70.0 idna-3.11 protobuf-3.20.0 pyasn1-0.6.2 pyasn1-modules-0.4.2 requests-2.32.4 requests-oauthlib-2.0.0 rsa-4.9.1 tensorboard-2.14.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 urllib3-2.2.3 werkzeug-3.0.6\n",
            "\n",
            "[2026-01-24 05:49:49,795][pkgmgr][INFO] - bayesian_torch.models.dnn_to_bnn not found.\n",
            "[2026-01-24 05:49:49,795][pkgmgr][INFO] - Installing bayesian-torch...\n",
            "[2026-01-24 05:49:53,569][pkgmgr][INFO] - Collecting bayesian-torch==0.5.0\n",
            "  Downloading bayesian_torch-0.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-torch==0.5.0) (2.4.1)\n",
            "Collecting torchvision>=0.8.1 (from bayesian-torch==0.5.0)\n",
            "  Downloading torchvision-0.19.1-cp38-cp38-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: tensorboard>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-torch==0.5.0) (2.14.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.8/dist-packages (from bayesian-torch==0.5.0) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.3->bayesian-torch==0.5.0) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.3->bayesian-torch==0.5.0) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.3->bayesian-torch==0.5.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.3->bayesian-torch==0.5.0) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->bayesian-torch==0.5.0) (2.3.1)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->bayesian-torch==0.5.0) (1.70.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->bayesian-torch==0.5.0) (2.47.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->bayesian-torch==0.5.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard>=1.15.0->bayesian-torch==0.5.0) (3.3.6)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->bayesian-torch==0.5.0) (3.20.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->bayesian-torch==0.5.0) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->bayesian-torch==0.5.0) (75.3.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->bayesian-torch==0.5.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=1.15.0->bayesian-torch==0.5.0) (3.0.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard>=1.15.0->bayesian-torch==0.5.0) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->bayesian-torch==0.5.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->bayesian-torch==0.5.0) (12.9.86)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision>=0.8.1->bayesian-torch==0.5.0)\n",
            "  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->bayesian-torch==0.5.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->bayesian-torch==0.5.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15.0->bayesian-torch==0.5.0) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/lib/python3/dist-packages (from markdown>=2.6.8->tensorboard>=1.15.0->bayesian-torch==0.5.0) (4.6.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->bayesian-torch==0.5.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->bayesian-torch==0.5.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->bayesian-torch==0.5.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15.0->bayesian-torch==0.5.0) (2026.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.15.0->bayesian-torch==0.5.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.7.0->bayesian-torch==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15.0->bayesian-torch==0.5.0) (0.6.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=1.15.0->bayesian-torch==0.5.0) (3.2.0)\n",
            "Downloading bayesian_torch-0.5.0-py3-none-any.whl (78 kB)\n",
            "Downloading torchvision-0.19.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 84.9 MB/s eta 0:00:00\n",
            "Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 126.5 MB/s eta 0:00:00\n",
            "Installing collected packages: pillow, torchvision, bayesian-torch\n",
            "Successfully installed bayesian-torch-0.5.0 pillow-10.4.0 torchvision-0.19.1\n",
            "\n",
            "[2026-01-24 05:49:53,620][__main__][INFO] - \u001b[94mTraining team recommender instance mdl.tntf.tNtf_mdl.bnn.Bnn ... \u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/content/opentf/src/mdl/fnn.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.unigram = Ntf.torch.tensor(y.sum(axis=0) / y.shape[0]).to(self.device)  # frequency of each expert in a batch\n",
            "[2026-01-24 05:49:55,584][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[94mTrain Loss: 54.4794\u001b[0m\n",
            "[2026-01-24 05:49:55,585][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[95mValid Loss: 59.2642\u001b[0m\n",
            "[2026-01-24 05:49:55,590][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2000/f0.e0.pt\n",
            "[2026-01-24 05:49:55,590][mdl.fnn][INFO] - Validation loss decreased (inf --> 59.264206)\n",
            "[2026-01-24 05:49:55,600][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[94mTrain Loss: 53.6724\u001b[0m\n",
            "[2026-01-24 05:49:55,601][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[95mValid Loss: 60.7857\u001b[0m\n",
            "[2026-01-24 05:49:55,602][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:55,611][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[94mTrain Loss: 52.7594\u001b[0m\n",
            "[2026-01-24 05:49:55,612][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[95mValid Loss: 56.1767\u001b[0m\n",
            "[2026-01-24 05:49:55,613][mdl.fnn][INFO] - Validation loss decreased (59.264206 --> 56.176743)\n",
            "[2026-01-24 05:49:55,622][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[94mTrain Loss: 54.6751\u001b[0m\n",
            "[2026-01-24 05:49:55,623][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[95mValid Loss: 59.5385\u001b[0m\n",
            "[2026-01-24 05:49:55,624][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:55,633][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[94mTrain Loss: 50.7194\u001b[0m\n",
            "[2026-01-24 05:49:55,634][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[95mValid Loss: 63.6673\u001b[0m\n",
            "[2026-01-24 05:49:55,634][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:55,644][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[94mTrain Loss: 51.2416\u001b[0m\n",
            "[2026-01-24 05:49:55,645][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[95mValid Loss: 56.6122\u001b[0m\n",
            "[2026-01-24 05:49:55,645][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:55,654][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[94mTrain Loss: 50.7418\u001b[0m\n",
            "[2026-01-24 05:49:55,655][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[95mValid Loss: 55.6860\u001b[0m\n",
            "[2026-01-24 05:49:55,656][mdl.fnn][INFO] - Validation loss decreased (56.176743 --> 55.685959)\n",
            "[2026-01-24 05:49:55,665][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[94mTrain Loss: 52.6133\u001b[0m\n",
            "[2026-01-24 05:49:55,665][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[95mValid Loss: 59.6629\u001b[0m\n",
            "[2026-01-24 05:49:55,666][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:55,676][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[94mTrain Loss: 53.1480\u001b[0m\n",
            "[2026-01-24 05:49:55,676][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[95mValid Loss: 60.0736\u001b[0m\n",
            "[2026-01-24 05:49:55,677][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:55,686][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[94mTrain Loss: 49.6738\u001b[0m\n",
            "[2026-01-24 05:49:55,687][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[95mValid Loss: 59.7574\u001b[0m\n",
            "[2026-01-24 05:49:55,692][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2000/f0.e9.pt\n",
            "[2026-01-24 05:49:55,692][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:55,702][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[94mTrain Loss: 54.2263\u001b[0m\n",
            "[2026-01-24 05:49:55,703][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[95mValid Loss: 63.0826\u001b[0m\n",
            "[2026-01-24 05:49:55,703][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:55,714][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[94mTrain Loss: 58.1332\u001b[0m\n",
            "[2026-01-24 05:49:55,714][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[95mValid Loss: 56.0082\u001b[0m\n",
            "[2026-01-24 05:49:55,715][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:55,715][mdl.fnn][INFO] - Early stopping triggered at epoch: 11\n",
            "[2026-01-24 05:49:55,719][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2000/f0.pt\n",
            "[2026-01-24 05:49:55,737][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[94mTrain Loss: 62.0537\u001b[0m\n",
            "[2026-01-24 05:49:55,737][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[95mValid Loss: 57.4051\u001b[0m\n",
            "[2026-01-24 05:49:55,742][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2000/f1.e0.pt\n",
            "[2026-01-24 05:49:55,742][mdl.fnn][INFO] - Validation loss decreased (inf --> 57.405083)\n",
            "[2026-01-24 05:49:55,757][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[94mTrain Loss: 55.5211\u001b[0m\n",
            "[2026-01-24 05:49:55,758][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[95mValid Loss: 58.6126\u001b[0m\n",
            "[2026-01-24 05:49:55,758][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:55,772][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[94mTrain Loss: 58.3310\u001b[0m\n",
            "[2026-01-24 05:49:55,773][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[95mValid Loss: 52.0530\u001b[0m\n",
            "[2026-01-24 05:49:55,774][mdl.fnn][INFO] - Validation loss decreased (57.405083 --> 52.053032)\n",
            "[2026-01-24 05:49:55,792][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[94mTrain Loss: 62.8586\u001b[0m\n",
            "[2026-01-24 05:49:55,792][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[95mValid Loss: 64.9364\u001b[0m\n",
            "[2026-01-24 05:49:55,793][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:55,809][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[94mTrain Loss: 57.8758\u001b[0m\n",
            "[2026-01-24 05:49:55,809][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[95mValid Loss: 51.2774\u001b[0m\n",
            "[2026-01-24 05:49:55,810][mdl.fnn][INFO] - Validation loss decreased (52.053032 --> 51.277367)\n",
            "[2026-01-24 05:49:55,827][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[94mTrain Loss: 56.4065\u001b[0m\n",
            "[2026-01-24 05:49:55,828][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[95mValid Loss: 57.4318\u001b[0m\n",
            "[2026-01-24 05:49:55,829][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:55,842][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[94mTrain Loss: 59.9988\u001b[0m\n",
            "[2026-01-24 05:49:55,843][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[95mValid Loss: 57.8416\u001b[0m\n",
            "[2026-01-24 05:49:55,844][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:55,857][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[94mTrain Loss: 59.3690\u001b[0m\n",
            "[2026-01-24 05:49:55,857][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[95mValid Loss: 63.3138\u001b[0m\n",
            "[2026-01-24 05:49:55,858][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:55,873][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[94mTrain Loss: 59.5311\u001b[0m\n",
            "[2026-01-24 05:49:55,873][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[95mValid Loss: 50.4173\u001b[0m\n",
            "[2026-01-24 05:49:55,873][mdl.fnn][INFO] - Validation loss decreased (51.277367 --> 50.417274)\n",
            "[2026-01-24 05:49:55,898][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[94mTrain Loss: 57.7604\u001b[0m\n",
            "[2026-01-24 05:49:55,899][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[95mValid Loss: 64.1724\u001b[0m\n",
            "[2026-01-24 05:49:55,906][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2000/f1.e9.pt\n",
            "[2026-01-24 05:49:55,906][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:55,929][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[94mTrain Loss: 57.0342\u001b[0m\n",
            "[2026-01-24 05:49:55,929][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[95mValid Loss: 62.8428\u001b[0m\n",
            "[2026-01-24 05:49:55,930][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:55,951][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[94mTrain Loss: 61.2724\u001b[0m\n",
            "[2026-01-24 05:49:55,951][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[95mValid Loss: 56.6995\u001b[0m\n",
            "[2026-01-24 05:49:55,951][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:55,975][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[94mTrain Loss: 57.4952\u001b[0m\n",
            "[2026-01-24 05:49:55,975][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[95mValid Loss: 57.9955\u001b[0m\n",
            "[2026-01-24 05:49:55,975][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:55,997][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[94mTrain Loss: 58.2751\u001b[0m\n",
            "[2026-01-24 05:49:55,998][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[95mValid Loss: 50.7844\u001b[0m\n",
            "[2026-01-24 05:49:55,999][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:55,999][mdl.fnn][INFO] - Early stopping triggered at epoch: 13\n",
            "[2026-01-24 05:49:56,007][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2000/f1.pt\n",
            "[2026-01-24 05:49:56,041][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[94mTrain Loss: 61.1478\u001b[0m\n",
            "[2026-01-24 05:49:56,041][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[95mValid Loss: 57.5092\u001b[0m\n",
            "[2026-01-24 05:49:56,051][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2000/f2.e0.pt\n",
            "[2026-01-24 05:49:56,051][mdl.fnn][INFO] - Validation loss decreased (inf --> 57.509155)\n",
            "[2026-01-24 05:49:56,076][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[94mTrain Loss: 58.7330\u001b[0m\n",
            "[2026-01-24 05:49:56,076][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[95mValid Loss: 65.5822\u001b[0m\n",
            "[2026-01-24 05:49:56,076][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:56,098][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[94mTrain Loss: 58.3715\u001b[0m\n",
            "[2026-01-24 05:49:56,099][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[95mValid Loss: 62.2105\u001b[0m\n",
            "[2026-01-24 05:49:56,099][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:56,123][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[94mTrain Loss: 60.6020\u001b[0m\n",
            "[2026-01-24 05:49:56,123][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[95mValid Loss: 63.0672\u001b[0m\n",
            "[2026-01-24 05:49:56,124][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:56,150][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[94mTrain Loss: 60.4984\u001b[0m\n",
            "[2026-01-24 05:49:56,151][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[95mValid Loss: 56.3865\u001b[0m\n",
            "[2026-01-24 05:49:56,151][mdl.fnn][INFO] - Validation loss decreased (57.509155 --> 56.386528)\n",
            "[2026-01-24 05:49:56,180][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[94mTrain Loss: 61.1029\u001b[0m\n",
            "[2026-01-24 05:49:56,181][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[95mValid Loss: 55.4876\u001b[0m\n",
            "[2026-01-24 05:49:56,182][mdl.fnn][INFO] - Validation loss decreased (56.386528 --> 55.487602)\n",
            "[2026-01-24 05:49:56,226][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[94mTrain Loss: 56.7952\u001b[0m\n",
            "[2026-01-24 05:49:56,227][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[95mValid Loss: 56.2222\u001b[0m\n",
            "[2026-01-24 05:49:56,228][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:56,254][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[94mTrain Loss: 60.8175\u001b[0m\n",
            "[2026-01-24 05:49:56,255][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[95mValid Loss: 50.0527\u001b[0m\n",
            "[2026-01-24 05:49:56,255][mdl.fnn][INFO] - Validation loss decreased (55.487602 --> 50.052685)\n",
            "[2026-01-24 05:49:56,282][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[94mTrain Loss: 59.7908\u001b[0m\n",
            "[2026-01-24 05:49:56,283][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[95mValid Loss: 57.2066\u001b[0m\n",
            "[2026-01-24 05:49:56,283][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:56,309][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[94mTrain Loss: 63.1876\u001b[0m\n",
            "[2026-01-24 05:49:56,311][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[95mValid Loss: 57.0416\u001b[0m\n",
            "[2026-01-24 05:49:56,316][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2000/f2.e9.pt\n",
            "[2026-01-24 05:49:56,316][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:56,347][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[94mTrain Loss: 58.0479\u001b[0m\n",
            "[2026-01-24 05:49:56,348][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[95mValid Loss: 55.2952\u001b[0m\n",
            "[2026-01-24 05:49:56,348][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:56,366][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[94mTrain Loss: 55.5742\u001b[0m\n",
            "[2026-01-24 05:49:56,367][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[95mValid Loss: 57.3061\u001b[0m\n",
            "[2026-01-24 05:49:56,367][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:56,385][mdl.fnn][INFO] - Fold 2/2, Epoch 12, \u001b[94mTrain Loss: 61.2058\u001b[0m\n",
            "[2026-01-24 05:49:56,386][mdl.fnn][INFO] - Fold 2/2, Epoch 12, \u001b[95mValid Loss: 48.1152\u001b[0m\n",
            "[2026-01-24 05:49:56,386][mdl.fnn][INFO] - Validation loss decreased (50.052685 --> 48.115242)\n",
            "[2026-01-24 05:49:56,404][mdl.fnn][INFO] - Fold 2/2, Epoch 13, \u001b[94mTrain Loss: 59.3760\u001b[0m\n",
            "[2026-01-24 05:49:56,404][mdl.fnn][INFO] - Fold 2/2, Epoch 13, \u001b[95mValid Loss: 61.8210\u001b[0m\n",
            "[2026-01-24 05:49:56,405][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:56,427][mdl.fnn][INFO] - Fold 2/2, Epoch 14, \u001b[94mTrain Loss: 61.3006\u001b[0m\n",
            "[2026-01-24 05:49:56,428][mdl.fnn][INFO] - Fold 2/2, Epoch 14, \u001b[95mValid Loss: 63.6618\u001b[0m\n",
            "[2026-01-24 05:49:56,428][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:56,446][mdl.fnn][INFO] - Fold 2/2, Epoch 15, \u001b[94mTrain Loss: 63.4867\u001b[0m\n",
            "[2026-01-24 05:49:56,447][mdl.fnn][INFO] - Fold 2/2, Epoch 15, \u001b[95mValid Loss: 55.6078\u001b[0m\n",
            "[2026-01-24 05:49:56,447][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:56,465][mdl.fnn][INFO] - Fold 2/2, Epoch 16, \u001b[94mTrain Loss: 59.3370\u001b[0m\n",
            "[2026-01-24 05:49:56,466][mdl.fnn][INFO] - Fold 2/2, Epoch 16, \u001b[95mValid Loss: 56.4497\u001b[0m\n",
            "[2026-01-24 05:49:56,466][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:56,484][mdl.fnn][INFO] - Fold 2/2, Epoch 17, \u001b[94mTrain Loss: 59.0908\u001b[0m\n",
            "[2026-01-24 05:49:56,484][mdl.fnn][INFO] - Fold 2/2, Epoch 17, \u001b[95mValid Loss: 56.1835\u001b[0m\n",
            "[2026-01-24 05:49:56,485][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:56,485][mdl.fnn][INFO] - Early stopping triggered at epoch: 17\n",
            "[2026-01-24 05:49:56,493][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2000/f2.pt\n",
            "/content/opentf/src/mdl/fnn.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if prev_model: self.model.load_state_dict(Ntf.torch.load(prev_model[foldidx], map_location=self.device)['model_state_dict'])\n",
            "[2026-01-24 05:49:56,525][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[94mTrain Loss: 60.8718\u001b[0m\n",
            "[2026-01-24 05:49:56,525][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[95mValid Loss: 62.9044\u001b[0m\n",
            "[2026-01-24 05:49:56,532][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2001/f0.e0.pt\n",
            "[2026-01-24 05:49:56,532][mdl.fnn][INFO] - Validation loss decreased (inf --> 62.904366)\n",
            "[2026-01-24 05:49:56,551][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[94mTrain Loss: 59.5204\u001b[0m\n",
            "[2026-01-24 05:49:56,551][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[95mValid Loss: 60.3424\u001b[0m\n",
            "[2026-01-24 05:49:56,552][mdl.fnn][INFO] - Validation loss decreased (62.904366 --> 60.342445)\n",
            "[2026-01-24 05:49:56,570][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[94mTrain Loss: 57.6107\u001b[0m\n",
            "[2026-01-24 05:49:56,570][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[95mValid Loss: 60.9475\u001b[0m\n",
            "[2026-01-24 05:49:56,571][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:56,589][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[94mTrain Loss: 61.4499\u001b[0m\n",
            "[2026-01-24 05:49:56,590][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[95mValid Loss: 62.9795\u001b[0m\n",
            "[2026-01-24 05:49:56,590][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:56,609][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[94mTrain Loss: 57.2858\u001b[0m\n",
            "[2026-01-24 05:49:56,609][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[95mValid Loss: 60.9298\u001b[0m\n",
            "[2026-01-24 05:49:56,610][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:56,633][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[94mTrain Loss: 56.8257\u001b[0m\n",
            "[2026-01-24 05:49:56,633][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[95mValid Loss: 62.1533\u001b[0m\n",
            "[2026-01-24 05:49:56,633][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:56,653][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[94mTrain Loss: 53.4013\u001b[0m\n",
            "[2026-01-24 05:49:56,653][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[95mValid Loss: 61.4798\u001b[0m\n",
            "[2026-01-24 05:49:56,653][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:56,654][mdl.fnn][INFO] - Early stopping triggered at epoch: 6\n",
            "[2026-01-24 05:49:56,660][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2001/f0.pt\n",
            "[2026-01-24 05:49:56,686][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[94mTrain Loss: 58.4143\u001b[0m\n",
            "[2026-01-24 05:49:56,686][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[95mValid Loss: 58.3845\u001b[0m\n",
            "[2026-01-24 05:49:56,693][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2001/f1.e0.pt\n",
            "[2026-01-24 05:49:56,693][mdl.fnn][INFO] - Validation loss decreased (inf --> 58.384468)\n",
            "[2026-01-24 05:49:56,712][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[94mTrain Loss: 63.0638\u001b[0m\n",
            "[2026-01-24 05:49:56,712][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[95mValid Loss: 58.2624\u001b[0m\n",
            "[2026-01-24 05:49:56,713][mdl.fnn][INFO] - Validation loss decreased (58.384468 --> 58.262444)\n",
            "[2026-01-24 05:49:56,732][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[94mTrain Loss: 61.2663\u001b[0m\n",
            "[2026-01-24 05:49:56,734][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[95mValid Loss: 58.6298\u001b[0m\n",
            "[2026-01-24 05:49:56,734][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:56,752][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[94mTrain Loss: 57.2121\u001b[0m\n",
            "[2026-01-24 05:49:56,752][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[95mValid Loss: 58.1492\u001b[0m\n",
            "[2026-01-24 05:49:56,753][mdl.fnn][INFO] - Validation loss decreased (58.262444 --> 58.149158)\n",
            "[2026-01-24 05:49:56,770][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[94mTrain Loss: 52.6154\u001b[0m\n",
            "[2026-01-24 05:49:56,771][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[95mValid Loss: 57.7400\u001b[0m\n",
            "[2026-01-24 05:49:56,771][mdl.fnn][INFO] - Validation loss decreased (58.149158 --> 57.739964)\n",
            "[2026-01-24 05:49:56,788][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[94mTrain Loss: 59.4284\u001b[0m\n",
            "[2026-01-24 05:49:56,789][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[95mValid Loss: 58.4465\u001b[0m\n",
            "[2026-01-24 05:49:56,789][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:56,809][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[94mTrain Loss: 59.1708\u001b[0m\n",
            "[2026-01-24 05:49:56,809][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[95mValid Loss: 57.8013\u001b[0m\n",
            "[2026-01-24 05:49:56,809][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:56,828][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[94mTrain Loss: 58.7676\u001b[0m\n",
            "[2026-01-24 05:49:56,828][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[95mValid Loss: 57.5218\u001b[0m\n",
            "[2026-01-24 05:49:56,829][mdl.fnn][INFO] - Validation loss decreased (57.739964 --> 57.521782)\n",
            "[2026-01-24 05:49:56,847][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[94mTrain Loss: 55.0348\u001b[0m\n",
            "[2026-01-24 05:49:56,848][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[95mValid Loss: 57.8588\u001b[0m\n",
            "[2026-01-24 05:49:56,848][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:56,866][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[94mTrain Loss: 57.1157\u001b[0m\n",
            "[2026-01-24 05:49:56,866][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[95mValid Loss: 57.3301\u001b[0m\n",
            "[2026-01-24 05:49:56,873][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2001/f1.e9.pt\n",
            "[2026-01-24 05:49:56,874][mdl.fnn][INFO] - Validation loss decreased (57.521782 --> 57.330112)\n",
            "[2026-01-24 05:49:56,892][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[94mTrain Loss: 60.0301\u001b[0m\n",
            "[2026-01-24 05:49:56,893][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[95mValid Loss: 57.4833\u001b[0m\n",
            "[2026-01-24 05:49:56,893][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:56,912][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[94mTrain Loss: 55.4480\u001b[0m\n",
            "[2026-01-24 05:49:56,912][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[95mValid Loss: 57.7914\u001b[0m\n",
            "[2026-01-24 05:49:56,913][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:56,937][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[94mTrain Loss: 60.6557\u001b[0m\n",
            "[2026-01-24 05:49:56,937][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[95mValid Loss: 57.0818\u001b[0m\n",
            "[2026-01-24 05:49:56,938][mdl.fnn][INFO] - Validation loss decreased (57.330112 --> 57.081825)\n",
            "[2026-01-24 05:49:56,963][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[94mTrain Loss: 55.3886\u001b[0m\n",
            "[2026-01-24 05:49:56,964][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[95mValid Loss: 56.7925\u001b[0m\n",
            "[2026-01-24 05:49:56,964][mdl.fnn][INFO] - Validation loss decreased (57.081825 --> 56.792480)\n",
            "[2026-01-24 05:49:56,983][mdl.fnn][INFO] - Fold 1/2, Epoch 14, \u001b[94mTrain Loss: 60.0009\u001b[0m\n",
            "[2026-01-24 05:49:56,984][mdl.fnn][INFO] - Fold 1/2, Epoch 14, \u001b[95mValid Loss: 57.6880\u001b[0m\n",
            "[2026-01-24 05:49:56,984][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:57,002][mdl.fnn][INFO] - Fold 1/2, Epoch 15, \u001b[94mTrain Loss: 61.3877\u001b[0m\n",
            "[2026-01-24 05:49:57,002][mdl.fnn][INFO] - Fold 1/2, Epoch 15, \u001b[95mValid Loss: 57.7159\u001b[0m\n",
            "[2026-01-24 05:49:57,003][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:57,021][mdl.fnn][INFO] - Fold 1/2, Epoch 16, \u001b[94mTrain Loss: 56.8944\u001b[0m\n",
            "[2026-01-24 05:49:57,022][mdl.fnn][INFO] - Fold 1/2, Epoch 16, \u001b[95mValid Loss: 57.3261\u001b[0m\n",
            "[2026-01-24 05:49:57,022][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:57,041][mdl.fnn][INFO] - Fold 1/2, Epoch 17, \u001b[94mTrain Loss: 62.4812\u001b[0m\n",
            "[2026-01-24 05:49:57,042][mdl.fnn][INFO] - Fold 1/2, Epoch 17, \u001b[95mValid Loss: 57.7491\u001b[0m\n",
            "[2026-01-24 05:49:57,042][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:57,065][mdl.fnn][INFO] - Fold 1/2, Epoch 18, \u001b[94mTrain Loss: 63.6813\u001b[0m\n",
            "[2026-01-24 05:49:57,065][mdl.fnn][INFO] - Fold 1/2, Epoch 18, \u001b[95mValid Loss: 58.3819\u001b[0m\n",
            "[2026-01-24 05:49:57,065][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:57,066][mdl.fnn][INFO] - Early stopping triggered at epoch: 18\n",
            "[2026-01-24 05:49:57,072][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2001/f1.pt\n",
            "[2026-01-24 05:49:57,104][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[94mTrain Loss: 60.7989\u001b[0m\n",
            "[2026-01-24 05:49:57,104][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[95mValid Loss: 56.6611\u001b[0m\n",
            "[2026-01-24 05:49:57,111][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2001/f2.e0.pt\n",
            "[2026-01-24 05:49:57,111][mdl.fnn][INFO] - Validation loss decreased (inf --> 56.661060)\n",
            "[2026-01-24 05:49:57,139][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[94mTrain Loss: 59.9046\u001b[0m\n",
            "[2026-01-24 05:49:57,139][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[95mValid Loss: 50.2835\u001b[0m\n",
            "[2026-01-24 05:49:57,140][mdl.fnn][INFO] - Validation loss decreased (56.661060 --> 50.283504)\n",
            "[2026-01-24 05:49:57,163][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[94mTrain Loss: 57.3034\u001b[0m\n",
            "[2026-01-24 05:49:57,164][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[95mValid Loss: 62.7363\u001b[0m\n",
            "[2026-01-24 05:49:57,164][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:57,188][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[94mTrain Loss: 52.8536\u001b[0m\n",
            "[2026-01-24 05:49:57,189][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[95mValid Loss: 56.5892\u001b[0m\n",
            "[2026-01-24 05:49:57,189][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:57,213][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[94mTrain Loss: 59.4388\u001b[0m\n",
            "[2026-01-24 05:49:57,214][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[95mValid Loss: 55.7981\u001b[0m\n",
            "[2026-01-24 05:49:57,214][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:57,245][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[94mTrain Loss: 59.6637\u001b[0m\n",
            "[2026-01-24 05:49:57,245][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[95mValid Loss: 56.3986\u001b[0m\n",
            "[2026-01-24 05:49:57,246][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:57,271][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[94mTrain Loss: 58.9202\u001b[0m\n",
            "[2026-01-24 05:49:57,272][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[95mValid Loss: 63.3871\u001b[0m\n",
            "[2026-01-24 05:49:57,272][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:57,272][mdl.fnn][INFO] - Early stopping triggered at epoch: 6\n",
            "[2026-01-24 05:49:57,279][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2001/f2.pt\n",
            "[2026-01-24 05:49:57,326][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[94mTrain Loss: 53.5558\u001b[0m\n",
            "[2026-01-24 05:49:57,326][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[95mValid Loss: 51.3690\u001b[0m\n",
            "[2026-01-24 05:49:57,335][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2002/f0.e0.pt\n",
            "[2026-01-24 05:49:57,336][mdl.fnn][INFO] - Validation loss decreased (inf --> 51.368980)\n",
            "[2026-01-24 05:49:57,357][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[94mTrain Loss: 52.7332\u001b[0m\n",
            "[2026-01-24 05:49:57,358][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[95mValid Loss: 51.6556\u001b[0m\n",
            "[2026-01-24 05:49:57,358][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:57,380][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[94mTrain Loss: 51.5049\u001b[0m\n",
            "[2026-01-24 05:49:57,381][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[95mValid Loss: 51.4696\u001b[0m\n",
            "[2026-01-24 05:49:57,381][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:57,401][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[94mTrain Loss: 51.8832\u001b[0m\n",
            "[2026-01-24 05:49:57,402][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[95mValid Loss: 51.3350\u001b[0m\n",
            "[2026-01-24 05:49:57,402][mdl.fnn][INFO] - Validation loss decreased (51.368980 --> 51.335014)\n",
            "[2026-01-24 05:49:57,420][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[94mTrain Loss: 54.8602\u001b[0m\n",
            "[2026-01-24 05:49:57,421][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[95mValid Loss: 51.4660\u001b[0m\n",
            "[2026-01-24 05:49:57,421][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:57,444][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[94mTrain Loss: 55.8385\u001b[0m\n",
            "[2026-01-24 05:49:57,445][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[95mValid Loss: 51.7527\u001b[0m\n",
            "[2026-01-24 05:49:57,445][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:57,467][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[94mTrain Loss: 51.9712\u001b[0m\n",
            "[2026-01-24 05:49:57,467][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[95mValid Loss: 51.4348\u001b[0m\n",
            "[2026-01-24 05:49:57,467][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:57,486][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[94mTrain Loss: 54.0936\u001b[0m\n",
            "[2026-01-24 05:49:57,487][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[95mValid Loss: 51.7211\u001b[0m\n",
            "[2026-01-24 05:49:57,487][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:57,506][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[94mTrain Loss: 50.9247\u001b[0m\n",
            "[2026-01-24 05:49:57,507][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[95mValid Loss: 51.2190\u001b[0m\n",
            "[2026-01-24 05:49:57,507][mdl.fnn][INFO] - Validation loss decreased (51.335014 --> 51.219009)\n",
            "[2026-01-24 05:49:57,526][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[94mTrain Loss: 49.1580\u001b[0m\n",
            "[2026-01-24 05:49:57,526][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[95mValid Loss: 51.6835\u001b[0m\n",
            "[2026-01-24 05:49:57,533][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2002/f0.e9.pt\n",
            "[2026-01-24 05:49:57,533][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:57,552][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[94mTrain Loss: 51.5258\u001b[0m\n",
            "[2026-01-24 05:49:57,553][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[95mValid Loss: 51.2172\u001b[0m\n",
            "[2026-01-24 05:49:57,553][mdl.fnn][INFO] - Validation loss decreased (51.219009 --> 51.217224)\n",
            "[2026-01-24 05:49:57,573][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[94mTrain Loss: 51.6763\u001b[0m\n",
            "[2026-01-24 05:49:57,573][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[95mValid Loss: 50.9787\u001b[0m\n",
            "[2026-01-24 05:49:57,573][mdl.fnn][INFO] - Validation loss decreased (51.217224 --> 50.978695)\n",
            "[2026-01-24 05:49:57,594][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[94mTrain Loss: 49.2841\u001b[0m\n",
            "[2026-01-24 05:49:57,595][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[95mValid Loss: 51.8424\u001b[0m\n",
            "[2026-01-24 05:49:57,595][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:57,615][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[94mTrain Loss: 48.4859\u001b[0m\n",
            "[2026-01-24 05:49:57,615][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[95mValid Loss: 51.9759\u001b[0m\n",
            "[2026-01-24 05:49:57,616][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:57,637][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[94mTrain Loss: 49.9346\u001b[0m\n",
            "[2026-01-24 05:49:57,638][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[95mValid Loss: 51.6856\u001b[0m\n",
            "[2026-01-24 05:49:57,639][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:57,658][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[94mTrain Loss: 50.8125\u001b[0m\n",
            "[2026-01-24 05:49:57,659][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[95mValid Loss: 50.6579\u001b[0m\n",
            "[2026-01-24 05:49:57,659][mdl.fnn][INFO] - Validation loss decreased (50.978695 --> 50.657902)\n",
            "[2026-01-24 05:49:57,678][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[94mTrain Loss: 47.7623\u001b[0m\n",
            "[2026-01-24 05:49:57,678][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[95mValid Loss: 51.2859\u001b[0m\n",
            "[2026-01-24 05:49:57,679][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:57,702][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[94mTrain Loss: 52.6454\u001b[0m\n",
            "[2026-01-24 05:49:57,703][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[95mValid Loss: 51.5260\u001b[0m\n",
            "[2026-01-24 05:49:57,703][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:57,722][mdl.fnn][INFO] - Fold 0/2, Epoch 18, \u001b[94mTrain Loss: 49.2107\u001b[0m\n",
            "[2026-01-24 05:49:57,723][mdl.fnn][INFO] - Fold 0/2, Epoch 18, \u001b[95mValid Loss: 52.0188\u001b[0m\n",
            "[2026-01-24 05:49:57,724][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:57,749][mdl.fnn][INFO] - Fold 0/2, Epoch 19, \u001b[94mTrain Loss: 53.0786\u001b[0m\n",
            "[2026-01-24 05:49:57,750][mdl.fnn][INFO] - Fold 0/2, Epoch 19, \u001b[95mValid Loss: 51.2494\u001b[0m\n",
            "[2026-01-24 05:49:57,759][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2002/f0.e19.pt\n",
            "[2026-01-24 05:49:57,759][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:57,781][mdl.fnn][INFO] - Fold 0/2, Epoch 20, \u001b[94mTrain Loss: 48.0359\u001b[0m\n",
            "[2026-01-24 05:49:57,782][mdl.fnn][INFO] - Fold 0/2, Epoch 20, \u001b[95mValid Loss: 51.0065\u001b[0m\n",
            "[2026-01-24 05:49:57,782][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:57,782][mdl.fnn][INFO] - Early stopping triggered at epoch: 20\n",
            "[2026-01-24 05:49:57,789][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2002/f0.pt\n",
            "[2026-01-24 05:49:57,818][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[94mTrain Loss: 53.3656\u001b[0m\n",
            "[2026-01-24 05:49:57,818][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[95mValid Loss: 57.6622\u001b[0m\n",
            "[2026-01-24 05:49:57,824][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2002/f1.e0.pt\n",
            "[2026-01-24 05:49:57,825][mdl.fnn][INFO] - Validation loss decreased (inf --> 57.662235)\n",
            "[2026-01-24 05:49:57,850][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[94mTrain Loss: 53.1644\u001b[0m\n",
            "[2026-01-24 05:49:57,851][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[95mValid Loss: 54.4059\u001b[0m\n",
            "[2026-01-24 05:49:57,851][mdl.fnn][INFO] - Validation loss decreased (57.662235 --> 54.405899)\n",
            "[2026-01-24 05:49:57,877][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[94mTrain Loss: 51.5113\u001b[0m\n",
            "[2026-01-24 05:49:57,878][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[95mValid Loss: 54.1762\u001b[0m\n",
            "[2026-01-24 05:49:57,878][mdl.fnn][INFO] - Validation loss decreased (54.405899 --> 54.176235)\n",
            "[2026-01-24 05:49:57,898][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[94mTrain Loss: 50.8977\u001b[0m\n",
            "[2026-01-24 05:49:57,898][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[95mValid Loss: 57.6646\u001b[0m\n",
            "[2026-01-24 05:49:57,899][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:57,918][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[94mTrain Loss: 52.1585\u001b[0m\n",
            "[2026-01-24 05:49:57,919][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[95mValid Loss: 51.0543\u001b[0m\n",
            "[2026-01-24 05:49:57,919][mdl.fnn][INFO] - Validation loss decreased (54.176235 --> 51.054302)\n",
            "[2026-01-24 05:49:57,939][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[94mTrain Loss: 52.7645\u001b[0m\n",
            "[2026-01-24 05:49:57,940][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[95mValid Loss: 51.4313\u001b[0m\n",
            "[2026-01-24 05:49:57,940][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:57,961][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[94mTrain Loss: 52.5752\u001b[0m\n",
            "[2026-01-24 05:49:57,962][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[95mValid Loss: 54.4058\u001b[0m\n",
            "[2026-01-24 05:49:57,962][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:57,982][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[94mTrain Loss: 54.0081\u001b[0m\n",
            "[2026-01-24 05:49:57,982][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[95mValid Loss: 53.8840\u001b[0m\n",
            "[2026-01-24 05:49:57,983][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:58,003][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[94mTrain Loss: 52.5407\u001b[0m\n",
            "[2026-01-24 05:49:58,003][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[95mValid Loss: 53.6935\u001b[0m\n",
            "[2026-01-24 05:49:58,004][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:58,022][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[94mTrain Loss: 52.7241\u001b[0m\n",
            "[2026-01-24 05:49:58,023][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[95mValid Loss: 54.5110\u001b[0m\n",
            "[2026-01-24 05:49:58,030][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2002/f1.e9.pt\n",
            "[2026-01-24 05:49:58,030][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:58,030][mdl.fnn][INFO] - Early stopping triggered at epoch: 9\n",
            "[2026-01-24 05:49:58,036][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2002/f1.pt\n",
            "[2026-01-24 05:49:58,079][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[94mTrain Loss: 53.3232\u001b[0m\n",
            "[2026-01-24 05:49:58,079][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[95mValid Loss: 57.3432\u001b[0m\n",
            "[2026-01-24 05:49:58,087][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2002/f2.e0.pt\n",
            "[2026-01-24 05:49:58,087][mdl.fnn][INFO] - Validation loss decreased (inf --> 57.343227)\n",
            "[2026-01-24 05:49:58,113][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[94mTrain Loss: 52.8450\u001b[0m\n",
            "[2026-01-24 05:49:58,114][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[95mValid Loss: 57.2516\u001b[0m\n",
            "[2026-01-24 05:49:58,114][mdl.fnn][INFO] - Validation loss decreased (57.343227 --> 57.251625)\n",
            "[2026-01-24 05:49:58,138][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[94mTrain Loss: 54.3684\u001b[0m\n",
            "[2026-01-24 05:49:58,139][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[95mValid Loss: 53.6295\u001b[0m\n",
            "[2026-01-24 05:49:58,140][mdl.fnn][INFO] - Validation loss decreased (57.251625 --> 53.629471)\n",
            "[2026-01-24 05:49:58,166][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[94mTrain Loss: 53.0272\u001b[0m\n",
            "[2026-01-24 05:49:58,167][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[95mValid Loss: 51.1523\u001b[0m\n",
            "[2026-01-24 05:49:58,167][mdl.fnn][INFO] - Validation loss decreased (53.629471 --> 51.152275)\n",
            "[2026-01-24 05:49:58,190][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[94mTrain Loss: 52.4136\u001b[0m\n",
            "[2026-01-24 05:49:58,191][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[95mValid Loss: 54.1691\u001b[0m\n",
            "[2026-01-24 05:49:58,191][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:58,210][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[94mTrain Loss: 52.1166\u001b[0m\n",
            "[2026-01-24 05:49:58,210][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[95mValid Loss: 54.3356\u001b[0m\n",
            "[2026-01-24 05:49:58,210][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:58,233][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[94mTrain Loss: 52.0733\u001b[0m\n",
            "[2026-01-24 05:49:58,234][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[95mValid Loss: 50.2317\u001b[0m\n",
            "[2026-01-24 05:49:58,234][mdl.fnn][INFO] - Validation loss decreased (51.152275 --> 50.231705)\n",
            "[2026-01-24 05:49:58,256][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[94mTrain Loss: 52.2287\u001b[0m\n",
            "[2026-01-24 05:49:58,257][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[95mValid Loss: 53.8223\u001b[0m\n",
            "[2026-01-24 05:49:58,257][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:58,276][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[94mTrain Loss: 52.4821\u001b[0m\n",
            "[2026-01-24 05:49:58,277][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[95mValid Loss: 53.2709\u001b[0m\n",
            "[2026-01-24 05:49:58,277][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:58,301][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[94mTrain Loss: 51.8630\u001b[0m\n",
            "[2026-01-24 05:49:58,302][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[95mValid Loss: 56.8422\u001b[0m\n",
            "[2026-01-24 05:49:58,309][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2002/f2.e9.pt\n",
            "[2026-01-24 05:49:58,310][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:58,334][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[94mTrain Loss: 51.9250\u001b[0m\n",
            "[2026-01-24 05:49:58,335][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[95mValid Loss: 50.6505\u001b[0m\n",
            "[2026-01-24 05:49:58,335][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:58,358][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[94mTrain Loss: 51.0949\u001b[0m\n",
            "[2026-01-24 05:49:58,358][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[95mValid Loss: 53.4239\u001b[0m\n",
            "[2026-01-24 05:49:58,359][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:58,359][mdl.fnn][INFO] - Early stopping triggered at epoch: 11\n",
            "[2026-01-24 05:49:58,366][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2002/f2.pt\n",
            "[2026-01-24 05:49:58,403][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[94mTrain Loss: 55.2694\u001b[0m\n",
            "[2026-01-24 05:49:58,403][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[95mValid Loss: 54.4790\u001b[0m\n",
            "[2026-01-24 05:49:58,412][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2003/f0.e0.pt\n",
            "[2026-01-24 05:49:58,412][mdl.fnn][INFO] - Validation loss decreased (inf --> 54.478966)\n",
            "[2026-01-24 05:49:58,442][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[94mTrain Loss: 56.8105\u001b[0m\n",
            "[2026-01-24 05:49:58,443][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[95mValid Loss: 51.5744\u001b[0m\n",
            "[2026-01-24 05:49:58,444][mdl.fnn][INFO] - Validation loss decreased (54.478966 --> 51.574390)\n",
            "[2026-01-24 05:49:58,477][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[94mTrain Loss: 58.2897\u001b[0m\n",
            "[2026-01-24 05:49:58,478][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[95mValid Loss: 51.2640\u001b[0m\n",
            "[2026-01-24 05:49:58,479][mdl.fnn][INFO] - Validation loss decreased (51.574390 --> 51.263973)\n",
            "[2026-01-24 05:49:58,501][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[94mTrain Loss: 56.0932\u001b[0m\n",
            "[2026-01-24 05:49:58,502][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[95mValid Loss: 57.7631\u001b[0m\n",
            "[2026-01-24 05:49:58,502][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:58,525][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[94mTrain Loss: 54.2162\u001b[0m\n",
            "[2026-01-24 05:49:58,526][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[95mValid Loss: 57.5461\u001b[0m\n",
            "[2026-01-24 05:49:58,526][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:58,548][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[94mTrain Loss: 53.9310\u001b[0m\n",
            "[2026-01-24 05:49:58,548][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[95mValid Loss: 57.4287\u001b[0m\n",
            "[2026-01-24 05:49:58,549][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:58,571][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[94mTrain Loss: 58.4586\u001b[0m\n",
            "[2026-01-24 05:49:58,572][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[95mValid Loss: 54.4730\u001b[0m\n",
            "[2026-01-24 05:49:58,572][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:58,590][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[94mTrain Loss: 59.0385\u001b[0m\n",
            "[2026-01-24 05:49:58,591][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[95mValid Loss: 51.2489\u001b[0m\n",
            "[2026-01-24 05:49:58,592][mdl.fnn][INFO] - Validation loss decreased (51.263973 --> 51.248898)\n",
            "[2026-01-24 05:49:58,611][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[94mTrain Loss: 53.3890\u001b[0m\n",
            "[2026-01-24 05:49:58,612][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[95mValid Loss: 52.6144\u001b[0m\n",
            "[2026-01-24 05:49:58,612][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:58,626][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[94mTrain Loss: 57.4068\u001b[0m\n",
            "[2026-01-24 05:49:58,627][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[95mValid Loss: 57.2693\u001b[0m\n",
            "[2026-01-24 05:49:58,632][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2003/f0.e9.pt\n",
            "[2026-01-24 05:49:58,632][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:58,647][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[94mTrain Loss: 61.0974\u001b[0m\n",
            "[2026-01-24 05:49:58,648][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[95mValid Loss: 57.2232\u001b[0m\n",
            "[2026-01-24 05:49:58,649][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:58,665][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[94mTrain Loss: 52.1281\u001b[0m\n",
            "[2026-01-24 05:49:58,666][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[95mValid Loss: 53.9228\u001b[0m\n",
            "[2026-01-24 05:49:58,666][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:58,680][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[94mTrain Loss: 53.6006\u001b[0m\n",
            "[2026-01-24 05:49:58,681][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[95mValid Loss: 50.5318\u001b[0m\n",
            "[2026-01-24 05:49:58,681][mdl.fnn][INFO] - Validation loss decreased (51.248898 --> 50.531830)\n",
            "[2026-01-24 05:49:58,694][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[94mTrain Loss: 53.4736\u001b[0m\n",
            "[2026-01-24 05:49:58,695][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[95mValid Loss: 50.6760\u001b[0m\n",
            "[2026-01-24 05:49:58,696][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:58,709][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[94mTrain Loss: 55.9573\u001b[0m\n",
            "[2026-01-24 05:49:58,710][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[95mValid Loss: 54.5249\u001b[0m\n",
            "[2026-01-24 05:49:58,711][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:58,725][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[94mTrain Loss: 57.0858\u001b[0m\n",
            "[2026-01-24 05:49:58,725][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[95mValid Loss: 50.7939\u001b[0m\n",
            "[2026-01-24 05:49:58,726][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:58,742][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[94mTrain Loss: 58.5259\u001b[0m\n",
            "[2026-01-24 05:49:58,743][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[95mValid Loss: 57.2857\u001b[0m\n",
            "[2026-01-24 05:49:58,743][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:58,762][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[94mTrain Loss: 56.7495\u001b[0m\n",
            "[2026-01-24 05:49:58,763][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[95mValid Loss: 54.3051\u001b[0m\n",
            "[2026-01-24 05:49:58,764][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:58,764][mdl.fnn][INFO] - Early stopping triggered at epoch: 17\n",
            "[2026-01-24 05:49:58,768][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2003/f0.pt\n",
            "[2026-01-24 05:49:58,786][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[94mTrain Loss: 54.2953\u001b[0m\n",
            "[2026-01-24 05:49:58,787][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[95mValid Loss: 51.1094\u001b[0m\n",
            "[2026-01-24 05:49:58,792][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2003/f1.e0.pt\n",
            "[2026-01-24 05:49:58,792][mdl.fnn][INFO] - Validation loss decreased (inf --> 51.109417)\n",
            "[2026-01-24 05:49:58,808][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[94mTrain Loss: 54.9988\u001b[0m\n",
            "[2026-01-24 05:49:58,809][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[95mValid Loss: 57.5973\u001b[0m\n",
            "[2026-01-24 05:49:58,810][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:58,824][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[94mTrain Loss: 59.9032\u001b[0m\n",
            "[2026-01-24 05:49:58,824][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[95mValid Loss: 54.1172\u001b[0m\n",
            "[2026-01-24 05:49:58,825][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:58,839][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[94mTrain Loss: 53.5631\u001b[0m\n",
            "[2026-01-24 05:49:58,840][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[95mValid Loss: 54.4442\u001b[0m\n",
            "[2026-01-24 05:49:58,841][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:58,855][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[94mTrain Loss: 54.2293\u001b[0m\n",
            "[2026-01-24 05:49:58,856][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[95mValid Loss: 53.9268\u001b[0m\n",
            "[2026-01-24 05:49:58,856][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:58,870][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[94mTrain Loss: 52.2600\u001b[0m\n",
            "[2026-01-24 05:49:58,871][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[95mValid Loss: 57.1083\u001b[0m\n",
            "[2026-01-24 05:49:58,871][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:58,872][mdl.fnn][INFO] - Early stopping triggered at epoch: 5\n",
            "[2026-01-24 05:49:58,876][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2003/f1.pt\n",
            "[2026-01-24 05:49:58,895][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[94mTrain Loss: 52.8800\u001b[0m\n",
            "[2026-01-24 05:49:58,896][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[95mValid Loss: 52.4149\u001b[0m\n",
            "[2026-01-24 05:49:58,900][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2003/f2.e0.pt\n",
            "[2026-01-24 05:49:58,901][mdl.fnn][INFO] - Validation loss decreased (inf --> 52.414909)\n",
            "[2026-01-24 05:49:58,915][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[94mTrain Loss: 52.8630\u001b[0m\n",
            "[2026-01-24 05:49:58,916][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[95mValid Loss: 56.5418\u001b[0m\n",
            "[2026-01-24 05:49:58,916][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:58,931][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[94mTrain Loss: 51.1407\u001b[0m\n",
            "[2026-01-24 05:49:58,931][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[95mValid Loss: 55.9838\u001b[0m\n",
            "[2026-01-24 05:49:58,932][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:58,947][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[94mTrain Loss: 50.7698\u001b[0m\n",
            "[2026-01-24 05:49:58,947][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[95mValid Loss: 49.2279\u001b[0m\n",
            "[2026-01-24 05:49:58,947][mdl.fnn][INFO] - Validation loss decreased (52.414909 --> 49.227882)\n",
            "[2026-01-24 05:49:58,966][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[94mTrain Loss: 55.3120\u001b[0m\n",
            "[2026-01-24 05:49:58,967][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[95mValid Loss: 55.7128\u001b[0m\n",
            "[2026-01-24 05:49:58,968][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:58,982][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[94mTrain Loss: 53.9951\u001b[0m\n",
            "[2026-01-24 05:49:58,982][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[95mValid Loss: 58.7249\u001b[0m\n",
            "[2026-01-24 05:49:58,983][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:58,997][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[94mTrain Loss: 55.1289\u001b[0m\n",
            "[2026-01-24 05:49:58,997][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[95mValid Loss: 64.4260\u001b[0m\n",
            "[2026-01-24 05:49:58,998][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:59,012][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[94mTrain Loss: 51.9014\u001b[0m\n",
            "[2026-01-24 05:49:59,013][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[95mValid Loss: 64.2731\u001b[0m\n",
            "[2026-01-24 05:49:59,014][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:59,028][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[94mTrain Loss: 50.6469\u001b[0m\n",
            "[2026-01-24 05:49:59,028][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[95mValid Loss: 55.9302\u001b[0m\n",
            "[2026-01-24 05:49:59,029][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:59,029][mdl.fnn][INFO] - Early stopping triggered at epoch: 8\n",
            "[2026-01-24 05:49:59,033][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2003/f2.pt\n",
            "[2026-01-24 05:49:59,058][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[94mTrain Loss: 53.7094\u001b[0m\n",
            "[2026-01-24 05:49:59,059][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[95mValid Loss: 46.1893\u001b[0m\n",
            "[2026-01-24 05:49:59,063][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.e0.pt\n",
            "[2026-01-24 05:49:59,063][mdl.fnn][INFO] - Validation loss decreased (inf --> 46.189304)\n",
            "[2026-01-24 05:49:59,077][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[94mTrain Loss: 56.0751\u001b[0m\n",
            "[2026-01-24 05:49:59,078][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[95mValid Loss: 45.8905\u001b[0m\n",
            "[2026-01-24 05:49:59,078][mdl.fnn][INFO] - Validation loss decreased (46.189304 --> 45.890476)\n",
            "[2026-01-24 05:49:59,092][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[94mTrain Loss: 53.0268\u001b[0m\n",
            "[2026-01-24 05:49:59,093][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[95mValid Loss: 45.5624\u001b[0m\n",
            "[2026-01-24 05:49:59,093][mdl.fnn][INFO] - Validation loss decreased (45.890476 --> 45.562416)\n",
            "[2026-01-24 05:49:59,107][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[94mTrain Loss: 49.4631\u001b[0m\n",
            "[2026-01-24 05:49:59,108][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[95mValid Loss: 45.5066\u001b[0m\n",
            "[2026-01-24 05:49:59,108][mdl.fnn][INFO] - Validation loss decreased (45.562416 --> 45.506645)\n",
            "[2026-01-24 05:49:59,122][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[94mTrain Loss: 55.6941\u001b[0m\n",
            "[2026-01-24 05:49:59,123][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[95mValid Loss: 46.0909\u001b[0m\n",
            "[2026-01-24 05:49:59,124][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:59,138][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[94mTrain Loss: 57.9907\u001b[0m\n",
            "[2026-01-24 05:49:59,139][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[95mValid Loss: 45.2276\u001b[0m\n",
            "[2026-01-24 05:49:59,140][mdl.fnn][INFO] - Validation loss decreased (45.506645 --> 45.227577)\n",
            "[2026-01-24 05:49:59,161][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[94mTrain Loss: 55.6566\u001b[0m\n",
            "[2026-01-24 05:49:59,162][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[95mValid Loss: 45.5030\u001b[0m\n",
            "[2026-01-24 05:49:59,162][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:59,176][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[94mTrain Loss: 52.1537\u001b[0m\n",
            "[2026-01-24 05:49:59,177][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[95mValid Loss: 45.9782\u001b[0m\n",
            "[2026-01-24 05:49:59,178][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:59,192][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[94mTrain Loss: 58.1639\u001b[0m\n",
            "[2026-01-24 05:49:59,192][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[95mValid Loss: 45.3729\u001b[0m\n",
            "[2026-01-24 05:49:59,192][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:59,207][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[94mTrain Loss: 52.6368\u001b[0m\n",
            "[2026-01-24 05:49:59,208][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[95mValid Loss: 45.9797\u001b[0m\n",
            "[2026-01-24 05:49:59,213][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.e9.pt\n",
            "[2026-01-24 05:49:59,213][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:59,229][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[94mTrain Loss: 52.4882\u001b[0m\n",
            "[2026-01-24 05:49:59,229][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[95mValid Loss: 45.5445\u001b[0m\n",
            "[2026-01-24 05:49:59,230][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:59,230][mdl.fnn][INFO] - Early stopping triggered at epoch: 10\n",
            "[2026-01-24 05:49:59,234][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.pt\n",
            "[2026-01-24 05:49:59,259][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[94mTrain Loss: 52.4132\u001b[0m\n",
            "[2026-01-24 05:49:59,260][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[95mValid Loss: 48.2582\u001b[0m\n",
            "[2026-01-24 05:49:59,266][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.e0.pt\n",
            "[2026-01-24 05:49:59,266][mdl.fnn][INFO] - Validation loss decreased (inf --> 48.258167)\n",
            "[2026-01-24 05:49:59,282][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[94mTrain Loss: 50.9260\u001b[0m\n",
            "[2026-01-24 05:49:59,283][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[95mValid Loss: 48.2807\u001b[0m\n",
            "[2026-01-24 05:49:59,283][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:59,298][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[94mTrain Loss: 52.3728\u001b[0m\n",
            "[2026-01-24 05:49:59,298][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[95mValid Loss: 48.2803\u001b[0m\n",
            "[2026-01-24 05:49:59,299][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:59,314][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[94mTrain Loss: 55.4335\u001b[0m\n",
            "[2026-01-24 05:49:59,314][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[95mValid Loss: 48.3392\u001b[0m\n",
            "[2026-01-24 05:49:59,315][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:59,329][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[94mTrain Loss: 53.8590\u001b[0m\n",
            "[2026-01-24 05:49:59,329][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[95mValid Loss: 48.2419\u001b[0m\n",
            "[2026-01-24 05:49:59,330][mdl.fnn][INFO] - Validation loss decreased (48.258167 --> 48.241932)\n",
            "[2026-01-24 05:49:59,344][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[94mTrain Loss: 55.3813\u001b[0m\n",
            "[2026-01-24 05:49:59,345][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[95mValid Loss: 48.2351\u001b[0m\n",
            "[2026-01-24 05:49:59,345][mdl.fnn][INFO] - Validation loss decreased (48.241932 --> 48.235054)\n",
            "[2026-01-24 05:49:59,360][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[94mTrain Loss: 50.7680\u001b[0m\n",
            "[2026-01-24 05:49:59,361][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[95mValid Loss: 48.3129\u001b[0m\n",
            "[2026-01-24 05:49:59,361][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:59,376][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[94mTrain Loss: 52.5995\u001b[0m\n",
            "[2026-01-24 05:49:59,376][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[95mValid Loss: 49.1060\u001b[0m\n",
            "[2026-01-24 05:49:59,377][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:59,392][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[94mTrain Loss: 52.3354\u001b[0m\n",
            "[2026-01-24 05:49:59,393][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[95mValid Loss: 48.2795\u001b[0m\n",
            "[2026-01-24 05:49:59,394][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:59,408][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[94mTrain Loss: 55.5286\u001b[0m\n",
            "[2026-01-24 05:49:59,409][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[95mValid Loss: 48.2459\u001b[0m\n",
            "[2026-01-24 05:49:59,414][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.e9.pt\n",
            "[2026-01-24 05:49:59,414][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:59,429][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[94mTrain Loss: 50.8831\u001b[0m\n",
            "[2026-01-24 05:49:59,429][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[95mValid Loss: 48.2625\u001b[0m\n",
            "[2026-01-24 05:49:59,430][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:59,430][mdl.fnn][INFO] - Early stopping triggered at epoch: 10\n",
            "[2026-01-24 05:49:59,435][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.pt\n",
            "[2026-01-24 05:49:59,460][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[94mTrain Loss: 53.4085\u001b[0m\n",
            "[2026-01-24 05:49:59,462][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[95mValid Loss: 56.6216\u001b[0m\n",
            "[2026-01-24 05:49:59,467][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.e0.pt\n",
            "[2026-01-24 05:49:59,468][mdl.fnn][INFO] - Validation loss decreased (inf --> 56.621605)\n",
            "[2026-01-24 05:49:59,491][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[94mTrain Loss: 50.3414\u001b[0m\n",
            "[2026-01-24 05:49:59,491][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[95mValid Loss: 58.2910\u001b[0m\n",
            "[2026-01-24 05:49:59,491][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:59,511][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[94mTrain Loss: 46.8445\u001b[0m\n",
            "[2026-01-24 05:49:59,512][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[95mValid Loss: 57.3612\u001b[0m\n",
            "[2026-01-24 05:49:59,513][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:59,528][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[94mTrain Loss: 48.9488\u001b[0m\n",
            "[2026-01-24 05:49:59,528][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[95mValid Loss: 50.8143\u001b[0m\n",
            "[2026-01-24 05:49:59,529][mdl.fnn][INFO] - Validation loss decreased (56.621605 --> 50.814270)\n",
            "[2026-01-24 05:49:59,544][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[94mTrain Loss: 47.0302\u001b[0m\n",
            "[2026-01-24 05:49:59,544][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[95mValid Loss: 58.1669\u001b[0m\n",
            "[2026-01-24 05:49:59,545][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:59,561][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[94mTrain Loss: 46.7723\u001b[0m\n",
            "[2026-01-24 05:49:59,561][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[95mValid Loss: 50.2770\u001b[0m\n",
            "[2026-01-24 05:49:59,562][mdl.fnn][INFO] - Validation loss decreased (50.814270 --> 50.276955)\n",
            "[2026-01-24 05:49:59,576][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[94mTrain Loss: 49.9287\u001b[0m\n",
            "[2026-01-24 05:49:59,577][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[95mValid Loss: 56.4255\u001b[0m\n",
            "[2026-01-24 05:49:59,578][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2026-01-24 05:49:59,591][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[94mTrain Loss: 46.7764\u001b[0m\n",
            "[2026-01-24 05:49:59,592][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[95mValid Loss: 62.7194\u001b[0m\n",
            "[2026-01-24 05:49:59,593][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2026-01-24 05:49:59,607][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[94mTrain Loss: 46.5231\u001b[0m\n",
            "[2026-01-24 05:49:59,607][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[95mValid Loss: 56.4928\u001b[0m\n",
            "[2026-01-24 05:49:59,608][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2026-01-24 05:49:59,622][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[94mTrain Loss: 46.4032\u001b[0m\n",
            "[2026-01-24 05:49:59,623][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[95mValid Loss: 56.6075\u001b[0m\n",
            "[2026-01-24 05:49:59,628][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.e9.pt\n",
            "[2026-01-24 05:49:59,628][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2026-01-24 05:49:59,642][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[94mTrain Loss: 46.7158\u001b[0m\n",
            "[2026-01-24 05:49:59,642][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[95mValid Loss: 50.3240\u001b[0m\n",
            "[2026-01-24 05:49:59,643][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2026-01-24 05:49:59,643][mdl.fnn][INFO] - Early stopping triggered at epoch: 10\n",
            "[2026-01-24 05:49:59,647][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.pt\n",
            "[2026-01-24 05:49:59,648][__main__][INFO] - \u001b[92mTesting team recommender instance mdl.tntf.tNtf_mdl.bnn.Bnn ... \u001b[0m\n",
            "/content/opentf/src/mdl/fnn.py:187: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.load_state_dict(Ntf.torch.load(modelfile, map_location=self.device)['model_state_dict'])\n",
            "[2026-01-24 05:49:59,679][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.test.pred\n",
            "[2026-01-24 05:49:59,707][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.test.e0.pred\n",
            "[2026-01-24 05:49:59,732][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e9. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.test.e9.pred\n",
            "[2026-01-24 05:49:59,759][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.test.pred\n",
            "[2026-01-24 05:49:59,779][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.test.e0.pred\n",
            "[2026-01-24 05:49:59,803][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e9. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.test.e9.pred\n",
            "[2026-01-24 05:49:59,827][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.test.pred\n",
            "[2026-01-24 05:49:59,848][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.test.e0.pred\n",
            "[2026-01-24 05:49:59,870][mdl.fnn][INFO] - /bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e9. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.test.e9.pred\n",
            "[2026-01-24 05:49:59,871][__main__][INFO] - \u001b[95mEvaluating team recommender instance mdl.tntf.tNtf_mdl.bnn.Bnn ... \u001b[0m\n",
            "[2026-01-24 05:49:59,873][pkgmgr][INFO] - pandas not found.\n",
            "[2026-01-24 05:49:59,874][pkgmgr][INFO] - Installing pandas...\n",
            "[2026-01-24 05:50:07,326][pkgmgr][INFO] - Collecting pandas==2.0.0\n",
            "  Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas==2.0.0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas==2.0.0)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.1 (from pandas==2.0.0)\n",
            "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas==2.0.0) (1.24.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.0) (1.16.0)\n",
            "Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 109.0 MB/s eta 0:00:00\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
            "Installing collected packages: pytz, tzdata, python-dateutil, pandas\n",
            "Successfully installed pandas-2.0.0 python-dateutil-2.9.0.post0 pytz-2025.2 tzdata-2025.3\n",
            "\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-01-24 05:50:07,558][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-24 05:50:07,559][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-24 05:50:07,566][pkgmgr][INFO] - pytrec_eval not found.\n",
            "[2026-01-24 05:50:07,566][pkgmgr][INFO] - Installing pytrec-eval-terrier...\n",
            "[2026-01-24 05:50:08,929][pkgmgr][INFO] - Collecting pytrec-eval-terrier==0.5.2\n",
            "  Downloading pytrec_eval_terrier-0.5.2-cp38-cp38-manylinux2010_x86_64.whl.metadata (800 bytes)\n",
            "Downloading pytrec_eval_terrier-0.5.2-cp38-cp38-manylinux2010_x86_64.whl (287 kB)\n",
            "Installing collected packages: pytrec-eval-terrier\n",
            "Successfully installed pytrec-eval-terrier-0.5.2\n",
            "\n",
            "[2026-01-24 05:50:08,931][evl.metric][INFO] - Building pytrec_eval input for 6 instances ...\n",
            "100% 6/6 [00:00<00:00, 612.50it/s]\n",
            "[2026-01-24 05:50:08,951][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-24 05:50:08,966][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 6/6 [00:00<00:00, 137.49it/s]\n",
            "[2026-01-24 05:50:09,023][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-01-24 05:50:09,029][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.test.e0.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-24 05:50:09,031][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-24 05:50:09,039][evl.metric][INFO] - Building pytrec_eval input for 6 instances ...\n",
            "100% 6/6 [00:00<00:00, 2343.84it/s]\n",
            "[2026-01-24 05:50:09,045][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-24 05:50:09,050][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 6/6 [00:00<00:00, 155.54it/s]\n",
            "[2026-01-24 05:50:09,100][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-01-24 05:50:09,102][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.test.e9.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-24 05:50:09,103][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-24 05:50:09,112][evl.metric][INFO] - Building pytrec_eval input for 6 instances ...\n",
            "100% 6/6 [00:00<00:00, 2417.00it/s]\n",
            "[2026-01-24 05:50:09,118][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-24 05:50:09,123][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 6/6 [00:00<00:00, 171.90it/s]\n",
            "[2026-01-24 05:50:09,170][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f0.test.e9.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-01-24 05:50:09,174][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-24 05:50:09,176][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-24 05:50:09,184][evl.metric][INFO] - Building pytrec_eval input for 6 instances ...\n",
            "100% 6/6 [00:00<00:00, 2346.03it/s]\n",
            "[2026-01-24 05:50:09,190][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-24 05:50:09,196][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 6/6 [00:00<00:00, 159.57it/s]\n",
            "[2026-01-24 05:50:09,247][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-01-24 05:50:09,250][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.test.e0.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-24 05:50:09,251][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-24 05:50:09,260][evl.metric][INFO] - Building pytrec_eval input for 6 instances ...\n",
            "100% 6/6 [00:00<00:00, 2430.78it/s]\n",
            "[2026-01-24 05:50:09,266][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-24 05:50:09,271][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 6/6 [00:00<00:00, 158.39it/s]\n",
            "[2026-01-24 05:50:09,321][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-01-24 05:50:09,323][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.test.e9.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-24 05:50:09,324][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-24 05:50:09,333][evl.metric][INFO] - Building pytrec_eval input for 6 instances ...\n",
            "100% 6/6 [00:00<00:00, 2115.13it/s]\n",
            "[2026-01-24 05:50:09,340][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-24 05:50:09,345][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 6/6 [00:00<00:00, 170.76it/s]\n",
            "[2026-01-24 05:50:09,392][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f1.test.e9.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-01-24 05:50:09,396][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-24 05:50:09,398][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-24 05:50:09,406][evl.metric][INFO] - Building pytrec_eval input for 6 instances ...\n",
            "100% 6/6 [00:00<00:00, 2369.66it/s]\n",
            "[2026-01-24 05:50:09,412][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-24 05:50:09,417][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 6/6 [00:00<00:00, 166.64it/s]\n",
            "[2026-01-24 05:50:09,465][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-01-24 05:50:09,469][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.test.e0.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-24 05:50:09,470][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-24 05:50:09,478][evl.metric][INFO] - Building pytrec_eval input for 6 instances ...\n",
            "100% 6/6 [00:00<00:00, 2216.28it/s]\n",
            "[2026-01-24 05:50:09,485][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-24 05:50:09,490][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 6/6 [00:00<00:00, 149.59it/s]\n",
            "[2026-01-24 05:50:09,544][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-01-24 05:50:09,546][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.test.e9.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-24 05:50:09,548][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-24 05:50:09,556][evl.metric][INFO] - Building pytrec_eval input for 6 instances ...\n",
            "100% 6/6 [00:00<00:00, 2246.35it/s]\n",
            "[2026-01-24 05:50:09,563][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-24 05:50:09,568][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 6/6 [00:00<00:00, 170.58it/s]\n",
            "[2026-01-24 05:50:09,615][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/f2.test.e9.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,620][mdl.ntf][INFO] - Saving mean evaluation file over 3 folds as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,623][__main__][INFO] - \u001b[92mAggregating the test results under ../output/dblp/toy.dblp.v12.json per splits from test.pred.eval.mean.csv files ... \u001b[0m\n",
            "[2026-01-24 05:50:09,635][__main__][INFO] - \u001b[92m../output/dblp/toy.dblp.v12.json/splits.f3.r0.85 ... \u001b[0m\n",
            "[2026-01-24 05:50:09,635][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,640][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,643][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,647][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,651][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,655][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,659][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,663][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/d2v.d128.e100.w5.dm1.skill/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,666][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/d2v.d128.e100.w5.dm1.skill/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,670][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/d2v.d128.e100.w5.dm1.skill/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,675][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,679][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,682][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,685][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,688][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,691][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,694][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,698][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,701][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,718][__main__][INFO] - \u001b[92mSaved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/test.pred.eval.mean.agg.csv. \u001b[0m\n",
            "[2026-01-24 05:50:09,719][__main__][INFO] - \u001b[92m../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1 ... \u001b[0m\n",
            "[2026-01-24 05:50:09,721][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,724][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/test.pred.eval.mean.csv\n",
            "[2026-01-24 05:50:09,733][__main__][INFO] - \u001b[92mSaved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/test.pred.eval.mean.agg.csv. \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu577_wqFMWq",
        "outputId": "b57c14b8-96c0-40c8-e98c-8bc31f3cf861",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000  2001  2002  2003\t2004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004"
      ],
      "metadata": {
        "id": "0b4vY4fzkACx",
        "outputId": "b44e9cd4-b302-442d-e284-c3f75129b1d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f0.e0.pt\t\t\t   f1.test.e9.pred.eval.mean.csv\n",
            "f0.e9.pt\t\t\t   f1.test.pred\n",
            "f0.pt\t\t\t\t   f1.test.pred.eval.instance.csv\n",
            "f0.test.e0.pred\t\t\t   f1.test.pred.eval.mean.csv\n",
            "f0.test.e0.pred.eval.instance.csv  f2.e0.pt\n",
            "f0.test.e0.pred.eval.mean.csv\t   f2.e9.pt\n",
            "f0.test.e9.pred\t\t\t   f2.pt\n",
            "f0.test.e9.pred.eval.instance.csv  f2.test.e0.pred\n",
            "f0.test.e9.pred.eval.mean.csv\t   f2.test.e0.pred.eval.instance.csv\n",
            "f0.test.pred\t\t\t   f2.test.e0.pred.eval.mean.csv\n",
            "f0.test.pred.eval.instance.csv\t   f2.test.e9.pred\n",
            "f0.test.pred.eval.mean.csv\t   f2.test.e9.pred.eval.instance.csv\n",
            "f1.e0.pt\t\t\t   f2.test.e9.pred.eval.mean.csv\n",
            "f1.e9.pt\t\t\t   f2.test.pred\n",
            "f1.pt\t\t\t\t   f2.test.pred.eval.instance.csv\n",
            "f1.test.e0.pred\t\t\t   f2.test.pred.eval.mean.csv\n",
            "f1.test.e0.pred.eval.instance.csv  logs4tboard\n",
            "f1.test.e0.pred.eval.mean.csv\t   splits.pkl\n",
            "f1.test.e9.pred\t\t\t   test.pred.eval.instance_mean.csv\n",
            "f1.test.e9.pred.eval.instance.csv  test.pred.eval.mean.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('/content/opentf/output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b2.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/test.pred.eval.mean.csv', index_col = 0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "cnLNdZBjFiZv",
        "outputId": "9a1802df-141f-4f5d-aa31-0c90b43b568b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       mean       std\n",
              "metrics                              \n",
              "P_2                0.166667  0.144338\n",
              "P_5                0.122222  0.038490\n",
              "P_10               0.155556  0.050918\n",
              "recall_2           0.166667  0.144338\n",
              "recall_5           0.287037  0.089293\n",
              "recall_10          0.722222  0.227371\n",
              "ndcg_cut_2         0.154095  0.124005\n",
              "ndcg_cut_5         0.222650  0.092011\n",
              "ndcg_cut_10        0.398633  0.105452\n",
              "map_cut_2          0.111111  0.086736\n",
              "map_cut_5          0.152778  0.068098\n",
              "map_cut_10         0.246355  0.058910\n",
              "success_2          0.333333  0.288675\n",
              "success_5          0.555556  0.254588\n",
              "success_10         0.888889  0.192450\n",
              "aucroc             0.425641  0.110803\n",
              "skill_coverage_2   0.861111  0.096225\n",
              "skill_coverage_5   0.916667  0.000000\n",
              "skill_coverage_10  0.916667  0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a272f202-3016-49ce-9222-87206b0163a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metrics</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>P_2</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.144338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_5</th>\n",
              "      <td>0.122222</td>\n",
              "      <td>0.038490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_10</th>\n",
              "      <td>0.155556</td>\n",
              "      <td>0.050918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_2</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.144338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_5</th>\n",
              "      <td>0.287037</td>\n",
              "      <td>0.089293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_10</th>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.227371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_2</th>\n",
              "      <td>0.154095</td>\n",
              "      <td>0.124005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_5</th>\n",
              "      <td>0.222650</td>\n",
              "      <td>0.092011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <td>0.398633</td>\n",
              "      <td>0.105452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_2</th>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.086736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_5</th>\n",
              "      <td>0.152778</td>\n",
              "      <td>0.068098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_10</th>\n",
              "      <td>0.246355</td>\n",
              "      <td>0.058910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_2</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.288675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_5</th>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.254588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_10</th>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.192450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aucroc</th>\n",
              "      <td>0.425641</td>\n",
              "      <td>0.110803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_2</th>\n",
              "      <td>0.861111</td>\n",
              "      <td>0.096225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_5</th>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_10</th>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a272f202-3016-49ce-9222-87206b0163a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a272f202-3016-49ce-9222-87206b0163a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a272f202-3016-49ce-9222-87206b0163a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"metrics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"P_2\",\n          \"recall_10\",\n          \"map_cut_10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3013980248676417,\n        \"min\": 0.1111111111111111,\n        \"max\": 0.9166666666666666,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.1666666666666666,\n          0.1222222222222222,\n          0.1540947563593935\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0796777224271451,\n        \"min\": 0.0,\n        \"max\": 0.2886751345948129,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.1443375672974064,\n          0.038490017945975,\n          0.1240046614275483\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tmp_opentf",
      "language": "python",
      "name": "tmp_opentf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}