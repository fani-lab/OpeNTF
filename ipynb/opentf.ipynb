{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fani-lab/OpeNTF/blob/main/ipynb/opentf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "NSSzz2dkP27t"
      },
      "source": [
        "## Extension to New Domains-Datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xupxPC5bP27u"
      },
      "source": [
        "## Structure and Inheritance\n",
        "\n",
        "### Dataset Structure\n",
        "<p align=\"center\"><img src='https://github.com/fani-lab/OpeNTF/blob/main/ipynb/src/cmn/dataset_hierarchy.png?raw=1' width=\"500\" ></p>\n",
        "\n",
        "To integrate a new dataset into the baseline, follow the structure of the `team` class. Additional fields can be added, like its derived classes. Ideally, only the `read_data()` function should be overriden.\n",
        "\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "wVOrnQ_lP27u"
      },
      "source": [
        "[\n",
        "  {\n",
        "    \"id\": 1,\n",
        "    \"reviewers\": [\n",
        "      { \"name\": \"Ada\", \"id\": 1, \"expertise\": \"Multimedia mining\" },\n",
        "      { \"name\": \"Bob\", \"id\": 11, \"expertise\": \"Image Captioning\" },\n",
        "      { \"name\": \"Cameron\", \"id\": 12, \"expertise\": \"Image Classification\" }\n",
        "    ],\n",
        "    \"fos\": [\"Image Captioning\"],\n",
        "    \"title\": \"A Comprehensive Review of Domain-specific Image Captioning\",\n",
        "    \"year\": 2000,\n",
        "  },\n",
        "  {\n",
        "    \"id\": 2,\n",
        "    \"reviewers\": [\n",
        "      { \"name\": \"Ada\", \"id\": 1, \"expertise\": \"Multimedia mining\" },\n",
        "      { \"name\": \"David\", \"id\": 9, \"expertise\": \"Video Classification\" },\n",
        "      { \"name\": \"Cameron\", \"id\": 12, \"expertise\": \"Image Classification\" }\n",
        "    ],\n",
        "    \"fos\": [\"Machine Learning\", \"Image Segmentation\"],\n",
        "    \"title\": \"A methodology for the physically accurate visualisation of medical imaging\",\n",
        "    \"year\": 1999,\n",
        "  }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiiktFYVP27u"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from cmn.member import Member\n",
        "from cmn.team import Team\n",
        "\n",
        "class Review(Team):\n",
        "    def _init_(self, id, title, year, fos, reviewers):\n",
        "        super().__init__(id, reviewers, fos, year)\n",
        "        self.title = title\n",
        "\n",
        "    @staticmethod\n",
        "    def read_data(datapath, output, index, filter, settings):\n",
        "        try:\n",
        "            return super(Review, Review).load_data(output, index)\n",
        "        except (FileNotFoundError, EOFError) as e:\n",
        "            print(f\"Pickles not found! Reading raw data from {datapath} (progress in bytes) ...\")\n",
        "            teams = {}; candidates = {}\n",
        "\n",
        "            with open(datapath, \"r\", encoding='utf-8') as jf:\n",
        "                for line in jf:\n",
        "                    try:\n",
        "                        if not line: break\n",
        "                        jsonline = json.loads(line.lower().lstrip(\",\"))\n",
        "                        id = jsonline['id']\n",
        "                        title = jsonline['title']\n",
        "                        year = jsonline['year']\n",
        "\n",
        "                        # a team must have skills and members\n",
        "                        try: fos = jsonline['fos']\n",
        "                        except: continue\n",
        "                        try: reviewers = jsonline['reviewers']\n",
        "                        except: continue\n",
        "\n",
        "                        members = []\n",
        "                        for reviewer in reviewers:\n",
        "                            member_id = reviewer['id']\n",
        "                            member_name = reviewer['name'].replace(\" \", \"_\")\n",
        "                            if (idname := f'{member_id}_{member_name}') not in candidates:\n",
        "                                candidates[idname] = Member(member_id, member_name)\n",
        "                                candidates[idname].skills.update(set(reviewer['expertise']))\n",
        "                            members.append(candidates[idname])\n",
        "\n",
        "                        team = Review(id, title, year, fos, members)\n",
        "                        teams[team.id] = team\n",
        "                    except json.JSONDecodeError as e:  # ideally should happen only for the last line ']'\n",
        "                        print(f'JSONDecodeError: There has been error in loading json line `{line}`!\\n{e}')\n",
        "                        continue\n",
        "                    except Exception as e:\n",
        "                        raise e\n",
        "            return super(Review, Review).read_data(teams, output, filter, settings)\n",
        "        except Exception as e: raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxnvMBwEP27u"
      },
      "source": [
        "## Extensiong to New Models\n",
        "![Class Diagram of the Model baseline.](https://github.com/fani-lab/OpeNTF/blob/main/ipynb/new-class-diagram.png?raw=1)\n",
        "\n",
        "To integrate a new model into the baseline, follow the `Ntf` class. Ideally, only the `learn()` method should be overriden, with `eval()` remaining the same for fair comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MScIUto2P27u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import pandas as pd\n",
        "\n",
        "from mdl.ntf import Ntf\n",
        "from mdl.cds import TFDataset\n",
        "from cmn.team import Team\n",
        "from cmn.tools import merge_teams_by_skills\n",
        "from mdl.cds import SuperlossDataset\n",
        "from mdl.superloss import SuperLoss\n",
        "\n",
        "class Random(Ntf):\n",
        "    def __init__(self):\n",
        "        super(Random, self).__init__()\n",
        "\n",
        "    def init(self):\n",
        "        self.model = keras.Sequential()\n",
        "\n",
        "    def learn(self, splits, indexes, vecs, params, prev_model, output):\n",
        "        input_size = vecs['skill'].shape[1]\n",
        "        output_size = len(indexes['i2c'])\n",
        "\n",
        "        for foldidx in splits['folds'].keys():\n",
        "            self.init(input_size=input_size, output_size=output_size)\n",
        "            if prev_model: keras.saving.load_model((prev_model[foldidx]))\n",
        "\n",
        "            keras.saving.save_model(self.model, f\"{output}/state_dict_model.f{foldidx}.pt\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "opentf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}