{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fani-lab/OpeNTF/blob/main/ipynb/nmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QGHFtvGnTLJ"
      },
      "source": [
        "<p align=\"center\"><img src='https://raw.githubusercontent.com/fani-lab/OpeNTF/cd22f8e183cacbb22f43c2c1e54948cd876975ac/docs/figs/opentf-openmt-logo.png' width=\"100\" ></p>\n",
        "\n",
        "`OpeNTF-Seq2Seq` via `OpenNMT-py`\n",
        "\n",
        "`OpeNTF` previously viewed the team formation problem as a multi-label classification task and integrated feedforward neural classifiers to map the vector representation of the required skills in the input layer to the to the `1-hot` encoded vector of experts in the ouput layer. However, the problem can also be viewed as a `seq-to-seq` prediction or `translation` task, mapping a dynamic-length input sequence of required skills onto a dynamic-length output sequence of predicted experts while leveraging the autoregression and global attention mechanisms, which capture dependencies beyond independent expert probabilities in multi-label classification. We integrated [`OpenNMT-py`](https://github.com/OpenNMT/OpenNMT-py) via a wrapper class [`mdl.nmt.Nmt`](https://github.com/fani-lab/OpeNTF/blob/main/src/mdl/nmt.py) to utilize modern `transformers` and `encoder-decoder` recurrent models with `attention` mechanisms."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dE7D-VfK3Fla"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4tk12X-nTLK"
      },
      "source": [
        "**Translative Team Recommendation [`[SIGIR25]`](https://dl.acm.org/doi/10.1145/3726302.3730259)**\n",
        "\n",
        "<p align=\"center\"><img src='https://raw.githubusercontent.com/fani-lab/OpeNTF/refs/heads/main/docs/figs/s2s.png' width=\"200\" ></p>\n",
        "\n",
        "To run `OpeNTF` in translation mode, the model instance should be set to `mdl.nmt.Nmt` in [`src/__config__.yaml#L59`](https://github.com/fani-lab/OpeNTF/blob/main/src/__config__.yaml#L59)\n",
        "\n",
        "`\"models.instances=[mdl.nmt.Nmt]\"`\n",
        "\n",
        "\n",
        "```\n",
        "python main.py  \"cmd=[prep,train,test,eval]\" \\\n",
        "                \"models.instances=[mdl.nmt.Nmt]\" \\\n",
        "                data.domain=cmn.publication.Publication \\\n",
        "                data.source=../data/dblp/toy.dblp.v12.json \\\n",
        "                data.output=../output/dblp/toy.dblp.v12.json \\\n",
        "                ~data.filter\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "U3bXSGQC3Lic"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "0Uiz41tPnTLK"
      },
      "source": [
        "**Seq-to-Seq Model Selection and Hyperparameters**\n",
        "\n",
        "In [`mdl.nmt.Nmt`](https://github.com/fani-lab/OpeNTF/blob/main/src/mdl/nmt.py), we prepare the required source and target sets as if parallel datasets from `source language` whose tokens are `skills` to `target language` whose tokens are `experts` and call `OpenNMT-py`'s executables by spawning a new process via python's `subprocess`.\n",
        "\n",
        "`OpeNTF` leverage [`OpenNMT-py`](https://opennmt.net/OpenNMT-py/quickstart.html) to manage model selection and its hyperparameters. For instance, to pick a `transformer`, the config file in [`src/mdl/__config__.nmt.yaml`](https://github.com/fani-lab/OpeNTF/blob/main/src/mdl/__config__.nmt.yaml) should be set for the required hyperparameters like below:\n",
        "\n",
        "```\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "\n",
        "position_encoding: False # w/o purticular order in input skills and output members.\n",
        "\n",
        "enc_layers: 4\n",
        "dec_layers: 4\n",
        "\n",
        "hidden_size: 128\n",
        "transformer_ff: 512\n",
        "attention_dropout: 0.2\n",
        "heads: 8\n",
        "\n",
        "beam_size: 10\n",
        "n_best: 1\n",
        "min_length: 2\n",
        "max_length: 100\n",
        "```\n",
        "(see default settings for common models in [`src/mdl/__config__.nmt.yaml`](https://github.com/fani-lab/OpeNTF/blob/main/src/mdl/__config__.nmt.yaml))\n",
        "\n",
        "(see [`OpenNMT-py`](https://opennmt.net/OpenNMT-py/quickstart.html)'s docs for more details)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rEqgd5eO95eD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwEN1xLDnTLK"
      },
      "source": [
        "**Setup & Quickstart**\n",
        "\n",
        "From the [`quickstart`](https://colab.research.google.com/github/fani-lab/OpeNTF/blob/main/ipynb/quickstart.ipynb) script:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mZln-_cnnTLM",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b88bcb4-2339-4ad1-e839-288271cdce95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://cli.github.com/packages stable InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-pip is already the newest version (22.0.2+dfsg-1ubuntu0.7).\n",
            "python3.8 is already the newest version (3.8.20-1+jammy1).\n",
            "python3.8-distutils is already the newest version (3.8.20-1+jammy1).\n",
            "python3.8-venv is already the newest version (3.8.20-1+jammy1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Python 3.8.20\n"
          ]
        }
      ],
      "source": [
        "# set up python 3.8\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y python3.8 python3.8-venv python3.8-distutils python3-pip\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 10\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get OpeNTF\n",
        "!rm -R opentf/\n",
        "!git clone https://github.com/Fani-Lab/opentf\n",
        "!pip install --upgrade pip setuptools\n",
        "!pip install -r opentf/requirements.txt"
      ],
      "metadata": {
        "id": "95eDgj3AAInL",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6790a1-8657-4584-b382-c5686ed2eaa4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'opentf/': No such file or directory\n",
            "Cloning into 'opentf'...\n",
            "remote: Enumerating objects: 26923, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 26923 (delta 61), reused 28 (delta 25), pack-reused 26825 (from 3)\u001b[K\n",
            "Receiving objects: 100% (26923/26923), 1.32 GiB | 24.44 MiB/s, done.\n",
            "Resolving deltas: 100% (13333/13333), done.\n",
            "Updating files: 100% (4274/4274), done.\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (25.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (75.3.3)\n",
            "Requirement already satisfied: hydra-core==1.3.2 in /usr/local/lib/python3.8/dist-packages (from -r opentf/requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.8/dist-packages (from -r opentf/requirements.txt (line 4)) (1.10.1)\n",
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.8/dist-packages (from -r opentf/requirements.txt (line 5)) (1.24.4)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.8/dist-packages (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.8/dist-packages (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3)) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3)) (26.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3)) (6.4.5)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.4,>=2.2->hydra-core==1.3.2->-r opentf/requirements.txt (line 3)) (6.0.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core==1.3.2->-r opentf/requirements.txt (line 3)) (3.20.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translative Neural Team Recommendation\n",
        "\n",
        "- Preprocessing raw data `cmd=prep` into `teamsvecs` sparse matrix each row of which is a team with its skills `teamsvecs['skill']`, members `teamsvecs['member']` as 1-hot vectors\n",
        "- `data.domain`, `data.source`, `data.output` from `toy.dblp` dataset, available at the codebase [`OpeNTF/data/dblp`](https://github.com/fani-lab/OpeNTF/tree/main/data/dblp)\n",
        "- No filtering for min team size `data.filter.min_nteam` and min number of teams per experts `data.filter.min_team_size`\n",
        "- Neural machine translation (`mdl.nmt.Nmt`) for team recommendation for `train`, `test`, and `eval` steps\n",
        "- The model and its hyperparameters in [`src/mdl/__config__.nmt.yaml`](https://github.com/fani-lab/OpeNTF/blob/main/src/mdl/__config__.nmt.yaml)"
      ],
      "metadata": {
        "id": "F0R0OLHXASxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Due to uninstallation bug in colab for 'blinker'. In a container/server, OpeNTF installs it on-demand.\n",
        "!pip install OpenNMT-py==3.3 --ignore-installed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "LGe5md56Te-0",
        "outputId": "619c1a1b-dfd4-4138-fd53-5bef124cada1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenNMT-py==3.3\n",
            "  Using cached OpenNMT_py-3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting torch<2.1,>=1.13 (from OpenNMT-py==3.3)\n",
            "  Using cached torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting configargparse (from OpenNMT-py==3.3)\n",
            "  Using cached configargparse-1.7.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting ctranslate2<4,>=3.2 (from OpenNMT-py==3.3)\n",
            "  Using cached ctranslate2-3.24.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting tensorboard>=2.3 (from OpenNMT-py==3.3)\n",
            "  Using cached tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting flask (from OpenNMT-py==3.3)\n",
            "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting waitress (from OpenNMT-py==3.3)\n",
            "  Using cached waitress-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pyonmttok<2,>=1.35 (from OpenNMT-py==3.3)\n",
            "  Using cached pyonmttok-1.37.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting pyyaml (from OpenNMT-py==3.3)\n",
            "  Using cached PyYAML-6.0.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting sacrebleu (from OpenNMT-py==3.3)\n",
            "  Using cached sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "Collecting rapidfuzz (from OpenNMT-py==3.3)\n",
            "  Using cached rapidfuzz-3.9.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting pyahocorasick (from OpenNMT-py==3.3)\n",
            "  Using cached pyahocorasick-2.1.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (13 kB)\n",
            "Collecting fasttext-wheel (from OpenNMT-py==3.3)\n",
            "  Using cached fasttext_wheel-0.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting setuptools (from ctranslate2<4,>=3.2->OpenNMT-py==3.3)\n",
            "  Using cached setuptools-75.3.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting numpy (from ctranslate2<4,>=3.2->OpenNMT-py==3.3)\n",
            "  Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached google_auth-2.47.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting protobuf>=3.19.6 (from tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting wheel>=0.26 (from tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting filelock (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting jinja2 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting cmake (from triton==2.0.0->torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached cmake-4.2.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting lit (from triton==2.0.0->torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel->OpenNMT-py==3.3)\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting itsdangerous>=2.1.2 (from flask->OpenNMT-py==3.3)\n",
            "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting click>=8.1.3 (from flask->OpenNMT-py==3.3)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting blinker>=1.6.2 (from flask->OpenNMT-py==3.3)\n",
            "  Using cached blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting importlib-metadata>=3.6.0 (from flask->OpenNMT-py==3.3)\n",
            "  Using cached importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting portalocker (from sacrebleu->OpenNMT-py==3.3)\n",
            "  Using cached portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting regex (from sacrebleu->OpenNMT-py==3.3)\n",
            "  Using cached regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tabulate>=0.8.9 (from sacrebleu->OpenNMT-py==3.3)\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting colorama (from sacrebleu->OpenNMT-py==3.3)\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lxml (from sacrebleu->OpenNMT-py==3.3)\n",
            "  Using cached lxml-6.0.2-cp38-cp38-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting zipp>=3.20 (from importlib-metadata>=3.6.0->flask->OpenNMT-py==3.3)\n",
            "  Using cached zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached charset_normalizer-3.4.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch<2.1,>=1.13->OpenNMT-py==3.3)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached pyasn1-0.6.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py==3.3)\n",
            "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Using cached OpenNMT_py-3.3-py3-none-any.whl (242 kB)\n",
            "Using cached ctranslate2-3.24.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.8 MB)\n",
            "Using cached pyonmttok-1.37.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "Using cached PyYAML-6.0.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
            "Using cached tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
            "Using cached torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
            "Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Using cached triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
            "Using cached configargparse-1.7.1-py3-none-any.whl (25 kB)\n",
            "Using cached fasttext_wheel-0.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "Using cached pyahocorasick-2.1.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (104 kB)\n",
            "Using cached rapidfuzz-3.9.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "Using cached sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "Using cached waitress-3.0.0-py3-none-any.whl (56 kB)\n",
            "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached google_auth-2.47.0-py3-none-any.whl (234 kB)\n",
            "Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Using cached grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "Using cached importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Using cached protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Using cached setuptools-75.3.3-py3-none-any.whl (1.3 MB)\n",
            "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Using cached werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Using cached lxml-6.0.2-cp38-cp38-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.2 MB)\n",
            "Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "Using cached portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Using cached regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
            "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
            "Using cached charset_normalizer-3.4.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (147 kB)\n",
            "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
            "Using cached MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Using cached zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Using cached cmake-4.2.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (28.9 MB)\n",
            "Using cached lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
            "Using cached pyasn1-0.6.2-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: mpmath, lit, zipp, wheel, waitress, urllib3, typing-extensions, tensorboard-data-server, tabulate, sympy, setuptools, regex, rapidfuzz, pyyaml, pyonmttok, pybind11, pyasn1, pyahocorasick, protobuf, portalocker, oauthlib, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, numpy, networkx, MarkupSafe, lxml, itsdangerous, idna, grpcio, filelock, configargparse, colorama, cmake, click, charset_normalizer, certifi, blinker, absl-py, werkzeug, sacrebleu, rsa, requests, pyasn1-modules, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jinja2, importlib-metadata, fasttext-wheel, ctranslate2, requests-oauthlib, nvidia-cusolver-cu11, nvidia-cudnn-cu11, markdown, google-auth, flask, google-auth-oauthlib, tensorboard, triton, torch, OpenNMT-py\n",
            "Successfully installed MarkupSafe-2.1.5 OpenNMT-py-3.3 absl-py-2.3.1 blinker-1.8.2 certifi-2026.1.4 charset_normalizer-3.4.4 click-8.1.8 cmake-4.2.1 colorama-0.4.6 configargparse-1.7.1 ctranslate2-3.24.0 fasttext-wheel-0.9.2 filelock-3.16.1 flask-3.0.3 google-auth-2.47.0 google-auth-oauthlib-1.0.0 grpcio-1.70.0 idna-3.11 importlib-metadata-8.5.0 itsdangerous-2.2.0 jinja2-3.1.6 lit-18.1.8 lxml-6.0.2 markdown-3.7 mpmath-1.3.0 networkx-3.1 numpy-1.24.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 oauthlib-3.3.1 portalocker-3.0.0 protobuf-3.20.0 pyahocorasick-2.1.0 pyasn1-0.6.2 pyasn1-modules-0.4.2 pybind11-3.0.1 pyonmttok-1.37.1 pyyaml-6.0.3 rapidfuzz-3.9.7 regex-2024.11.6 requests-2.32.4 requests-oauthlib-2.0.0 rsa-4.9.1 sacrebleu-2.5.1 setuptools-75.3.3 sympy-1.13.3 tabulate-0.9.0 tensorboard-2.14.0 tensorboard-data-server-0.7.2 torch-2.0.1 triton-2.0.0 typing-extensions-4.13.2 urllib3-2.2.3 waitress-3.0.0 werkzeug-3.0.6 wheel-0.45.1 zipp-3.20.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "google",
                  "numpy"
                ]
              },
              "id": "b99537aae7754d2e9f51e2ceee36dbbe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd opentf/src/\n",
        "!python main.py \"cmd=[prep,train,test,eval]\" \"models.instances=[mdl.rnd.Rnd, mdl.nmt.Nmt]\" data.domain=cmn.publication.Publication data.source=../data/dblp/toy.dblp.v12.json data.output=../output/dblp/toy.dblp.v12.json ~data.filter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDdbvZnWATUw",
        "outputId": "534e228a-2241-4082-e286-c9a091c66a23",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/opentf/src/opentf/src\n",
            "[2026-01-22 15:45:35,236][cmn.team][INFO] - Loading teamsvecs matrices from ../output/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "[2026-01-22 15:45:35,252][cmn.team][INFO] - Loading indexes pickle from ../output/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "[2026-01-22 15:45:35,253][cmn.team][INFO] - Indexes pickle is loaded.\n",
            "[2026-01-22 15:45:35,253][cmn.team][INFO] - Teamsvecs matrices and indexes for skills (31, 10), members (31, 13), and locations (31, 29) are loaded.\n",
            "[2026-01-22 15:45:35,254][__main__][INFO] - Loading splits from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.pkl ...\n",
            "[2026-01-22 15:45:35,256][cmn.team][INFO] - Loading member-skill co-occurrence matrix (13, 10) from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/skillcoverage.pkl ...\n",
            "[2026-01-22 15:45:39,808][__main__][INFO] - \u001b[94mTraining team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "[2026-01-22 15:45:39,808][__main__][INFO] - \u001b[92mTesting team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "[2026-01-22 15:45:39,913][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold0.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred\n",
            "[2026-01-22 15:45:39,915][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold1.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred\n",
            "[2026-01-22 15:45:39,918][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold2.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred\n",
            "[2026-01-22 15:45:39,918][__main__][INFO] - \u001b[95mEvaluating team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "[2026-01-22 15:45:40,583][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-22 15:45:40,591][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-22 15:45:40,606][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 790.66it/s]\n",
            "[2026-01-22 15:45:40,628][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-22 15:45:41,621][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 175.10it/s]\n",
            "[2026-01-22 15:45:41,659][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:41,668][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-22 15:45:41,669][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-22 15:45:41,674][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3711.77it/s]\n",
            "[2026-01-22 15:45:41,677][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-22 15:45:41,680][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 335.82it/s]\n",
            "[2026-01-22 15:45:41,702][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:41,705][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-22 15:45:41,706][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-22 15:45:41,710][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4144.57it/s]\n",
            "[2026-01-22 15:45:41,713][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-22 15:45:41,717][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 320.79it/s]\n",
            "[2026-01-22 15:45:41,739][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:41,743][mdl.ntf][INFO] - Saving mean evaluation file over 3 folds as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:41,965][__main__][INFO] - \u001b[94mTraining team recommender instance mdl.nmt.Nmt ... \u001b[0m\n",
            "[2026-01-22 15:45:41,965][mdl.nmt][INFO] - Loading src and tgt files and/or folding folders for OpenNMT in ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer ...\n",
            "[2026-01-22 15:45:42,216][mdl.nmt][INFO] - \u001b[94mOverriding onmt config for train for fold0 in ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f0.config.yml ...\u001b[0m\n",
            "[2026-01-22 15:45:42,230 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2026-01-22 15:45:42,230][onmt][WARNING] - Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2026-01-22 15:45:42,230 INFO] Missing transforms field for valid data, set to default: [].\n",
            "[2026-01-22 15:45:42,230][onmt][INFO] - Missing transforms field for valid data, set to default: [].\n",
            "[2026-01-22 15:45:42,230 INFO] Parsed 2 corpora from -data.\n",
            "[2026-01-22 15:45:42,230][onmt][INFO] - Parsed 2 corpora from -data.\n",
            "[2026-01-22 15:45:42,230 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2026-01-22 15:45:42,230][onmt][INFO] - Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2026-01-22 15:45:42,233 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 's5', 's1', 's4', 's6', 's8', 's7']\n",
            "[2026-01-22 15:45:42,233][onmt][INFO] - The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 's5', 's1', 's4', 's6', 's8', 's7']\n",
            "[2026-01-22 15:45:42,233 INFO] The decoder start token is: <s>\n",
            "[2026-01-22 15:45:42,233][onmt][INFO] - The decoder start token is: <s>\n",
            "[2026-01-22 15:45:42,233 INFO] Building model...\n",
            "[2026-01-22 15:45:42,233][onmt][INFO] - Building model...\n",
            "[2026-01-22 15:45:42,403 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2026-01-22 15:45:42,403][onmt][INFO] - Switching model to float32 for amp/apex_amp\n",
            "[2026-01-22 15:45:42,403 INFO] Non quantized layer compute is fp16\n",
            "[2026-01-22 15:45:42,403][onmt][INFO] - Non quantized layer compute is fp16\n",
            "[2026-01-22 15:45:42,405 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(16, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-3): 4 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(24, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-3): 4 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=128, out_features=24, bias=True)\n",
            ")\n",
            "[2026-01-22 15:45:42,405][onmt][INFO] - NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(16, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-3): 4 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(24, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-3): 4 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=128, out_features=24, bias=True)\n",
            ")\n",
            "[2026-01-22 15:45:42,408 INFO] encoder: 790784\n",
            "[2026-01-22 15:45:42,408][onmt][INFO] - encoder: 790784\n",
            "[2026-01-22 15:45:42,408 INFO] decoder: 1058072\n",
            "[2026-01-22 15:45:42,408][onmt][INFO] - decoder: 1058072\n",
            "[2026-01-22 15:45:42,408 INFO] * number of parameters: 1848856\n",
            "[2026-01-22 15:45:42,408][onmt][INFO] - * number of parameters: 1848856\n",
            "[2026-01-22 15:45:42,408 INFO] Trainable parameters = {'torch.float32': 1848856, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:42,408][onmt][INFO] - Trainable parameters = {'torch.float32': 1848856, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:42,408 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:42,408][onmt][INFO] - Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:42,408 INFO]  * src vocab size = 16\n",
            "[2026-01-22 15:45:42,408][onmt][INFO] -  * src vocab size = 16\n",
            "[2026-01-22 15:45:42,408 INFO]  * tgt vocab size = 24\n",
            "[2026-01-22 15:45:42,408][onmt][INFO] -  * tgt vocab size = 24\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
            "[2026-01-22 15:45:42,411 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2026-01-22 15:45:42,411][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2026-01-22 15:45:42,411 INFO] Starting training on CPU, could be very slow\n",
            "[2026-01-22 15:45:42,411][onmt][INFO] - Starting training on CPU, could be very slow\n",
            "[2026-01-22 15:45:42,411 INFO] Start training loop and validate every 1 steps...\n",
            "[2026-01-22 15:45:42,411][onmt][INFO] - Start training loop and validate every 1 steps...\n",
            "[2026-01-22 15:45:42,411 INFO] Scoring with: TransformPipe()\n",
            "[2026-01-22 15:45:42,411][onmt][INFO] - Scoring with: TransformPipe()\n",
            "/usr/local/lib/python3.8/dist-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
            "[2026-01-22 15:45:42,579 INFO] Step  1/  100; acc: 0.0; ppl:  23.8; xent: 3.2; lr: 0.00100; sents:      12; bsz:   31/  39/12; 185/233 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:42,579][onmt][INFO] - Step  1/  100; acc: 0.0; ppl:  23.8; xent: 3.2; lr: 0.00100; sents:      12; bsz:   31/  39/12; 185/233 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:42,594 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.014505386352539062 s.\n",
            "[2026-01-22 15:45:42,594][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.014505386352539062 s.\n",
            "[2026-01-22 15:45:42,596 INFO] Train perplexity: 23.7532\n",
            "[2026-01-22 15:45:42,596][onmt][INFO] - Train perplexity: 23.7532\n",
            "[2026-01-22 15:45:42,596 INFO] Train accuracy: 0\n",
            "[2026-01-22 15:45:42,596][onmt][INFO] - Train accuracy: 0\n",
            "[2026-01-22 15:45:42,596 INFO] Sentences processed: 12\n",
            "[2026-01-22 15:45:42,596][onmt][INFO] - Sentences processed: 12\n",
            "[2026-01-22 15:45:42,596 INFO] Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,596][onmt][INFO] - Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,596 INFO] Validation perplexity: 22.6581\n",
            "[2026-01-22 15:45:42,596][onmt][INFO] - Validation perplexity: 22.6581\n",
            "[2026-01-22 15:45:42,596 INFO] Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,596][onmt][INFO] - Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,596 INFO] Model is improving acc: -inf --> 32.1429.\n",
            "[2026-01-22 15:45:42,596][onmt][INFO] - Model is improving acc: -inf --> 32.1429.\n",
            "[2026-01-22 15:45:42,596 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2026-01-22 15:45:42,596][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2026-01-22 15:45:42,643 INFO] Step  2/  100; acc: 30.8; ppl:  21.8; xent: 3.1; lr: 0.00100; sents:      12; bsz:   31/  39/12; 483/608 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:42,643][onmt][INFO] - Step  2/  100; acc: 30.8; ppl:  21.8; xent: 3.1; lr: 0.00100; sents:      12; bsz:   31/  39/12; 483/608 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:42,655 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.010685205459594727 s.\n",
            "[2026-01-22 15:45:42,655][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.010685205459594727 s.\n",
            "[2026-01-22 15:45:42,656 INFO] Train perplexity: 22.7517\n",
            "[2026-01-22 15:45:42,656][onmt][INFO] - Train perplexity: 22.7517\n",
            "[2026-01-22 15:45:42,656 INFO] Train accuracy: 15.3846\n",
            "[2026-01-22 15:45:42,656][onmt][INFO] - Train accuracy: 15.3846\n",
            "[2026-01-22 15:45:42,656 INFO] Sentences processed: 24\n",
            "[2026-01-22 15:45:42,656][onmt][INFO] - Sentences processed: 24\n",
            "[2026-01-22 15:45:42,656 INFO] Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,656][onmt][INFO] - Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,656 INFO] Validation perplexity: 21.8789\n",
            "[2026-01-22 15:45:42,656][onmt][INFO] - Validation perplexity: 21.8789\n",
            "[2026-01-22 15:45:42,656 INFO] Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,656][onmt][INFO] - Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,656 INFO] Stalled patience: 4/5\n",
            "[2026-01-22 15:45:42,656][onmt][INFO] - Stalled patience: 4/5\n",
            "[2026-01-22 15:45:42,657 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2026-01-22 15:45:42,657][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2026-01-22 15:45:42,706 INFO] Step  3/  100; acc: 30.8; ppl:  20.9; xent: 3.0; lr: 0.00100; sents:      12; bsz:   31/  39/12; 495/623 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:42,706][onmt][INFO] - Step  3/  100; acc: 30.8; ppl:  20.9; xent: 3.0; lr: 0.00100; sents:      12; bsz:   31/  39/12; 495/623 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:42,720 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.012689590454101562 s.\n",
            "[2026-01-22 15:45:42,720][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.012689590454101562 s.\n",
            "[2026-01-22 15:45:42,721 INFO] Train perplexity: 22.1341\n",
            "[2026-01-22 15:45:42,721][onmt][INFO] - Train perplexity: 22.1341\n",
            "[2026-01-22 15:45:42,721 INFO] Train accuracy: 20.5128\n",
            "[2026-01-22 15:45:42,721][onmt][INFO] - Train accuracy: 20.5128\n",
            "[2026-01-22 15:45:42,721 INFO] Sentences processed: 36\n",
            "[2026-01-22 15:45:42,721][onmt][INFO] - Sentences processed: 36\n",
            "[2026-01-22 15:45:42,721 INFO] Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,721][onmt][INFO] - Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,721 INFO] Validation perplexity: 21.4059\n",
            "[2026-01-22 15:45:42,721][onmt][INFO] - Validation perplexity: 21.4059\n",
            "[2026-01-22 15:45:42,722 INFO] Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,722][onmt][INFO] - Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,722 INFO] Stalled patience: 3/5\n",
            "[2026-01-22 15:45:42,722][onmt][INFO] - Stalled patience: 3/5\n",
            "[2026-01-22 15:45:42,722 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2026-01-22 15:45:42,722][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2026-01-22 15:45:42,771 INFO] Step  4/  100; acc: 30.8; ppl:  20.5; xent: 3.0; lr: 0.00100; sents:      12; bsz:   31/  39/12; 483/608 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:42,771][onmt][INFO] - Step  4/  100; acc: 30.8; ppl:  20.5; xent: 3.0; lr: 0.00100; sents:      12; bsz:   31/  39/12; 483/608 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:42,783 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.011176347732543945 s.\n",
            "[2026-01-22 15:45:42,783][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.011176347732543945 s.\n",
            "[2026-01-22 15:45:42,784 INFO] Train perplexity: 21.7213\n",
            "[2026-01-22 15:45:42,784][onmt][INFO] - Train perplexity: 21.7213\n",
            "[2026-01-22 15:45:42,784 INFO] Train accuracy: 23.0769\n",
            "[2026-01-22 15:45:42,784][onmt][INFO] - Train accuracy: 23.0769\n",
            "[2026-01-22 15:45:42,784 INFO] Sentences processed: 48\n",
            "[2026-01-22 15:45:42,784][onmt][INFO] - Sentences processed: 48\n",
            "[2026-01-22 15:45:42,784 INFO] Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,784][onmt][INFO] - Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,784 INFO] Validation perplexity: 21.0892\n",
            "[2026-01-22 15:45:42,784][onmt][INFO] - Validation perplexity: 21.0892\n",
            "[2026-01-22 15:45:42,784 INFO] Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,784][onmt][INFO] - Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,784 INFO] Stalled patience: 2/5\n",
            "[2026-01-22 15:45:42,784][onmt][INFO] - Stalled patience: 2/5\n",
            "[2026-01-22 15:45:42,785 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2026-01-22 15:45:42,785][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2026-01-22 15:45:42,833 INFO] Step  5/  100; acc: 30.8; ppl:  20.1; xent: 3.0; lr: 0.00100; sents:      12; bsz:   31/  39/12; 502/632 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:42,833][onmt][INFO] - Step  5/  100; acc: 30.8; ppl:  20.1; xent: 3.0; lr: 0.00100; sents:      12; bsz:   31/  39/12; 502/632 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:42,847 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.013063192367553711 s.\n",
            "[2026-01-22 15:45:42,847][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.013063192367553711 s.\n",
            "[2026-01-22 15:45:42,848 INFO] Train perplexity: 21.3831\n",
            "[2026-01-22 15:45:42,848][onmt][INFO] - Train perplexity: 21.3831\n",
            "[2026-01-22 15:45:42,849 INFO] Train accuracy: 24.6154\n",
            "[2026-01-22 15:45:42,849][onmt][INFO] - Train accuracy: 24.6154\n",
            "[2026-01-22 15:45:42,849 INFO] Sentences processed: 60\n",
            "[2026-01-22 15:45:42,849][onmt][INFO] - Sentences processed: 60\n",
            "[2026-01-22 15:45:42,849 INFO] Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,849][onmt][INFO] - Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,849 INFO] Validation perplexity: 20.8341\n",
            "[2026-01-22 15:45:42,849][onmt][INFO] - Validation perplexity: 20.8341\n",
            "[2026-01-22 15:45:42,849 INFO] Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,849][onmt][INFO] - Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,849 INFO] Stalled patience: 1/5\n",
            "[2026-01-22 15:45:42,849][onmt][INFO] - Stalled patience: 1/5\n",
            "[2026-01-22 15:45:42,849 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2026-01-22 15:45:42,849][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2026-01-22 15:45:42,919 INFO] Step  6/  100; acc: 30.8; ppl:  19.8; xent: 3.0; lr: 0.00100; sents:      12; bsz:   31/  39/12; 362/456 tok/s;      1 sec;\n",
            "[2026-01-22 15:45:42,919][onmt][INFO] - Step  6/  100; acc: 30.8; ppl:  19.8; xent: 3.0; lr: 0.00100; sents:      12; bsz:   31/  39/12; 362/456 tok/s;      1 sec;\n",
            "[2026-01-22 15:45:42,932 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.011816263198852539 s.\n",
            "[2026-01-22 15:45:42,932][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.011816263198852539 s.\n",
            "[2026-01-22 15:45:42,933 INFO] Train perplexity: 21.1113\n",
            "[2026-01-22 15:45:42,933][onmt][INFO] - Train perplexity: 21.1113\n",
            "[2026-01-22 15:45:42,933 INFO] Train accuracy: 25.641\n",
            "[2026-01-22 15:45:42,933][onmt][INFO] - Train accuracy: 25.641\n",
            "[2026-01-22 15:45:42,933 INFO] Sentences processed: 72\n",
            "[2026-01-22 15:45:42,933][onmt][INFO] - Sentences processed: 72\n",
            "[2026-01-22 15:45:42,933 INFO] Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,933][onmt][INFO] - Average bsz:   31/  39/12\n",
            "[2026-01-22 15:45:42,933 INFO] Validation perplexity: 20.5959\n",
            "[2026-01-22 15:45:42,933][onmt][INFO] - Validation perplexity: 20.5959\n",
            "[2026-01-22 15:45:42,933 INFO] Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,933][onmt][INFO] - Validation accuracy: 32.1429\n",
            "[2026-01-22 15:45:42,933 INFO] Stalled patience: 0/5\n",
            "[2026-01-22 15:45:42,933][onmt][INFO] - Stalled patience: 0/5\n",
            "[2026-01-22 15:45:42,933 INFO] Training finished after stalled validations. Early Stop!\n",
            "[2026-01-22 15:45:42,933][onmt][INFO] - Training finished after stalled validations. Early Stop!\n",
            "[2026-01-22 15:45:42,933 INFO] Best model found at step 1\n",
            "[2026-01-22 15:45:42,933][onmt][INFO] - Best model found at step 1\n",
            "[2026-01-22 15:45:42,934 INFO] earlystopper has_stopped!\n",
            "[2026-01-22 15:45:42,934][onmt][INFO] - earlystopper has_stopped!\n",
            "[2026-01-22 15:45:42,935 INFO] Saving checkpoint ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f0._step_6.pt\n",
            "[2026-01-22 15:45:42,935][onmt][INFO] - Saving checkpoint ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f0._step_6.pt\n",
            "[2026-01-22 15:45:42,989][mdl.nmt][INFO] - \u001b[94mOverriding onmt config for train for fold1 in ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f1.config.yml ...\u001b[0m\n",
            "[2026-01-22 15:45:43,004 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2026-01-22 15:45:43,004][onmt][WARNING] - Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2026-01-22 15:45:43,005 INFO] Missing transforms field for valid data, set to default: [].\n",
            "[2026-01-22 15:45:43,005][onmt][INFO] - Missing transforms field for valid data, set to default: [].\n",
            "[2026-01-22 15:45:43,006 INFO] Parsed 2 corpora from -data.\n",
            "[2026-01-22 15:45:43,006][onmt][INFO] - Parsed 2 corpora from -data.\n",
            "[2026-01-22 15:45:43,006 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2026-01-22 15:45:43,006][onmt][INFO] - Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2026-01-22 15:45:43,009 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 's1', 's5', 's4', 's8', 's6', 's7']\n",
            "[2026-01-22 15:45:43,009][onmt][INFO] - The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 's1', 's5', 's4', 's8', 's6', 's7']\n",
            "[2026-01-22 15:45:43,009 INFO] The decoder start token is: <s>\n",
            "[2026-01-22 15:45:43,009][onmt][INFO] - The decoder start token is: <s>\n",
            "[2026-01-22 15:45:43,009 INFO] Building model...\n",
            "[2026-01-22 15:45:43,009][onmt][INFO] - Building model...\n",
            "[2026-01-22 15:45:43,061 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2026-01-22 15:45:43,061][onmt][INFO] - Switching model to float32 for amp/apex_amp\n",
            "[2026-01-22 15:45:43,061 INFO] Non quantized layer compute is fp16\n",
            "[2026-01-22 15:45:43,061][onmt][INFO] - Non quantized layer compute is fp16\n",
            "[2026-01-22 15:45:43,063 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(16, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-3): 4 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(24, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-3): 4 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=128, out_features=24, bias=True)\n",
            ")\n",
            "[2026-01-22 15:45:43,063][onmt][INFO] - NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(16, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-3): 4 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(24, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-3): 4 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=128, out_features=24, bias=True)\n",
            ")\n",
            "[2026-01-22 15:45:43,065 INFO] encoder: 790784\n",
            "[2026-01-22 15:45:43,065][onmt][INFO] - encoder: 790784\n",
            "[2026-01-22 15:45:43,065 INFO] decoder: 1058072\n",
            "[2026-01-22 15:45:43,065][onmt][INFO] - decoder: 1058072\n",
            "[2026-01-22 15:45:43,066 INFO] * number of parameters: 1848856\n",
            "[2026-01-22 15:45:43,066][onmt][INFO] - * number of parameters: 1848856\n",
            "[2026-01-22 15:45:43,066 INFO] Trainable parameters = {'torch.float32': 1848856, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:43,066][onmt][INFO] - Trainable parameters = {'torch.float32': 1848856, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:43,066 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:43,066][onmt][INFO] - Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:43,066 INFO]  * src vocab size = 16\n",
            "[2026-01-22 15:45:43,066][onmt][INFO] -  * src vocab size = 16\n",
            "[2026-01-22 15:45:43,066 INFO]  * tgt vocab size = 24\n",
            "[2026-01-22 15:45:43,066][onmt][INFO] -  * tgt vocab size = 24\n",
            "[2026-01-22 15:45:43,068 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2026-01-22 15:45:43,068][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2026-01-22 15:45:43,069 INFO] Starting training on CPU, could be very slow\n",
            "[2026-01-22 15:45:43,069][onmt][INFO] - Starting training on CPU, could be very slow\n",
            "[2026-01-22 15:45:43,069 INFO] Start training loop and validate every 1 steps...\n",
            "[2026-01-22 15:45:43,069][onmt][INFO] - Start training loop and validate every 1 steps...\n",
            "[2026-01-22 15:45:43,069 INFO] Scoring with: TransformPipe()\n",
            "[2026-01-22 15:45:43,069][onmt][INFO] - Scoring with: TransformPipe()\n",
            "[2026-01-22 15:45:43,136 INFO] Step  1/  100; acc: 7.5; ppl:  24.4; xent: 3.2; lr: 0.00100; sents:      12; bsz:   29/  40/12; 435/601 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,136][onmt][INFO] - Step  1/  100; acc: 7.5; ppl:  24.4; xent: 3.2; lr: 0.00100; sents:      12; bsz:   29/  40/12; 435/601 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,150 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.013086080551147461 s.\n",
            "[2026-01-22 15:45:43,150][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.013086080551147461 s.\n",
            "[2026-01-22 15:45:43,151 INFO] Train perplexity: 24.379\n",
            "[2026-01-22 15:45:43,151][onmt][INFO] - Train perplexity: 24.379\n",
            "[2026-01-22 15:45:43,151 INFO] Train accuracy: 7.5\n",
            "[2026-01-22 15:45:43,151][onmt][INFO] - Train accuracy: 7.5\n",
            "[2026-01-22 15:45:43,151 INFO] Sentences processed: 12\n",
            "[2026-01-22 15:45:43,151][onmt][INFO] - Sentences processed: 12\n",
            "[2026-01-22 15:45:43,151 INFO] Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,151][onmt][INFO] - Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,151 INFO] Validation perplexity: 22.1392\n",
            "[2026-01-22 15:45:43,151][onmt][INFO] - Validation perplexity: 22.1392\n",
            "[2026-01-22 15:45:43,151 INFO] Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,151][onmt][INFO] - Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,151 INFO] Model is improving acc: -inf --> 33.3333.\n",
            "[2026-01-22 15:45:43,151][onmt][INFO] - Model is improving acc: -inf --> 33.3333.\n",
            "[2026-01-22 15:45:43,152 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2026-01-22 15:45:43,152][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2026-01-22 15:45:43,199 INFO] Step  2/  100; acc: 30.0; ppl:  22.2; xent: 3.1; lr: 0.00100; sents:      12; bsz:   29/  40/12; 457/631 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,199][onmt][INFO] - Step  2/  100; acc: 30.0; ppl:  22.2; xent: 3.1; lr: 0.00100; sents:      12; bsz:   29/  40/12; 457/631 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,212 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.011361360549926758 s.\n",
            "[2026-01-22 15:45:43,212][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.011361360549926758 s.\n",
            "[2026-01-22 15:45:43,213 INFO] Train perplexity: 23.2411\n",
            "[2026-01-22 15:45:43,213][onmt][INFO] - Train perplexity: 23.2411\n",
            "[2026-01-22 15:45:43,213 INFO] Train accuracy: 18.75\n",
            "[2026-01-22 15:45:43,213][onmt][INFO] - Train accuracy: 18.75\n",
            "[2026-01-22 15:45:43,213 INFO] Sentences processed: 24\n",
            "[2026-01-22 15:45:43,213][onmt][INFO] - Sentences processed: 24\n",
            "[2026-01-22 15:45:43,213 INFO] Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,213][onmt][INFO] - Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,213 INFO] Validation perplexity: 21.3899\n",
            "[2026-01-22 15:45:43,213][onmt][INFO] - Validation perplexity: 21.3899\n",
            "[2026-01-22 15:45:43,214 INFO] Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,214][onmt][INFO] - Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,214 INFO] Stalled patience: 4/5\n",
            "[2026-01-22 15:45:43,214][onmt][INFO] - Stalled patience: 4/5\n",
            "[2026-01-22 15:45:43,214 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2026-01-22 15:45:43,214][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2026-01-22 15:45:43,261 INFO] Step  3/  100; acc: 30.0; ppl:  21.3; xent: 3.1; lr: 0.00100; sents:      12; bsz:   29/  40/12; 477/658 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,261][onmt][INFO] - Step  3/  100; acc: 30.0; ppl:  21.3; xent: 3.1; lr: 0.00100; sents:      12; bsz:   29/  40/12; 477/658 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,273 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.01154184341430664 s.\n",
            "[2026-01-22 15:45:43,273][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.01154184341430664 s.\n",
            "[2026-01-22 15:45:43,274 INFO] Train perplexity: 22.5822\n",
            "[2026-01-22 15:45:43,274][onmt][INFO] - Train perplexity: 22.5822\n",
            "[2026-01-22 15:45:43,275 INFO] Train accuracy: 22.5\n",
            "[2026-01-22 15:45:43,275][onmt][INFO] - Train accuracy: 22.5\n",
            "[2026-01-22 15:45:43,275 INFO] Sentences processed: 36\n",
            "[2026-01-22 15:45:43,275][onmt][INFO] - Sentences processed: 36\n",
            "[2026-01-22 15:45:43,275 INFO] Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,275][onmt][INFO] - Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,275 INFO] Validation perplexity: 21.0005\n",
            "[2026-01-22 15:45:43,275][onmt][INFO] - Validation perplexity: 21.0005\n",
            "[2026-01-22 15:45:43,275 INFO] Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,275][onmt][INFO] - Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,275 INFO] Stalled patience: 3/5\n",
            "[2026-01-22 15:45:43,275][onmt][INFO] - Stalled patience: 3/5\n",
            "[2026-01-22 15:45:43,275 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2026-01-22 15:45:43,275][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2026-01-22 15:45:43,328 INFO] Step  4/  100; acc: 30.0; ppl:  20.8; xent: 3.0; lr: 0.00100; sents:      12; bsz:   29/  40/12; 431/594 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,328][onmt][INFO] - Step  4/  100; acc: 30.0; ppl:  20.8; xent: 3.0; lr: 0.00100; sents:      12; bsz:   29/  40/12; 431/594 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,343 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.013019084930419922 s.\n",
            "[2026-01-22 15:45:43,343][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.013019084930419922 s.\n",
            "[2026-01-22 15:45:43,344 INFO] Train perplexity: 22.1316\n",
            "[2026-01-22 15:45:43,344][onmt][INFO] - Train perplexity: 22.1316\n",
            "[2026-01-22 15:45:43,344 INFO] Train accuracy: 24.375\n",
            "[2026-01-22 15:45:43,344][onmt][INFO] - Train accuracy: 24.375\n",
            "[2026-01-22 15:45:43,344 INFO] Sentences processed: 48\n",
            "[2026-01-22 15:45:43,344][onmt][INFO] - Sentences processed: 48\n",
            "[2026-01-22 15:45:43,344 INFO] Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,344][onmt][INFO] - Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,344 INFO] Validation perplexity: 20.7391\n",
            "[2026-01-22 15:45:43,344][onmt][INFO] - Validation perplexity: 20.7391\n",
            "[2026-01-22 15:45:43,344 INFO] Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,344][onmt][INFO] - Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,344 INFO] Stalled patience: 2/5\n",
            "[2026-01-22 15:45:43,344][onmt][INFO] - Stalled patience: 2/5\n",
            "[2026-01-22 15:45:43,345 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2026-01-22 15:45:43,345][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2026-01-22 15:45:43,394 INFO] Step  5/  100; acc: 30.0; ppl:  20.4; xent: 3.0; lr: 0.00100; sents:      12; bsz:   29/  40/12; 447/616 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,394][onmt][INFO] - Step  5/  100; acc: 30.0; ppl:  20.4; xent: 3.0; lr: 0.00100; sents:      12; bsz:   29/  40/12; 447/616 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,407 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.01165628433227539 s.\n",
            "[2026-01-22 15:45:43,407][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.01165628433227539 s.\n",
            "[2026-01-22 15:45:43,408 INFO] Train perplexity: 21.7658\n",
            "[2026-01-22 15:45:43,408][onmt][INFO] - Train perplexity: 21.7658\n",
            "[2026-01-22 15:45:43,408 INFO] Train accuracy: 25.5\n",
            "[2026-01-22 15:45:43,408][onmt][INFO] - Train accuracy: 25.5\n",
            "[2026-01-22 15:45:43,408 INFO] Sentences processed: 60\n",
            "[2026-01-22 15:45:43,408][onmt][INFO] - Sentences processed: 60\n",
            "[2026-01-22 15:45:43,408 INFO] Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,408][onmt][INFO] - Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,408 INFO] Validation perplexity: 20.5143\n",
            "[2026-01-22 15:45:43,408][onmt][INFO] - Validation perplexity: 20.5143\n",
            "[2026-01-22 15:45:43,408 INFO] Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,408][onmt][INFO] - Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,408 INFO] Stalled patience: 1/5\n",
            "[2026-01-22 15:45:43,408][onmt][INFO] - Stalled patience: 1/5\n",
            "[2026-01-22 15:45:43,409 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2026-01-22 15:45:43,409][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2026-01-22 15:45:43,455 INFO] Step  6/  100; acc: 30.0; ppl:  20.0; xent: 3.0; lr: 0.00100; sents:      12; bsz:   29/  40/12; 483/666 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,455][onmt][INFO] - Step  6/  100; acc: 30.0; ppl:  20.0; xent: 3.0; lr: 0.00100; sents:      12; bsz:   29/  40/12; 483/666 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,469 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.013422727584838867 s.\n",
            "[2026-01-22 15:45:43,469][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.013422727584838867 s.\n",
            "[2026-01-22 15:45:43,470 INFO] Train perplexity: 21.4652\n",
            "[2026-01-22 15:45:43,470][onmt][INFO] - Train perplexity: 21.4652\n",
            "[2026-01-22 15:45:43,470 INFO] Train accuracy: 26.25\n",
            "[2026-01-22 15:45:43,470][onmt][INFO] - Train accuracy: 26.25\n",
            "[2026-01-22 15:45:43,471 INFO] Sentences processed: 72\n",
            "[2026-01-22 15:45:43,471][onmt][INFO] - Sentences processed: 72\n",
            "[2026-01-22 15:45:43,471 INFO] Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,471][onmt][INFO] - Average bsz:   29/  40/12\n",
            "[2026-01-22 15:45:43,471 INFO] Validation perplexity: 20.304\n",
            "[2026-01-22 15:45:43,471][onmt][INFO] - Validation perplexity: 20.304\n",
            "[2026-01-22 15:45:43,471 INFO] Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,471][onmt][INFO] - Validation accuracy: 33.3333\n",
            "[2026-01-22 15:45:43,471 INFO] Stalled patience: 0/5\n",
            "[2026-01-22 15:45:43,471][onmt][INFO] - Stalled patience: 0/5\n",
            "[2026-01-22 15:45:43,471 INFO] Training finished after stalled validations. Early Stop!\n",
            "[2026-01-22 15:45:43,471][onmt][INFO] - Training finished after stalled validations. Early Stop!\n",
            "[2026-01-22 15:45:43,471 INFO] Best model found at step 1\n",
            "[2026-01-22 15:45:43,471][onmt][INFO] - Best model found at step 1\n",
            "[2026-01-22 15:45:43,471 INFO] earlystopper has_stopped!\n",
            "[2026-01-22 15:45:43,471][onmt][INFO] - earlystopper has_stopped!\n",
            "[2026-01-22 15:45:43,472 INFO] Saving checkpoint ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f1._step_6.pt\n",
            "[2026-01-22 15:45:43,472][onmt][INFO] - Saving checkpoint ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f1._step_6.pt\n",
            "[2026-01-22 15:45:43,520][mdl.nmt][INFO] - \u001b[94mOverriding onmt config for train for fold2 in ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f2.config.yml ...\u001b[0m\n",
            "[2026-01-22 15:45:43,535 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2026-01-22 15:45:43,535][onmt][WARNING] - Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2026-01-22 15:45:43,535 INFO] Missing transforms field for valid data, set to default: [].\n",
            "[2026-01-22 15:45:43,535][onmt][INFO] - Missing transforms field for valid data, set to default: [].\n",
            "[2026-01-22 15:45:43,535 INFO] Parsed 2 corpora from -data.\n",
            "[2026-01-22 15:45:43,535][onmt][INFO] - Parsed 2 corpora from -data.\n",
            "[2026-01-22 15:45:43,535 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2026-01-22 15:45:43,535][onmt][INFO] - Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2026-01-22 15:45:43,538 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 's5', 's1', 's4', 's6', 's7', 's8']\n",
            "[2026-01-22 15:45:43,538][onmt][INFO] - The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', 's5', 's1', 's4', 's6', 's7', 's8']\n",
            "[2026-01-22 15:45:43,538 INFO] The decoder start token is: <s>\n",
            "[2026-01-22 15:45:43,538][onmt][INFO] - The decoder start token is: <s>\n",
            "[2026-01-22 15:45:43,538 INFO] Building model...\n",
            "[2026-01-22 15:45:43,538][onmt][INFO] - Building model...\n",
            "[2026-01-22 15:45:43,582 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2026-01-22 15:45:43,582][onmt][INFO] - Switching model to float32 for amp/apex_amp\n",
            "[2026-01-22 15:45:43,582 INFO] Non quantized layer compute is fp16\n",
            "[2026-01-22 15:45:43,582][onmt][INFO] - Non quantized layer compute is fp16\n",
            "[2026-01-22 15:45:43,585 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(16, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-3): 4 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(16, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-3): 4 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=128, out_features=16, bias=True)\n",
            ")\n",
            "[2026-01-22 15:45:43,585][onmt][INFO] - NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(16, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-3): 4 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(16, 128, padding_idx=1)\n",
            "        )\n",
            "      )\n",
            "      (dropout): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-3): 4 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=128, out_features=512, bias=False)\n",
            "          (w_2): Linear(in_features=512, out_features=128, bias=False)\n",
            "          (layer_norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_values): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (linear_query): Linear(in_features=128, out_features=128, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "          (final_linear): Linear(in_features=128, out_features=128, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=128, out_features=16, bias=True)\n",
            ")\n",
            "[2026-01-22 15:45:43,589 INFO] encoder: 790784\n",
            "[2026-01-22 15:45:43,589][onmt][INFO] - encoder: 790784\n",
            "[2026-01-22 15:45:43,589 INFO] decoder: 1056016\n",
            "[2026-01-22 15:45:43,589][onmt][INFO] - decoder: 1056016\n",
            "[2026-01-22 15:45:43,589 INFO] * number of parameters: 1846800\n",
            "[2026-01-22 15:45:43,589][onmt][INFO] - * number of parameters: 1846800\n",
            "[2026-01-22 15:45:43,590 INFO] Trainable parameters = {'torch.float32': 1846800, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:43,590][onmt][INFO] - Trainable parameters = {'torch.float32': 1846800, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:43,590 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:43,590][onmt][INFO] - Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2026-01-22 15:45:43,590 INFO]  * src vocab size = 16\n",
            "[2026-01-22 15:45:43,590][onmt][INFO] -  * src vocab size = 16\n",
            "[2026-01-22 15:45:43,590 INFO]  * tgt vocab size = 16\n",
            "[2026-01-22 15:45:43,590][onmt][INFO] -  * tgt vocab size = 16\n",
            "[2026-01-22 15:45:43,592 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2026-01-22 15:45:43,592][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2026-01-22 15:45:43,592 INFO] Starting training on CPU, could be very slow\n",
            "[2026-01-22 15:45:43,592][onmt][INFO] - Starting training on CPU, could be very slow\n",
            "[2026-01-22 15:45:43,592 INFO] Start training loop and validate every 1 steps...\n",
            "[2026-01-22 15:45:43,592][onmt][INFO] - Start training loop and validate every 1 steps...\n",
            "[2026-01-22 15:45:43,592 INFO] Scoring with: TransformPipe()\n",
            "[2026-01-22 15:45:43,592][onmt][INFO] - Scoring with: TransformPipe()\n",
            "[2026-01-22 15:45:43,640 INFO] Step  1/  100; acc: 6.1; ppl:  15.9; xent: 2.8; lr: 0.00100; sents:      11; bsz:   25/  33/11; 526/694 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,640][onmt][INFO] - Step  1/  100; acc: 6.1; ppl:  15.9; xent: 2.8; lr: 0.00100; sents:      11; bsz:   25/  33/11; 526/694 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,654 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.013150453567504883 s.\n",
            "[2026-01-22 15:45:43,654][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.013150453567504883 s.\n",
            "[2026-01-22 15:45:43,655 INFO] Train perplexity: 15.9499\n",
            "[2026-01-22 15:45:43,655][onmt][INFO] - Train perplexity: 15.9499\n",
            "[2026-01-22 15:45:43,655 INFO] Train accuracy: 6.06061\n",
            "[2026-01-22 15:45:43,655][onmt][INFO] - Train accuracy: 6.06061\n",
            "[2026-01-22 15:45:43,655 INFO] Sentences processed: 11\n",
            "[2026-01-22 15:45:43,655][onmt][INFO] - Sentences processed: 11\n",
            "[2026-01-22 15:45:43,655 INFO] Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,655][onmt][INFO] - Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,656 INFO] Validation perplexity: 14.8985\n",
            "[2026-01-22 15:45:43,656][onmt][INFO] - Validation perplexity: 14.8985\n",
            "[2026-01-22 15:45:43,656 INFO] Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,656][onmt][INFO] - Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,656 INFO] Model is improving acc: -inf --> 28.5714.\n",
            "[2026-01-22 15:45:43,656][onmt][INFO] - Model is improving acc: -inf --> 28.5714.\n",
            "[2026-01-22 15:45:43,656 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2026-01-22 15:45:43,656][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2026-01-22 15:45:43,706 INFO] Step  2/  100; acc: 33.3; ppl:  14.8; xent: 2.7; lr: 0.00100; sents:      11; bsz:   25/  33/11; 379/500 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,706][onmt][INFO] - Step  2/  100; acc: 33.3; ppl:  14.8; xent: 2.7; lr: 0.00100; sents:      11; bsz:   25/  33/11; 379/500 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,719 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.011389732360839844 s.\n",
            "[2026-01-22 15:45:43,719][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.011389732360839844 s.\n",
            "[2026-01-22 15:45:43,720 INFO] Train perplexity: 15.3584\n",
            "[2026-01-22 15:45:43,720][onmt][INFO] - Train perplexity: 15.3584\n",
            "[2026-01-22 15:45:43,720 INFO] Train accuracy: 19.697\n",
            "[2026-01-22 15:45:43,720][onmt][INFO] - Train accuracy: 19.697\n",
            "[2026-01-22 15:45:43,720 INFO] Sentences processed: 22\n",
            "[2026-01-22 15:45:43,720][onmt][INFO] - Sentences processed: 22\n",
            "[2026-01-22 15:45:43,720 INFO] Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,720][onmt][INFO] - Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,720 INFO] Validation perplexity: 14.5606\n",
            "[2026-01-22 15:45:43,720][onmt][INFO] - Validation perplexity: 14.5606\n",
            "[2026-01-22 15:45:43,720 INFO] Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,720][onmt][INFO] - Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,720 INFO] Stalled patience: 4/5\n",
            "[2026-01-22 15:45:43,720][onmt][INFO] - Stalled patience: 4/5\n",
            "[2026-01-22 15:45:43,721 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2026-01-22 15:45:43,721][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2026-01-22 15:45:43,764 INFO] Step  3/  100; acc: 33.3; ppl:  14.4; xent: 2.7; lr: 0.00100; sents:      11; bsz:   25/  33/11; 438/578 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,764][onmt][INFO] - Step  3/  100; acc: 33.3; ppl:  14.4; xent: 2.7; lr: 0.00100; sents:      11; bsz:   25/  33/11; 438/578 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,776 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.011155843734741211 s.\n",
            "[2026-01-22 15:45:43,776][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.011155843734741211 s.\n",
            "[2026-01-22 15:45:43,777 INFO] Train perplexity: 15.0235\n",
            "[2026-01-22 15:45:43,777][onmt][INFO] - Train perplexity: 15.0235\n",
            "[2026-01-22 15:45:43,777 INFO] Train accuracy: 24.2424\n",
            "[2026-01-22 15:45:43,777][onmt][INFO] - Train accuracy: 24.2424\n",
            "[2026-01-22 15:45:43,777 INFO] Sentences processed: 33\n",
            "[2026-01-22 15:45:43,777][onmt][INFO] - Sentences processed: 33\n",
            "[2026-01-22 15:45:43,777 INFO] Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,777][onmt][INFO] - Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,777 INFO] Validation perplexity: 14.3916\n",
            "[2026-01-22 15:45:43,777][onmt][INFO] - Validation perplexity: 14.3916\n",
            "[2026-01-22 15:45:43,777 INFO] Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,777][onmt][INFO] - Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,778 INFO] Stalled patience: 3/5\n",
            "[2026-01-22 15:45:43,778][onmt][INFO] - Stalled patience: 3/5\n",
            "[2026-01-22 15:45:43,778 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2026-01-22 15:45:43,778][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2026-01-22 15:45:43,823 INFO] Step  4/  100; acc: 33.3; ppl:  14.0; xent: 2.6; lr: 0.00100; sents:      11; bsz:   25/  33/11; 428/565 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,823][onmt][INFO] - Step  4/  100; acc: 33.3; ppl:  14.0; xent: 2.6; lr: 0.00100; sents:      11; bsz:   25/  33/11; 428/565 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,835 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.010723590850830078 s.\n",
            "[2026-01-22 15:45:43,835][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.010723590850830078 s.\n",
            "[2026-01-22 15:45:43,835 INFO] Train perplexity: 14.7569\n",
            "[2026-01-22 15:45:43,835][onmt][INFO] - Train perplexity: 14.7569\n",
            "[2026-01-22 15:45:43,836 INFO] Train accuracy: 26.5152\n",
            "[2026-01-22 15:45:43,836][onmt][INFO] - Train accuracy: 26.5152\n",
            "[2026-01-22 15:45:43,836 INFO] Sentences processed: 44\n",
            "[2026-01-22 15:45:43,836][onmt][INFO] - Sentences processed: 44\n",
            "[2026-01-22 15:45:43,836 INFO] Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,836][onmt][INFO] - Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,836 INFO] Validation perplexity: 14.2808\n",
            "[2026-01-22 15:45:43,836][onmt][INFO] - Validation perplexity: 14.2808\n",
            "[2026-01-22 15:45:43,836 INFO] Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,836][onmt][INFO] - Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,836 INFO] Stalled patience: 2/5\n",
            "[2026-01-22 15:45:43,836][onmt][INFO] - Stalled patience: 2/5\n",
            "[2026-01-22 15:45:43,836 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2026-01-22 15:45:43,836][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2026-01-22 15:45:43,884 INFO] Step  5/  100; acc: 33.3; ppl:  13.9; xent: 2.6; lr: 0.00100; sents:      11; bsz:   25/  33/11; 408/539 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,884][onmt][INFO] - Step  5/  100; acc: 33.3; ppl:  13.9; xent: 2.6; lr: 0.00100; sents:      11; bsz:   25/  33/11; 408/539 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,902 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.016457080841064453 s.\n",
            "[2026-01-22 15:45:43,902][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.016457080841064453 s.\n",
            "[2026-01-22 15:45:43,904 INFO] Train perplexity: 14.5798\n",
            "[2026-01-22 15:45:43,904][onmt][INFO] - Train perplexity: 14.5798\n",
            "[2026-01-22 15:45:43,904 INFO] Train accuracy: 27.8788\n",
            "[2026-01-22 15:45:43,904][onmt][INFO] - Train accuracy: 27.8788\n",
            "[2026-01-22 15:45:43,904 INFO] Sentences processed: 55\n",
            "[2026-01-22 15:45:43,904][onmt][INFO] - Sentences processed: 55\n",
            "[2026-01-22 15:45:43,904 INFO] Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,904][onmt][INFO] - Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,904 INFO] Validation perplexity: 14.1932\n",
            "[2026-01-22 15:45:43,904][onmt][INFO] - Validation perplexity: 14.1932\n",
            "[2026-01-22 15:45:43,904 INFO] Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,904][onmt][INFO] - Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,904 INFO] Stalled patience: 1/5\n",
            "[2026-01-22 15:45:43,904][onmt][INFO] - Stalled patience: 1/5\n",
            "[2026-01-22 15:45:43,905 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2026-01-22 15:45:43,905][onmt][INFO] - Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2026-01-22 15:45:43,957 INFO] Step  6/  100; acc: 33.3; ppl:  13.6; xent: 2.6; lr: 0.00100; sents:      11; bsz:   25/  33/11; 347/459 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,957][onmt][INFO] - Step  6/  100; acc: 33.3; ppl:  13.6; xent: 2.6; lr: 0.00100; sents:      11; bsz:   25/  33/11; 347/459 tok/s;      0 sec;\n",
            "[2026-01-22 15:45:43,968 INFO] valid stats calculation and sentences rebuilding\n",
            "                           took: 0.010404825210571289 s.\n",
            "[2026-01-22 15:45:43,968][onmt][INFO] - valid stats calculation and sentences rebuilding\n",
            "                           took: 0.010404825210571289 s.\n",
            "[2026-01-22 15:45:43,969 INFO] Train perplexity: 14.4201\n",
            "[2026-01-22 15:45:43,969][onmt][INFO] - Train perplexity: 14.4201\n",
            "[2026-01-22 15:45:43,969 INFO] Train accuracy: 28.7879\n",
            "[2026-01-22 15:45:43,969][onmt][INFO] - Train accuracy: 28.7879\n",
            "[2026-01-22 15:45:43,969 INFO] Sentences processed: 66\n",
            "[2026-01-22 15:45:43,969][onmt][INFO] - Sentences processed: 66\n",
            "[2026-01-22 15:45:43,969 INFO] Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,969][onmt][INFO] - Average bsz:   25/  33/11\n",
            "[2026-01-22 15:45:43,969 INFO] Validation perplexity: 14.1117\n",
            "[2026-01-22 15:45:43,969][onmt][INFO] - Validation perplexity: 14.1117\n",
            "[2026-01-22 15:45:43,969 INFO] Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,969][onmt][INFO] - Validation accuracy: 28.5714\n",
            "[2026-01-22 15:45:43,969 INFO] Stalled patience: 0/5\n",
            "[2026-01-22 15:45:43,969][onmt][INFO] - Stalled patience: 0/5\n",
            "[2026-01-22 15:45:43,970 INFO] Training finished after stalled validations. Early Stop!\n",
            "[2026-01-22 15:45:43,970][onmt][INFO] - Training finished after stalled validations. Early Stop!\n",
            "[2026-01-22 15:45:43,970 INFO] Best model found at step 1\n",
            "[2026-01-22 15:45:43,970][onmt][INFO] - Best model found at step 1\n",
            "[2026-01-22 15:45:43,970 INFO] earlystopper has_stopped!\n",
            "[2026-01-22 15:45:43,970][onmt][INFO] - earlystopper has_stopped!\n",
            "[2026-01-22 15:45:43,971 INFO] Saving checkpoint ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f2._step_6.pt\n",
            "[2026-01-22 15:45:43,971][onmt][INFO] - Saving checkpoint ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f2._step_6.pt\n",
            "[2026-01-22 15:45:44,005][__main__][INFO] - \u001b[92mTesting team recommender instance mdl.nmt.Nmt ... \u001b[0m\n",
            "onmt_translate -model ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f0._step_6.pt -src ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/src-test.txt -output ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f0.test.e6.pred_ --min_length 2 --max_length 100 --beam_size 10 --n_best 1 --replace_unk -verbose \n",
            "[2026-01-22 15:45:45,356][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:45,355 INFO] Loading checkpoint from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f0._step_6.pt\n",
            "[2026-01-22 15:45:45,421][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:45,421 INFO] Loading data into the model\n",
            "[2026-01-22 15:45:45,475][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:45,475 INFO]\n",
            "[2026-01-22 15:45:45,475][mdl.nmt][INFO] - [onmt_translate] SENT 1: ['s1', 's3']\n",
            "[2026-01-22 15:45:45,475][mdl.nmt][INFO] - [onmt_translate] PRED 1: m11 m11\n",
            "[2026-01-22 15:45:45,475][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -2.0992\n",
            "[2026-01-22 15:45:45,475][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:45,475][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:45,475 INFO]\n",
            "[2026-01-22 15:45:45,475][mdl.nmt][INFO] - [onmt_translate] SENT 2: ['s5', 's6', 's7']\n",
            "[2026-01-22 15:45:45,475][mdl.nmt][INFO] - [onmt_translate] PRED 2: m11 m11\n",
            "[2026-01-22 15:45:45,475][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -2.0968\n",
            "[2026-01-22 15:45:45,475][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:45,475 INFO]\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] SENT 3: ['s5', 's8']\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] PRED 3: m11 m11\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -2.0979\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:45,475 INFO]\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] SENT 4: ['s1', 's6', 's7']\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] PRED 4: m11 m11\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -2.0978\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:45,475 INFO]\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] SENT 5: ['s5', 's6']\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] PRED 5: m11 m11\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -2.0975\n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:45,476][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:45,475 INFO] PRED SCORE: -2.0979, PRED PPL: 8.15 NB SENTENCES: 5\n",
            "onmt_translate -model ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f1._step_6.pt -src ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/src-test.txt -output ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f1.test.e6.pred_ --min_length 2 --max_length 100 --beam_size 10 --n_best 1 --replace_unk -verbose \n",
            "[2026-01-22 15:45:47,938][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:47,937 INFO] Loading checkpoint from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f1._step_6.pt\n",
            "[2026-01-22 15:45:48,022][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:48,022 INFO] Loading data into the model\n",
            "[2026-01-22 15:45:48,075][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:48,075 INFO]\n",
            "[2026-01-22 15:45:48,075][mdl.nmt][INFO] - [onmt_translate] SENT 1: ['s1', 's3']\n",
            "[2026-01-22 15:45:48,075][mdl.nmt][INFO] - [onmt_translate] PRED 1: m0 m0\n",
            "[2026-01-22 15:45:48,075][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -2.1397\n",
            "[2026-01-22 15:45:48,075][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:48,075][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:48,075 INFO]\n",
            "[2026-01-22 15:45:48,075][mdl.nmt][INFO] - [onmt_translate] SENT 2: ['s5', 's6', 's7']\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] PRED 2: m0 m0\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -2.1407\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:48,075 INFO]\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] SENT 3: ['s5', 's8']\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] PRED 3: m0 m0\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -2.1409\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:48,075 INFO]\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] SENT 4: ['s1', 's6', 's7']\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] PRED 4: m0 m0\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -2.1401\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:48,075 INFO]\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] SENT 5: ['s5', 's6']\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] PRED 5: m0 m0\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -2.1407\n",
            "[2026-01-22 15:45:48,076][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:48,077][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:48,075 INFO] PRED SCORE: -2.1404, PRED PPL: 8.50 NB SENTENCES: 5\n",
            "onmt_translate -model ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f2._step_6.pt -src ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/src-test.txt -output ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f2.test.e6.pred_ --min_length 2 --max_length 100 --beam_size 10 --n_best 1 --replace_unk -verbose \n",
            "[2026-01-22 15:45:50,129][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:50,129 INFO] Loading checkpoint from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f2._step_6.pt\n",
            "[2026-01-22 15:45:50,212][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:50,212 INFO] Loading data into the model\n",
            "[2026-01-22 15:45:50,246][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:50,246 INFO]\n",
            "[2026-01-22 15:45:50,246][mdl.nmt][INFO] - [onmt_translate] SENT 1: ['s1', 's3']\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] PRED 1: m10 m10\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -1.9181\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:50,246 INFO]\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] SENT 2: ['s5', 's6', 's7']\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] PRED 2: m10 m10\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -1.9176\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:50,246 INFO]\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] SENT 3: ['s5', 's8']\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] PRED 3: m10 m10\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -1.9163\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:50,246 INFO]\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] SENT 4: ['s1', 's6', 's7']\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] PRED 4: m10 m10\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -1.9174\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:50,246 INFO]\n",
            "[2026-01-22 15:45:50,247][mdl.nmt][INFO] - [onmt_translate] SENT 5: ['s5', 's6']\n",
            "[2026-01-22 15:45:50,248][mdl.nmt][INFO] - [onmt_translate] PRED 5: m10 m10\n",
            "[2026-01-22 15:45:50,248][mdl.nmt][INFO] - [onmt_translate] PRED SCORE: -1.9176\n",
            "[2026-01-22 15:45:50,248][mdl.nmt][INFO] - [onmt_translate] \n",
            "[2026-01-22 15:45:50,248][mdl.nmt][INFO] - [onmt_translate] [2026-01-22 15:45:50,247 INFO] PRED SCORE: -1.9174, PRED PPL: 6.80 NB SENTENCES: 5\n",
            "[2026-01-22 15:45:50,584][__main__][INFO] - \u001b[95mEvaluating team recommender instance mdl.nmt.Nmt ... \u001b[0m\n",
            "[2026-01-22 15:45:50,591][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f0.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-22 15:45:50,591][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-22 15:45:50,596][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3035.39it/s]\n",
            "[2026-01-22 15:45:50,601][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-22 15:45:50,606][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 278.07it/s]\n",
            "[2026-01-22 15:45:50,632][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f0.test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,634][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f0.test.e6.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-22 15:45:50,635][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-22 15:45:50,640][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3565.37it/s]\n",
            "[2026-01-22 15:45:50,643][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-22 15:45:50,647][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 331.30it/s]\n",
            "[2026-01-22 15:45:50,668][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f0.test.e6.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,671][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f1.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-22 15:45:50,672][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-22 15:45:50,676][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3918.45it/s]\n",
            "[2026-01-22 15:45:50,680][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-22 15:45:50,683][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 337.00it/s]\n",
            "[2026-01-22 15:45:50,704][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f1.test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,706][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f1.test.e6.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-22 15:45:50,707][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-22 15:45:50,712][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4001.43it/s]\n",
            "[2026-01-22 15:45:50,715][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-22 15:45:50,718][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 329.76it/s]\n",
            "[2026-01-22 15:45:50,740][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f1.test.e6.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,743][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f2.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-22 15:45:50,743][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-22 15:45:50,748][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3980.17it/s]\n",
            "[2026-01-22 15:45:50,751][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-22 15:45:50,754][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 326.90it/s]\n",
            "[2026-01-22 15:45:50,776][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f2.test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,778][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f2.test.e6.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-01-22 15:45:50,779][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-01-22 15:45:50,783][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3772.53it/s]\n",
            "[2026-01-22 15:45:50,787][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-01-22 15:45:50,790][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 328.10it/s]\n",
            "[2026-01-22 15:45:50,811][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/f2.test.e6.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,814][mdl.ntf][INFO] - Saving mean evaluation file over 3 folds as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,816][__main__][INFO] - \u001b[92mAggregating the test results under ../output/dblp/toy.dblp.v12.json per splits from test.pred.eval.mean.csv files ... \u001b[0m\n",
            "[2026-01-22 15:45:50,825][__main__][INFO] - \u001b[92m../output/dblp/toy.dblp.v12.json/splits.f3.r0.85 ... \u001b[0m\n",
            "[2026-01-22 15:45:50,825][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,828][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,833][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,836][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,838][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,841][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,844][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,849][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,853][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,856][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,858][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,862][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,866][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,869][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,872][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,874][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,878][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/d2v.d128.e100.w5.dm1.skill/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,882][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/d2v.d128.e100.w5.dm1.skill/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,886][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/d2v.d128.e100.w5.dm1.skill/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-01-22 15:45:50,893][__main__][INFO] - \u001b[92mSaved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/test.pred.eval.mean.agg.csv. \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/dblp/toy.dblp.v12.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feJf72sDElJ4",
        "outputId": "4912ea97-e405-4772-bc60-d06270a97d39"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c2g.pkl      indexes.pkl     splits.f3.r0.85\t  stm.add.graph.pkl\n",
            "females.csv  skill.docs.pkl  splits.f3.r0.85.pkl  teamsvecs.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu577_wqFMWq",
        "outputId": "ac0970f0-ca5e-4d6c-d2a7-17d03a3666b5",
        "collapsed": true
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f0.config.yml\t\t\t   f1.test.pred.eval.mean.csv\n",
            "f0.src-train.txt\t\t   f1.tgt-train.txt\n",
            "f0.src-valid.txt\t\t   f1.tgt-valid.txt\n",
            "f0._step_6.pt\t\t\t   f1.vocab.src\n",
            "f0.test.e6.pred\t\t\t   f1.vocab.tgt\n",
            "f0.test.e6.pred_\t\t   f2.config.yml\n",
            "f0.test.e6.pred.eval.instance.csv  f2.src-train.txt\n",
            "f0.test.e6.pred.eval.mean.csv\t   f2.src-valid.txt\n",
            "f0.test.pred\t\t\t   f2._step_6.pt\n",
            "f0.test.pred.eval.instance.csv\t   f2.test.e6.pred\n",
            "f0.test.pred.eval.mean.csv\t   f2.test.e6.pred_\n",
            "f0.tgt-train.txt\t\t   f2.test.e6.pred.eval.instance.csv\n",
            "f0.tgt-valid.txt\t\t   f2.test.e6.pred.eval.mean.csv\n",
            "f0.vocab.src\t\t\t   f2.test.pred\n",
            "f0.vocab.tgt\t\t\t   f2.test.pred.eval.instance.csv\n",
            "f1.config.yml\t\t\t   f2.test.pred.eval.mean.csv\n",
            "f1.src-train.txt\t\t   f2.tgt-train.txt\n",
            "f1.src-valid.txt\t\t   f2.tgt-valid.txt\n",
            "f1._step_6.pt\t\t\t   f2.vocab.src\n",
            "f1.test.e6.pred\t\t\t   f2.vocab.tgt\n",
            "f1.test.e6.pred_\t\t   src-test.txt\n",
            "f1.test.e6.pred.eval.instance.csv  test.pred.eval.instance_mean.csv\n",
            "f1.test.e6.pred.eval.mean.csv\t   test.pred.eval.mean.csv\n",
            "f1.test.pred\t\t\t   tgt-test.txt\n",
            "f1.test.pred.eval.instance.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('/content/opentf/output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/test.pred.eval.mean.csv', index_col = 0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "cnLNdZBjFiZv",
        "outputId": "f6bc2ab6-2e34-4ab6-8b92-72502a965cfb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       mean       std\n",
              "metrics                              \n",
              "P_2                0.166667  0.057735\n",
              "P_5                0.146667  0.023094\n",
              "P_10               0.153333  0.011547\n",
              "recall_2           0.166667  0.057735\n",
              "recall_5           0.333333  0.057735\n",
              "recall_10          0.666667  0.057735\n",
              "ndcg_cut_2         0.204382  0.070800\n",
              "ndcg_cut_5         0.288130  0.070800\n",
              "ndcg_cut_10        0.430639  0.070800\n",
              "map_cut_2          0.166667  0.057735\n",
              "map_cut_5          0.200000  0.057735\n",
              "map_cut_10         0.294180  0.051320\n",
              "success_2          0.333333  0.115470\n",
              "success_5          0.733333  0.115470\n",
              "success_10         0.866667  0.230940\n",
              "aucroc             0.544893  0.031589\n",
              "skill_coverage_2   0.777778  0.211695\n",
              "skill_coverage_5   1.000000  0.000000\n",
              "skill_coverage_10  1.000000  0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f071466a-4719-4491-97ac-f88c97b8fd06\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metrics</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>P_2</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.057735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_5</th>\n",
              "      <td>0.146667</td>\n",
              "      <td>0.023094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_10</th>\n",
              "      <td>0.153333</td>\n",
              "      <td>0.011547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_2</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.057735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_5</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.057735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_10</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.057735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_2</th>\n",
              "      <td>0.204382</td>\n",
              "      <td>0.070800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_5</th>\n",
              "      <td>0.288130</td>\n",
              "      <td>0.070800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <td>0.430639</td>\n",
              "      <td>0.070800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_2</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.057735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_5</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.057735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_10</th>\n",
              "      <td>0.294180</td>\n",
              "      <td>0.051320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_2</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.115470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_5</th>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.115470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_10</th>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.230940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aucroc</th>\n",
              "      <td>0.544893</td>\n",
              "      <td>0.031589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_2</th>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.211695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_5</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_10</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f071466a-4719-4491-97ac-f88c97b8fd06')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f071466a-4719-4491-97ac-f88c97b8fd06 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f071466a-4719-4491-97ac-f88c97b8fd06');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"metrics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"P_2\",\n          \"recall_10\",\n          \"map_cut_10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30218917493289615,\n        \"min\": 0.1466666666666667,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.2941798941798941,\n          0.8666666666666667,\n          0.1666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.061571602133605345,\n        \"min\": 0.0,\n        \"max\": 0.2309401076758503,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.2116950987028628,\n          0.023094010767585,\n          0.1154700538379251\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tmp_opentf",
      "language": "python",
      "name": "tmp_opentf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}