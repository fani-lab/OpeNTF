{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fani-lab/OpeNTF/blob/main/ipynb/fair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QGHFtvGnTLJ"
      },
      "source": [
        "`OpeNTF-Fair` via [`Adila`](https://github.com/fani-lab/Adila)\n",
        "\n",
        "<p align=\"center\"><img src='https://github.com/fani-lab/OpeNTF/blob/main/docs/figs/adila_.png?raw=true' width=\"400\" ></p>\n",
        "\n",
        "With [`Adila`](https://github.com/fani-lab/Adila)'s submodule in `OpeNTF`, we now have integrated fairness-aware reranking methods to rerank the final model's recommendation of experts for a team in order to dibiase `poularity` or `gender` disparities. To apply, `cmd=[..., fair]` and `fair.*` in [`./src/__config.yml`](https://github.com/fani-lab/OpeNTF/blob/main/src/__config__.yaml#L95C1-L110C24) should be set.\n",
        "\n",
        "  - **fair**.`fgender`, contains the `female` member ids as the `minority` also `protected` group.\n",
        "\n",
        "  > In `Adila`, we keep the labels of `minority` group for efficiency as they are very few relative to majority group. However, `protected` group could be the same as `minority` group, like in `gender` protected attribute, or the `majority` group (non-popular experts, who are more often than popular ones), like in `popularity` protected attribute.\n",
        "\n",
        "  - **fair.**`algorithm`, list of reranking algorithms from `det_greedy`, `det_cons`, `det_relaxed`, `det_const_sort`, `fa-ir`\n",
        "  - **fair.**`notion`, list of notions of fairness, from equality of odds (`eo`), demographic parity (`dp`)\n",
        "  - **fair.**`attribute`, list of protected attributes from `popularity`, `gender`\n",
        "  - **fair.**`is_popular_alg`, popularity status based on either `avg` teams per experts, i.e., whoever above this value is popular, or `auc` whoever is in the head of distribution figure, or both\n",
        "  - **fair.**`k_max`, cutoff for the reranking algorithms\n",
        "  - **fair.**`alpha`, the significance value for fa-ir algorithm\n",
        "  - **fair.**`acceleration`, 'cpu' for `all` cpu cores but one, 'cpu:n' for `n` cores\n",
        "\n",
        "```\n",
        "fair:\n",
        "  fgender: ../data/dblp/toy.dblp.v12.json.females.csv\n",
        "  algorithm: [fa-ir, det_greedy, det_relaxed, det_const_sort, det_cons]\n",
        "  notion: [eo,dp]\n",
        "  attribute: [gender, popularity]\n",
        "  is_popular_alg: [avg, auc]\n",
        "  k_max: 5\n",
        "  alpha: 0.1\n",
        "  acceleration: 'cpu:1'\n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "To **evaluate** the fair-accuracy trade-offs, fairness and accuracy metrics `before` and `after` applying reranking algorithms are calculated based on the `OpeNTF`'s evaluation settings in [`./src/__config.yml`](https://github.com/fani-lab/OpeNTF/blob/main/src/__config__.yaml#L84C1-L93C60)\n",
        "\n",
        "- **eval.**`fair`, fairness measures `before` and `after` reranking using `ndkl` and `skew`\n",
        "- **eval.**`topk`, cutoffs for measuring accuracy (utility) metrics\n",
        "- **eval.**`trec`, measuring ranking-based accuracy (utility) metrics `before` and `after` reranking\n",
        "- **eval.**`other`, measuring other utility metrics `before` and `after` reranking like `aucroc`, `skill_coverage`, ...\n",
        "- **eval.**`per_epoch`, also apply rerankings on per-epoch predictions\n",
        "- **eval.**`per_instance`, fairness and accuray metrics per each test team, needed for paired significance tests\n",
        "\n",
        "```\n",
        "eval:\n",
        "  fair: [ndkl, skew]\n",
        "  topk: '2,5,10'\n",
        "  trec: [P_topk, recall_topk, ndcg_cut_topk, map_cut_topk, success_topk]\n",
        "  other: [skill_coverage_topk, aucroc]\n",
        "  per_epoch: 10\n",
        "  per_instance: True\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample Command**\n",
        "```\n",
        "python main.py  \"cmd=[prep,train,test,eval,fair]\" \\\n",
        "                \n",
        "                \"models.instances=[mdl.rnd.Rnd]\" \\\n",
        "                \n",
        "                data.domain=cmn.publication.Publication \\\n",
        "                data.source=../data/dblp/toy.dblp.v12.json \\\n",
        "                data.output=../output/dblp/toy.dblp.v12.json \\\n",
        "                ~data.filter \\\n",
        "                \n",
        "                fair.fgender=../data/dblp/toy.dblp.v12.json.females.csv \\\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c8R8Dp2_wejY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwEN1xLDnTLK"
      },
      "source": [
        "**Setup & Quickstart**\n",
        "\n",
        "From `OpeNTF`'s [`quickstart`](https://colab.research.google.com/github/fani-lab/OpeNTF/blob/main/ipynb/quickstart.ipynb) script:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mZln-_cnnTLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98f5c20-e6f1-4e16-83af-1389d2e1ce48",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [2 InRelease 24.3 kB/128 kB 19%] [3 InRelease 59.1 kB/129 kB 46%] [Connected\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [2 InRelease 67.7 kB/128 kB 53%] [3 InRelease 126 kB/129 kB 97%] [Waiting fo\r0% [2 InRelease 76.4 kB/128 kB 60%] [Waiting for headers] [Connected to ppa.lau\r                                                                               \rGet:5 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\r0% [2 InRelease 82.2 kB/128 kB 64%] [Waiting for headers] [Connected to ppa.lau\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rGet:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [85.0 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,538 kB]\n",
            "Get:12 https://cli.github.com/packages stable/main amd64 Packages [355 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,749 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,737 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,301 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [62.6 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,613 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,756 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [70.9 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [4,070 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,904 kB]\n",
            "Get:22 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [39.2 kB]\n",
            "Get:23 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [75.3 kB]\n",
            "Fetched 37.4 MB in 4s (8,561 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  javascript-common libjs-sphinxdoc libjs-underscore libpython3.10\n",
            "  libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3-dev python3-pkg-resources\n",
            "  python3-setuptools python3-wheel python3.10 python3.10-dev\n",
            "  python3.10-minimal python3.8-lib2to3 python3.8-minimal\n",
            "Suggested packages:\n",
            "  apache2 | lighttpd | httpd python-setuptools-doc python3.10-venv\n",
            "  python3.10-doc binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  javascript-common libjs-sphinxdoc libjs-underscore libpython3.8-minimal\n",
            "  libpython3.8-stdlib python3-dev python3-pip python3-setuptools python3-wheel\n",
            "  python3.10-dev python3.8 python3.8-distutils python3.8-lib2to3\n",
            "  python3.8-minimal python3.8-venv\n",
            "The following packages will be upgraded:\n",
            "  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n",
            "  python3-pkg-resources python3.10 python3.10-minimal\n",
            "7 upgraded, 15 newly installed, 0 to remove and 73 not upgraded.\n",
            "Need to get 23.0 MB of archives.\n",
            "After this operation, 33.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.14 [4,765 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.14 [1,949 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.14 [509 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.14 [1,850 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.14 [2,275 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.14 [816 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5,936 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-underscore all 1.13.2~dfsg-2 [118 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjs-sphinxdoc all 4.3.2-1 [139 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.14 [508 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-dev amd64 3.10.6-1~22.04.1 [26.0 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.7 [1,306 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-pkg-resources all 68.1.2-2~jammy3 [216 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-setuptools all 68.1.2-2~jammy3 [465 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.20-1+jammy1 [126 kB]\n",
            "Get:21 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.20-1+jammy1 [193 kB]\n",
            "Get:22 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-venv amd64 3.8.20-1+jammy1 [2,618 kB]\n",
            "Fetched 23.0 MB in 15s (1,562 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 22.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 117540 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython3.10-dev_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Preparing to unpack .../01-libpython3.10_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking libpython3.10:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Preparing to unpack .../02-python3.10_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking python3.10 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Preparing to unpack .../03-libpython3.10-stdlib_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Preparing to unpack .../04-python3.10-minimal_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking python3.10-minimal (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Preparing to unpack .../05-libpython3.10-minimal_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "Preparing to unpack .../06-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../07-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../08-javascript-common_11+nmu1_all.deb ...\n",
            "Unpacking javascript-common (11+nmu1) ...\n",
            "Selecting previously unselected package libjs-underscore.\n",
            "Preparing to unpack .../09-libjs-underscore_1.13.2~dfsg-2_all.deb ...\n",
            "Unpacking libjs-underscore (1.13.2~dfsg-2) ...\n",
            "Selecting previously unselected package libjs-sphinxdoc.\n",
            "Preparing to unpack .../10-libjs-sphinxdoc_4.3.2-1_all.deb ...\n",
            "Unpacking libjs-sphinxdoc (4.3.2-1) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../11-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.10-dev.\n",
            "Preparing to unpack .../12-python3.10-dev_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking python3.10-dev (3.10.12-1~22.04.14) ...\n",
            "Selecting previously unselected package python3-dev.\n",
            "Preparing to unpack .../13-python3-dev_3.10.6-1~22.04.1_amd64.deb ...\n",
            "Unpacking python3-dev (3.10.6-1~22.04.1) ...\n",
            "Preparing to unpack .../14-python3-pkg-resources_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-pkg-resources (68.1.2-2~jammy3) over (59.6.0-1.2ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../15-python3-setuptools_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-setuptools (68.1.2-2~jammy3) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../16-python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../17-python3-pip_22.0.2+dfsg-1ubuntu0.7_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../18-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "Preparing to unpack .../19-python3.8-lib2to3_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../20-python3.8-distutils_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-venv.\n",
            "Preparing to unpack .../21-python3.8-venv_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Setting up python3-pkg-resources (68.1.2-2~jammy3) ...\n",
            "Setting up javascript-common (11+nmu1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3-setuptools (68.1.2-2~jammy3) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.14) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Setting up libjs-underscore (1.13.2~dfsg-2) ...\n",
            "Setting up python3.10-minimal (3.10.12-1~22.04.14) ...\n",
            "Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.14) ...\n",
            "Setting up python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Setting up libjs-sphinxdoc (4.3.2-1) ...\n",
            "Setting up libpython3.10:amd64 (3.10.12-1~22.04.14) ...\n",
            "Setting up python3.10 (3.10.12-1~22.04.14) ...\n",
            "Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.14) ...\n",
            "Setting up python3.10-dev (3.10.12-1~22.04.14) ...\n",
            "Setting up python3-dev (3.10.6-1~22.04.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.8.20\n"
          ]
        }
      ],
      "source": [
        "# set up python 3.8\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y python3.8 python3.8-venv python3.8-distutils python3-pip\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 10\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get OpeNTF and Adila submodule\n",
        "!rm -R opentf/\n",
        "!git clone --recurse-submodules https://github.com/Fani-Lab/opentf\n",
        "!pip install --upgrade pip setuptools\n",
        "!pip install -r opentf/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "95eDgj3AAInL",
        "outputId": "c39f824c-6f3a-4e07-bfe1-a08d071326f2",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'opentf/': No such file or directory\n",
            "Cloning into 'opentf'...\n",
            "remote: Enumerating objects: 27105, done.\u001b[K\n",
            "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (213/213), done.\u001b[K\n",
            "remote: Total 27105 (delta 125), reused 159 (delta 66), pack-reused 26825 (from 3)\u001b[K\n",
            "Receiving objects: 100% (27105/27105), 1.32 GiB | 20.94 MiB/s, done.\n",
            "Resolving deltas: 100% (13396/13396), done.\n",
            "Updating files: 100% (4379/4379), done.\n",
            "Submodule 'src/Adila' (https://github.com/fani-lab/Adila.git) registered for path 'src/Adila'\n",
            "Cloning into '/content/opentf/src/Adila'...\n",
            "remote: Enumerating objects: 1903, done.        \n",
            "remote: Counting objects: 100% (155/155), done.        \n",
            "remote: Compressing objects: 100% (93/93), done.        \n",
            "remote: Total 1903 (delta 110), reused 69 (delta 62), pack-reused 1748 (from 1)        \n",
            "Receiving objects: 100% (1903/1903), 17.64 MiB | 16.87 MiB/s, done.\n",
            "Resolving deltas: 100% (1038/1038), done.\n",
            "Submodule path 'src/Adila': checked out '708b05a9ddc32cafe03b3052502f04f762237032'\n",
            "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (68.1.2)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-75.3.4-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 68.1.2\n",
            "    Not uninstalling setuptools at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'setuptools'. No files were found to uninstall.\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.2\n",
            "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'pip'. No files were found to uninstall.\n",
            "Successfully installed pip-25.0.1 setuptools-75.3.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "f354116416a94872b7c5842c187fbd55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hydra-core==1.3.2 (from -r opentf/requirements.txt (line 3))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting scipy==1.10.1 (from -r opentf/requirements.txt (line 4))\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Collecting numpy==1.24.4 (from -r opentf/requirements.txt (line 5))\n",
            "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting importlib-resources (from hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting PyYAML>=5.1.0 (from omegaconf<2.4,>=2.2->hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading PyYAML-6.0.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting zipp>=3.1.0 (from importlib-resources->hydra-core==1.3.2->-r opentf/requirements.txt (line 3))\n",
            "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Downloading packaging-26.0-py3-none-any.whl (74 kB)\n",
            "Downloading PyYAML-6.0.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.0/806.0 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=438a7119e29e6bd9b878fefd5a09e21e224eddbbb3d236022fe006381c3736e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, zipp, PyYAML, packaging, numpy, scipy, omegaconf, importlib-resources, hydra-core\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 1.0.0\n",
            "    Uninstalling zipp-1.0.0:\n",
            "      Successfully uninstalled zipp-1.0.0\n",
            "Successfully installed PyYAML-6.0.3 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 importlib-resources-6.4.5 numpy-1.24.4 omegaconf-2.3.0 packaging-26.0 scipy-1.10.1 zipp-3.20.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging",
                  "pydevd_plugins"
                ]
              },
              "id": "5e6c61d529c54879b4a24623ca74fcbf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd opentf/src/\n",
        "!python main.py  \"cmd=[prep,train,test,eval,fair]\" \"models.instances=[mdl.rnd.Rnd]\" data.domain=cmn.publication.Publication data.source=../data/dblp/toy.dblp.v12.json data.output=../output/dblp/toy.dblp.v12.json ~data.filter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDdbvZnWATUw",
        "outputId": "a160b0d1-086b-41ce-d8fe-818483dc0d60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/opentf/src\n",
            "[2026-02-19 18:13:43,036][cmn.team][INFO] - Loading teamsvecs matrices from ../output/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "[2026-02-19 18:13:43,039][pkgmgr][INFO] - tqdm not found.\n",
            "[2026-02-19 18:13:43,039][pkgmgr][INFO] - Installing tqdm...\n",
            "[2026-02-19 18:13:44,395][pkgmgr][INFO] - Collecting tqdm==4.65.0\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
            "Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.65.0\n",
            "\n",
            "[2026-02-19 18:13:44,400][cmn.team][INFO] - Loading indexes pickle from ../output/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "[2026-02-19 18:13:44,400][cmn.team][INFO] - Indexes pickle is loaded.\n",
            "[2026-02-19 18:13:44,400][cmn.team][INFO] - Teamsvecs matrices and indexes for skills (31, 10), members (31, 13), and locations (31, 29) are loaded.\n",
            "[2026-02-19 18:13:44,401][__main__][INFO] - Loading splits from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.pkl ...\n",
            "[2026-02-19 18:13:44,401][cmn.team][INFO] - Loading member-skill co-occurrence matrix (13, 10) from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/skillcoverage.pkl ...\n",
            "[2026-02-19 18:13:44,437][pkgmgr][INFO] - torch not found.\n",
            "[2026-02-19 18:13:44,437][pkgmgr][INFO] - Installing torch...\n",
            "[2026-02-19 18:16:16,262][pkgmgr][INFO] - Collecting torch==2.4.1\n",
            "  Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting filelock (from torch==2.4.1)\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch==2.4.1)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch==2.4.1)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.4.1)\n",
            "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting jinja2 (from torch==2.4.1)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.4.1)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.1)\n",
            "  Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch==2.4.1) (2.0.1)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.1)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 797.1/797.1 MB 29.2 MB/s eta 0:00:00\n",
            "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 56.0 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 96.0 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 106.8 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 27.8 MB/s eta 0:00:00\n",
            "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 37.2 MB/s eta 0:00:00\n",
            "Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 50.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 46.0 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 52.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 61.4 MB/s eta 0:00:00\n",
            "Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.2/176.2 MB 58.6 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.4/209.4 MB 63.1 MB/s eta 0:00:00\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 47.8 MB/s eta 0:00:00\n",
            "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 78.4 MB/s eta 0:00:00\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 13.5 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.7/39.7 MB 50.3 MB/s eta 0:00:00\n",
            "Installing collected packages: mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, jinja2, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "Successfully installed filelock-3.16.1 fsspec-2025.3.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.1 triton-3.0.0 typing-extensions-4.13.2\n",
            "\n",
            "[2026-02-19 18:16:19,473][pkgmgr][INFO] - tensorboardX not found.\n",
            "[2026-02-19 18:16:19,473][pkgmgr][INFO] - Installing tensorboardX...\n",
            "[2026-02-19 18:16:38,528][pkgmgr][INFO] - Collecting tensorboardX==2.6.2.2\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting tensorboard==2.14.0\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting protobuf==3.20\n",
            "  Downloading protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (698 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX==2.6.2.2) (1.24.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX==2.6.2.2) (26.0)\n",
            "Collecting absl-py>=0.4 (from tensorboard==2.14.0)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard==2.14.0)\n",
            "  Downloading grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard==2.14.0)\n",
            "  Downloading google_auth-2.48.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard==2.14.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard==2.14.0) (3.3.6)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard==2.14.0)\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard==2.14.0) (75.3.4)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard==2.14.0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard==2.14.0)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard==2.14.0) (0.37.1)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard==2.14.0)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting cryptography>=38.0.3 (from google-auth<3,>=1.6.3->tensorboard==2.14.0)\n",
            "  Downloading cryptography-46.0.5-cp38-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard==2.14.0)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard==2.14.0)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/lib/python3/dist-packages (from markdown>=2.6.8->tensorboard==2.14.0) (4.6.4)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard==2.14.0)\n",
            "  Downloading charset_normalizer-3.4.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard==2.14.0)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard==2.14.0)\n",
            "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard==2.14.0)\n",
            "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard==2.14.0)\n",
            "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting cffi>=1.14 (from cryptography>=38.0.3->google-auth<3,>=1.6.3->tensorboard==2.14.0)\n",
            "  Downloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.13.2 in /usr/local/lib/python3.8/dist-packages (from cryptography>=38.0.3->google-auth<3,>=1.6.3->tensorboard==2.14.0) (4.13.2)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.14.0)\n",
            "  Downloading pyasn1-0.6.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard==2.14.0) (3.2.0)\n",
            "Collecting pycparser (from cffi>=1.14->cryptography>=38.0.3->google-auth<3,>=1.6.3->tensorboard==2.14.0)\n",
            "  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 50.0 MB/s eta 0:00:00\n",
            "Downloading protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 16.0 MB/s eta 0:00:00\n",
            "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Downloading google_auth-2.48.0-py3-none-any.whl (236 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.70.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 61.8 MB/s eta 0:00:00\n",
            "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 59.6 MB/s eta 0:00:00\n",
            "Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (147 kB)\n",
            "Downloading cryptography-46.0.5-cp38-abi3-manylinux_2_34_x86_64.whl (4.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 51.4 MB/s eta 0:00:00\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Downloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
            "Downloading pyasn1-0.6.2-py3-none-any.whl (83 kB)\n",
            "Downloading pycparser-2.23-py3-none-any.whl (118 kB)\n",
            "Installing collected packages: urllib3, tensorboard-data-server, pycparser, pyasn1, protobuf, MarkupSafe, idna, grpcio, charset_normalizer, certifi, absl-py, werkzeug, tensorboardX, rsa, requests, pyasn1-modules, cffi, requests-oauthlib, cryptography, google-auth, google-auth-oauthlib, tensorboard\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 3.4.8\n",
            "    Uninstalling cryptography-3.4.8:\n",
            "      Successfully uninstalled cryptography-3.4.8\n",
            "Successfully installed MarkupSafe-2.1.5 absl-py-2.3.1 certifi-2026.1.4 cffi-1.17.1 charset_normalizer-3.4.4 cryptography-46.0.5 google-auth-2.48.0 google-auth-oauthlib-1.0.0 grpcio-1.70.0 idna-3.11 protobuf-3.20.0 pyasn1-0.6.2 pyasn1-modules-0.4.2 pycparser-2.23 requests-2.32.4 requests-oauthlib-2.0.0 rsa-4.9.1 tensorboard-2.14.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 urllib3-2.2.3 werkzeug-3.0.6\n",
            "\n",
            "[2026-02-19 18:16:38,634][__main__][INFO] - \u001b[94mTraining team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "[2026-02-19 18:16:38,636][__main__][INFO] - \u001b[92mTesting team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "[2026-02-19 18:16:38,688][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold0.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred\n",
            "[2026-02-19 18:16:38,692][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold1.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred\n",
            "[2026-02-19 18:16:38,695][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold2.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred\n",
            "[2026-02-19 18:16:38,696][__main__][INFO] - \u001b[95mEvaluating team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "[2026-02-19 18:16:38,699][pkgmgr][INFO] - pandas not found.\n",
            "[2026-02-19 18:16:38,699][pkgmgr][INFO] - Installing pandas...\n",
            "[2026-02-19 18:16:49,136][pkgmgr][INFO] - Collecting pandas==2.0.0\n",
            "  Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas==2.0.0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas==2.0.0)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.1 (from pandas==2.0.0)\n",
            "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas==2.0.0) (1.24.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.0) (1.16.0)\n",
            "Downloading pandas-2.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 78.5 MB/s eta 0:00:00\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
            "Installing collected packages: pytz, tzdata, python-dateutil, pandas\n",
            "Successfully installed pandas-2.0.0 python-dateutil-2.9.0.post0 pytz-2025.2 tzdata-2025.3\n",
            "\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:16:49,419][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-02-19 18:16:49,421][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:16:49,429][pkgmgr][INFO] - pytrec_eval not found.\n",
            "[2026-02-19 18:16:49,429][pkgmgr][INFO] - Installing pytrec-eval-terrier...\n",
            "[2026-02-19 18:16:50,815][pkgmgr][INFO] - Collecting pytrec-eval-terrier==0.5.2\n",
            "  Downloading pytrec_eval_terrier-0.5.2-cp38-cp38-manylinux2010_x86_64.whl.metadata (800 bytes)\n",
            "Downloading pytrec_eval_terrier-0.5.2-cp38-cp38-manylinux2010_x86_64.whl (287 kB)\n",
            "Installing collected packages: pytrec-eval-terrier\n",
            "Successfully installed pytrec-eval-terrier-0.5.2\n",
            "\n",
            "[2026-02-19 18:16:50,818][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 245.62it/s]\n",
            "[2026-02-19 18:16:50,856][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:16:50,856][pkgmgr][INFO] - sklearn.metrics not found.\n",
            "[2026-02-19 18:16:50,857][pkgmgr][INFO] - Installing scikit-learn...\n",
            "[2026-02-19 18:16:57,400][pkgmgr][INFO] - Collecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (1.10.1)\n",
            "Collecting joblib>=1.1.1 (from scikit-learn==1.2.2)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn==1.2.2)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.8/9.8 MB 49.6 MB/s eta 0:00:00\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
            "Successfully installed joblib-1.4.2 scikit-learn-1.2.2 threadpoolctl-3.5.0\n",
            "\n",
            "[2026-02-19 18:16:58,806][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 110.71it/s]\n",
            "[2026-02-19 18:16:58,867][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:16:58,877][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-02-19 18:16:58,878][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:16:58,886][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2298.25it/s]\n",
            "[2026-02-19 18:16:58,891][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:16:58,896][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 221.84it/s]\n",
            "[2026-02-19 18:16:58,929][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:16:58,934][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ... for {'fair': ['ndkl', 'skew'], 'topk': '2,5,10', 'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2026-02-19 18:16:58,936][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:16:58,943][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2939.66it/s]\n",
            "[2026-02-19 18:16:58,948][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:16:58,953][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 203.65it/s]\n",
            "[2026-02-19 18:16:58,993][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv\n",
            "[2026-02-19 18:16:59,005][mdl.ntf][INFO] - Saving mean evaluation file over 3 folds as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:16:59,010][__main__][INFO] - \u001b[96mFair-rerank team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "[2026-02-19 18:16:59,038][Adila.src.adila][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "[2026-02-19 18:16:59,047][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mgender.eo.None ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:16:59,050][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:16:59,051][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:16:59,054][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:16:59,054][pkgmgr][INFO] - reranking not found.\n",
            "[2026-02-19 18:16:59,054][pkgmgr][INFO] - Installing reranking...\n",
            "[2026-02-19 18:17:00,859][pkgmgr][INFO] - Collecting reranking==0.3.6\n",
            "  Downloading reranking-0.3.6-py3-none-any.whl.metadata (3.9 kB)\n",
            "Downloading reranking-0.3.6-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: reranking\n",
            "Successfully installed reranking-0.3.6\n",
            "\n",
            "5it [00:00, 1877.15it/s]\n",
            "[2026-02-19 18:17:00,893][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:00,896][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:00,896][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:00,901][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:00,903][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:00,911][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2347.12it/s]\n",
            "[2026-02-19 18:17:00,917][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:00,923][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 174.99it/s]\n",
            "[2026-02-19 18:17:00,968][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:00,969][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:00,969][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.fa-ir.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:00,973][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.fa-ir.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3570.23it/s]\n",
            "[2026-02-19 18:17:00,988][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:00,991][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.fa-ir.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:00,992][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:00,997][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.fa-ir.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:00,998][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:01,005][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2010.50it/s]\n",
            "[2026-02-19 18:17:01,011][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:01,016][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 199.84it/s]\n",
            "[2026-02-19 18:17:01,055][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:01,056][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:01,056][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.fa-ir.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:01,060][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.fa-ir.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2178.86it/s]\n",
            "[2026-02-19 18:17:01,082][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:01,087][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.fa-ir.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:01,087][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:01,092][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.fa-ir.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:01,094][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:01,105][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2229.12it/s]\n",
            "[2026-02-19 18:17:01,113][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:01,120][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 167.18it/s]\n",
            "[2026-02-19 18:17:01,168][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:01,170][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mgender.eo.None ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:01,173][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:01,173][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:01,173][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 87.12it/s]\n",
            "[2026-02-19 18:17:01,236][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 1327.31it/s]\n",
            "[2026-02-19 18:17:01,271][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:01,274][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:01,274][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:01,295][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred ...\n",
            "[2026-02-19 18:17:01,297][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:01,312][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2099.25it/s]\n",
            "[2026-02-19 18:17:01,318][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:01,328][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 120.96it/s]\n",
            "[2026-02-19 18:17:01,391][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:01,393][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:01,393][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_greedy.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:01,393][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 87.71it/s]\n",
            "[2026-02-19 18:17:01,454][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_greedy.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2513.67it/s]\n",
            "[2026-02-19 18:17:01,471][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_greedy.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:01,474][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_greedy.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:01,474][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:01,485][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_greedy.5.rerank.pred ...\n",
            "[2026-02-19 18:17:01,489][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:01,508][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1459.90it/s]\n",
            "[2026-02-19 18:17:01,514][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:01,521][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 92.49it/s]\n",
            "[2026-02-19 18:17:01,600][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:01,601][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:01,601][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_greedy.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:01,602][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 94.83it/s]\n",
            "[2026-02-19 18:17:01,659][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_greedy.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3580.59it/s]\n",
            "[2026-02-19 18:17:01,675][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_greedy.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:01,680][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_greedy.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:01,681][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:01,691][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_greedy.5.rerank.pred ...\n",
            "[2026-02-19 18:17:01,692][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:01,699][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2251.37it/s]\n",
            "[2026-02-19 18:17:01,704][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:01,710][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 163.53it/s]\n",
            "[2026-02-19 18:17:01,758][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:01,760][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mgender.eo.None ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:01,765][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:01,766][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:01,767][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 77.64it/s]\n",
            "[2026-02-19 18:17:01,836][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3623.90it/s]\n",
            "[2026-02-19 18:17:01,850][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:01,854][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:01,854][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:01,859][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred ...\n",
            "[2026-02-19 18:17:01,860][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:01,869][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2933.49it/s]\n",
            "[2026-02-19 18:17:01,874][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:01,879][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 171.70it/s]\n",
            "[2026-02-19 18:17:01,926][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:01,928][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:01,928][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_relaxed.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:01,928][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 142.73it/s]\n",
            "[2026-02-19 18:17:01,967][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_relaxed.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2667.45it/s]\n",
            "[2026-02-19 18:17:01,983][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:01,987][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_relaxed.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:01,987][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:01,993][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_relaxed.5.rerank.pred ...\n",
            "[2026-02-19 18:17:01,995][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:02,008][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1970.64it/s]\n",
            "[2026-02-19 18:17:02,014][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:02,019][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 171.71it/s]\n",
            "[2026-02-19 18:17:02,062][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:02,063][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:02,063][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_relaxed.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:02,063][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 130.83it/s]\n",
            "[2026-02-19 18:17:02,106][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_relaxed.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3490.60it/s]\n",
            "[2026-02-19 18:17:02,122][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:02,125][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_relaxed.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:02,125][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:02,134][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_relaxed.5.rerank.pred ...\n",
            "[2026-02-19 18:17:02,136][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:02,143][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2857.54it/s]\n",
            "[2026-02-19 18:17:02,148][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:02,153][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 208.69it/s]\n",
            "[2026-02-19 18:17:02,191][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:02,192][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mgender.eo.None ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:02,195][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:02,195][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:02,196][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 70.29it/s]\n",
            "[2026-02-19 18:17:02,272][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2895.82it/s]\n",
            "[2026-02-19 18:17:02,291][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:02,295][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:02,295][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:02,302][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred ...\n",
            "[2026-02-19 18:17:02,304][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:02,311][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2878.33it/s]\n",
            "[2026-02-19 18:17:02,315][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:02,321][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 161.87it/s]\n",
            "[2026-02-19 18:17:02,368][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:02,369][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:02,369][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_const_sort.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:02,369][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 124.33it/s]\n",
            "[2026-02-19 18:17:02,415][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_const_sort.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3515.17it/s]\n",
            "[2026-02-19 18:17:02,427][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:02,430][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_const_sort.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:02,430][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:02,435][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_const_sort.5.rerank.pred ...\n",
            "[2026-02-19 18:17:02,437][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:02,443][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2481.84it/s]\n",
            "[2026-02-19 18:17:02,449][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:02,455][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 239.67it/s]\n",
            "[2026-02-19 18:17:02,494][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:02,496][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:02,496][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_const_sort.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:02,497][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 88.94it/s]\n",
            "[2026-02-19 18:17:02,564][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_const_sort.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2849.00it/s]\n",
            "[2026-02-19 18:17:02,576][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:02,580][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_const_sort.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:02,580][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:02,585][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_const_sort.5.rerank.pred ...\n",
            "[2026-02-19 18:17:02,586][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:02,593][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1855.23it/s]\n",
            "[2026-02-19 18:17:02,600][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:02,607][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 151.00it/s]\n",
            "[2026-02-19 18:17:02,656][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:02,657][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mgender.eo.None ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:02,660][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:02,660][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:02,660][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 135.27it/s]\n",
            "[2026-02-19 18:17:02,702][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 1938.40it/s]\n",
            "[2026-02-19 18:17:02,718][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:02,721][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:02,721][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:02,726][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred ...\n",
            "[2026-02-19 18:17:02,727][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:02,734][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2933.08it/s]\n",
            "[2026-02-19 18:17:02,738][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:02,743][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 182.44it/s]\n",
            "[2026-02-19 18:17:02,785][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f0.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:02,786][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:02,786][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_cons.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:02,786][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 107.66it/s]\n",
            "[2026-02-19 18:17:02,837][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_cons.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3458.36it/s]\n",
            "[2026-02-19 18:17:02,850][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_cons.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:02,853][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_cons.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:02,853][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:02,858][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_cons.5.rerank.pred ...\n",
            "[2026-02-19 18:17:02,859][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:02,865][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2936.78it/s]\n",
            "[2026-02-19 18:17:02,870][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:02,875][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 182.21it/s]\n",
            "[2026-02-19 18:17:02,916][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f2.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:02,916][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:02,917][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_cons.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:02,917][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 132.68it/s]\n",
            "[2026-02-19 18:17:02,958][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_cons.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3481.33it/s]\n",
            "[2026-02-19 18:17:02,970][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_cons.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:02,973][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_cons.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:02,973][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:02,978][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_cons.5.rerank.pred ...\n",
            "[2026-02-19 18:17:02,981][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:02,989][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1631.39it/s]\n",
            "[2026-02-19 18:17:02,995][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:03,001][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 123.15it/s]\n",
            "[2026-02-19 18:17:03,065][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/eo/f1.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:03,065][Adila.src.adila][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "[2026-02-19 18:17:03,069][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mgender.dp.None ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:03,073][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:03,073][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:03,078][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 1750.54it/s]\n",
            "[2026-02-19 18:17:03,095][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:03,098][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:03,098][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:03,104][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:03,105][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:03,114][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2954.57it/s]\n",
            "[2026-02-19 18:17:03,119][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:03,124][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 202.70it/s]\n",
            "[2026-02-19 18:17:03,163][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:03,164][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:03,165][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.fa-ir.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:03,168][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.fa-ir.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2864.57it/s]\n",
            "[2026-02-19 18:17:03,181][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:03,184][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.fa-ir.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:03,184][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:03,189][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.fa-ir.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:03,190][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:03,196][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3182.81it/s]\n",
            "[2026-02-19 18:17:03,201][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:03,206][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 157.34it/s]\n",
            "[2026-02-19 18:17:03,255][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:03,256][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:03,256][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.fa-ir.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:03,261][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.fa-ir.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2926.94it/s]\n",
            "[2026-02-19 18:17:03,273][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:03,276][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.fa-ir.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:03,276][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:03,283][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.fa-ir.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:03,288][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:03,295][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1487.76it/s]\n",
            "[2026-02-19 18:17:03,304][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:03,311][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 164.65it/s]\n",
            "[2026-02-19 18:17:03,354][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:03,355][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mgender.dp.None ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:03,358][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:03,358][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:03,359][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 121.82it/s]\n",
            "[2026-02-19 18:17:03,407][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2236.72it/s]\n",
            "[2026-02-19 18:17:03,425][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:03,428][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:03,429][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:03,434][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred ...\n",
            "[2026-02-19 18:17:03,435][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:03,441][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2361.39it/s]\n",
            "[2026-02-19 18:17:03,449][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:03,453][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 211.99it/s]\n",
            "[2026-02-19 18:17:03,490][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:03,491][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:03,491][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_greedy.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:03,492][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 109.94it/s]\n",
            "[2026-02-19 18:17:03,542][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_greedy.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2905.85it/s]\n",
            "[2026-02-19 18:17:03,556][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_greedy.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:03,558][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_greedy.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:03,558][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:03,564][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_greedy.5.rerank.pred ...\n",
            "[2026-02-19 18:17:03,565][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:03,572][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2805.18it/s]\n",
            "[2026-02-19 18:17:03,577][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:03,581][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 224.63it/s]\n",
            "[2026-02-19 18:17:03,616][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:03,617][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:03,617][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_greedy.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:03,617][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 99.92it/s]\n",
            "[2026-02-19 18:17:03,671][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_greedy.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3298.45it/s]\n",
            "[2026-02-19 18:17:03,683][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_greedy.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:03,686][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_greedy.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:03,686][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:03,690][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_greedy.5.rerank.pred ...\n",
            "[2026-02-19 18:17:03,691][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:03,697][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3023.14it/s]\n",
            "[2026-02-19 18:17:03,702][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:03,707][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 137.07it/s]\n",
            "[2026-02-19 18:17:03,756][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:03,757][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mgender.dp.None ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:03,760][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:03,760][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:03,760][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 125.35it/s]\n",
            "[2026-02-19 18:17:03,805][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2869.67it/s]\n",
            "[2026-02-19 18:17:03,819][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:03,823][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:03,823][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:03,829][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred ...\n",
            "[2026-02-19 18:17:03,830][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:03,837][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2980.60it/s]\n",
            "[2026-02-19 18:17:03,842][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:03,846][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 191.86it/s]\n",
            "[2026-02-19 18:17:03,885][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:03,886][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:03,886][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_relaxed.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:03,886][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 103.94it/s]\n",
            "[2026-02-19 18:17:03,938][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_relaxed.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3450.97it/s]\n",
            "[2026-02-19 18:17:03,949][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:03,952][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_relaxed.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:03,952][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:03,957][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_relaxed.5.rerank.pred ...\n",
            "[2026-02-19 18:17:03,958][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:03,964][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2992.51it/s]\n",
            "[2026-02-19 18:17:03,968][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:03,972][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 189.19it/s]\n",
            "[2026-02-19 18:17:04,011][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:04,012][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:04,012][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_relaxed.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:04,012][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 131.37it/s]\n",
            "[2026-02-19 18:17:04,056][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_relaxed.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2539.23it/s]\n",
            "[2026-02-19 18:17:04,072][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:04,075][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_relaxed.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:04,075][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:04,080][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_relaxed.5.rerank.pred ...\n",
            "[2026-02-19 18:17:04,081][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:04,088][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1742.83it/s]\n",
            "[2026-02-19 18:17:04,094][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:04,099][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 123.72it/s]\n",
            "[2026-02-19 18:17:04,153][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:04,154][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mgender.dp.None ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:04,158][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:04,158][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:04,158][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 138.02it/s]\n",
            "[2026-02-19 18:17:04,198][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2919.60it/s]\n",
            "[2026-02-19 18:17:04,212][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:04,215][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:04,215][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:04,220][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred ...\n",
            "[2026-02-19 18:17:04,221][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:04,228][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2789.14it/s]\n",
            "[2026-02-19 18:17:04,232][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:04,237][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 158.71it/s]\n",
            "[2026-02-19 18:17:04,283][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:04,284][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:04,284][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_const_sort.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:04,284][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 126.47it/s]\n",
            "[2026-02-19 18:17:04,328][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_const_sort.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3395.65it/s]\n",
            "[2026-02-19 18:17:04,340][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:04,342][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_const_sort.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:04,343][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:04,347][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_const_sort.5.rerank.pred ...\n",
            "[2026-02-19 18:17:04,349][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:04,355][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3047.30it/s]\n",
            "[2026-02-19 18:17:04,359][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:04,364][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 234.02it/s]\n",
            "[2026-02-19 18:17:04,400][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:04,401][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:04,401][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_const_sort.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:04,401][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 112.14it/s]\n",
            "[2026-02-19 18:17:04,449][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_const_sort.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3627.66it/s]\n",
            "[2026-02-19 18:17:04,460][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:04,463][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_const_sort.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:04,463][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:04,468][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_const_sort.5.rerank.pred ...\n",
            "[2026-02-19 18:17:04,469][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:04,475][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3112.89it/s]\n",
            "[2026-02-19 18:17:04,479][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:04,485][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 220.23it/s]\n",
            "[2026-02-19 18:17:04,522][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:04,524][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mgender.dp.None ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:04,527][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:04,527][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:04,528][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 120.47it/s]\n",
            "[2026-02-19 18:17:04,573][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2786.54it/s]\n",
            "[2026-02-19 18:17:04,587][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:04,590][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:04,590][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:04,596][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred ...\n",
            "[2026-02-19 18:17:04,597][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:04,603][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1911.89it/s]\n",
            "[2026-02-19 18:17:04,609][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:04,614][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 139.71it/s]\n",
            "[2026-02-19 18:17:04,663][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f0.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:04,664][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:04,664][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_cons.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:04,664][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 95.29it/s]\n",
            "[2026-02-19 18:17:04,720][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_cons.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3020.96it/s]\n",
            "[2026-02-19 18:17:04,733][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_cons.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:04,735][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_cons.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:04,736][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:04,741][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_cons.5.rerank.pred ...\n",
            "[2026-02-19 18:17:04,742][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:04,749][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2820.65it/s]\n",
            "[2026-02-19 18:17:04,754][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:04,763][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 217.32it/s]\n",
            "[2026-02-19 18:17:04,800][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f2.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:04,801][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:04,802][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_cons.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:04,802][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 131.35it/s]\n",
            "[2026-02-19 18:17:04,844][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_cons.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2914.74it/s]\n",
            "[2026-02-19 18:17:04,856][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_cons.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:04,860][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_cons.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:04,860][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:04,866][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_cons.5.rerank.pred ...\n",
            "[2026-02-19 18:17:04,867][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:04,873][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3153.61it/s]\n",
            "[2026-02-19 18:17:04,877][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:04,882][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 232.81it/s]\n",
            "[2026-02-19 18:17:04,917][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/gender/dp/f1.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:04,917][Adila.src.adila][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "[2026-02-19 18:17:04,927][Adila.src.adila][INFO] - Loading failed! Generating files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg ...\n",
            "[2026-02-19 18:17:04,931][Adila.src.adila][INFO] - Generating ratios ... \n",
            "100% 5/5 [00:00<00:00, 503.26it/s]\n",
            "[2026-02-19 18:17:04,943][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.eo.avg ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:04,948][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:04,948][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:04,948][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "[2026-02-19 18:17:04,949][pkgmgr][INFO] - fairsearchcore not found.\n",
            "[2026-02-19 18:17:04,949][pkgmgr][INFO] - Installing fairsearchcore...\n",
            "[2026-02-19 18:17:09,490][pkgmgr][INFO] - Collecting fairsearchcore@ git+https://github.com/fani-lab/fairsearch-fair-python.git\n",
            "  Cloning https://github.com/fani-lab/fairsearch-fair-python.git to /tmp/pip-install-te594_gr/fairsearchcore_99b87d0ec9f54488aaf4795d5742e02f\n",
            "  Resolved https://github.com/fani-lab/fairsearch-fair-python.git to commit 1649e423d378800c99a988437d66b6479001f92a\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.8/dist-packages (from fairsearchcore@ git+https://github.com/fani-lab/fairsearch-fair-python.git) (2.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from fairsearchcore@ git+https://github.com/fani-lab/fairsearch-fair-python.git) (1.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->fairsearchcore@ git+https://github.com/fani-lab/fairsearch-fair-python.git) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->fairsearchcore@ git+https://github.com/fani-lab/fairsearch-fair-python.git) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->fairsearchcore@ git+https://github.com/fani-lab/fairsearch-fair-python.git) (2025.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->fairsearchcore@ git+https://github.com/fani-lab/fairsearch-fair-python.git) (1.24.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=0.23->fairsearchcore@ git+https://github.com/fani-lab/fairsearch-fair-python.git) (1.16.0)\n",
            "Building wheels for collected packages: fairsearchcore\n",
            "  Building wheel for fairsearchcore (setup.py): started\n",
            "  Building wheel for fairsearchcore (setup.py): finished with status 'done'\n",
            "  Created wheel for fairsearchcore: filename=fairsearchcore-1.0.4-py3-none-any.whl size=11596 sha256=fe90e74be44358d5f96078384902f3f7126d59b80104e7d67ce0a2b93ae66984\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2oc86oym/wheels/d1/74/c3/f9baeb6bd3c865ed524752365d9800a8fd82b7e71b312bf910\n",
            "Successfully built fairsearchcore\n",
            "Installing collected packages: fairsearchcore\n",
            "Successfully installed fairsearchcore-1.0.4\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "  0% 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            " 40% 2/5 [00:00<00:00, 12.28it/s]/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            " 80% 4/5 [00:00<00:00, 13.14it/s]/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "100% 5/5 [00:00<00:00, 13.28it/s]\n",
            "[2026-02-19 18:17:09,873][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3344.74it/s]\n",
            "[2026-02-19 18:17:09,886][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:09,889][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:09,889][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:09,894][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:09,895][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:09,901][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2233.15it/s]\n",
            "[2026-02-19 18:17:09,906][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:09,911][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 202.98it/s]\n",
            "[2026-02-19 18:17:09,952][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:09,953][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:09,954][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.fa-ir.avg.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:09,954][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            " 20% 1/5 [00:00<00:00,  9.73it/s]/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            " 60% 3/5 [00:00<00:00, 12.38it/s]/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "100% 5/5 [00:00<00:00, 12.30it/s]\n",
            "[2026-02-19 18:17:10,367][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.fa-ir.avg.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3383.05it/s]\n",
            "[2026-02-19 18:17:10,378][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:10,381][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.fa-ir.avg.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:10,382][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:10,386][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.fa-ir.avg.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:10,387][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:10,393][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2255.00it/s]\n",
            "[2026-02-19 18:17:10,399][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:10,404][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 230.49it/s]\n",
            "[2026-02-19 18:17:10,437][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:10,438][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:10,438][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.fa-ir.avg.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:10,441][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.fa-ir.avg.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2438.27it/s]\n",
            "[2026-02-19 18:17:10,454][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:10,458][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.fa-ir.avg.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:10,459][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:10,465][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.fa-ir.avg.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:10,467][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:10,478][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2126.28it/s]\n",
            "[2026-02-19 18:17:10,484][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:10,490][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 228.30it/s]\n",
            "[2026-02-19 18:17:10,524][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:10,525][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.eo.avg ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:10,529][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:10,529][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_greedy.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:10,529][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 140.24it/s]\n",
            "[2026-02-19 18:17:10,568][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_greedy.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3688.27it/s]\n",
            "[2026-02-19 18:17:10,579][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:10,582][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_greedy.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:10,582][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:10,586][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_greedy.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:10,588][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:10,594][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2999.79it/s]\n",
            "[2026-02-19 18:17:10,598][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:10,603][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 214.43it/s]\n",
            "[2026-02-19 18:17:10,639][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:10,640][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:10,640][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_greedy.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:10,640][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 139.90it/s]\n",
            "[2026-02-19 18:17:10,680][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_greedy.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3486.54it/s]\n",
            "[2026-02-19 18:17:10,692][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:10,695][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_greedy.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:10,695][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:10,700][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_greedy.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:10,701][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:10,707][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3101.38it/s]\n",
            "[2026-02-19 18:17:10,711][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:10,716][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 248.94it/s]\n",
            "[2026-02-19 18:17:10,747][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:10,748][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:10,748][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_greedy.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:10,749][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 104.88it/s]\n",
            "[2026-02-19 18:17:10,800][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_greedy.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3809.54it/s]\n",
            "[2026-02-19 18:17:10,811][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:10,814][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_greedy.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:10,814][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:10,819][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_greedy.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:10,820][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:10,827][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2653.62it/s]\n",
            "[2026-02-19 18:17:10,832][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:10,837][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 231.69it/s]\n",
            "[2026-02-19 18:17:10,870][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:10,871][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.eo.avg ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:10,874][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:10,874][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:10,875][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 144.56it/s]\n",
            "[2026-02-19 18:17:10,913][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3674.70it/s]\n",
            "[2026-02-19 18:17:10,925][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:10,928][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:10,928][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:10,934][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:10,935][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:10,941][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2895.02it/s]\n",
            "[2026-02-19 18:17:10,946][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:10,951][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 160.49it/s]\n",
            "[2026-02-19 18:17:11,001][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:11,002][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:11,002][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_relaxed.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:11,002][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 120.83it/s]\n",
            "[2026-02-19 18:17:11,049][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_relaxed.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3716.38it/s]\n",
            "[2026-02-19 18:17:11,060][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:11,062][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_relaxed.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:11,063][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:11,068][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_relaxed.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:11,069][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:11,076][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3146.51it/s]\n",
            "[2026-02-19 18:17:11,080][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:11,085][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 219.45it/s]\n",
            "[2026-02-19 18:17:11,120][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:11,121][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:11,122][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_relaxed.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:11,122][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 152.34it/s]\n",
            "[2026-02-19 18:17:11,158][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_relaxed.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3635.84it/s]\n",
            "[2026-02-19 18:17:11,170][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:11,174][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_relaxed.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:11,174][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:11,178][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_relaxed.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:11,180][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:11,188][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2470.14it/s]\n",
            "[2026-02-19 18:17:11,193][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:11,198][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 198.87it/s]\n",
            "[2026-02-19 18:17:11,239][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:11,240][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.eo.avg ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:11,244][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:11,245][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:11,245][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 85.76it/s]\n",
            "[2026-02-19 18:17:11,307][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3466.94it/s]\n",
            "[2026-02-19 18:17:11,319][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:11,321][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:11,322][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:11,326][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:11,327][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:11,334][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2918.79it/s]\n",
            "[2026-02-19 18:17:11,338][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:11,343][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 235.92it/s]\n",
            "[2026-02-19 18:17:11,377][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:11,378][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:11,378][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_const_sort.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:11,379][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 144.57it/s]\n",
            "[2026-02-19 18:17:11,417][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_const_sort.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3789.58it/s]\n",
            "[2026-02-19 18:17:11,428][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:11,431][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_const_sort.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:11,432][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:11,436][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_const_sort.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:11,438][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:11,444][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2192.53it/s]\n",
            "[2026-02-19 18:17:11,449][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:11,454][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 138.84it/s]\n",
            "[2026-02-19 18:17:11,503][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:11,504][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:11,505][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_const_sort.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:11,505][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 140.43it/s]\n",
            "[2026-02-19 18:17:11,544][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_const_sort.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3507.53it/s]\n",
            "[2026-02-19 18:17:11,557][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:11,559][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_const_sort.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:11,560][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:11,565][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_const_sort.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:11,567][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:11,573][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2953.32it/s]\n",
            "[2026-02-19 18:17:11,577][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:11,582][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 220.02it/s]\n",
            "[2026-02-19 18:17:11,617][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:11,618][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.eo.avg ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:11,621][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:11,622][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_cons.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:11,622][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 139.51it/s]\n",
            "[2026-02-19 18:17:11,661][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_cons.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3744.25it/s]\n",
            "[2026-02-19 18:17:11,673][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:11,676][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_cons.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:11,676][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:11,680][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_cons.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:11,681][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:11,688][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3074.55it/s]\n",
            "[2026-02-19 18:17:11,692][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:11,697][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 235.80it/s]\n",
            "[2026-02-19 18:17:11,730][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:11,731][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:11,731][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_cons.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:11,731][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 115.98it/s]\n",
            "[2026-02-19 18:17:11,778][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_cons.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 1866.62it/s]\n",
            "[2026-02-19 18:17:11,796][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:11,799][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_cons.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:11,799][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:11,804][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_cons.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:11,805][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:11,811][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3124.95it/s]\n",
            "[2026-02-19 18:17:11,816][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:11,820][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 225.68it/s]\n",
            "[2026-02-19 18:17:11,854][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f2.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:11,855][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:11,855][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_cons.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:11,855][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 155.62it/s]\n",
            "[2026-02-19 18:17:11,891][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_cons.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3892.26it/s]\n",
            "[2026-02-19 18:17:11,902][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:11,905][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_cons.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:11,905][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:11,909][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_cons.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:11,911][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:11,916][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3173.18it/s]\n",
            "[2026-02-19 18:17:11,921][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:11,925][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 225.82it/s]\n",
            "[2026-02-19 18:17:11,959][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f1.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:11,973][pkgmgr][INFO] - matplotlib not found.\n",
            "[2026-02-19 18:17:11,973][pkgmgr][INFO] - Installing matplotlib...\n",
            "[2026-02-19 18:17:22,038][pkgmgr][INFO] - Collecting matplotlib==3.7.5\n",
            "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib==3.7.5)\n",
            "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib==3.7.5)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib==3.7.5)\n",
            "  Downloading fonttools-4.57.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib==3.7.5)\n",
            "  Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.7.5) (1.24.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.7.5) (26.0)\n",
            "Collecting pillow>=6.2.0 (from matplotlib==3.7.5)\n",
            "  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib==3.7.5) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.7.5) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.7.5) (6.4.5)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib==3.7.5) (3.20.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.5) (1.16.0)\n",
            "Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.2/9.2 MB 49.1 MB/s eta 0:00:00\n",
            "Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.57.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 79.6 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 37.5 MB/s eta 0:00:00\n",
            "Downloading pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 90.8 MB/s eta 0:00:00\n",
            "Installing collected packages: pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.7 matplotlib-3.7.5 pillow-10.4.0\n",
            "\n",
            "[2026-02-19 18:17:22,622][matplotlib.font_manager][INFO] - generated new fontManager\n",
            "[2026-02-19 18:17:22,921][Adila.src.adila][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "[2026-02-19 18:17:22,927][Adila.src.adila][INFO] - Loading failed! Generating files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc ...\n",
            "[2026-02-19 18:17:22,965][matplotlib.legend][WARNING] - No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "[2026-02-19 18:17:22,970][Adila.src.adila][INFO] - Generating ratios ... \n",
            "100% 5/5 [00:00<00:00, 1130.78it/s]\n",
            "[2026-02-19 18:17:22,976][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.eo.auc ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:22,981][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:22,981][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:22,983][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2726.05it/s]\n",
            "[2026-02-19 18:17:23,126][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:23,129][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:23,130][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:23,138][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:23,140][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:23,150][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1819.18it/s]\n",
            "[2026-02-19 18:17:23,158][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:23,167][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 202.90it/s]\n",
            "[2026-02-19 18:17:23,206][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:23,207][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:23,207][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.fa-ir.auc.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:23,207][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "  0% 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            " 40% 2/5 [00:00<00:00, 12.79it/s]/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            " 80% 4/5 [00:00<00:00, 14.03it/s]/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "100% 5/5 [00:00<00:00, 13.44it/s]\n",
            "[2026-02-19 18:17:23,583][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.fa-ir.auc.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3444.16it/s]\n",
            "[2026-02-19 18:17:23,596][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:23,599][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.fa-ir.auc.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:23,599][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:23,604][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.fa-ir.auc.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:23,606][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:23,613][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2715.46it/s]\n",
            "[2026-02-19 18:17:23,619][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:23,624][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 224.20it/s]\n",
            "[2026-02-19 18:17:23,659][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:23,660][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:23,660][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.fa-ir.auc.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:23,661][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "  0% 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            " 40% 2/5 [00:00<00:00, 14.16it/s]/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            " 80% 4/5 [00:00<00:00, 12.98it/s]/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "100% 5/5 [00:00<00:00, 13.37it/s]\n",
            "[2026-02-19 18:17:24,038][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.fa-ir.auc.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 1902.01it/s]\n",
            "[2026-02-19 18:17:24,055][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:24,059][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.fa-ir.auc.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:24,059][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:24,065][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.fa-ir.auc.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:24,067][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:24,075][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3084.50it/s]\n",
            "[2026-02-19 18:17:24,080][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:24,084][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 236.65it/s]\n",
            "[2026-02-19 18:17:24,118][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:24,119][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.eo.auc ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:24,122][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:24,123][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_greedy.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:24,123][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3817.86it/s]\n",
            "[2026-02-19 18:17:24,128][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_greedy.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3790.95it/s]\n",
            "[2026-02-19 18:17:24,139][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:24,142][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_greedy.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:24,143][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:24,147][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_greedy.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:24,148][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:24,155][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2787.65it/s]\n",
            "[2026-02-19 18:17:24,160][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:24,165][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 223.39it/s]\n",
            "[2026-02-19 18:17:24,200][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:24,201][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:24,201][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_greedy.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:24,201][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 4096.80it/s]\n",
            "[2026-02-19 18:17:24,206][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_greedy.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3592.86it/s]\n",
            "[2026-02-19 18:17:24,218][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:24,221][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_greedy.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:24,221][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:24,227][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_greedy.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:24,228][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:24,236][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2934.72it/s]\n",
            "[2026-02-19 18:17:24,243][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:24,251][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 112.71it/s]\n",
            "[2026-02-19 18:17:24,313][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:24,314][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:24,314][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_greedy.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:24,315][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3020.96it/s]\n",
            "[2026-02-19 18:17:24,320][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_greedy.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3541.89it/s]\n",
            "[2026-02-19 18:17:24,332][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:24,335][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_greedy.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:24,335][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:24,340][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_greedy.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:24,341][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:24,347][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3229.87it/s]\n",
            "[2026-02-19 18:17:24,352][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:24,356][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 236.88it/s]\n",
            "[2026-02-19 18:17:24,389][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:24,390][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.eo.auc ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:24,393][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:24,394][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:24,394][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 4045.43it/s]\n",
            "[2026-02-19 18:17:24,398][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3434.58it/s]\n",
            "[2026-02-19 18:17:24,410][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:24,413][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:24,413][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:24,418][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:24,419][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:24,425][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3148.88it/s]\n",
            "[2026-02-19 18:17:24,429][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:24,434][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 231.79it/s]\n",
            "[2026-02-19 18:17:24,467][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:24,468][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:24,469][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_relaxed.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:24,469][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3700.64it/s]\n",
            "[2026-02-19 18:17:24,473][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_relaxed.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3337.29it/s]\n",
            "[2026-02-19 18:17:24,487][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:24,489][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_relaxed.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:24,490][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:24,495][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_relaxed.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:24,496][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:24,503][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2284.73it/s]\n",
            "[2026-02-19 18:17:24,509][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:24,514][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 222.98it/s]\n",
            "[2026-02-19 18:17:24,555][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:24,556][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:24,556][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_relaxed.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:24,556][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 2623.08it/s]\n",
            "[2026-02-19 18:17:24,563][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_relaxed.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2678.70it/s]\n",
            "[2026-02-19 18:17:24,579][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:24,583][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_relaxed.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:24,583][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:24,588][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_relaxed.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:24,589][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:24,596][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2293.22it/s]\n",
            "[2026-02-19 18:17:24,601][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:24,605][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 208.46it/s]\n",
            "[2026-02-19 18:17:24,642][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:24,643][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.eo.auc ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:24,646][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:24,647][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:24,647][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 4027.56it/s]\n",
            "[2026-02-19 18:17:24,651][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3583.65it/s]\n",
            "[2026-02-19 18:17:24,662][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:24,666][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:24,666][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:24,671][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:24,672][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:24,679][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2899.42it/s]\n",
            "[2026-02-19 18:17:24,683][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:24,688][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 225.40it/s]\n",
            "[2026-02-19 18:17:24,722][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:24,723][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:24,723][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_const_sort.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:24,723][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3953.16it/s]\n",
            "[2026-02-19 18:17:24,728][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_const_sort.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3230.86it/s]\n",
            "[2026-02-19 18:17:24,741][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:24,745][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_const_sort.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:24,745][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:24,755][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_const_sort.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:24,757][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:24,773][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1928.06it/s]\n",
            "[2026-02-19 18:17:24,779][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:24,789][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 184.69it/s]\n",
            "[2026-02-19 18:17:24,830][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:24,831][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:24,831][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_const_sort.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:24,831][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3927.25it/s]\n",
            "[2026-02-19 18:17:24,836][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_const_sort.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2858.71it/s]\n",
            "[2026-02-19 18:17:24,849][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:24,852][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_const_sort.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:24,852][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:24,857][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_const_sort.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:24,858][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:24,864][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3031.44it/s]\n",
            "[2026-02-19 18:17:24,869][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:24,873][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 241.23it/s]\n",
            "[2026-02-19 18:17:24,906][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:24,907][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.eo.auc ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:24,911][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:24,911][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_cons.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:24,911][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 2389.10it/s]\n",
            "[2026-02-19 18:17:24,918][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_cons.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 1923.11it/s]\n",
            "[2026-02-19 18:17:24,935][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:24,939][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_cons.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:24,939][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:24,946][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_cons.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:24,948][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:24,955][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2994.65it/s]\n",
            "[2026-02-19 18:17:24,959][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:24,964][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 205.53it/s]\n",
            "[2026-02-19 18:17:25,001][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:25,002][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:25,003][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_cons.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:25,003][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 2066.36it/s]\n",
            "[2026-02-19 18:17:25,012][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_cons.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3100.00it/s]\n",
            "[2026-02-19 18:17:25,026][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:25,031][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_cons.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:25,032][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:25,039][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_cons.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:25,041][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:25,051][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1540.21it/s]\n",
            "[2026-02-19 18:17:25,058][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:25,065][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 166.92it/s]\n",
            "[2026-02-19 18:17:25,110][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f2.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:25,111][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:25,111][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_cons.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:25,112][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3911.14it/s]\n",
            "[2026-02-19 18:17:25,117][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_cons.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2516.38it/s]\n",
            "[2026-02-19 18:17:25,129][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:25,132][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_cons.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:25,132][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:25,136][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_cons.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:25,138][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:25,143][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3020.09it/s]\n",
            "[2026-02-19 18:17:25,148][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:25,153][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 241.20it/s]\n",
            "[2026-02-19 18:17:25,186][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/eo/f1.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:25,186][Adila.src.adila][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "[2026-02-19 18:17:25,189][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.dp.avg ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:25,192][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:25,192][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:25,195][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3540.69it/s]\n",
            "[2026-02-19 18:17:25,206][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:25,209][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:25,209][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:25,214][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:25,215][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:25,221][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2671.53it/s]\n",
            "[2026-02-19 18:17:25,226][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:25,230][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 166.18it/s]\n",
            "[2026-02-19 18:17:25,276][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:25,277][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:25,277][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.fa-ir.avg.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:25,277][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "100% 5/5 [00:00<00:00, 65.46it/s]\n",
            "[2026-02-19 18:17:25,358][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.fa-ir.avg.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3666.99it/s]\n",
            "[2026-02-19 18:17:25,369][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:25,373][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.fa-ir.avg.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:25,373][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:25,379][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.fa-ir.avg.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:25,380][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:25,387][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2922.45it/s]\n",
            "[2026-02-19 18:17:25,391][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:25,396][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 214.00it/s]\n",
            "[2026-02-19 18:17:25,433][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:25,434][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:25,435][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.fa-ir.avg.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:25,435][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "100% 5/5 [00:00<00:00, 66.98it/s]\n",
            "[2026-02-19 18:17:25,513][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.fa-ir.avg.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3538.30it/s]\n",
            "[2026-02-19 18:17:25,526][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:25,529][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.fa-ir.avg.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:25,529][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:25,533][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.fa-ir.avg.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:25,535][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:25,541][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3171.26it/s]\n",
            "[2026-02-19 18:17:25,545][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:25,550][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 147.53it/s]\n",
            "[2026-02-19 18:17:25,600][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:25,601][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.dp.avg ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:25,604][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:25,604][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_greedy.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:25,604][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 134.36it/s]\n",
            "[2026-02-19 18:17:25,645][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_greedy.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3656.12it/s]\n",
            "[2026-02-19 18:17:25,656][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:25,659][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_greedy.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:25,659][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:25,664][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_greedy.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:25,665][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:25,671][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3061.09it/s]\n",
            "[2026-02-19 18:17:25,676][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:25,680][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 236.39it/s]\n",
            "[2026-02-19 18:17:25,714][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:25,715][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:25,715][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_greedy.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:25,715][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 126.00it/s]\n",
            "[2026-02-19 18:17:25,759][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_greedy.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2529.74it/s]\n",
            "[2026-02-19 18:17:25,774][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:25,778][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_greedy.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:25,778][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:25,784][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_greedy.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:25,786][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:25,796][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2767.79it/s]\n",
            "[2026-02-19 18:17:25,801][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:25,805][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 238.00it/s]\n",
            "[2026-02-19 18:17:25,839][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:25,840][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:25,840][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_greedy.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:25,840][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 147.80it/s]\n",
            "[2026-02-19 18:17:25,878][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_greedy.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2854.04it/s]\n",
            "[2026-02-19 18:17:25,890][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:25,893][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_greedy.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:25,893][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:25,897][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_greedy.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:25,898][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:25,904][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3231.86it/s]\n",
            "[2026-02-19 18:17:25,909][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:25,913][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 233.16it/s]\n",
            "[2026-02-19 18:17:25,947][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:25,948][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.dp.avg ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:25,952][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:25,952][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:25,952][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 108.48it/s]\n",
            "[2026-02-19 18:17:26,003][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3092.69it/s]\n",
            "[2026-02-19 18:17:26,018][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:26,021][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:26,022][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:26,028][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:26,029][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:26,036][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2526.69it/s]\n",
            "[2026-02-19 18:17:26,041][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:26,046][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 162.39it/s]\n",
            "[2026-02-19 18:17:26,093][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:26,094][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:26,095][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_relaxed.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:26,095][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 129.25it/s]\n",
            "[2026-02-19 18:17:26,138][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_relaxed.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3337.29it/s]\n",
            "[2026-02-19 18:17:26,150][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:26,153][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_relaxed.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:26,153][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:26,158][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_relaxed.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:26,159][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:26,166][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3007.96it/s]\n",
            "[2026-02-19 18:17:26,172][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:26,176][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 241.25it/s]\n",
            "[2026-02-19 18:17:26,210][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:26,211][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:26,211][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_relaxed.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:26,211][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 125.29it/s]\n",
            "[2026-02-19 18:17:26,255][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_relaxed.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2112.79it/s]\n",
            "[2026-02-19 18:17:26,273][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:26,278][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_relaxed.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:26,278][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:26,284][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_relaxed.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:26,286][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:26,297][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1899.59it/s]\n",
            "[2026-02-19 18:17:26,303][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:26,310][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 214.62it/s]\n",
            "[2026-02-19 18:17:26,346][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:26,348][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.dp.avg ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:26,351][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:26,351][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:26,351][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 147.84it/s]\n",
            "[2026-02-19 18:17:26,389][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3632.69it/s]\n",
            "[2026-02-19 18:17:26,401][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:26,404][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:26,404][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:26,409][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:26,410][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:26,416][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3036.27it/s]\n",
            "[2026-02-19 18:17:26,421][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:26,425][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 239.32it/s]\n",
            "[2026-02-19 18:17:26,458][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:26,459][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:26,459][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_const_sort.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:26,459][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 136.35it/s]\n",
            "[2026-02-19 18:17:26,500][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_const_sort.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2741.02it/s]\n",
            "[2026-02-19 18:17:26,514][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:26,517][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_const_sort.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:26,517][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:26,522][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_const_sort.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:26,523][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:26,529][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3202.25it/s]\n",
            "[2026-02-19 18:17:26,533][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:26,538][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 211.74it/s]\n",
            "[2026-02-19 18:17:26,577][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:26,578][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:26,578][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_const_sort.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:26,578][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 125.28it/s]\n",
            "[2026-02-19 18:17:26,623][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_const_sort.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3329.87it/s]\n",
            "[2026-02-19 18:17:26,635][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:26,637][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_const_sort.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:26,638][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:26,642][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_const_sort.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:26,644][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:26,650][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3094.97it/s]\n",
            "[2026-02-19 18:17:26,655][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:26,661][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 232.59it/s]\n",
            "[2026-02-19 18:17:26,695][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:26,696][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.dp.avg ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:26,700][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:26,700][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_cons.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:26,700][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 135.77it/s]\n",
            "[2026-02-19 18:17:26,741][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_cons.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3621.40it/s]\n",
            "[2026-02-19 18:17:26,754][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:26,757][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_cons.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:26,758][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:26,765][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_cons.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:26,767][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:26,777][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1757.44it/s]\n",
            "[2026-02-19 18:17:26,784][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:26,792][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 133.43it/s]\n",
            "[2026-02-19 18:17:26,844][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:26,845][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:26,846][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_cons.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:26,846][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 137.97it/s]\n",
            "[2026-02-19 18:17:26,886][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_cons.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3552.69it/s]\n",
            "[2026-02-19 18:17:26,897][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:26,899][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_cons.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:26,900][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:26,905][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_cons.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:26,906][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:26,913][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2840.90it/s]\n",
            "[2026-02-19 18:17:26,917][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:26,922][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 183.84it/s]\n",
            "[2026-02-19 18:17:26,964][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f2.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:26,965][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:26,965][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_cons.avg.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:26,965][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 69.78it/s]\n",
            "[2026-02-19 18:17:27,042][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_cons.avg.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2071.06it/s]\n",
            "[2026-02-19 18:17:27,058][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:27,061][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_cons.avg.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:27,062][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:27,067][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_cons.avg.5.rerank.pred ...\n",
            "[2026-02-19 18:17:27,068][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:27,074][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2873.60it/s]\n",
            "[2026-02-19 18:17:27,079][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:27,084][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 234.99it/s]\n",
            "[2026-02-19 18:17:27,120][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/dp/f1.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:27,120][Adila.src.adila][INFO] - Loading stats, ratios, and ids for minority experts ...\n",
            "[2026-02-19 18:17:27,123][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.dp.auc ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:27,126][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:27,126][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:27,129][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3614.53it/s]\n",
            "[2026-02-19 18:17:27,141][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:27,145][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:27,145][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:27,151][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:27,153][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:27,160][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2995.50it/s]\n",
            "[2026-02-19 18:17:27,166][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:27,172][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 138.39it/s]\n",
            "[2026-02-19 18:17:27,225][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:27,226][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:27,226][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.fa-ir.auc.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:27,227][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "100% 5/5 [00:00<00:00, 57.38it/s]\n",
            "[2026-02-19 18:17:27,319][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.fa-ir.auc.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3532.94it/s]\n",
            "[2026-02-19 18:17:27,331][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:27,333][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.fa-ir.auc.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:27,334][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:27,338][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.fa-ir.auc.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:27,340][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:27,347][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3171.26it/s]\n",
            "[2026-02-19 18:17:27,351][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:27,356][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 210.42it/s]\n",
            "[2026-02-19 18:17:27,392][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:27,392][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mfa-ir with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:27,393][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.fa-ir.auc.10.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:27,393][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "/usr/local/lib/python3.8/dist-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
            "  warnings.warn(\"Library has not been tested with values outside this range\")\n",
            "100% 5/5 [00:00<00:00, 74.61it/s]\n",
            "[2026-02-19 18:17:27,464][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.fa-ir.auc.10.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 1723.50it/s]\n",
            "[2026-02-19 18:17:27,482][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:27,486][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.fa-ir.auc.10.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:27,487][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:27,493][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.fa-ir.auc.10.5.rerank.pred ...\n",
            "[2026-02-19 18:17:27,495][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:27,505][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2203.82it/s]\n",
            "[2026-02-19 18:17:27,511][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:27,517][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 204.90it/s]\n",
            "[2026-02-19 18:17:27,554][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:27,556][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.dp.auc ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:27,558][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:27,559][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_greedy.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:27,559][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3934.62it/s]\n",
            "[2026-02-19 18:17:27,564][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_greedy.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3730.92it/s]\n",
            "[2026-02-19 18:17:27,575][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:27,578][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_greedy.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:27,578][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:27,583][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_greedy.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:27,584][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:27,591][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3079.52it/s]\n",
            "[2026-02-19 18:17:27,595][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:27,601][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 215.41it/s]\n",
            "[2026-02-19 18:17:27,637][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:27,638][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:27,638][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_greedy.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:27,638][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3206.65it/s]\n",
            "[2026-02-19 18:17:27,643][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_greedy.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3515.76it/s]\n",
            "[2026-02-19 18:17:27,655][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:27,657][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_greedy.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:27,658][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:27,662][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_greedy.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:27,663][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:27,670][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2994.65it/s]\n",
            "[2026-02-19 18:17:27,675][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:27,679][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 221.28it/s]\n",
            "[2026-02-19 18:17:27,714][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:27,715][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_greedy with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:27,715][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_greedy.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:27,715][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3999.15it/s]\n",
            "[2026-02-19 18:17:27,720][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_greedy.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2354.76it/s]\n",
            "[2026-02-19 18:17:27,736][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:27,739][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_greedy.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:27,739][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:27,747][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_greedy.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:27,748][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:27,758][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1737.49it/s]\n",
            "[2026-02-19 18:17:27,767][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:27,779][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 118.92it/s]\n",
            "[2026-02-19 18:17:27,842][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:27,844][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.dp.auc ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:27,849][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:27,849][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:27,849][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 2500.18it/s]\n",
            "[2026-02-19 18:17:27,856][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2233.15it/s]\n",
            "[2026-02-19 18:17:27,872][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:27,875][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:27,875][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:27,880][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:27,881][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:27,887][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2751.08it/s]\n",
            "[2026-02-19 18:17:27,892][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:27,897][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 237.10it/s]\n",
            "[2026-02-19 18:17:27,932][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:27,933][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:27,933][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_relaxed.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:27,934][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3785.47it/s]\n",
            "[2026-02-19 18:17:27,939][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_relaxed.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3476.13it/s]\n",
            "[2026-02-19 18:17:27,950][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:27,954][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_relaxed.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:27,954][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:27,958][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_relaxed.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:27,960][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:27,966][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3041.55it/s]\n",
            "[2026-02-19 18:17:27,970][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:27,977][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 134.62it/s]\n",
            "[2026-02-19 18:17:28,039][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:28,041][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_relaxed with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:28,041][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_relaxed.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:28,042][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 2597.41it/s]\n",
            "[2026-02-19 18:17:28,052][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_relaxed.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2059.06it/s]\n",
            "[2026-02-19 18:17:28,074][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:28,078][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_relaxed.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:28,078][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:28,087][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_relaxed.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:28,089][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:28,098][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1822.50it/s]\n",
            "[2026-02-19 18:17:28,105][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:28,112][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 192.93it/s]\n",
            "[2026-02-19 18:17:28,152][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:28,153][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.dp.auc ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:28,159][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:28,159][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:28,159][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3906.04it/s]\n",
            "[2026-02-19 18:17:28,164][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3177.02it/s]\n",
            "[2026-02-19 18:17:28,176][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:28,179][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:28,179][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:28,184][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:28,185][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:28,192][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2968.79it/s]\n",
            "[2026-02-19 18:17:28,197][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:28,202][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 158.00it/s]\n",
            "[2026-02-19 18:17:28,251][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:28,252][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:28,252][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_const_sort.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:28,252][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 1275.56it/s]\n",
            "[2026-02-19 18:17:28,262][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_const_sort.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 1400.15it/s]\n",
            "[2026-02-19 18:17:28,282][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:28,288][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_const_sort.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:28,288][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:28,295][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_const_sort.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:28,297][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:28,308][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2048.60it/s]\n",
            "[2026-02-19 18:17:28,314][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:28,323][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 174.42it/s]\n",
            "[2026-02-19 18:17:28,369][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:28,370][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_const_sort with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:28,371][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_const_sort.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:28,371][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 4039.20it/s]\n",
            "[2026-02-19 18:17:28,376][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_const_sort.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 2513.06it/s]\n",
            "[2026-02-19 18:17:28,388][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:28,391][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_const_sort.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:28,391][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:28,396][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_const_sort.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:28,397][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:28,403][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1975.09it/s]\n",
            "[2026-02-19 18:17:28,409][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:28,414][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 212.94it/s]\n",
            "[2026-02-19 18:17:28,450][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:28,451][Adila.src.main][INFO] - Queuing all *.pred files at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000 for \u001b[96mpopularity.dp.auc ... \u001b[0m\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:28,454][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:28,454][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_cons.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred if exists ...\n",
            "[2026-02-19 18:17:28,454][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 3683.09it/s]\n",
            "[2026-02-19 18:17:28,459][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_cons.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3649.12it/s]\n",
            "[2026-02-19 18:17:28,470][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:28,473][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_cons.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:28,474][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:28,479][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_cons.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:28,480][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:28,486][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3135.69it/s]\n",
            "[2026-02-19 18:17:28,491][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:28,495][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 239.22it/s]\n",
            "[2026-02-19 18:17:28,529][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:28,530][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:28,530][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_cons.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred if exists ...\n",
            "[2026-02-19 18:17:28,530][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 4071.35it/s]\n",
            "[2026-02-19 18:17:28,535][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_cons.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3522.85it/s]\n",
            "[2026-02-19 18:17:28,546][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:28,548][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_cons.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:28,549][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:28,553][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_cons.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:28,554][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:28,560][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3096.34it/s]\n",
            "[2026-02-19 18:17:28,565][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:28,569][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 127.62it/s]\n",
            "[2026-02-19 18:17:28,624][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f2.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "/content/opentf/src/Adila/src/adila.py:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  preds = torch.load(fpred, map_location='cpu')['y_pred']\n",
            "[2026-02-19 18:17:28,625][Adila.src.adila][INFO] - Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred using \u001b[94mdet_cons with 5 cutoff ...\u001b[0m\n",
            "[2026-02-19 18:17:28,625][Adila.src.adila][INFO] - Loading reranked file ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_cons.auc.5.rerank.pred for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred if exists ...\n",
            "[2026-02-19 18:17:28,625][Adila.src.adila][INFO] - No existing rerank version. Reranking ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ...\n",
            "100% 5/5 [00:00<00:00, 1265.17it/s]\n",
            "[2026-02-19 18:17:28,635][Adila.src.adila][INFO] - \u001b[92mFairness evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_cons.auc.5.rerank.pred using ['ndkl', 'skew'] with 1000 cutoff ...\u001b[0m\n",
            "5it [00:00, 3215.01it/s]\n",
            "[2026-02-19 18:17:28,647][Adila.src.adila][INFO] - Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean/instance.csv.\n",
            "[2026-02-19 18:17:28,652][Adila.src.adila][INFO] - \u001b[95mUtility evaluation for ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_cons.auc.5.rerank.pred ... \u001b[0m\n",
            "[2026-02-19 18:17:28,652][Adila.src.adila][INFO] - Before: Loading ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv ...\n",
            "[2026-02-19 18:17:28,657][Adila.src.adila][INFO] - After: Evaluating ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_cons.auc.5.rerank.pred ...\n",
            "[2026-02-19 18:17:28,658][Adila.src.adila][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2026-02-19 18:17:28,664][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3141.80it/s]\n",
            "[2026-02-19 18:17:28,668][Adila.src.adila][INFO] - ['aucroc'] ...\n",
            "[2026-02-19 18:17:28,673][Adila.src.adila][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 218.36it/s]\n",
            "[2026-02-19 18:17:28,709][Adila.src.adila][INFO] - After: Saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.auc/dp/f1.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv.\n",
            "[2026-02-19 18:17:28,709][__main__][INFO] - \u001b[92mAggregating the test results under ../output/dblp/toy.dblp.v12.json per splits from test.pred.eval.mean.csv files ... \u001b[0m\n",
            "[2026-02-19 18:17:28,719][__main__][INFO] - \u001b[92m../output/dblp/toy.dblp.v12.json/splits.f3.r0.85 ... \u001b[0m\n",
            "[2026-02-19 18:17:28,720][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,724][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,728][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,733][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/gcn.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.h128.nn30-20/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,737][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,741][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,745][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,749][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/m2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w4.wl3.wn10.tstm/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,753][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/d2v.d128.e100.w5.dm1.skill/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,758][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/d2v.d128.e100.w5.dm1.skill/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,762][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/d2v.d128.e100.w5.dm1.skill/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,766][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,769][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,773][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,780][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,786][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/n2v.b1000.e100.ns5.lr0.001.es5.spe10.d128.add.stm.w5.wl5.wn10/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,792][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,798][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,804][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/nmt.b1000.e100.lr0.001.es5.spe10.enctransformer/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,825][__main__][INFO] - \u001b[92mSaved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/test.pred.eval.mean.agg.csv. \u001b[0m\n",
            "[2026-02-19 18:17:28,827][__main__][INFO] - \u001b[92m../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1 ... \u001b[0m\n",
            "[2026-02-19 18:17:28,829][__main__][INFO] - ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe10.lbce.tpw10.tnw1.nsdunigram_b.nmc10/2004/test.pred.eval.mean.csv\n",
            "[2026-02-19 18:17:28,839][__main__][INFO] - \u001b[92mSaved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.t1/test.pred.eval.mean.agg.csv. \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Folders and Files**\n",
        "\n",
        "From `Adila`'s [`quickstart`](https://colab.research.google.com/github/fani-lab/Adila/blob/main/quickstart.ipynb) script:\n",
        "\n",
        "- `adila/{popularity,gender}/stats.pkl`, the distribution of popular/non-popular, or male/female experts in the entire dataset\n",
        "- `adila/{popularity,gender}/labels.csv`, the ids for popular or female experts. While the female ids are fixed and obtained from the `data.fgender` file, the popular ids depends on `is_popular_alg` and is calculated based on the data distribution\n",
        "\n",
        "- `adila/{popularity,gender}/{notion}`, the subfolder containg the results based on the fairness notion\n",
        "- `adila/{popularity,gender}/{notion}/{data.fpred}.{fair.algorithm}.{fair.k_max}.rerank.pred`, the reranked version of the recommended members from `data.fpred`\n",
        "- `adila/{popularity,gender}/{notion}/{data.fpred}.{fair.algorithm}.{fair.k_max}.rerank.pred.eval.fair.instance.csv`, the fairness metric values for `data.fpred` (before) and the reranked version (after) per each team instance in the test set  \n",
        "- `adila/{popularity,gender}/{notion}/{data.fpred}.{fair.algorithm}.{fair.k_max}.rerank.pred.eval.fair.mean.csv`, the average of fairness metric values for `data.fpred` (before) and the reranked version (after) over all teams of the test set  \n",
        "- `adila/{popularity,gender}/{notion}/{data.fpred}.{fair.algorithm}.{fair.k_max}.rerank.pred.eval.utility.instance.csv`, the accuracy metric values for `data.fpred` (before) and the reranked version (after) per each team instance in the test set  \n",
        "- `adila/{popularity,gender}/{notion}/{data.fpred}.{fair.algorithm}.{fair.k_max}.rerank.pred.eval.utility.mean.csv`, the average of accuracy metric values for `data.fpred` (before) and the reranked version (after) over all teams of the test set"
      ],
      "metadata": {
        "id": "_sZ9lZ2_ef-K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1ktJb2ghLXu",
        "outputId": "f5444d28-f72f-456d-f2ab-2759d0327ebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "│   │   │   │   │   │   │   \n",
            "│   │   │   │   │   │   ├── popularity.auc\n",
            "│   │   │   │   │   │   │   ├── stats.pkl\n",
            "│   │   │   │   │   │   │   ├── dp\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.auc.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.auc.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.auc.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   ├── eo\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.auc.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.auc.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.auc.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.auc.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── ratios.pkl\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.auc.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.auc.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.auc.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.auc.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.auc.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   ├── labels.csv\n",
            "│   │   │   │   │   │   ├── gender\n",
            "│   │   │   │   │   │   │   ├── stats.pkl\n",
            "│   │   │   │   │   │   │   ├── dp\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   ├── eo\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── ratios.pkl\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   ├── labels.csv\n",
            "│   │   │   │   │   │   ├── popularity.avg\n",
            "│   │   │   │   │   │   │   ├── stats.pkl\n",
            "│   │   │   │   │   │   │   ├── dp\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.avg.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.avg.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.avg.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   ├── eo\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.avg.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.avg.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_const_sort.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_const_sort.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── ratios.pkl\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_const_sort.avg.5.rerank.pred.eval.fair.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_greedy.avg.5.rerank.pred.eval.fair.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.fa-ir.avg.10.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_greedy.avg.5.rerank.pred.eval.utility.instance.csv\n",
            "│   │   │   │   │   │   │   │   ├── f0.test.pred.det_cons.avg.5.rerank.pred\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_relaxed.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f2.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   │   ├── f1.test.pred.det_cons.avg.5.rerank.pred.eval.utility.mean.csv\n",
            "│   │   │   │   │   │   │   ├── labels.csv\n"
          ]
        }
      ],
      "source": [
        "!find ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/ -print | sed 's;[^/]*/;│   ;g;s;│   \\([^│]\\);├── \\1;'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Average fairness measures**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0XPjutdQ4_dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.mean.csv', index_col=0)"
      ],
      "metadata": {
        "id": "afwtkamt5moP",
        "outputId": "7d57f64f-3392-4694-b86b-d45e9d6472ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               mean.after  mean.before\n",
              "metrics                               \n",
              "ndkl             0.171038     0.171038\n",
              "skew.majority    0.025318     0.025318\n",
              "skew.minority   -0.262364    -0.262364"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f8b097a-8683-4cca-afe9-503f0719bdd2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean.after</th>\n",
              "      <th>mean.before</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metrics</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ndkl</th>\n",
              "      <td>0.171038</td>\n",
              "      <td>0.171038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skew.majority</th>\n",
              "      <td>0.025318</td>\n",
              "      <td>0.025318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skew.minority</th>\n",
              "      <td>-0.262364</td>\n",
              "      <td>-0.262364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f8b097a-8683-4cca-afe9-503f0719bdd2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0f8b097a-8683-4cca-afe9-503f0719bdd2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0f8b097a-8683-4cca-afe9-503f0719bdd2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"metrics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ndkl\",\n          \"skew.majority\",\n          \"skew.minority\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean.after\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2205420920481196,\n        \"min\": -0.2623642644644909,\n        \"max\": 0.1710380122403349,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.1710380122403349,\n          0.025317807984262,\n          -0.2623642644644909\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean.before\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2205420920481196,\n        \"min\": -0.2623642644644909,\n        \"max\": 0.1710380122403349,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.1710380122403349,\n          0.025317807984262,\n          -0.2623642644644909\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fairness measures per each test team**"
      ],
      "metadata": {
        "id": "fIdoGfzC7EVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.fair.instance.csv')"
      ],
      "metadata": {
        "id": "wfpmBbgv6CEx",
        "outputId": "d74c532a-1db9-489b-b9f3-ab29abf43e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   before.ndkl  after.ndkl  before.skew.minority  before.skew.majority  \\\n",
              "0     0.100350    0.100350             -0.262364              0.025318   \n",
              "1     0.066075    0.066075             -0.262364              0.025318   \n",
              "2     0.055013    0.055013             -0.262364              0.025318   \n",
              "3     0.522018    0.522018             -0.262364              0.025318   \n",
              "4     0.111735    0.111735             -0.262364              0.025318   \n",
              "\n",
              "   after.skew.minority  after.skew.majority  \n",
              "0            -0.262364             0.025318  \n",
              "1            -0.262364             0.025318  \n",
              "2            -0.262364             0.025318  \n",
              "3            -0.262364             0.025318  \n",
              "4            -0.262364             0.025318  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f966ed27-ba0b-4a8c-8a7d-b46a40cb9d08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>before.ndkl</th>\n",
              "      <th>after.ndkl</th>\n",
              "      <th>before.skew.minority</th>\n",
              "      <th>before.skew.majority</th>\n",
              "      <th>after.skew.minority</th>\n",
              "      <th>after.skew.majority</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.100350</td>\n",
              "      <td>0.100350</td>\n",
              "      <td>-0.262364</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>-0.262364</td>\n",
              "      <td>0.025318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.066075</td>\n",
              "      <td>0.066075</td>\n",
              "      <td>-0.262364</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>-0.262364</td>\n",
              "      <td>0.025318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.055013</td>\n",
              "      <td>0.055013</td>\n",
              "      <td>-0.262364</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>-0.262364</td>\n",
              "      <td>0.025318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.522018</td>\n",
              "      <td>0.522018</td>\n",
              "      <td>-0.262364</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>-0.262364</td>\n",
              "      <td>0.025318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.111735</td>\n",
              "      <td>0.111735</td>\n",
              "      <td>-0.262364</td>\n",
              "      <td>0.025318</td>\n",
              "      <td>-0.262364</td>\n",
              "      <td>0.025318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f966ed27-ba0b-4a8c-8a7d-b46a40cb9d08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f966ed27-ba0b-4a8c-8a7d-b46a40cb9d08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f966ed27-ba0b-4a8c-8a7d-b46a40cb9d08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"before.ndkl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19759770839214405,\n        \"min\": 0.0550130340103111,\n        \"max\": 0.5220176037342419,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0660750627741903,\n          0.1117347693708669,\n          0.0550130340103111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"after.ndkl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19759770839214405,\n        \"min\": 0.0550130340103111,\n        \"max\": 0.5220176037342419,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0660750627741903,\n          0.1117347693708669,\n          0.0550130340103111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"before.skew.minority\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": -0.2623642644644909,\n        \"max\": -0.2623642644644909,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.2623642644644909\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"before.skew.majority\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.878959614448864e-18,\n        \"min\": 0.025317807984262,\n        \"max\": 0.025317807984262,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.025317807984262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"after.skew.minority\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": -0.2623642644644909,\n        \"max\": -0.2623642644644909,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.2623642644644909\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"after.skew.majority\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.878959614448864e-18,\n        \"min\": 0.025317807984262,\n        \"max\": 0.025317807984262,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.025317807984262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Average accuracy values (Utility)**\n"
      ],
      "metadata": {
        "id": "GwYM3i9e6KyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.mean.csv', index_col = 0)"
      ],
      "metadata": {
        "id": "3OguPqka6Hrl",
        "outputId": "bb9e5892-4704-4281-8151-253ef450306c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   mean.before  mean.after\n",
              "metric                                    \n",
              "P_2                   0.200000    0.200000\n",
              "P_5                   0.120000    0.120000\n",
              "P_10                  0.140000    0.140000\n",
              "recall_2              0.200000    0.200000\n",
              "recall_5              0.300000    0.300000\n",
              "recall_10             0.666667    0.666667\n",
              "ndcg_cut_2            0.200000    0.200000\n",
              "ndcg_cut_5            0.252814    0.252814\n",
              "ndcg_cut_10           0.400669    0.400669\n",
              "map_cut_2             0.150000    0.150000\n",
              "map_cut_5             0.175000    0.175000\n",
              "map_cut_10            0.249405    0.249405\n",
              "success_2             0.400000    0.400000\n",
              "success_5             0.600000    0.600000\n",
              "success_10            1.000000    1.000000\n",
              "aucroc                0.452862    0.452862\n",
              "skill_coverage_2      1.000000    1.000000\n",
              "skill_coverage_5      1.000000    1.000000\n",
              "skill_coverage_10     1.000000    1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e844d6c5-18dd-4281-90a4-45c0859a0760\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean.before</th>\n",
              "      <th>mean.after</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metric</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>P_2</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_5</th>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_10</th>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_2</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_5</th>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_10</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_2</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_5</th>\n",
              "      <td>0.252814</td>\n",
              "      <td>0.252814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <td>0.400669</td>\n",
              "      <td>0.400669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_2</th>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_5</th>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_10</th>\n",
              "      <td>0.249405</td>\n",
              "      <td>0.249405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_2</th>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_5</th>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_10</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aucroc</th>\n",
              "      <td>0.452862</td>\n",
              "      <td>0.452862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_2</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_5</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_10</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e844d6c5-18dd-4281-90a4-45c0859a0760')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e844d6c5-18dd-4281-90a4-45c0859a0760 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e844d6c5-18dd-4281-90a4-45c0859a0760');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"metric\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"P_2\",\n          \"recall_10\",\n          \"map_cut_10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean.before\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32863663407302096,\n        \"min\": 0.12,\n        \"max\": 1.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.2494047619047618,\n          0.6,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean.after\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32863663407302096,\n        \"min\": 0.12,\n        \"max\": 1.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.2494047619047618,\n          0.6,\n          0.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy values per each test team (Utility)**\n"
      ],
      "metadata": {
        "id": "fHxFVLr16cN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/adila/popularity.avg/eo/f0.test.pred.fa-ir.avg.10.5.rerank.pred.eval.utility.instance.csv')"
      ],
      "metadata": {
        "id": "UN5XfxuG6iyO",
        "outputId": "b016f79f-3697-4511-cbfe-b620dbf94c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   P_2.before  P_5.before  P_10.before  recall_2.before  recall_5.before  \\\n",
              "0         0.0         0.0          0.1              0.0              0.0   \n",
              "1         0.5         0.2          0.2              0.5              0.5   \n",
              "2         0.0         0.0          0.1              0.0              0.0   \n",
              "3         0.0         0.2          0.1              0.0              0.5   \n",
              "4         0.5         0.2          0.2              0.5              0.5   \n",
              "\n",
              "   recall_10.before  ndcg_cut_2.before  ndcg_cut_5.before  ndcg_cut_10.before  \\\n",
              "0           0.50000            0.00000            0.00000             0.19343   \n",
              "1           1.00000            0.61315            0.61315             0.81753   \n",
              "2           0.33333            0.00000            0.00000             0.14804   \n",
              "3           0.50000            0.00000            0.26407             0.26407   \n",
              "4           1.00000            0.38685            0.38685             0.58028   \n",
              "\n",
              "   map_cut_2.before  ...  ndcg_cut_10.after  map_cut_2.after  map_cut_5.after  \\\n",
              "0              0.00  ...            0.19343             0.00            0.000   \n",
              "1              0.50  ...            0.81753             0.50            0.500   \n",
              "2              0.00  ...            0.14804             0.00            0.000   \n",
              "3              0.00  ...            0.26407             0.00            0.125   \n",
              "4              0.25  ...            0.58028             0.25            0.250   \n",
              "\n",
              "   map_cut_10.after  success_2.after  success_5.after  success_10.after  \\\n",
              "0           0.06250              0.0              0.0               1.0   \n",
              "1           0.64286              1.0              1.0               1.0   \n",
              "2           0.04167              0.0              0.0               1.0   \n",
              "3           0.12500              0.0              1.0               1.0   \n",
              "4           0.37500              1.0              1.0               1.0   \n",
              "\n",
              "   skill_coverage_2.after  skill_coverage_5.after  skill_coverage_10.after  \n",
              "0                     1.0                     1.0                      1.0  \n",
              "1                     1.0                     1.0                      1.0  \n",
              "2                     1.0                     1.0                      1.0  \n",
              "3                     1.0                     1.0                      1.0  \n",
              "4                     1.0                     1.0                      1.0  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00696276-4ae1-40ee-adab-088e5f35cb2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P_2.before</th>\n",
              "      <th>P_5.before</th>\n",
              "      <th>P_10.before</th>\n",
              "      <th>recall_2.before</th>\n",
              "      <th>recall_5.before</th>\n",
              "      <th>recall_10.before</th>\n",
              "      <th>ndcg_cut_2.before</th>\n",
              "      <th>ndcg_cut_5.before</th>\n",
              "      <th>ndcg_cut_10.before</th>\n",
              "      <th>map_cut_2.before</th>\n",
              "      <th>...</th>\n",
              "      <th>ndcg_cut_10.after</th>\n",
              "      <th>map_cut_2.after</th>\n",
              "      <th>map_cut_5.after</th>\n",
              "      <th>map_cut_10.after</th>\n",
              "      <th>success_2.after</th>\n",
              "      <th>success_5.after</th>\n",
              "      <th>success_10.after</th>\n",
              "      <th>skill_coverage_2.after</th>\n",
              "      <th>skill_coverage_5.after</th>\n",
              "      <th>skill_coverage_10.after</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.19343</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.19343</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.06250</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.61315</td>\n",
              "      <td>0.61315</td>\n",
              "      <td>0.81753</td>\n",
              "      <td>0.50</td>\n",
              "      <td>...</td>\n",
              "      <td>0.81753</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.64286</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.14804</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14804</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.04167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.26407</td>\n",
              "      <td>0.26407</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.26407</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.38685</td>\n",
              "      <td>0.38685</td>\n",
              "      <td>0.58028</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.58028</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00696276-4ae1-40ee-adab-088e5f35cb2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-00696276-4ae1-40ee-adab-088e5f35cb2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-00696276-4ae1-40ee-adab-088e5f35cb2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tmp_opentf",
      "language": "python",
      "name": "tmp_opentf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}