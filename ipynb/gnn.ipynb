{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fani-lab/OpeNTF/blob/main/ipynb/gnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QGHFtvGnTLJ"
      },
      "source": [
        "# `OpeNTF` with `GNN`:\n",
        "`OpeNTF` previously used traditional embedding methods (non-graph based) to provide skill embeddings as an input alternative to the one-hot encoded skills. With the advent of `GNN` methods, we now have graph-based **learned** skill embeddings usable as a form of more meaningful input. The gnns are now able to capture the synergistic collaborative ties within our transformed graph data to provide us with significant embeddings, resulting in even better recommendation of experts  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRbAgvZmnTLJ"
      },
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4tk12X-nTLK"
      },
      "source": [
        "#### **Graph Structures**\n",
        "\n",
        "OpeNTF applied with gnn aims to cover as many variations in graph structures for a given datasets. Currently, it implemented `heterogeneous`, `directed`, `unweighted` graph structures including `[[[skill, to, member]], sm]` bipartite, `[[[skill, to, team], [member, to, team]], stm]` tripartite and `[[[skill, to, team], [member, to, team], [loc, to, team]], stml]`, as seen in the figure, and can be set at [`src/mdl/emb/__config__.yaml`](https://github.com/fani-lab/OpeNTF/blob/756f729153b423989f862dd63903396c293d07b2/src/mdl/emb/__config__.yaml#L27)\n",
        "\n",
        "<p align=\"center\"><img src='https://raw.githubusercontent.com/fani-lab/OpeNTF/refs/heads/main/docs/graph_structures.png' width=\"500\" ></p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "MyHTxeMznTLK"
      },
      "source": [
        "#### **Neighborhood Sampling**\n",
        "\n",
        "We employ `mini-batching` strategy to extract smaller subgraphs as batches to accomodate large-scale dataset. The subgraphs are sampled based on surrounding neighborhood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "0Uiz41tPnTLK"
      },
      "source": [
        "## **Transfer vs. End-to-End Learning with GNN**\n",
        "\n",
        "Learning vector representations of skills, transfer it to a multilabel classifier to recommend top-k expert members of a team\n",
        "\n",
        "Directly predict expert-team links to recommend top-k expert members of a team\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQDUISpPnTLK"
      },
      "source": [
        "## Setup\n",
        "\n",
        "from quickstart script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwEN1xLDnTLK"
      },
      "source": [
        "## Quickstart on `OpeNTF` with `GNN`\n",
        "\n",
        "\n",
        "The embedding generation pipeline consists of the models``d2v (Doc2Vec), m2v (Metapath2Vec), gs (GraphSAGE), gat (GraphAttention), gatv2 (GraphAttentionV2),\n",
        "han (Heterogeneous Attention Network), gin (Graph Isomorphism Network) and gine (GIN-Edge feature enhanced).``\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "93caHB2EnTLL"
      },
      "source": [
        "## Setting Hyperparameters\n",
        "`OpeNTF`'s codebase offers the following hyperparameter to be set for each neural team formation methods:\n",
        "\n",
        "### `model`\n",
        "- Contains the baseline hyperparameters in the form of `'model-name' : { params }`, which allows the models to be integrated into the baseline with their unique parameters.\n",
        "- Allows the customization of which stages of the system to be executed through `cmd`.\n",
        "- Contains other training parameter for the models (e.g., temporal).\n",
        "\n",
        "### `data`\n",
        "- Contains parameters for manipulating datasets, including dataset filters (e.g., minimum team size) and bucket size for sparse matrix parallel generation.\n",
        "\n",
        "### `fair`\n",
        "- Contains parameters for the fairness metrics used in consideration during team formation.\n",
        "\n",
        "A snippet of the parameters used in `src/mdl/team2vec/params.py` is displayed as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-3guRWunTLM"
      },
      "source": [
        "# Additional Resources\n",
        "\n",
        "- [`WSDM` paper](https://)\n",
        "- [`WISE` paper](https://)\n",
        "- [`Radin sigir` paper](https://)\n",
        "- [`Sagar ` paper](https://)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZln-_cnnTLM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tmp_opentf",
      "language": "python",
      "name": "tmp_opentf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}