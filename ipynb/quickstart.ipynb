{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quickstart.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fani-lab/OpeNTF/blob/main/ipynb/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Setup Python 3.8 in Colab**\n",
        "- No need to create an environment as we are already in an environment/container\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hsO795wNk9WL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzuvvMImFFWg",
        "outputId": "dc1dc0d4-cf57-4acb-8209-feb30b132bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.83)] [\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,389 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,799 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,473 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,816 kB]\n",
            "Fetched 21.5 MB in 2s (9,635 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3-pkg-resources\n",
            "  python3-setuptools python3-wheel python3.8-lib2to3 python3.8-minimal\n",
            "Suggested packages:\n",
            "  python-setuptools-doc binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3-pip python3-setuptools\n",
            "  python3-wheel python3.8 python3.8-distutils python3.8-lib2to3\n",
            "  python3.8-minimal python3.8-venv\n",
            "The following packages will be upgraded:\n",
            "  python3-pkg-resources\n",
            "1 upgraded, 10 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 10.0 MB of archives.\n",
            "After this operation, 32.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.7 [1,306 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-pkg-resources all 68.1.2-2~jammy3 [216 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-setuptools all 68.1.2-2~jammy3 [465 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.20-1+jammy1 [126 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.20-1+jammy1 [193 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-venv amd64 3.8.20-1+jammy1 [2,618 kB]\n",
            "Fetched 10.0 MB in 2s (4,866 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 11.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 126718 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../01-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../02-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Preparing to unpack .../03-python3-pkg-resources_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-pkg-resources (68.1.2-2~jammy3) over (59.6.0-1.2ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../04-python3-setuptools_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-setuptools (68.1.2-2~jammy3) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../05-python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../06-python3-pip_22.0.2+dfsg-1ubuntu0.7_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../07-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "Preparing to unpack .../08-python3.8-lib2to3_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../09-python3.8-distutils_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-venv.\n",
            "Preparing to unpack .../10-python3.8-venv_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Setting up python3-pkg-resources (68.1.2-2~jammy3) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3-setuptools (68.1.2-2~jammy3) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.8.20\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y python3.8 python3.8-venv python3.8-distutils python3-pip\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 10\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Installing OpeNTF**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6tKkPogYlQxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R opentf/\n",
        "!git clone https://github.com/Fani-Lab/opentf\n",
        "!pip install --upgrade pip setuptools\n",
        "!pip install -r opentf/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fwIEGOF9FT4U",
        "outputId": "5a7ce294-5383-4916-876d-c72b39038dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'opentf/': No such file or directory\n",
            "Cloning into 'opentf'...\n",
            "remote: Enumerating objects: 22502, done.\u001b[K\n",
            "remote: Counting objects: 100% (679/679), done.\u001b[K\n",
            "remote: Compressing objects: 100% (528/528), done.\u001b[K\n",
            "remote: Total 22502 (delta 189), reused 497 (delta 138), pack-reused 21823 (from 4)\u001b[K\n",
            "Receiving objects: 100% (22502/22502), 903.37 MiB | 25.35 MiB/s, done.\n",
            "Resolving deltas: 100% (10982/10982), done.\n",
            "Updating files: 100% (1570/1570), done.\n",
            "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (68.1.2)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 68.1.2\n",
            "    Not uninstalling setuptools at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'setuptools'. No files were found to uninstall.\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.2\n",
            "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "    Can't uninstall 'pip'. No files were found to uninstall.\n",
            "Successfully installed pip-25.0.1 setuptools-75.3.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "6e64c94ddf6f4d4e9520b890dde11346"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hydra-core==1.3.2 (from -r opentf/requirements.txt (line 7))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting scipy==1.10.1 (from -r opentf/requirements.txt (line 8))\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Collecting numpy==1.24.4 (from -r opentf/requirements.txt (line 9))\n",
            "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core==1.3.2->-r opentf/requirements.txt (line 7))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core==1.3.2->-r opentf/requirements.txt (line 7))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging (from hydra-core==1.3.2->-r opentf/requirements.txt (line 7))\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting importlib-resources (from hydra-core==1.3.2->-r opentf/requirements.txt (line 7))\n",
            "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting PyYAML>=5.1.0 (from omegaconf<2.4,>=2.2->hydra-core==1.3.2->-r opentf/requirements.txt (line 7))\n",
            "  Downloading PyYAML-6.0.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting zipp>=3.1.0 (from importlib-resources->hydra-core==1.3.2->-r opentf/requirements.txt (line 7))\n",
            "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m174.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m195.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading PyYAML-6.0.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.0/806.0 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144552 sha256=4be9cd567186888a26cbd144f027839ad46565036a197168c0781b327a58f44b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, zipp, PyYAML, packaging, numpy, scipy, omegaconf, importlib-resources, hydra-core\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 1.0.0\n",
            "    Uninstalling zipp-1.0.0:\n",
            "      Successfully uninstalled zipp-1.0.0\n",
            "Successfully installed PyYAML-6.0.3 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 importlib-resources-6.4.5 numpy-1.24.4 omegaconf-2.3.0 packaging-25.0 scipy-1.10.1 zipp-3.20.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "packaging",
                  "pydevd_plugins"
                ]
              },
              "id": "37e76d929660423b8957505367969db8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**1. Running OpeNTF (Prep)**\n",
        "\n",
        "- Hydra config overriding `data.*` in [OpeNTF/src/\\_\\_config\\_\\_.yaml](https://github.com/fani-lab/OpeNTF/blob/main/src/__config__.yaml)\n",
        "\n",
        "  - Preprocessing raw data `cmd=prep` into `teamsvecs` sparse matrix each row of which is a team with its skills `teamsvecs['skill']`, members `teamsvecs['member']` as 1-hot vectors\n",
        "  - `data.domain`, `data.source`, `data.output` from `toy.dblp` dataset, available at the codebase [`OpeNTF/data/dblp`](https://github.com/fani-lab/OpeNTF/tree/main/data/dblp)\n",
        "  - No filtering for min team size `data.filter.min_nteam` and min number of teams per experts `data.filter.min_team_size`\n",
        "  - No embedding learning for skills\n",
        "  - No check for the availability of the preprocessed data at [`OpeNTF's huggingface`](https://huggingface.co/datasets/fani-lab/OpeNTF/tree/main/output)\n",
        "\n"
      ],
      "metadata": {
        "id": "SvDFzQM8KeMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd opentf/src/\n",
        "!python main.py cmd=prep data.domain=cmn.publication.Publication data.source=../data/dblp/toy.dblp.v12.json data.output=../output/dblp/toy.dblp.v12.json ~data.filter ~data.embedding ~data.hf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4xGf8dLr9g",
        "outputId": "ab18eb06-2642-438f-b770-b175eb32923f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'opentf/src/'\n",
            "/content/opentf/src\n",
            "[2025-10-25 13:27:24,320][cmn.team][INFO] - Loading teamsvecs matrices from ../output/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "[2025-10-25 13:27:24,321][pkgmgr][INFO] - tqdm not found.\n",
            "[2025-10-25 13:27:24,321][pkgmgr][INFO] - Installing tqdm...\n",
            "[2025-10-25 13:27:25,081][pkgmgr][INFO] - Collecting tqdm==4.65.0\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
            "Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.65.0\n",
            "\n",
            "[2025-10-25 13:27:25,086][cmn.team][INFO] - Loading indexes pickle from ../output/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "[2025-10-25 13:27:25,087][cmn.team][INFO] - Indexes pickle is loaded.\n",
            "[2025-10-25 13:27:25,087][cmn.team][INFO] - Teamsvecs matrices and indexes for skills (31, 10), members (31, 13), and locations (31, 29) are loaded.\n",
            "[2025-10-25 13:27:25,087][__main__][INFO] - Loading splits from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.pkl ...\n",
            "[2025-10-25 13:27:25,087][cmn.team][INFO] - Loading member-skill co-occurrence matrix (13, 10) from ../output/dblp/toy.dblp.v12.json/skillcoverage.pkl ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Folders and Files**\n",
        "\n",
        "- `teams.pkl`: team objects defined in [`OpeNTF/src/cmn/team.py`](https://github.com/fani-lab/OpeNTF/blob/main/src/cmn/team.py) and populated from the raw dataset\n",
        "- `teamsvecs.pkl`: sparse metrix representation of teams created from `teams.pkl`\n",
        "- `indexes.pkl`: dictionaries of metadata for mapping raw data to preprocessed data\n",
        "- `skillcoverage.pkl`: the member-skill co-occurrence matrix each row represent the skills of a member considering all the member's teams in the dataset   "
      ],
      "metadata": {
        "id": "Ly68SQwYrYav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/dblp/toy.dblp.v12.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5feIYp88sGHH",
        "outputId": "7f939469-a8c1-4d03-fc5e-3db0ee2c1561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indexes.pkl  skillcoverage.pkl  teams.pkl  teamsvecs.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**2. Running OpeNTF (Train)**\n",
        "\n",
        "- [`Hydra`](https://hydra.cc/) config overriding `train.*` in [`OpeNTF/src/__config__.yaml`](https://github.com/fani-lab/OpeNTF/blob/main/src/__config__.yaml#L74)\n",
        "\n",
        "  - Training `cmd=train` models `models.instances` based on the hydra subconfigs for models in [`OpeNTF/src/mdl/*__config__*.yaml`](https://github.com/fani-lab/OpeNTF/blob/main/src/mdl/__config__.yaml)\n",
        "  - For `train.train_test_ratio` splits of train and test sets\n",
        "  - With `train.nfolds` cross-validation in the train set\n",
        "  - Save every `train.save_per_epoch` epochs\n",
        "  "
      ],
      "metadata": {
        "id": "nirD2LQZknJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Random model (No training happens)\n",
        "# !python main.py cmd=train \"models.instances=[mdl.rnd.Rnd]\" data.domain=cmn.publication.Publication data.source=../data/dblp/toy.dblp.v12.json data.output=../output/dblp/toy.dblp.v12.json ~data.filter train.train_test_ratio=0.85 train.nfolds=3 train.save_per_epoch=3\n",
        "\n",
        "# # Non-variational feedforward neural net (Fnn)\n",
        "# !python main.py cmd=train \"models.instances=[mdl.fnn.Fnn]\" data.domain=cmn.publication.Publication data.source=../data/dblp/toy.dblp.v12.json data.output=../output/dblp/toy.dblp.v12.json ~data.filter train.train_test_ratio=0.85 train.nfolds=3 train.save_per_epoch=3\n",
        "\n",
        "# # Baysian variational feedforward neural net (Bnn)\n",
        "# !python main.py cmd=train \"models.instances=[mdl.bnn.Bnn]\" data.domain=cmn.publication.Publication data.source=../data/dblp/toy.dblp.v12.json data.output=../output/dblp/toy.dblp.v12.json ~data.filter train.train_test_ratio=0.85 train.nfolds=3 train.save_per_epoch=3\n",
        "\n",
        "# Train all in one command\n",
        "!python main.py cmd=train \"models.instances=[mdl.rnd.Rnd, mdl.fnn.Fnn, mdl.bnn.Bnn]\" data.domain=cmn.publication.Publication data.source=../data/dblp/toy.dblp.v12.json data.output=../output/dblp/toy.dblp.v12.json ~data.filter train.train_test_ratio=0.85 train.nfolds=3 train.save_per_epoch=3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f-JtQq1lq4m",
        "outputId": "e91c43c6-5d77-4381-c79d-d4b734332f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-25 14:14:59,399][cmn.team][INFO] - Loading teamsvecs matrices from ../output/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "[2025-10-25 14:14:59,436][cmn.team][INFO] - Loading indexes pickle from ../output/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "[2025-10-25 14:14:59,436][cmn.team][INFO] - Indexes pickle is loaded.\n",
            "[2025-10-25 14:14:59,436][cmn.team][INFO] - Teamsvecs matrices and indexes for skills (31, 10), members (31, 13), and locations (31, 29) are loaded.\n",
            "[2025-10-25 14:14:59,437][__main__][INFO] - Loading splits from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.pkl ...\n",
            "[2025-10-25 14:15:00,231][pkgmgr][INFO] - \u001b[93mVersion mismatch detected. scikit-learn version 1.3.2 is installed, but 1.2.2 is required.\u001b[0m\n",
            "[2025-10-25 14:15:00,231][pkgmgr][INFO] - Uninstalling scikit-learn...\n",
            "[2025-10-25 14:15:00,997][pkgmgr][INFO] - Found existing installation: scikit-learn 1.3.2\n",
            "Uninstalling scikit-learn-1.3.2:\n",
            "  Successfully uninstalled scikit-learn-1.3.2\n",
            "\n",
            "[2025-10-25 14:15:00,998][pkgmgr][INFO] - Installing scikit-learn...\n",
            "[2025-10-25 14:15:03,744][pkgmgr][INFO] - Collecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (3.5.0)\n",
            "Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.8/9.8 MB 132.9 MB/s eta 0:00:00\n",
            "Installing collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-1.2.2\n",
            "\n",
            "[2025-10-25 14:15:03,744][__main__][INFO] - Splits file not found! Generating ...\n",
            "[2025-10-25 14:15:03,747][cmn.team][INFO] - Loading member-skill co-occurrence matrix (13, 10) from ../output/dblp/toy.dblp.v12.json/skillcoverage.pkl ...\n",
            "[2025-10-25 14:15:05,191][__main__][INFO] - \u001b[94mTraining team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "[2025-10-25 14:15:05,195][__main__][INFO] - \u001b[94mTraining team recommender instance mdl.fnn.Fnn ... \u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/content/opentf/src/mdl/fnn.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.unigram = Ntf.torch.tensor(y.sum(axis=0) / y.shape[0]).to(self.device)  # frequency of each expert in a batch\n",
            "[2025-10-25 14:15:05,902][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[94mTrain Loss: 56.5375\u001b[0m\n",
            "[2025-10-25 14:15:05,902][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[95mValid Loss: 55.6674\u001b[0m\n",
            "[2025-10-25 14:15:05,905][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e0.pt\n",
            "[2025-10-25 14:15:05,906][mdl.fnn][INFO] - Validation loss decreased (inf --> 55.667397)\n",
            "[2025-10-25 14:15:05,916][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[94mTrain Loss: 55.7426\u001b[0m\n",
            "[2025-10-25 14:15:05,917][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[95mValid Loss: 55.0569\u001b[0m\n",
            "[2025-10-25 14:15:05,917][mdl.fnn][INFO] - Validation loss decreased (55.667397 --> 55.056931)\n",
            "[2025-10-25 14:15:05,928][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[94mTrain Loss: 55.9899\u001b[0m\n",
            "[2025-10-25 14:15:05,928][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[95mValid Loss: 54.8882\u001b[0m\n",
            "[2025-10-25 14:15:05,931][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e2.pt\n",
            "[2025-10-25 14:15:05,931][mdl.fnn][INFO] - Validation loss decreased (55.056931 --> 54.888226)\n",
            "[2025-10-25 14:15:05,942][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[94mTrain Loss: 55.6564\u001b[0m\n",
            "[2025-10-25 14:15:05,943][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[95mValid Loss: 54.6679\u001b[0m\n",
            "[2025-10-25 14:15:05,943][mdl.fnn][INFO] - Validation loss decreased (54.888226 --> 54.667866)\n",
            "[2025-10-25 14:15:05,954][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[94mTrain Loss: 55.2048\u001b[0m\n",
            "[2025-10-25 14:15:05,954][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[95mValid Loss: 54.6480\u001b[0m\n",
            "[2025-10-25 14:15:05,954][mdl.fnn][INFO] - Validation loss decreased (54.667866 --> 54.647987)\n",
            "[2025-10-25 14:15:05,965][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[94mTrain Loss: 55.1856\u001b[0m\n",
            "[2025-10-25 14:15:05,965][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[95mValid Loss: 54.7965\u001b[0m\n",
            "[2025-10-25 14:15:05,968][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e5.pt\n",
            "[2025-10-25 14:15:05,968][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:05,979][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[94mTrain Loss: 54.9536\u001b[0m\n",
            "[2025-10-25 14:15:05,979][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[95mValid Loss: 54.1813\u001b[0m\n",
            "[2025-10-25 14:15:05,979][mdl.fnn][INFO] - Validation loss decreased (54.647987 --> 54.181313)\n",
            "[2025-10-25 14:15:05,990][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[94mTrain Loss: 54.7461\u001b[0m\n",
            "[2025-10-25 14:15:05,990][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[95mValid Loss: 54.2936\u001b[0m\n",
            "[2025-10-25 14:15:05,990][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,000][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[94mTrain Loss: 54.6121\u001b[0m\n",
            "[2025-10-25 14:15:06,001][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[95mValid Loss: 54.4439\u001b[0m\n",
            "[2025-10-25 14:15:06,004][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e8.pt\n",
            "[2025-10-25 14:15:06,004][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:06,014][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[94mTrain Loss: 54.6274\u001b[0m\n",
            "[2025-10-25 14:15:06,014][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[95mValid Loss: 53.9398\u001b[0m\n",
            "[2025-10-25 14:15:06,015][mdl.fnn][INFO] - Validation loss decreased (54.181313 --> 53.939804)\n",
            "[2025-10-25 14:15:06,025][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[94mTrain Loss: 54.6755\u001b[0m\n",
            "[2025-10-25 14:15:06,025][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[95mValid Loss: 54.1059\u001b[0m\n",
            "[2025-10-25 14:15:06,026][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,036][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[94mTrain Loss: 53.9895\u001b[0m\n",
            "[2025-10-25 14:15:06,036][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[95mValid Loss: 54.0531\u001b[0m\n",
            "[2025-10-25 14:15:06,039][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e11.pt\n",
            "[2025-10-25 14:15:06,039][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:06,050][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[94mTrain Loss: 53.9197\u001b[0m\n",
            "[2025-10-25 14:15:06,050][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[95mValid Loss: 53.9538\u001b[0m\n",
            "[2025-10-25 14:15:06,050][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 14:15:06,061][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[94mTrain Loss: 53.8581\u001b[0m\n",
            "[2025-10-25 14:15:06,062][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[95mValid Loss: 53.7434\u001b[0m\n",
            "[2025-10-25 14:15:06,062][mdl.fnn][INFO] - Validation loss decreased (53.939804 --> 53.743439)\n",
            "[2025-10-25 14:15:06,080][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[94mTrain Loss: 53.9669\u001b[0m\n",
            "[2025-10-25 14:15:06,080][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[95mValid Loss: 53.6799\u001b[0m\n",
            "[2025-10-25 14:15:06,084][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e14.pt\n",
            "[2025-10-25 14:15:06,085][mdl.fnn][INFO] - Validation loss decreased (53.743439 --> 53.679916)\n",
            "[2025-10-25 14:15:06,096][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[94mTrain Loss: 53.8270\u001b[0m\n",
            "[2025-10-25 14:15:06,096][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[95mValid Loss: 53.7475\u001b[0m\n",
            "[2025-10-25 14:15:06,097][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,107][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[94mTrain Loss: 53.8763\u001b[0m\n",
            "[2025-10-25 14:15:06,107][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[95mValid Loss: 53.5964\u001b[0m\n",
            "[2025-10-25 14:15:06,107][mdl.fnn][INFO] - Validation loss decreased (53.679916 --> 53.596363)\n",
            "[2025-10-25 14:15:06,120][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[94mTrain Loss: 53.5568\u001b[0m\n",
            "[2025-10-25 14:15:06,120][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[95mValid Loss: 53.4238\u001b[0m\n",
            "[2025-10-25 14:15:06,123][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e17.pt\n",
            "[2025-10-25 14:15:06,123][mdl.fnn][INFO] - Validation loss decreased (53.596363 --> 53.423775)\n",
            "[2025-10-25 14:15:06,133][mdl.fnn][INFO] - Fold 0/2, Epoch 18, \u001b[94mTrain Loss: 53.9005\u001b[0m\n",
            "[2025-10-25 14:15:06,133][mdl.fnn][INFO] - Fold 0/2, Epoch 18, \u001b[95mValid Loss: 53.8329\u001b[0m\n",
            "[2025-10-25 14:15:06,134][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,144][mdl.fnn][INFO] - Fold 0/2, Epoch 19, \u001b[94mTrain Loss: 53.6651\u001b[0m\n",
            "[2025-10-25 14:15:06,144][mdl.fnn][INFO] - Fold 0/2, Epoch 19, \u001b[95mValid Loss: 53.7087\u001b[0m\n",
            "[2025-10-25 14:15:06,144][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:06,157][mdl.fnn][INFO] - Fold 0/2, Epoch 20, \u001b[94mTrain Loss: 53.9768\u001b[0m\n",
            "[2025-10-25 14:15:06,157][mdl.fnn][INFO] - Fold 0/2, Epoch 20, \u001b[95mValid Loss: 53.4652\u001b[0m\n",
            "[2025-10-25 14:15:06,160][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e20.pt\n",
            "[2025-10-25 14:15:06,160][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 14:15:06,171][mdl.fnn][INFO] - Fold 0/2, Epoch 21, \u001b[94mTrain Loss: 53.7048\u001b[0m\n",
            "[2025-10-25 14:15:06,171][mdl.fnn][INFO] - Fold 0/2, Epoch 21, \u001b[95mValid Loss: 53.8384\u001b[0m\n",
            "[2025-10-25 14:15:06,171][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 14:15:06,182][mdl.fnn][INFO] - Fold 0/2, Epoch 22, \u001b[94mTrain Loss: 53.7000\u001b[0m\n",
            "[2025-10-25 14:15:06,182][mdl.fnn][INFO] - Fold 0/2, Epoch 22, \u001b[95mValid Loss: 53.4741\u001b[0m\n",
            "[2025-10-25 14:15:06,182][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 14:15:06,182][mdl.fnn][INFO] - Early stopping triggered at epoch: 22\n",
            "[2025-10-25 14:15:06,185][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.pt\n",
            "[2025-10-25 14:15:06,196][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[94mTrain Loss: 57.0149\u001b[0m\n",
            "[2025-10-25 14:15:06,196][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[95mValid Loss: 56.0183\u001b[0m\n",
            "[2025-10-25 14:15:06,199][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e0.pt\n",
            "[2025-10-25 14:15:06,199][mdl.fnn][INFO] - Validation loss decreased (inf --> 56.018291)\n",
            "[2025-10-25 14:15:06,209][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[94mTrain Loss: 55.7020\u001b[0m\n",
            "[2025-10-25 14:15:06,210][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[95mValid Loss: 56.7937\u001b[0m\n",
            "[2025-10-25 14:15:06,210][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,220][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[94mTrain Loss: 55.9707\u001b[0m\n",
            "[2025-10-25 14:15:06,221][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[95mValid Loss: 56.2316\u001b[0m\n",
            "[2025-10-25 14:15:06,224][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e2.pt\n",
            "[2025-10-25 14:15:06,224][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:06,234][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[94mTrain Loss: 56.7553\u001b[0m\n",
            "[2025-10-25 14:15:06,234][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[95mValid Loss: 55.3608\u001b[0m\n",
            "[2025-10-25 14:15:06,235][mdl.fnn][INFO] - Validation loss decreased (56.018291 --> 55.360764)\n",
            "[2025-10-25 14:15:06,245][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[94mTrain Loss: 55.7055\u001b[0m\n",
            "[2025-10-25 14:15:06,245][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[95mValid Loss: 55.2015\u001b[0m\n",
            "[2025-10-25 14:15:06,245][mdl.fnn][INFO] - Validation loss decreased (55.360764 --> 55.201500)\n",
            "[2025-10-25 14:15:06,256][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[94mTrain Loss: 55.6291\u001b[0m\n",
            "[2025-10-25 14:15:06,256][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[95mValid Loss: 55.2516\u001b[0m\n",
            "[2025-10-25 14:15:06,259][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e5.pt\n",
            "[2025-10-25 14:15:06,259][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,269][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[94mTrain Loss: 55.6617\u001b[0m\n",
            "[2025-10-25 14:15:06,269][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[95mValid Loss: 54.9422\u001b[0m\n",
            "[2025-10-25 14:15:06,270][mdl.fnn][INFO] - Validation loss decreased (55.201500 --> 54.942219)\n",
            "[2025-10-25 14:15:06,280][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[94mTrain Loss: 55.7109\u001b[0m\n",
            "[2025-10-25 14:15:06,280][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[95mValid Loss: 55.1114\u001b[0m\n",
            "[2025-10-25 14:15:06,281][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,291][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[94mTrain Loss: 55.2338\u001b[0m\n",
            "[2025-10-25 14:15:06,291][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[95mValid Loss: 54.5381\u001b[0m\n",
            "[2025-10-25 14:15:06,294][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e8.pt\n",
            "[2025-10-25 14:15:06,294][mdl.fnn][INFO] - Validation loss decreased (54.942219 --> 54.538139)\n",
            "[2025-10-25 14:15:06,309][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[94mTrain Loss: 55.4953\u001b[0m\n",
            "[2025-10-25 14:15:06,309][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[95mValid Loss: 54.7886\u001b[0m\n",
            "[2025-10-25 14:15:06,309][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,321][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[94mTrain Loss: 55.1421\u001b[0m\n",
            "[2025-10-25 14:15:06,322][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[95mValid Loss: 54.0172\u001b[0m\n",
            "[2025-10-25 14:15:06,322][mdl.fnn][INFO] - Validation loss decreased (54.538139 --> 54.017178)\n",
            "[2025-10-25 14:15:06,332][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[94mTrain Loss: 54.8071\u001b[0m\n",
            "[2025-10-25 14:15:06,332][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[95mValid Loss: 54.2378\u001b[0m\n",
            "[2025-10-25 14:15:06,335][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e11.pt\n",
            "[2025-10-25 14:15:06,335][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,345][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[94mTrain Loss: 54.7225\u001b[0m\n",
            "[2025-10-25 14:15:06,346][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[95mValid Loss: 54.3693\u001b[0m\n",
            "[2025-10-25 14:15:06,346][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:06,356][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[94mTrain Loss: 54.4445\u001b[0m\n",
            "[2025-10-25 14:15:06,356][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[95mValid Loss: 53.5857\u001b[0m\n",
            "[2025-10-25 14:15:06,356][mdl.fnn][INFO] - Validation loss decreased (54.017178 --> 53.585678)\n",
            "[2025-10-25 14:15:06,367][mdl.fnn][INFO] - Fold 1/2, Epoch 14, \u001b[94mTrain Loss: 54.6662\u001b[0m\n",
            "[2025-10-25 14:15:06,367][mdl.fnn][INFO] - Fold 1/2, Epoch 14, \u001b[95mValid Loss: 53.7320\u001b[0m\n",
            "[2025-10-25 14:15:06,370][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e14.pt\n",
            "[2025-10-25 14:15:06,370][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,380][mdl.fnn][INFO] - Fold 1/2, Epoch 15, \u001b[94mTrain Loss: 54.5700\u001b[0m\n",
            "[2025-10-25 14:15:06,380][mdl.fnn][INFO] - Fold 1/2, Epoch 15, \u001b[95mValid Loss: 53.4958\u001b[0m\n",
            "[2025-10-25 14:15:06,381][mdl.fnn][INFO] - Validation loss decreased (53.585678 --> 53.495781)\n",
            "[2025-10-25 14:15:06,392][mdl.fnn][INFO] - Fold 1/2, Epoch 16, \u001b[94mTrain Loss: 54.3574\u001b[0m\n",
            "[2025-10-25 14:15:06,392][mdl.fnn][INFO] - Fold 1/2, Epoch 16, \u001b[95mValid Loss: 53.3371\u001b[0m\n",
            "[2025-10-25 14:15:06,392][mdl.fnn][INFO] - Validation loss decreased (53.495781 --> 53.337082)\n",
            "[2025-10-25 14:15:06,402][mdl.fnn][INFO] - Fold 1/2, Epoch 17, \u001b[94mTrain Loss: 54.2990\u001b[0m\n",
            "[2025-10-25 14:15:06,402][mdl.fnn][INFO] - Fold 1/2, Epoch 17, \u001b[95mValid Loss: 53.2332\u001b[0m\n",
            "[2025-10-25 14:15:06,405][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e17.pt\n",
            "[2025-10-25 14:15:06,405][mdl.fnn][INFO] - Validation loss decreased (53.337082 --> 53.233238)\n",
            "[2025-10-25 14:15:06,416][mdl.fnn][INFO] - Fold 1/2, Epoch 18, \u001b[94mTrain Loss: 54.1944\u001b[0m\n",
            "[2025-10-25 14:15:06,416][mdl.fnn][INFO] - Fold 1/2, Epoch 18, \u001b[95mValid Loss: 53.6433\u001b[0m\n",
            "[2025-10-25 14:15:06,417][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,427][mdl.fnn][INFO] - Fold 1/2, Epoch 19, \u001b[94mTrain Loss: 54.1146\u001b[0m\n",
            "[2025-10-25 14:15:06,427][mdl.fnn][INFO] - Fold 1/2, Epoch 19, \u001b[95mValid Loss: 53.3684\u001b[0m\n",
            "[2025-10-25 14:15:06,427][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:06,438][mdl.fnn][INFO] - Fold 1/2, Epoch 20, \u001b[94mTrain Loss: 54.1371\u001b[0m\n",
            "[2025-10-25 14:15:06,438][mdl.fnn][INFO] - Fold 1/2, Epoch 20, \u001b[95mValid Loss: 52.9164\u001b[0m\n",
            "[2025-10-25 14:15:06,441][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e20.pt\n",
            "[2025-10-25 14:15:06,441][mdl.fnn][INFO] - Validation loss decreased (53.233238 --> 52.916439)\n",
            "[2025-10-25 14:15:06,453][mdl.fnn][INFO] - Fold 1/2, Epoch 21, \u001b[94mTrain Loss: 54.1262\u001b[0m\n",
            "[2025-10-25 14:15:06,454][mdl.fnn][INFO] - Fold 1/2, Epoch 21, \u001b[95mValid Loss: 53.3078\u001b[0m\n",
            "[2025-10-25 14:15:06,454][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,465][mdl.fnn][INFO] - Fold 1/2, Epoch 22, \u001b[94mTrain Loss: 53.9746\u001b[0m\n",
            "[2025-10-25 14:15:06,465][mdl.fnn][INFO] - Fold 1/2, Epoch 22, \u001b[95mValid Loss: 53.2600\u001b[0m\n",
            "[2025-10-25 14:15:06,466][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:06,476][mdl.fnn][INFO] - Fold 1/2, Epoch 23, \u001b[94mTrain Loss: 54.0177\u001b[0m\n",
            "[2025-10-25 14:15:06,476][mdl.fnn][INFO] - Fold 1/2, Epoch 23, \u001b[95mValid Loss: 53.1334\u001b[0m\n",
            "[2025-10-25 14:15:06,479][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e23.pt\n",
            "[2025-10-25 14:15:06,479][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 14:15:06,489][mdl.fnn][INFO] - Fold 1/2, Epoch 24, \u001b[94mTrain Loss: 53.9258\u001b[0m\n",
            "[2025-10-25 14:15:06,489][mdl.fnn][INFO] - Fold 1/2, Epoch 24, \u001b[95mValid Loss: 53.1868\u001b[0m\n",
            "[2025-10-25 14:15:06,489][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 14:15:06,500][mdl.fnn][INFO] - Fold 1/2, Epoch 25, \u001b[94mTrain Loss: 53.8081\u001b[0m\n",
            "[2025-10-25 14:15:06,500][mdl.fnn][INFO] - Fold 1/2, Epoch 25, \u001b[95mValid Loss: 53.1506\u001b[0m\n",
            "[2025-10-25 14:15:06,500][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 14:15:06,501][mdl.fnn][INFO] - Early stopping triggered at epoch: 25\n",
            "[2025-10-25 14:15:06,503][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.pt\n",
            "[2025-10-25 14:15:06,515][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[94mTrain Loss: 54.7810\u001b[0m\n",
            "[2025-10-25 14:15:06,515][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[95mValid Loss: 57.4886\u001b[0m\n",
            "[2025-10-25 14:15:06,518][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e0.pt\n",
            "[2025-10-25 14:15:06,518][mdl.fnn][INFO] - Validation loss decreased (inf --> 57.488632)\n",
            "[2025-10-25 14:15:06,530][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[94mTrain Loss: 54.7522\u001b[0m\n",
            "[2025-10-25 14:15:06,533][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[95mValid Loss: 56.9629\u001b[0m\n",
            "[2025-10-25 14:15:06,533][mdl.fnn][INFO] - Validation loss decreased (57.488632 --> 56.962887)\n",
            "[2025-10-25 14:15:06,551][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[94mTrain Loss: 54.0770\u001b[0m\n",
            "[2025-10-25 14:15:06,551][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[95mValid Loss: 57.7038\u001b[0m\n",
            "[2025-10-25 14:15:06,555][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e2.pt\n",
            "[2025-10-25 14:15:06,555][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,568][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[94mTrain Loss: 54.3484\u001b[0m\n",
            "[2025-10-25 14:15:06,568][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[95mValid Loss: 56.9704\u001b[0m\n",
            "[2025-10-25 14:15:06,568][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:06,579][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[94mTrain Loss: 53.8592\u001b[0m\n",
            "[2025-10-25 14:15:06,579][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[95mValid Loss: 56.6893\u001b[0m\n",
            "[2025-10-25 14:15:06,580][mdl.fnn][INFO] - Validation loss decreased (56.962887 --> 56.689297)\n",
            "[2025-10-25 14:15:06,590][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[94mTrain Loss: 53.5943\u001b[0m\n",
            "[2025-10-25 14:15:06,590][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[95mValid Loss: 57.1859\u001b[0m\n",
            "[2025-10-25 14:15:06,593][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e5.pt\n",
            "[2025-10-25 14:15:06,594][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,604][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[94mTrain Loss: 53.6844\u001b[0m\n",
            "[2025-10-25 14:15:06,604][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[95mValid Loss: 56.5434\u001b[0m\n",
            "[2025-10-25 14:15:06,604][mdl.fnn][INFO] - Validation loss decreased (56.689297 --> 56.543392)\n",
            "[2025-10-25 14:15:06,615][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[94mTrain Loss: 53.5197\u001b[0m\n",
            "[2025-10-25 14:15:06,616][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[95mValid Loss: 56.2402\u001b[0m\n",
            "[2025-10-25 14:15:06,616][mdl.fnn][INFO] - Validation loss decreased (56.543392 --> 56.240242)\n",
            "[2025-10-25 14:15:06,626][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[94mTrain Loss: 53.2509\u001b[0m\n",
            "[2025-10-25 14:15:06,627][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[95mValid Loss: 56.0766\u001b[0m\n",
            "[2025-10-25 14:15:06,630][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e8.pt\n",
            "[2025-10-25 14:15:06,630][mdl.fnn][INFO] - Validation loss decreased (56.240242 --> 56.076565)\n",
            "[2025-10-25 14:15:06,640][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[94mTrain Loss: 53.3092\u001b[0m\n",
            "[2025-10-25 14:15:06,641][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[95mValid Loss: 56.5757\u001b[0m\n",
            "[2025-10-25 14:15:06,641][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,654][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[94mTrain Loss: 53.0044\u001b[0m\n",
            "[2025-10-25 14:15:06,654][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[95mValid Loss: 56.0600\u001b[0m\n",
            "[2025-10-25 14:15:06,655][mdl.fnn][INFO] - Validation loss decreased (56.076565 --> 56.059963)\n",
            "[2025-10-25 14:15:06,666][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[94mTrain Loss: 53.0029\u001b[0m\n",
            "[2025-10-25 14:15:06,666][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[95mValid Loss: 56.1187\u001b[0m\n",
            "[2025-10-25 14:15:06,669][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e11.pt\n",
            "[2025-10-25 14:15:06,669][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,681][mdl.fnn][INFO] - Fold 2/2, Epoch 12, \u001b[94mTrain Loss: 53.0313\u001b[0m\n",
            "[2025-10-25 14:15:06,682][mdl.fnn][INFO] - Fold 2/2, Epoch 12, \u001b[95mValid Loss: 55.5317\u001b[0m\n",
            "[2025-10-25 14:15:06,682][mdl.fnn][INFO] - Validation loss decreased (56.059963 --> 55.531677)\n",
            "[2025-10-25 14:15:06,693][mdl.fnn][INFO] - Fold 2/2, Epoch 13, \u001b[94mTrain Loss: 52.8177\u001b[0m\n",
            "[2025-10-25 14:15:06,693][mdl.fnn][INFO] - Fold 2/2, Epoch 13, \u001b[95mValid Loss: 56.0350\u001b[0m\n",
            "[2025-10-25 14:15:06,693][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,703][mdl.fnn][INFO] - Fold 2/2, Epoch 14, \u001b[94mTrain Loss: 52.7721\u001b[0m\n",
            "[2025-10-25 14:15:06,704][mdl.fnn][INFO] - Fold 2/2, Epoch 14, \u001b[95mValid Loss: 55.4759\u001b[0m\n",
            "[2025-10-25 14:15:06,706][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e14.pt\n",
            "[2025-10-25 14:15:06,707][mdl.fnn][INFO] - Validation loss decreased (55.531677 --> 55.475929)\n",
            "[2025-10-25 14:15:06,717][mdl.fnn][INFO] - Fold 2/2, Epoch 15, \u001b[94mTrain Loss: 52.8636\u001b[0m\n",
            "[2025-10-25 14:15:06,717][mdl.fnn][INFO] - Fold 2/2, Epoch 15, \u001b[95mValid Loss: 55.6114\u001b[0m\n",
            "[2025-10-25 14:15:06,717][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,728][mdl.fnn][INFO] - Fold 2/2, Epoch 16, \u001b[94mTrain Loss: 52.7980\u001b[0m\n",
            "[2025-10-25 14:15:06,728][mdl.fnn][INFO] - Fold 2/2, Epoch 16, \u001b[95mValid Loss: 55.5690\u001b[0m\n",
            "[2025-10-25 14:15:06,728][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:06,738][mdl.fnn][INFO] - Fold 2/2, Epoch 17, \u001b[94mTrain Loss: 52.5881\u001b[0m\n",
            "[2025-10-25 14:15:06,739][mdl.fnn][INFO] - Fold 2/2, Epoch 17, \u001b[95mValid Loss: 55.7257\u001b[0m\n",
            "[2025-10-25 14:15:06,742][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e17.pt\n",
            "[2025-10-25 14:15:06,742][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 14:15:06,754][mdl.fnn][INFO] - Fold 2/2, Epoch 18, \u001b[94mTrain Loss: 52.8473\u001b[0m\n",
            "[2025-10-25 14:15:06,755][mdl.fnn][INFO] - Fold 2/2, Epoch 18, \u001b[95mValid Loss: 55.5387\u001b[0m\n",
            "[2025-10-25 14:15:06,755][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 14:15:06,773][mdl.fnn][INFO] - Fold 2/2, Epoch 19, \u001b[94mTrain Loss: 52.7851\u001b[0m\n",
            "[2025-10-25 14:15:06,774][mdl.fnn][INFO] - Fold 2/2, Epoch 19, \u001b[95mValid Loss: 55.7392\u001b[0m\n",
            "[2025-10-25 14:15:06,774][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 14:15:06,774][mdl.fnn][INFO] - Early stopping triggered at epoch: 19\n",
            "[2025-10-25 14:15:06,778][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.pt\n",
            "[2025-10-25 14:15:06,794][__main__][INFO] - \u001b[94mTraining team recommender instance mdl.bnn.Bnn ... \u001b[0m\n",
            "[2025-10-25 14:15:06,810][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[94mTrain Loss: 55.8699\u001b[0m\n",
            "[2025-10-25 14:15:06,810][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[95mValid Loss: 56.7096\u001b[0m\n",
            "[2025-10-25 14:15:06,814][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e0.pt\n",
            "[2025-10-25 14:15:06,814][mdl.fnn][INFO] - Validation loss decreased (inf --> 56.709644)\n",
            "[2025-10-25 14:15:06,828][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[94mTrain Loss: 55.9380\u001b[0m\n",
            "[2025-10-25 14:15:06,828][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[95mValid Loss: 56.2262\u001b[0m\n",
            "[2025-10-25 14:15:06,828][mdl.fnn][INFO] - Validation loss decreased (56.709644 --> 56.226158)\n",
            "[2025-10-25 14:15:06,841][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[94mTrain Loss: 55.8123\u001b[0m\n",
            "[2025-10-25 14:15:06,841][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[95mValid Loss: 56.1281\u001b[0m\n",
            "[2025-10-25 14:15:06,844][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e2.pt\n",
            "[2025-10-25 14:15:06,844][mdl.fnn][INFO] - Validation loss decreased (56.226158 --> 56.128094)\n",
            "[2025-10-25 14:15:06,857][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[94mTrain Loss: 55.2799\u001b[0m\n",
            "[2025-10-25 14:15:06,857][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[95mValid Loss: 55.9876\u001b[0m\n",
            "[2025-10-25 14:15:06,858][mdl.fnn][INFO] - Validation loss decreased (56.128094 --> 55.987579)\n",
            "[2025-10-25 14:15:06,871][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[94mTrain Loss: 55.6912\u001b[0m\n",
            "[2025-10-25 14:15:06,871][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[95mValid Loss: 56.2795\u001b[0m\n",
            "[2025-10-25 14:15:06,871][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,884][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[94mTrain Loss: 55.4871\u001b[0m\n",
            "[2025-10-25 14:15:06,885][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[95mValid Loss: 55.6443\u001b[0m\n",
            "[2025-10-25 14:15:06,888][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e5.pt\n",
            "[2025-10-25 14:15:06,888][mdl.fnn][INFO] - Validation loss decreased (55.987579 --> 55.644329)\n",
            "[2025-10-25 14:15:06,901][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[94mTrain Loss: 55.3050\u001b[0m\n",
            "[2025-10-25 14:15:06,902][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[95mValid Loss: 55.7185\u001b[0m\n",
            "[2025-10-25 14:15:06,902][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,914][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[94mTrain Loss: 55.2790\u001b[0m\n",
            "[2025-10-25 14:15:06,915][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[95mValid Loss: 55.9072\u001b[0m\n",
            "[2025-10-25 14:15:06,915][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:06,928][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[94mTrain Loss: 54.8306\u001b[0m\n",
            "[2025-10-25 14:15:06,928][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[95mValid Loss: 55.7106\u001b[0m\n",
            "[2025-10-25 14:15:06,931][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e8.pt\n",
            "[2025-10-25 14:15:06,932][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 14:15:06,946][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[94mTrain Loss: 54.9492\u001b[0m\n",
            "[2025-10-25 14:15:06,946][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[95mValid Loss: 56.2660\u001b[0m\n",
            "[2025-10-25 14:15:06,946][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 14:15:06,963][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[94mTrain Loss: 55.0732\u001b[0m\n",
            "[2025-10-25 14:15:06,963][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[95mValid Loss: 55.6022\u001b[0m\n",
            "[2025-10-25 14:15:06,963][mdl.fnn][INFO] - Validation loss decreased (55.644329 --> 55.602226)\n",
            "[2025-10-25 14:15:06,977][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[94mTrain Loss: 54.8042\u001b[0m\n",
            "[2025-10-25 14:15:06,977][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[95mValid Loss: 55.7355\u001b[0m\n",
            "[2025-10-25 14:15:06,980][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e11.pt\n",
            "[2025-10-25 14:15:06,980][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:06,993][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[94mTrain Loss: 55.0498\u001b[0m\n",
            "[2025-10-25 14:15:06,993][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[95mValid Loss: 55.5379\u001b[0m\n",
            "[2025-10-25 14:15:06,994][mdl.fnn][INFO] - Validation loss decreased (55.602226 --> 55.537910)\n",
            "[2025-10-25 14:15:07,006][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[94mTrain Loss: 55.3867\u001b[0m\n",
            "[2025-10-25 14:15:07,006][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[95mValid Loss: 55.2177\u001b[0m\n",
            "[2025-10-25 14:15:07,007][mdl.fnn][INFO] - Validation loss decreased (55.537910 --> 55.217693)\n",
            "[2025-10-25 14:15:07,020][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[94mTrain Loss: 54.5639\u001b[0m\n",
            "[2025-10-25 14:15:07,020][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[95mValid Loss: 55.6992\u001b[0m\n",
            "[2025-10-25 14:15:07,023][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e14.pt\n",
            "[2025-10-25 14:15:07,023][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:07,035][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[94mTrain Loss: 54.5846\u001b[0m\n",
            "[2025-10-25 14:15:07,036][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[95mValid Loss: 55.3301\u001b[0m\n",
            "[2025-10-25 14:15:07,036][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:07,049][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[94mTrain Loss: 54.8063\u001b[0m\n",
            "[2025-10-25 14:15:07,049][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[95mValid Loss: 55.4990\u001b[0m\n",
            "[2025-10-25 14:15:07,049][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 14:15:07,062][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[94mTrain Loss: 54.5938\u001b[0m\n",
            "[2025-10-25 14:15:07,062][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[95mValid Loss: 56.1086\u001b[0m\n",
            "[2025-10-25 14:15:07,065][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e17.pt\n",
            "[2025-10-25 14:15:07,065][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 14:15:07,081][mdl.fnn][INFO] - Fold 0/2, Epoch 18, \u001b[94mTrain Loss: 54.5526\u001b[0m\n",
            "[2025-10-25 14:15:07,081][mdl.fnn][INFO] - Fold 0/2, Epoch 18, \u001b[95mValid Loss: 55.3335\u001b[0m\n",
            "[2025-10-25 14:15:07,081][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 14:15:07,081][mdl.fnn][INFO] - Early stopping triggered at epoch: 18\n",
            "[2025-10-25 14:15:07,085][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.pt\n",
            "[2025-10-25 14:15:07,101][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[94mTrain Loss: 56.2187\u001b[0m\n",
            "[2025-10-25 14:15:07,102][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[95mValid Loss: 55.8349\u001b[0m\n",
            "[2025-10-25 14:15:07,105][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e0.pt\n",
            "[2025-10-25 14:15:07,105][mdl.fnn][INFO] - Validation loss decreased (inf --> 55.834946)\n",
            "[2025-10-25 14:15:07,119][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[94mTrain Loss: 56.5845\u001b[0m\n",
            "[2025-10-25 14:15:07,119][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[95mValid Loss: 54.6991\u001b[0m\n",
            "[2025-10-25 14:15:07,120][mdl.fnn][INFO] - Validation loss decreased (55.834946 --> 54.699120)\n",
            "[2025-10-25 14:15:07,133][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[94mTrain Loss: 56.0198\u001b[0m\n",
            "[2025-10-25 14:15:07,133][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[95mValid Loss: 55.2755\u001b[0m\n",
            "[2025-10-25 14:15:07,136][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e2.pt\n",
            "[2025-10-25 14:15:07,136][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:07,149][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[94mTrain Loss: 56.3215\u001b[0m\n",
            "[2025-10-25 14:15:07,149][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[95mValid Loss: 55.3733\u001b[0m\n",
            "[2025-10-25 14:15:07,150][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:07,164][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[94mTrain Loss: 55.9023\u001b[0m\n",
            "[2025-10-25 14:15:07,165][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[95mValid Loss: 55.0186\u001b[0m\n",
            "[2025-10-25 14:15:07,165][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 14:15:07,178][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[94mTrain Loss: 56.1089\u001b[0m\n",
            "[2025-10-25 14:15:07,179][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[95mValid Loss: 54.4789\u001b[0m\n",
            "[2025-10-25 14:15:07,182][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e5.pt\n",
            "[2025-10-25 14:15:07,182][mdl.fnn][INFO] - Validation loss decreased (54.699120 --> 54.478939)\n",
            "[2025-10-25 14:15:07,195][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[94mTrain Loss: 55.6965\u001b[0m\n",
            "[2025-10-25 14:15:07,195][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[95mValid Loss: 54.7984\u001b[0m\n",
            "[2025-10-25 14:15:07,196][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:07,208][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[94mTrain Loss: 55.6870\u001b[0m\n",
            "[2025-10-25 14:15:07,209][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[95mValid Loss: 54.3168\u001b[0m\n",
            "[2025-10-25 14:15:07,209][mdl.fnn][INFO] - Validation loss decreased (54.478939 --> 54.316780)\n",
            "[2025-10-25 14:15:07,222][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[94mTrain Loss: 56.4392\u001b[0m\n",
            "[2025-10-25 14:15:07,222][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[95mValid Loss: 54.4878\u001b[0m\n",
            "[2025-10-25 14:15:07,225][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e8.pt\n",
            "[2025-10-25 14:15:07,225][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:07,237][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[94mTrain Loss: 55.7026\u001b[0m\n",
            "[2025-10-25 14:15:07,238][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[95mValid Loss: 55.0580\u001b[0m\n",
            "[2025-10-25 14:15:07,238][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:07,251][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[94mTrain Loss: 55.8184\u001b[0m\n",
            "[2025-10-25 14:15:07,251][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[95mValid Loss: 54.1445\u001b[0m\n",
            "[2025-10-25 14:15:07,252][mdl.fnn][INFO] - Validation loss decreased (54.316780 --> 54.144478)\n",
            "[2025-10-25 14:15:07,264][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[94mTrain Loss: 55.8001\u001b[0m\n",
            "[2025-10-25 14:15:07,265][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[95mValid Loss: 54.7832\u001b[0m\n",
            "[2025-10-25 14:15:07,268][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e11.pt\n",
            "[2025-10-25 14:15:07,268][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:07,281][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[94mTrain Loss: 55.9865\u001b[0m\n",
            "[2025-10-25 14:15:07,281][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[95mValid Loss: 54.5986\u001b[0m\n",
            "[2025-10-25 14:15:07,281][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:07,294][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[94mTrain Loss: 55.5947\u001b[0m\n",
            "[2025-10-25 14:15:07,294][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[95mValid Loss: 55.0731\u001b[0m\n",
            "[2025-10-25 14:15:07,295][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 14:15:07,307][mdl.fnn][INFO] - Fold 1/2, Epoch 14, \u001b[94mTrain Loss: 55.7173\u001b[0m\n",
            "[2025-10-25 14:15:07,307][mdl.fnn][INFO] - Fold 1/2, Epoch 14, \u001b[95mValid Loss: 54.6146\u001b[0m\n",
            "[2025-10-25 14:15:07,311][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e14.pt\n",
            "[2025-10-25 14:15:07,311][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 14:15:07,325][mdl.fnn][INFO] - Fold 1/2, Epoch 15, \u001b[94mTrain Loss: 56.3928\u001b[0m\n",
            "[2025-10-25 14:15:07,325][mdl.fnn][INFO] - Fold 1/2, Epoch 15, \u001b[95mValid Loss: 54.6889\u001b[0m\n",
            "[2025-10-25 14:15:07,326][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 14:15:07,326][mdl.fnn][INFO] - Early stopping triggered at epoch: 15\n",
            "[2025-10-25 14:15:07,329][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.pt\n",
            "[2025-10-25 14:15:07,344][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[94mTrain Loss: 55.4082\u001b[0m\n",
            "[2025-10-25 14:15:07,344][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[95mValid Loss: 58.0916\u001b[0m\n",
            "[2025-10-25 14:15:07,347][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.e0.pt\n",
            "[2025-10-25 14:15:07,347][mdl.fnn][INFO] - Validation loss decreased (inf --> 58.091587)\n",
            "[2025-10-25 14:15:07,360][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[94mTrain Loss: 55.1100\u001b[0m\n",
            "[2025-10-25 14:15:07,360][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[95mValid Loss: 57.4678\u001b[0m\n",
            "[2025-10-25 14:15:07,360][mdl.fnn][INFO] - Validation loss decreased (58.091587 --> 57.467751)\n",
            "[2025-10-25 14:15:07,374][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[94mTrain Loss: 55.1349\u001b[0m\n",
            "[2025-10-25 14:15:07,374][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[95mValid Loss: 57.7490\u001b[0m\n",
            "[2025-10-25 14:15:07,377][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.e2.pt\n",
            "[2025-10-25 14:15:07,377][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:07,389][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[94mTrain Loss: 54.5135\u001b[0m\n",
            "[2025-10-25 14:15:07,390][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[95mValid Loss: 56.9044\u001b[0m\n",
            "[2025-10-25 14:15:07,390][mdl.fnn][INFO] - Validation loss decreased (57.467751 --> 56.904366)\n",
            "[2025-10-25 14:15:07,403][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[94mTrain Loss: 54.2709\u001b[0m\n",
            "[2025-10-25 14:15:07,403][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[95mValid Loss: 57.6934\u001b[0m\n",
            "[2025-10-25 14:15:07,404][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:07,416][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[94mTrain Loss: 54.5239\u001b[0m\n",
            "[2025-10-25 14:15:07,416][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[95mValid Loss: 57.4714\u001b[0m\n",
            "[2025-10-25 14:15:07,419][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.e5.pt\n",
            "[2025-10-25 14:15:07,419][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:07,432][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[94mTrain Loss: 54.3981\u001b[0m\n",
            "[2025-10-25 14:15:07,432][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[95mValid Loss: 57.6087\u001b[0m\n",
            "[2025-10-25 14:15:07,433][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 14:15:07,445][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[94mTrain Loss: 54.3081\u001b[0m\n",
            "[2025-10-25 14:15:07,446][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[95mValid Loss: 57.9233\u001b[0m\n",
            "[2025-10-25 14:15:07,446][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 14:15:07,462][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[94mTrain Loss: 53.8749\u001b[0m\n",
            "[2025-10-25 14:15:07,462][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[95mValid Loss: 56.8240\u001b[0m\n",
            "[2025-10-25 14:15:07,465][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.e8.pt\n",
            "[2025-10-25 14:15:07,465][mdl.fnn][INFO] - Validation loss decreased (56.904366 --> 56.823997)\n",
            "[2025-10-25 14:15:07,478][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[94mTrain Loss: 54.0046\u001b[0m\n",
            "[2025-10-25 14:15:07,478][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[95mValid Loss: 57.4810\u001b[0m\n",
            "[2025-10-25 14:15:07,478][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 14:15:07,491][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[94mTrain Loss: 54.0000\u001b[0m\n",
            "[2025-10-25 14:15:07,492][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[95mValid Loss: 57.3392\u001b[0m\n",
            "[2025-10-25 14:15:07,492][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 14:15:07,505][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[94mTrain Loss: 54.3159\u001b[0m\n",
            "[2025-10-25 14:15:07,505][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[95mValid Loss: 56.8328\u001b[0m\n",
            "[2025-10-25 14:15:07,508][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.e11.pt\n",
            "[2025-10-25 14:15:07,508][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 14:15:07,521][mdl.fnn][INFO] - Fold 2/2, Epoch 12, \u001b[94mTrain Loss: 54.2377\u001b[0m\n",
            "[2025-10-25 14:15:07,521][mdl.fnn][INFO] - Fold 2/2, Epoch 12, \u001b[95mValid Loss: 57.1624\u001b[0m\n",
            "[2025-10-25 14:15:07,521][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 14:15:07,535][mdl.fnn][INFO] - Fold 2/2, Epoch 13, \u001b[94mTrain Loss: 54.5491\u001b[0m\n",
            "[2025-10-25 14:15:07,535][mdl.fnn][INFO] - Fold 2/2, Epoch 13, \u001b[95mValid Loss: 57.7939\u001b[0m\n",
            "[2025-10-25 14:15:07,535][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 14:15:07,536][mdl.fnn][INFO] - Early stopping triggered at epoch: 13\n",
            "[2025-10-25 14:15:07,538][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Folders and Files**\n",
        "- `splits.f{train.nfolds}.r{train_test_ratio}.pkl`: The dictionary of `['train']` and `['test']` of teams' row ids in each set. Also, `['train']['f0']`, ..., `['train']['f{train.nfold}']` contains the teams' row ids in each fold\n",
        "- `splits.f{train.nfolds}.r{train_test_ratio}/`: The folder containing the saved models for the current training settings"
      ],
      "metadata": {
        "id": "9YU8pfTprBbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/dblp/toy.dblp.v12.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NICl9L67uUDV",
        "outputId": "25867c8e-43ab-458f-c3b0-79bb8aa619c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "indexes.pkl        \u001b[0m\u001b[01;34msplits.f3.r0.85\u001b[0m/     teams.pkl\n",
            "skillcoverage.pkl  splits.f3.r0.85.pkl  teamsvecs.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9sjEcPFuYQy",
        "outputId": "6c1273a5-e277-4243-adb7-4ece644b90f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m'bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10'\u001b[0m/\n",
            "\u001b[01;34m'fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b'\u001b[0m/\n",
            " \u001b[01;34mrnd.b1000\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVsvwjVtugWk",
        "outputId": "92adac9e-9d40-4b8e-f487-f00b6780cf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f0.e0.pt   f0.e20.pt  f0.pt      f1.e17.pt  f1.e5.pt  f2.e11.pt  f2.e5.pt\n",
            "f0.e11.pt  f0.e2.pt   f1.e0.pt   f1.e20.pt  f1.e8.pt  f2.e14.pt  f2.e8.pt\n",
            "f0.e14.pt  f0.e5.pt   f1.e11.pt  f1.e23.pt  f1.pt     f2.e17.pt  f2.pt\n",
            "f0.e17.pt  f0.e8.pt   f1.e14.pt  f1.e2.pt   f2.e0.pt  f2.e2.pt   \u001b[0m\u001b[01;34mlogs4tboard\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**3. Running OpeNTF (Test)**\n",
        "\n",
        "- Hydra config overriding `test.*` in [`OpeNTF/src/__config__.yaml`](https://github.com/fani-lab/OpeNTF/blob//main/src/__config__.yaml#L81)\n",
        "\n",
        "  - Testing `cmd=test` models on the test set\n",
        "  - For `test.per_epoch` checkpoints of a model\n",
        "  - Saving only the `test.topK` predicted members and probs  \n"
      ],
      "metadata": {
        "id": "Mk1FJFHbq2t4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py cmd=test \"models.instances=[mdl.rnd.Rnd, mdl.fnn.Fnn, mdl.bnn.Bnn]\" data.domain=cmn.publication.Publication data.source=../data/dblp/toy.dblp.v12.json data.output=../output/dblp/toy.dblp.v12.json ~data.filter train.train_test_ratio=0.85 train.nfolds=3 train.save_per_epoch=3 test.per_epoch=True test.topK=100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhLkNzyhyIO4",
        "outputId": "dfd94750-f5fb-4c85-d132-5b677f2c3139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-25 14:36:00,390][cmn.team][INFO] - Loading teamsvecs matrices from ../output/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "[2025-10-25 14:36:00,406][cmn.team][INFO] - Loading indexes pickle from ../output/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "[2025-10-25 14:36:00,406][cmn.team][INFO] - Indexes pickle is loaded.\n",
            "[2025-10-25 14:36:00,406][cmn.team][INFO] - Teamsvecs matrices and indexes for skills (31, 10), members (31, 13), and locations (31, 29) are loaded.\n",
            "[2025-10-25 14:36:00,407][__main__][INFO] - Loading splits from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.pkl ...\n",
            "[2025-10-25 14:36:00,407][cmn.team][INFO] - Loading member-skill co-occurrence matrix (13, 10) from ../output/dblp/toy.dblp.v12.json/skillcoverage.pkl ...\n",
            "[2025-10-25 14:36:01,783][__main__][INFO] - \u001b[92mTesting team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "[2025-10-25 14:36:01,788][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold0.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred\n",
            "[2025-10-25 14:36:01,790][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold1.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred\n",
            "[2025-10-25 14:36:01,792][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold2.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred\n",
            "[2025-10-25 14:36:01,796][__main__][INFO] - \u001b[92mTesting team recommender instance mdl.fnn.Fnn ... \u001b[0m\n",
            "/content/opentf/src/mdl/fnn.py:187: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.load_state_dict(Ntf.torch.load(modelfile, map_location=self.device)['model_state_dict'])\n",
            "[2025-10-25 14:36:01,802][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.pred\n",
            "[2025-10-25 14:36:01,808][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e0.pred\n",
            "[2025-10-25 14:36:01,812][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e2.pred\n",
            "[2025-10-25 14:36:01,817][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e5.pred\n",
            "[2025-10-25 14:36:01,822][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e8.pred\n",
            "[2025-10-25 14:36:01,826][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e11.pred\n",
            "[2025-10-25 14:36:01,830][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e14. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e14.pred\n",
            "[2025-10-25 14:36:01,835][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e17. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e17.pred\n",
            "[2025-10-25 14:36:01,839][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e20. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e20.pred\n",
            "[2025-10-25 14:36:01,844][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.pred\n",
            "[2025-10-25 14:36:01,848][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e0.pred\n",
            "[2025-10-25 14:36:01,852][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e2.pred\n",
            "[2025-10-25 14:36:01,857][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e5.pred\n",
            "[2025-10-25 14:36:01,862][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e8.pred\n",
            "[2025-10-25 14:36:01,866][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e11.pred\n",
            "[2025-10-25 14:36:01,870][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e14. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e14.pred\n",
            "[2025-10-25 14:36:01,875][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e17. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e17.pred\n",
            "[2025-10-25 14:36:01,879][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e20. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e20.pred\n",
            "[2025-10-25 14:36:01,883][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e23. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e23.pred\n",
            "[2025-10-25 14:36:01,887][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.pred\n",
            "[2025-10-25 14:36:01,891][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e0.pred\n",
            "[2025-10-25 14:36:01,896][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e2.pred\n",
            "[2025-10-25 14:36:01,900][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e5.pred\n",
            "[2025-10-25 14:36:01,904][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e8.pred\n",
            "[2025-10-25 14:36:01,908][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e11.pred\n",
            "[2025-10-25 14:36:01,913][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e14. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e14.pred\n",
            "[2025-10-25 14:36:01,918][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e17. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e17.pred\n",
            "[2025-10-25 14:36:01,927][__main__][INFO] - \u001b[92mTesting team recommender instance mdl.bnn.Bnn ... \u001b[0m\n",
            "[2025-10-25 14:36:01,937][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.pred\n",
            "[2025-10-25 14:36:01,946][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e0.pred\n",
            "[2025-10-25 14:36:01,955][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e2.pred\n",
            "[2025-10-25 14:36:01,964][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e5.pred\n",
            "[2025-10-25 14:36:01,972][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e8.pred\n",
            "[2025-10-25 14:36:01,980][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e11.pred\n",
            "[2025-10-25 14:36:01,989][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e14. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e14.pred\n",
            "[2025-10-25 14:36:01,998][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e17. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e17.pred\n",
            "[2025-10-25 14:36:02,007][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.pred\n",
            "[2025-10-25 14:36:02,015][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e0.pred\n",
            "[2025-10-25 14:36:02,024][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e2.pred\n",
            "[2025-10-25 14:36:02,033][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e5.pred\n",
            "[2025-10-25 14:36:02,043][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e8.pred\n",
            "[2025-10-25 14:36:02,053][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e11.pred\n",
            "[2025-10-25 14:36:02,061][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e14. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e14.pred\n",
            "[2025-10-25 14:36:02,070][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.pred\n",
            "[2025-10-25 14:36:02,078][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e0.pred\n",
            "[2025-10-25 14:36:02,087][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e2.pred\n",
            "[2025-10-25 14:36:02,096][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e5.pred\n",
            "[2025-10-25 14:36:02,104][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e8.pred\n",
            "[2025-10-25 14:36:02,115][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e11.pred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Folders and Files**\n",
        "- `{model}.*/f*.test.e*.pred`: The prediction files of a `model` for each of its checkpoints `e*` trained on `f*` on the test set  "
      ],
      "metadata": {
        "id": "yB0fneIZzNqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note escaping the '[' and ']' chars in the folder name\n",
        "!ls ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h\\[128\\].spe3.lbce.tpw10.tnw1.nsdunigram_b/*.pred | xargs -n 1 basename"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhhmGNOD0PHa",
        "outputId": "e6b63e11-6070-41bd-a4c3-80cfa8d3c7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f0.test.e0.pred\n",
            "f0.test.e11.pred\n",
            "f0.test.e14.pred\n",
            "f0.test.e17.pred\n",
            "f0.test.e20.pred\n",
            "f0.test.e2.pred\n",
            "f0.test.e5.pred\n",
            "f0.test.e8.pred\n",
            "f0.test.pred\n",
            "f1.test.e0.pred\n",
            "f1.test.e11.pred\n",
            "f1.test.e14.pred\n",
            "f1.test.e17.pred\n",
            "f1.test.e20.pred\n",
            "f1.test.e23.pred\n",
            "f1.test.e2.pred\n",
            "f1.test.e5.pred\n",
            "f1.test.e8.pred\n",
            "f1.test.pred\n",
            "f2.test.e0.pred\n",
            "f2.test.e11.pred\n",
            "f2.test.e14.pred\n",
            "f2.test.e17.pred\n",
            "f2.test.e2.pred\n",
            "f2.test.e5.pred\n",
            "f2.test.e8.pred\n",
            "f2.test.pred\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**4. Running OpeNTF (Eval)**\n",
        "\n",
        "-Hydra config overriding `eval.*` in [`OpeNTF/src/__config__.yaml`](https://github.com/fani-lab/OpeNTF/blob/main/src/__config__.yaml#L86)\n",
        "\n",
        "  - Evaluating `cmd=eval` models' predictions of the test set\n",
        "  - For `eval.metrics` including classification and ranking metrics as in the [`default list`](https://github.com/fani-lab/opentf/blob/main/src/__config__.yaml#L89)  \n",
        "  - At `eval.topk`   \n"
      ],
      "metadata": {
        "id": "Rh4MG5Yrq9DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py cmd=eval \"models.instances=[mdl.rnd.Rnd, mdl.fnn.Fnn, mdl.bnn.Bnn]\" data.domain=cmn.publication.Publication data.source=../data/dblp/toy.dblp.v12.json data.output=../output/dblp/toy.dblp.v12.json ~data.filter train.train_test_ratio=0.85 train.nfolds=3 train.save_per_epoch=3 test.per_epoch=True test.topK=100 eval.topk=\\'2,5,10\\'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgbxODMW7Jh6",
        "outputId": "0ce17772-b464-417b-89db-8e492181403c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-25 15:20:43,321][cmn.team][INFO] - Loading teamsvecs matrices from ../output/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "[2025-10-25 15:20:43,346][cmn.team][INFO] - Loading indexes pickle from ../output/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "[2025-10-25 15:20:43,346][cmn.team][INFO] - Indexes pickle is loaded.\n",
            "[2025-10-25 15:20:43,346][cmn.team][INFO] - Teamsvecs matrices and indexes for skills (31, 10), members (31, 13), and locations (31, 29) are loaded.\n",
            "[2025-10-25 15:20:43,347][__main__][INFO] - Loading splits from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.pkl ...\n",
            "[2025-10-25 15:20:43,347][cmn.team][INFO] - Loading member-skill co-occurrence matrix (13, 10) from ../output/dblp/toy.dblp.v12.json/skillcoverage.pkl ...\n",
            "[2025-10-25 15:20:44,891][__main__][INFO] - \u001b[95mEvaluating team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,056][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,057][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,062][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3552.09it/s]\n",
            "[2025-10-25 15:20:45,074][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,374][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 229.55it/s]\n",
            "[2025-10-25 15:20:45,404][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,407][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,408][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,414][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2341.88it/s]\n",
            "[2025-10-25 15:20:45,418][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,423][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 304.86it/s]\n",
            "[2025-10-25 15:20:45,446][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,449][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,450][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,455][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4417.85it/s]\n",
            "[2025-10-25 15:20:45,457][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,460][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 293.33it/s]\n",
            "[2025-10-25 15:20:45,484][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv\n",
            "[2025-10-25 15:20:45,487][mdl.ntf][INFO] - Saving mean evaluation file over 3 folds as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2025-10-25 15:20:45,492][__main__][INFO] - \u001b[95mEvaluating team recommender instance mdl.fnn.Fnn ... \u001b[0m\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,497][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,498][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,503][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4161.02it/s]\n",
            "[2025-10-25 15:20:45,506][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,509][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 212.32it/s]\n",
            "[2025-10-25 15:20:45,541][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,544][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,545][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,553][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3862.16it/s]\n",
            "[2025-10-25 15:20:45,557][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,560][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 310.45it/s]\n",
            "[2025-10-25 15:20:45,583][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,584][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,585][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,593][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3439.65it/s]\n",
            "[2025-10-25 15:20:45,596][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,599][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 290.27it/s]\n",
            "[2025-10-25 15:20:45,622][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,624][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,625][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,631][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3362.44it/s]\n",
            "[2025-10-25 15:20:45,634][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,638][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 252.71it/s]\n",
            "[2025-10-25 15:20:45,664][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,665][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,666][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,671][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4234.96it/s]\n",
            "[2025-10-25 15:20:45,674][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,677][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 203.28it/s]\n",
            "[2025-10-25 15:20:45,707][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,708][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,709][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,714][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4315.13it/s]\n",
            "[2025-10-25 15:20:45,717][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,720][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 292.91it/s]\n",
            "[2025-10-25 15:20:45,743][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e11.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,744][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e14.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,745][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,749][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4151.95it/s]\n",
            "[2025-10-25 15:20:45,752][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,755][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 304.65it/s]\n",
            "[2025-10-25 15:20:45,778][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e14.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,779][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e17.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,780][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,785][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2420.26it/s]\n",
            "[2025-10-25 15:20:45,790][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,795][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 288.88it/s]\n",
            "[2025-10-25 15:20:45,818][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e17.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,820][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e20.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,820][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,826][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4510.00it/s]\n",
            "[2025-10-25 15:20:45,828][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,831][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 293.95it/s]\n",
            "[2025-10-25 15:20:45,855][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e20.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,857][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,857][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,862][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4398.39it/s]\n",
            "[2025-10-25 15:20:45,865][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,868][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 286.88it/s]\n",
            "[2025-10-25 15:20:45,892][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,893][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,894][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,899][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4373.62it/s]\n",
            "[2025-10-25 15:20:45,902][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,906][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 303.17it/s]\n",
            "[2025-10-25 15:20:45,929][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,930][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,931][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,936][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3927.99it/s]\n",
            "[2025-10-25 15:20:45,939][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,942][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 267.29it/s]\n",
            "[2025-10-25 15:20:45,966][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:45,967][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:45,968][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:45,973][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3977.91it/s]\n",
            "[2025-10-25 15:20:45,976][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:45,979][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 235.20it/s]\n",
            "[2025-10-25 15:20:46,008][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,009][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,010][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,015][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4327.59it/s]\n",
            "[2025-10-25 15:20:46,018][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,021][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 291.00it/s]\n",
            "[2025-10-25 15:20:46,044][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,045][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,046][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,051][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4023.70it/s]\n",
            "[2025-10-25 15:20:46,054][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,057][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 287.77it/s]\n",
            "[2025-10-25 15:20:46,081][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e11.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,082][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e14.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,083][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,088][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 1813.67it/s]\n",
            "[2025-10-25 15:20:46,093][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,097][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 286.05it/s]\n",
            "[2025-10-25 15:20:46,121][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e14.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,122][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e17.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,123][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,128][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2953.74it/s]\n",
            "[2025-10-25 15:20:46,132][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,135][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 304.08it/s]\n",
            "[2025-10-25 15:20:46,157][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e17.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,158][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e20.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,159][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,163][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4434.66it/s]\n",
            "[2025-10-25 15:20:46,166][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,169][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 304.16it/s]\n",
            "[2025-10-25 15:20:46,192][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e20.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,193][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e23.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,193][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,198][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4503.23it/s]\n",
            "[2025-10-25 15:20:46,201][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,204][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 300.80it/s]\n",
            "[2025-10-25 15:20:46,226][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e23.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,228][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,229][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,233][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4605.08it/s]\n",
            "[2025-10-25 15:20:46,236][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,239][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 304.49it/s]\n",
            "[2025-10-25 15:20:46,261][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,263][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,264][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,269][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4195.14it/s]\n",
            "[2025-10-25 15:20:46,271][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,274][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 200.86it/s]\n",
            "[2025-10-25 15:20:46,308][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,309][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,310][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,315][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4142.11it/s]\n",
            "[2025-10-25 15:20:46,318][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,322][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 305.60it/s]\n",
            "[2025-10-25 15:20:46,344][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,345][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,346][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,351][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4135.58it/s]\n",
            "[2025-10-25 15:20:46,354][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,357][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 312.52it/s]\n",
            "[2025-10-25 15:20:46,378][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,380][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,380][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,385][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4512.92it/s]\n",
            "[2025-10-25 15:20:46,388][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,391][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 303.31it/s]\n",
            "[2025-10-25 15:20:46,413][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,415][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,415][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,420][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4443.12it/s]\n",
            "[2025-10-25 15:20:46,423][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,426][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 296.64it/s]\n",
            "[2025-10-25 15:20:46,449][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e11.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,450][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e14.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,451][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,456][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4195.14it/s]\n",
            "[2025-10-25 15:20:46,458][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,462][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 294.29it/s]\n",
            "[2025-10-25 15:20:46,485][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e14.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,486][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e17.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,487][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,492][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2754.34it/s]\n",
            "[2025-10-25 15:20:46,496][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,500][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 255.15it/s]\n",
            "[2025-10-25 15:20:46,528][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e17.pred.eval.mean.csv\n",
            "[2025-10-25 15:20:46,531][mdl.ntf][INFO] - Saving mean evaluation file over 3 folds as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2025-10-25 15:20:46,543][__main__][INFO] - \u001b[95mEvaluating team recommender instance mdl.bnn.Bnn ... \u001b[0m\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,549][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,550][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,557][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2671.19it/s]\n",
            "[2025-10-25 15:20:46,561][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,566][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 160.70it/s]\n",
            "[2025-10-25 15:20:46,605][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,607][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,608][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,613][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4287.78it/s]\n",
            "[2025-10-25 15:20:46,616][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,619][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 303.52it/s]\n",
            "[2025-10-25 15:20:46,641][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,642][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,643][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,648][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4441.24it/s]\n",
            "[2025-10-25 15:20:46,651][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,654][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 279.23it/s]\n",
            "[2025-10-25 15:20:46,678][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,679][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,679][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,684][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4234.96it/s]\n",
            "[2025-10-25 15:20:46,687][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,690][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 226.49it/s]\n",
            "[2025-10-25 15:20:46,718][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,720][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,720][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,725][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4358.17it/s]\n",
            "[2025-10-25 15:20:46,728][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,731][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 314.54it/s]\n",
            "[2025-10-25 15:20:46,753][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,754][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,755][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,760][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4386.43it/s]\n",
            "[2025-10-25 15:20:46,763][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,766][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 295.10it/s]\n",
            "[2025-10-25 15:20:46,788][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e11.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,790][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e14.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,791][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,796][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3228.87it/s]\n",
            "[2025-10-25 15:20:46,799][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,802][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 311.23it/s]\n",
            "[2025-10-25 15:20:46,824][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e14.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,825][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e17.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,826][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,831][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4395.62it/s]\n",
            "[2025-10-25 15:20:46,833][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,836][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 208.09it/s]\n",
            "[2025-10-25 15:20:46,866][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e17.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,868][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,869][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,873][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4300.09it/s]\n",
            "[2025-10-25 15:20:46,876][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,879][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 301.16it/s]\n",
            "[2025-10-25 15:20:46,901][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,903][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,904][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,909][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4377.27it/s]\n",
            "[2025-10-25 15:20:46,912][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,915][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 312.48it/s]\n",
            "[2025-10-25 15:20:46,937][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,938][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,939][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,944][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4371.80it/s]\n",
            "[2025-10-25 15:20:46,947][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,950][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 300.34it/s]\n",
            "[2025-10-25 15:20:46,973][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:46,974][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:46,975][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:46,980][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4373.62it/s]\n",
            "[2025-10-25 15:20:46,983][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:46,986][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 227.69it/s]\n",
            "[2025-10-25 15:20:47,014][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:47,016][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:47,016][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:47,021][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4074.51it/s]\n",
            "[2025-10-25 15:20:47,024][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:47,027][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 291.62it/s]\n",
            "[2025-10-25 15:20:47,050][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:47,051][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:47,052][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:47,057][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3359.74it/s]\n",
            "[2025-10-25 15:20:47,060][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:47,063][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 290.18it/s]\n",
            "[2025-10-25 15:20:47,086][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e11.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:47,087][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e14.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:47,088][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:47,093][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4041.53it/s]\n",
            "[2025-10-25 15:20:47,096][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:47,099][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 264.80it/s]\n",
            "[2025-10-25 15:20:47,126][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e14.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:47,128][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:47,130][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:47,138][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2334.84it/s]\n",
            "[2025-10-25 15:20:47,143][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:47,147][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 262.62it/s]\n",
            "[2025-10-25 15:20:47,174][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:47,176][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:47,177][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:47,181][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4147.03it/s]\n",
            "[2025-10-25 15:20:47,184][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:47,187][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 233.81it/s]\n",
            "[2025-10-25 15:20:47,216][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:47,218][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:47,219][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:47,223][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4061.10it/s]\n",
            "[2025-10-25 15:20:47,227][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:47,230][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 299.06it/s]\n",
            "[2025-10-25 15:20:47,252][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:47,254][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:47,254][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:47,259][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3950.18it/s]\n",
            "[2025-10-25 15:20:47,262][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:47,265][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 290.35it/s]\n",
            "[2025-10-25 15:20:47,288][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:47,290][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:47,290][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:47,296][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4158.54it/s]\n",
            "[2025-10-25 15:20:47,299][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:47,302][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 300.97it/s]\n",
            "[2025-10-25 15:20:47,324][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:20:47,325][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:20:47,326][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:20:47,331][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4152.78it/s]\n",
            "[2025-10-25 15:20:47,334][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:20:47,337][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 303.25it/s]\n",
            "[2025-10-25 15:20:47,360][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e11.pred.eval.mean.csv\n",
            "[2025-10-25 15:20:47,363][mdl.ntf][INFO] - Saving mean evaluation file over 3 folds as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output Folders and Files**\n",
        "- `f*.test.e*.pred.eval.per_instance.csv`: Metric values on **each** of the `test` team instance for the model trained up to checkpoints `e*` on `f*`\n",
        "\n",
        "- `f*.test.e*.pred.eval.mean.csv`: Average of metric values over the **entire** `test` set for the model trained up to checkpoints `e*` on `f*`\n",
        "\n",
        "- `f*.test.pred.eval.per_instance.csv`: Metric values on **each** of the `test` team instance for the model trained up to the early stopping\n",
        "\n",
        "- `f*.test.pred.eval.mean.csv`: Average of metric values over the **entire** `test` set for the model trained up to the early stopping\n",
        "\n",
        "- `test.pred.eval.per_instance_mean.csv`: Average of metric values over the **folds** over **each** of the `test` instance for the model trained up to the early stopping\n",
        "\n",
        "- **`test.pred.eval.mean.csv`**: Average of metric values over the **folds** over the **entire** `test` set for the model trained up to the early stopping\n",
        "\n"
      ],
      "metadata": {
        "id": "VtwEXxqV9Vn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note escaping the '[' and ']' chars in the folder name\n",
        "!ls ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h\\[128\\].spe3.lbce.tpw10.tnw1.nsdunigram_b/*.csv | xargs -n 1 basename"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS2Jiq7T9e8J",
        "outputId": "b83481b0-0e10-4ab1-b6ba-e9b329cb4aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f0.test.e0.pred.eval.mean.csv\n",
            "f0.test.e0.pred.eval.per_instance.csv\n",
            "f0.test.e11.pred.eval.mean.csv\n",
            "f0.test.e11.pred.eval.per_instance.csv\n",
            "f0.test.e14.pred.eval.mean.csv\n",
            "f0.test.e14.pred.eval.per_instance.csv\n",
            "f0.test.e17.pred.eval.mean.csv\n",
            "f0.test.e17.pred.eval.per_instance.csv\n",
            "f0.test.e20.pred.eval.mean.csv\n",
            "f0.test.e20.pred.eval.per_instance.csv\n",
            "f0.test.e2.pred.eval.mean.csv\n",
            "f0.test.e2.pred.eval.per_instance.csv\n",
            "f0.test.e5.pred.eval.mean.csv\n",
            "f0.test.e5.pred.eval.per_instance.csv\n",
            "f0.test.e8.pred.eval.mean.csv\n",
            "f0.test.e8.pred.eval.per_instance.csv\n",
            "f0.test.pred.eval.mean.csv\n",
            "f0.test.pred.eval.per_instance.csv\n",
            "f1.test.e0.pred.eval.mean.csv\n",
            "f1.test.e0.pred.eval.per_instance.csv\n",
            "f1.test.e11.pred.eval.mean.csv\n",
            "f1.test.e11.pred.eval.per_instance.csv\n",
            "f1.test.e14.pred.eval.mean.csv\n",
            "f1.test.e14.pred.eval.per_instance.csv\n",
            "f1.test.e17.pred.eval.mean.csv\n",
            "f1.test.e17.pred.eval.per_instance.csv\n",
            "f1.test.e20.pred.eval.mean.csv\n",
            "f1.test.e20.pred.eval.per_instance.csv\n",
            "f1.test.e23.pred.eval.mean.csv\n",
            "f1.test.e23.pred.eval.per_instance.csv\n",
            "f1.test.e2.pred.eval.mean.csv\n",
            "f1.test.e2.pred.eval.per_instance.csv\n",
            "f1.test.e5.pred.eval.mean.csv\n",
            "f1.test.e5.pred.eval.per_instance.csv\n",
            "f1.test.e8.pred.eval.mean.csv\n",
            "f1.test.e8.pred.eval.per_instance.csv\n",
            "f1.test.pred.eval.mean.csv\n",
            "f1.test.pred.eval.per_instance.csv\n",
            "f2.test.e0.pred.eval.mean.csv\n",
            "f2.test.e0.pred.eval.per_instance.csv\n",
            "f2.test.e11.pred.eval.mean.csv\n",
            "f2.test.e11.pred.eval.per_instance.csv\n",
            "f2.test.e14.pred.eval.mean.csv\n",
            "f2.test.e14.pred.eval.per_instance.csv\n",
            "f2.test.e17.pred.eval.mean.csv\n",
            "f2.test.e17.pred.eval.per_instance.csv\n",
            "f2.test.e2.pred.eval.mean.csv\n",
            "f2.test.e2.pred.eval.per_instance.csv\n",
            "f2.test.e5.pred.eval.mean.csv\n",
            "f2.test.e5.pred.eval.per_instance.csv\n",
            "f2.test.e8.pred.eval.mean.csv\n",
            "f2.test.e8.pred.eval.per_instance.csv\n",
            "f2.test.pred.eval.mean.csv\n",
            "f2.test.pred.eval.per_instance.csv\n",
            "test.pred.eval.mean.csv\n",
            "test.pred.eval.per_instance_mean.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Let's look at the Bayesian (Bnn) Results for `toy.dblp`**\n",
        "\n",
        "```\n",
        "#team:31, #skills:10, #members:13\n",
        "layers:[128], learning rate:0.001, batch:1000, epoch:100, negative sampling: 5 via unigram_b\n",
        "```"
      ],
      "metadata": {
        "id": "AMe6O86CpuPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('/content/opentf/output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv', index_col = 0)"
      ],
      "metadata": {
        "id": "bdooeMNexjjl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "b1b1e6ce-d326-4a03-95f0-5a753e80b331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       mean           std\n",
              "P_2                0.166667  1.154701e-01\n",
              "P_5                0.186667  2.309401e-02\n",
              "P_10               0.160000  1.962616e-17\n",
              "recall_2           0.155556  9.622504e-02\n",
              "recall_5           0.433333  3.333333e-02\n",
              "recall_10          0.711111  1.924501e-02\n",
              "ndcg_cut_2         0.159124  1.416003e-01\n",
              "ndcg_cut_5         0.302551  8.832534e-02\n",
              "ndcg_cut_10        0.416574  8.553846e-02\n",
              "map_cut_2          0.105556  9.622504e-02\n",
              "map_cut_5          0.198333  8.352386e-02\n",
              "map_cut_10         0.263955  9.232878e-02\n",
              "success_2          0.333333  2.309401e-01\n",
              "success_5          0.733333  1.154701e-01\n",
              "success_10         0.933333  1.154701e-01\n",
              "aucroc             0.503367  1.186958e-01\n",
              "skill_coverage_2   0.888889  1.924501e-02\n",
              "skill_coverage_5   0.966667  5.773503e-02\n",
              "skill_coverage_10  1.000000  0.000000e+00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d18d8583-c9c1-4b68-b2e7-aa6db70d8632\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>P_2</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.154701e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_5</th>\n",
              "      <td>0.186667</td>\n",
              "      <td>2.309401e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_10</th>\n",
              "      <td>0.160000</td>\n",
              "      <td>1.962616e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_2</th>\n",
              "      <td>0.155556</td>\n",
              "      <td>9.622504e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_5</th>\n",
              "      <td>0.433333</td>\n",
              "      <td>3.333333e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_10</th>\n",
              "      <td>0.711111</td>\n",
              "      <td>1.924501e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_2</th>\n",
              "      <td>0.159124</td>\n",
              "      <td>1.416003e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_5</th>\n",
              "      <td>0.302551</td>\n",
              "      <td>8.832534e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <td>0.416574</td>\n",
              "      <td>8.553846e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_2</th>\n",
              "      <td>0.105556</td>\n",
              "      <td>9.622504e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_5</th>\n",
              "      <td>0.198333</td>\n",
              "      <td>8.352386e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_10</th>\n",
              "      <td>0.263955</td>\n",
              "      <td>9.232878e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_2</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>2.309401e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_5</th>\n",
              "      <td>0.733333</td>\n",
              "      <td>1.154701e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>success_10</th>\n",
              "      <td>0.933333</td>\n",
              "      <td>1.154701e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aucroc</th>\n",
              "      <td>0.503367</td>\n",
              "      <td>1.186958e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_2</th>\n",
              "      <td>0.888889</td>\n",
              "      <td>1.924501e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_5</th>\n",
              "      <td>0.966667</td>\n",
              "      <td>5.773503e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skill_coverage_10</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d18d8583-c9c1-4b68-b2e7-aa6db70d8632')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d18d8583-c9c1-4b68-b2e7-aa6db70d8632 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d18d8583-c9c1-4b68-b2e7-aa6db70d8632');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-86c0e283-6d01-46d5-844d-8de4ea4ed383\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86c0e283-6d01-46d5-844d-8de4ea4ed383')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-86c0e283-6d01-46d5-844d-8de4ea4ed383 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3166758773869791,\n        \"min\": 0.1055555555555555,\n        \"max\": 1.0,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          0.1666666666666666,\n          0.7111111111111109,\n          0.2639550264550265\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05711884101740012,\n        \"min\": 0.0,\n        \"max\": 0.2309401076758502,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.0835238562801145,\n          0.2309401076758502,\n          0.1154700538379251\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Running OpeNTF for All Steps (Prep, Train, Test, Eval)**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "r6zeM_UWAxxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \"cmd=[prep, train, test, eval]\" \"models.instances=[mdl.rnd.Rnd, mdl.fnn.Fnn, mdl.bnn.Bnn]\" data.domain=cmn.publication.Publication data.source=../data/dblp/toy.dblp.v12.json data.output=../output/dblp/toy.dblp.v12.json ~data.filter train.train_test_ratio=0.85 train.nfolds=3 train.save_per_epoch=3 test.per_epoch=True test.topK=100 eval.topk=\\'2,5,10\\'"
      ],
      "metadata": {
        "id": "DUynKC5aA84j",
        "outputId": "8fbf7c84-95e6-4c70-f888-b36c32794e7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-10-25 15:37:38,328][cmn.team][INFO] - Loading teamsvecs matrices from ../output/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "[2025-10-25 15:37:38,349][cmn.team][INFO] - Loading indexes pickle from ../output/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "[2025-10-25 15:37:38,350][cmn.team][INFO] - Indexes pickle is loaded.\n",
            "[2025-10-25 15:37:38,350][cmn.team][INFO] - Teamsvecs matrices and indexes for skills (31, 10), members (31, 13), and locations (31, 29) are loaded.\n",
            "[2025-10-25 15:37:38,351][__main__][INFO] - Loading splits from ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85.pkl ...\n",
            "[2025-10-25 15:37:38,351][cmn.team][INFO] - Loading member-skill co-occurrence matrix (13, 10) from ../output/dblp/toy.dblp.v12.json/skillcoverage.pkl ...\n",
            "[2025-10-25 15:37:39,845][__main__][INFO] - \u001b[94mTraining team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "[2025-10-25 15:37:39,845][__main__][INFO] - \u001b[92mTesting team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "[2025-10-25 15:37:39,850][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold0.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred\n",
            "[2025-10-25 15:37:39,853][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold1.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred\n",
            "[2025-10-25 15:37:39,855][mdl.rnd][INFO] - /rnd.b1000 model predictions for fold2.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred\n",
            "[2025-10-25 15:37:39,855][__main__][INFO] - \u001b[95mEvaluating team recommender instance mdl.rnd.Rnd ... \u001b[0m\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:40,019][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:40,020][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:40,025][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3387.97it/s]\n",
            "[2025-10-25 15:37:40,037][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:40,363][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 293.79it/s]\n",
            "[2025-10-25 15:37:40,387][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f0.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:40,390][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:40,391][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:40,396][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4257.31it/s]\n",
            "[2025-10-25 15:37:40,399][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:40,403][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 285.68it/s]\n",
            "[2025-10-25 15:37:40,427][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f1.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:40,430][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:40,431][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:40,436][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4195.14it/s]\n",
            "[2025-10-25 15:37:40,438][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:40,441][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 289.87it/s]\n",
            "[2025-10-25 15:37:40,465][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/f2.test.pred.eval.mean.csv\n",
            "[2025-10-25 15:37:40,469][mdl.ntf][INFO] - Saving mean evaluation file over 3 folds as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/rnd.b1000/test.pred.eval.mean.csv\n",
            "[2025-10-25 15:37:40,474][__main__][INFO] - \u001b[94mTraining team recommender instance mdl.fnn.Fnn ... \u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/content/opentf/src/mdl/fnn.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.unigram = Ntf.torch.tensor(y.sum(axis=0) / y.shape[0]).to(self.device)  # frequency of each expert in a batch\n",
            "[2025-10-25 15:37:41,118][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[94mTrain Loss: 56.5375\u001b[0m\n",
            "[2025-10-25 15:37:41,119][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[95mValid Loss: 55.6674\u001b[0m\n",
            "[2025-10-25 15:37:41,123][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e0.pt\n",
            "[2025-10-25 15:37:41,123][mdl.fnn][INFO] - Validation loss decreased (inf --> 55.667397)\n",
            "[2025-10-25 15:37:41,136][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[94mTrain Loss: 55.7426\u001b[0m\n",
            "[2025-10-25 15:37:41,136][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[95mValid Loss: 55.0569\u001b[0m\n",
            "[2025-10-25 15:37:41,137][mdl.fnn][INFO] - Validation loss decreased (55.667397 --> 55.056931)\n",
            "[2025-10-25 15:37:41,147][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[94mTrain Loss: 55.9899\u001b[0m\n",
            "[2025-10-25 15:37:41,148][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[95mValid Loss: 54.8882\u001b[0m\n",
            "[2025-10-25 15:37:41,151][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e2.pt\n",
            "[2025-10-25 15:37:41,151][mdl.fnn][INFO] - Validation loss decreased (55.056931 --> 54.888226)\n",
            "[2025-10-25 15:37:41,161][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[94mTrain Loss: 55.6564\u001b[0m\n",
            "[2025-10-25 15:37:41,161][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[95mValid Loss: 54.6679\u001b[0m\n",
            "[2025-10-25 15:37:41,161][mdl.fnn][INFO] - Validation loss decreased (54.888226 --> 54.667866)\n",
            "[2025-10-25 15:37:41,172][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[94mTrain Loss: 55.2048\u001b[0m\n",
            "[2025-10-25 15:37:41,172][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[95mValid Loss: 54.6480\u001b[0m\n",
            "[2025-10-25 15:37:41,172][mdl.fnn][INFO] - Validation loss decreased (54.667866 --> 54.647987)\n",
            "[2025-10-25 15:37:41,183][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[94mTrain Loss: 55.1856\u001b[0m\n",
            "[2025-10-25 15:37:41,183][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[95mValid Loss: 54.7965\u001b[0m\n",
            "[2025-10-25 15:37:41,187][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e5.pt\n",
            "[2025-10-25 15:37:41,187][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,197][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[94mTrain Loss: 54.9536\u001b[0m\n",
            "[2025-10-25 15:37:41,197][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[95mValid Loss: 54.1813\u001b[0m\n",
            "[2025-10-25 15:37:41,198][mdl.fnn][INFO] - Validation loss decreased (54.647987 --> 54.181313)\n",
            "[2025-10-25 15:37:41,209][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[94mTrain Loss: 54.7461\u001b[0m\n",
            "[2025-10-25 15:37:41,209][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[95mValid Loss: 54.2936\u001b[0m\n",
            "[2025-10-25 15:37:41,209][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,221][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[94mTrain Loss: 54.6121\u001b[0m\n",
            "[2025-10-25 15:37:41,221][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[95mValid Loss: 54.4439\u001b[0m\n",
            "[2025-10-25 15:37:41,225][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e8.pt\n",
            "[2025-10-25 15:37:41,225][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:41,235][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[94mTrain Loss: 54.6274\u001b[0m\n",
            "[2025-10-25 15:37:41,235][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[95mValid Loss: 53.9398\u001b[0m\n",
            "[2025-10-25 15:37:41,235][mdl.fnn][INFO] - Validation loss decreased (54.181313 --> 53.939804)\n",
            "[2025-10-25 15:37:41,245][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[94mTrain Loss: 54.6755\u001b[0m\n",
            "[2025-10-25 15:37:41,246][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[95mValid Loss: 54.1059\u001b[0m\n",
            "[2025-10-25 15:37:41,246][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,263][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[94mTrain Loss: 53.9895\u001b[0m\n",
            "[2025-10-25 15:37:41,263][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[95mValid Loss: 54.0531\u001b[0m\n",
            "[2025-10-25 15:37:41,268][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e11.pt\n",
            "[2025-10-25 15:37:41,268][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:41,284][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[94mTrain Loss: 53.9197\u001b[0m\n",
            "[2025-10-25 15:37:41,284][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[95mValid Loss: 53.9538\u001b[0m\n",
            "[2025-10-25 15:37:41,284][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 15:37:41,294][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[94mTrain Loss: 53.8581\u001b[0m\n",
            "[2025-10-25 15:37:41,295][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[95mValid Loss: 53.7434\u001b[0m\n",
            "[2025-10-25 15:37:41,295][mdl.fnn][INFO] - Validation loss decreased (53.939804 --> 53.743439)\n",
            "[2025-10-25 15:37:41,305][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[94mTrain Loss: 53.9669\u001b[0m\n",
            "[2025-10-25 15:37:41,305][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[95mValid Loss: 53.6799\u001b[0m\n",
            "[2025-10-25 15:37:41,309][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e14.pt\n",
            "[2025-10-25 15:37:41,310][mdl.fnn][INFO] - Validation loss decreased (53.743439 --> 53.679916)\n",
            "[2025-10-25 15:37:41,321][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[94mTrain Loss: 53.8270\u001b[0m\n",
            "[2025-10-25 15:37:41,321][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[95mValid Loss: 53.7475\u001b[0m\n",
            "[2025-10-25 15:37:41,322][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,332][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[94mTrain Loss: 53.8763\u001b[0m\n",
            "[2025-10-25 15:37:41,333][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[95mValid Loss: 53.5964\u001b[0m\n",
            "[2025-10-25 15:37:41,333][mdl.fnn][INFO] - Validation loss decreased (53.679916 --> 53.596363)\n",
            "[2025-10-25 15:37:41,344][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[94mTrain Loss: 53.5568\u001b[0m\n",
            "[2025-10-25 15:37:41,344][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[95mValid Loss: 53.4238\u001b[0m\n",
            "[2025-10-25 15:37:41,347][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e17.pt\n",
            "[2025-10-25 15:37:41,347][mdl.fnn][INFO] - Validation loss decreased (53.596363 --> 53.423775)\n",
            "[2025-10-25 15:37:41,358][mdl.fnn][INFO] - Fold 0/2, Epoch 18, \u001b[94mTrain Loss: 53.9005\u001b[0m\n",
            "[2025-10-25 15:37:41,358][mdl.fnn][INFO] - Fold 0/2, Epoch 18, \u001b[95mValid Loss: 53.8329\u001b[0m\n",
            "[2025-10-25 15:37:41,358][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,369][mdl.fnn][INFO] - Fold 0/2, Epoch 19, \u001b[94mTrain Loss: 53.6651\u001b[0m\n",
            "[2025-10-25 15:37:41,369][mdl.fnn][INFO] - Fold 0/2, Epoch 19, \u001b[95mValid Loss: 53.7087\u001b[0m\n",
            "[2025-10-25 15:37:41,369][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:41,379][mdl.fnn][INFO] - Fold 0/2, Epoch 20, \u001b[94mTrain Loss: 53.9768\u001b[0m\n",
            "[2025-10-25 15:37:41,380][mdl.fnn][INFO] - Fold 0/2, Epoch 20, \u001b[95mValid Loss: 53.4652\u001b[0m\n",
            "[2025-10-25 15:37:41,383][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.e20.pt\n",
            "[2025-10-25 15:37:41,383][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 15:37:41,394][mdl.fnn][INFO] - Fold 0/2, Epoch 21, \u001b[94mTrain Loss: 53.7048\u001b[0m\n",
            "[2025-10-25 15:37:41,394][mdl.fnn][INFO] - Fold 0/2, Epoch 21, \u001b[95mValid Loss: 53.8384\u001b[0m\n",
            "[2025-10-25 15:37:41,394][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 15:37:41,405][mdl.fnn][INFO] - Fold 0/2, Epoch 22, \u001b[94mTrain Loss: 53.7000\u001b[0m\n",
            "[2025-10-25 15:37:41,405][mdl.fnn][INFO] - Fold 0/2, Epoch 22, \u001b[95mValid Loss: 53.4741\u001b[0m\n",
            "[2025-10-25 15:37:41,405][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 15:37:41,406][mdl.fnn][INFO] - Early stopping triggered at epoch: 22\n",
            "[2025-10-25 15:37:41,409][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.pt\n",
            "[2025-10-25 15:37:41,420][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[94mTrain Loss: 57.0149\u001b[0m\n",
            "[2025-10-25 15:37:41,421][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[95mValid Loss: 56.0183\u001b[0m\n",
            "[2025-10-25 15:37:41,424][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e0.pt\n",
            "[2025-10-25 15:37:41,424][mdl.fnn][INFO] - Validation loss decreased (inf --> 56.018291)\n",
            "[2025-10-25 15:37:41,434][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[94mTrain Loss: 55.7020\u001b[0m\n",
            "[2025-10-25 15:37:41,435][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[95mValid Loss: 56.7937\u001b[0m\n",
            "[2025-10-25 15:37:41,435][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,445][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[94mTrain Loss: 55.9707\u001b[0m\n",
            "[2025-10-25 15:37:41,445][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[95mValid Loss: 56.2316\u001b[0m\n",
            "[2025-10-25 15:37:41,449][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e2.pt\n",
            "[2025-10-25 15:37:41,449][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:41,459][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[94mTrain Loss: 56.7553\u001b[0m\n",
            "[2025-10-25 15:37:41,459][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[95mValid Loss: 55.3608\u001b[0m\n",
            "[2025-10-25 15:37:41,460][mdl.fnn][INFO] - Validation loss decreased (56.018291 --> 55.360764)\n",
            "[2025-10-25 15:37:41,470][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[94mTrain Loss: 55.7055\u001b[0m\n",
            "[2025-10-25 15:37:41,470][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[95mValid Loss: 55.2015\u001b[0m\n",
            "[2025-10-25 15:37:41,471][mdl.fnn][INFO] - Validation loss decreased (55.360764 --> 55.201500)\n",
            "[2025-10-25 15:37:41,481][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[94mTrain Loss: 55.6291\u001b[0m\n",
            "[2025-10-25 15:37:41,481][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[95mValid Loss: 55.2516\u001b[0m\n",
            "[2025-10-25 15:37:41,485][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e5.pt\n",
            "[2025-10-25 15:37:41,485][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,495][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[94mTrain Loss: 55.6617\u001b[0m\n",
            "[2025-10-25 15:37:41,495][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[95mValid Loss: 54.9422\u001b[0m\n",
            "[2025-10-25 15:37:41,495][mdl.fnn][INFO] - Validation loss decreased (55.201500 --> 54.942219)\n",
            "[2025-10-25 15:37:41,506][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[94mTrain Loss: 55.7109\u001b[0m\n",
            "[2025-10-25 15:37:41,506][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[95mValid Loss: 55.1114\u001b[0m\n",
            "[2025-10-25 15:37:41,506][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,518][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[94mTrain Loss: 55.2338\u001b[0m\n",
            "[2025-10-25 15:37:41,518][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[95mValid Loss: 54.5381\u001b[0m\n",
            "[2025-10-25 15:37:41,521][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e8.pt\n",
            "[2025-10-25 15:37:41,521][mdl.fnn][INFO] - Validation loss decreased (54.942219 --> 54.538139)\n",
            "[2025-10-25 15:37:41,532][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[94mTrain Loss: 55.4953\u001b[0m\n",
            "[2025-10-25 15:37:41,533][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[95mValid Loss: 54.7886\u001b[0m\n",
            "[2025-10-25 15:37:41,533][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,544][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[94mTrain Loss: 55.1421\u001b[0m\n",
            "[2025-10-25 15:37:41,545][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[95mValid Loss: 54.0172\u001b[0m\n",
            "[2025-10-25 15:37:41,545][mdl.fnn][INFO] - Validation loss decreased (54.538139 --> 54.017178)\n",
            "[2025-10-25 15:37:41,556][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[94mTrain Loss: 54.8071\u001b[0m\n",
            "[2025-10-25 15:37:41,556][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[95mValid Loss: 54.2378\u001b[0m\n",
            "[2025-10-25 15:37:41,559][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e11.pt\n",
            "[2025-10-25 15:37:41,560][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,570][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[94mTrain Loss: 54.7225\u001b[0m\n",
            "[2025-10-25 15:37:41,570][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[95mValid Loss: 54.3693\u001b[0m\n",
            "[2025-10-25 15:37:41,571][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:41,581][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[94mTrain Loss: 54.4445\u001b[0m\n",
            "[2025-10-25 15:37:41,582][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[95mValid Loss: 53.5857\u001b[0m\n",
            "[2025-10-25 15:37:41,582][mdl.fnn][INFO] - Validation loss decreased (54.017178 --> 53.585678)\n",
            "[2025-10-25 15:37:41,592][mdl.fnn][INFO] - Fold 1/2, Epoch 14, \u001b[94mTrain Loss: 54.6662\u001b[0m\n",
            "[2025-10-25 15:37:41,592][mdl.fnn][INFO] - Fold 1/2, Epoch 14, \u001b[95mValid Loss: 53.7320\u001b[0m\n",
            "[2025-10-25 15:37:41,596][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e14.pt\n",
            "[2025-10-25 15:37:41,596][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,607][mdl.fnn][INFO] - Fold 1/2, Epoch 15, \u001b[94mTrain Loss: 54.5700\u001b[0m\n",
            "[2025-10-25 15:37:41,607][mdl.fnn][INFO] - Fold 1/2, Epoch 15, \u001b[95mValid Loss: 53.4958\u001b[0m\n",
            "[2025-10-25 15:37:41,607][mdl.fnn][INFO] - Validation loss decreased (53.585678 --> 53.495781)\n",
            "[2025-10-25 15:37:41,623][mdl.fnn][INFO] - Fold 1/2, Epoch 16, \u001b[94mTrain Loss: 54.3574\u001b[0m\n",
            "[2025-10-25 15:37:41,623][mdl.fnn][INFO] - Fold 1/2, Epoch 16, \u001b[95mValid Loss: 53.3371\u001b[0m\n",
            "[2025-10-25 15:37:41,624][mdl.fnn][INFO] - Validation loss decreased (53.495781 --> 53.337082)\n",
            "[2025-10-25 15:37:41,634][mdl.fnn][INFO] - Fold 1/2, Epoch 17, \u001b[94mTrain Loss: 54.2990\u001b[0m\n",
            "[2025-10-25 15:37:41,634][mdl.fnn][INFO] - Fold 1/2, Epoch 17, \u001b[95mValid Loss: 53.2332\u001b[0m\n",
            "[2025-10-25 15:37:41,638][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e17.pt\n",
            "[2025-10-25 15:37:41,638][mdl.fnn][INFO] - Validation loss decreased (53.337082 --> 53.233238)\n",
            "[2025-10-25 15:37:41,649][mdl.fnn][INFO] - Fold 1/2, Epoch 18, \u001b[94mTrain Loss: 54.1944\u001b[0m\n",
            "[2025-10-25 15:37:41,649][mdl.fnn][INFO] - Fold 1/2, Epoch 18, \u001b[95mValid Loss: 53.6433\u001b[0m\n",
            "[2025-10-25 15:37:41,649][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,660][mdl.fnn][INFO] - Fold 1/2, Epoch 19, \u001b[94mTrain Loss: 54.1146\u001b[0m\n",
            "[2025-10-25 15:37:41,660][mdl.fnn][INFO] - Fold 1/2, Epoch 19, \u001b[95mValid Loss: 53.3684\u001b[0m\n",
            "[2025-10-25 15:37:41,660][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:41,672][mdl.fnn][INFO] - Fold 1/2, Epoch 20, \u001b[94mTrain Loss: 54.1371\u001b[0m\n",
            "[2025-10-25 15:37:41,672][mdl.fnn][INFO] - Fold 1/2, Epoch 20, \u001b[95mValid Loss: 52.9164\u001b[0m\n",
            "[2025-10-25 15:37:41,676][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e20.pt\n",
            "[2025-10-25 15:37:41,676][mdl.fnn][INFO] - Validation loss decreased (53.233238 --> 52.916439)\n",
            "[2025-10-25 15:37:41,687][mdl.fnn][INFO] - Fold 1/2, Epoch 21, \u001b[94mTrain Loss: 54.1262\u001b[0m\n",
            "[2025-10-25 15:37:41,687][mdl.fnn][INFO] - Fold 1/2, Epoch 21, \u001b[95mValid Loss: 53.3078\u001b[0m\n",
            "[2025-10-25 15:37:41,687][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,698][mdl.fnn][INFO] - Fold 1/2, Epoch 22, \u001b[94mTrain Loss: 53.9746\u001b[0m\n",
            "[2025-10-25 15:37:41,698][mdl.fnn][INFO] - Fold 1/2, Epoch 22, \u001b[95mValid Loss: 53.2600\u001b[0m\n",
            "[2025-10-25 15:37:41,698][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:41,709][mdl.fnn][INFO] - Fold 1/2, Epoch 23, \u001b[94mTrain Loss: 54.0177\u001b[0m\n",
            "[2025-10-25 15:37:41,709][mdl.fnn][INFO] - Fold 1/2, Epoch 23, \u001b[95mValid Loss: 53.1334\u001b[0m\n",
            "[2025-10-25 15:37:41,712][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.e23.pt\n",
            "[2025-10-25 15:37:41,712][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 15:37:41,723][mdl.fnn][INFO] - Fold 1/2, Epoch 24, \u001b[94mTrain Loss: 53.9258\u001b[0m\n",
            "[2025-10-25 15:37:41,723][mdl.fnn][INFO] - Fold 1/2, Epoch 24, \u001b[95mValid Loss: 53.1868\u001b[0m\n",
            "[2025-10-25 15:37:41,723][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 15:37:41,733][mdl.fnn][INFO] - Fold 1/2, Epoch 25, \u001b[94mTrain Loss: 53.8081\u001b[0m\n",
            "[2025-10-25 15:37:41,734][mdl.fnn][INFO] - Fold 1/2, Epoch 25, \u001b[95mValid Loss: 53.1506\u001b[0m\n",
            "[2025-10-25 15:37:41,734][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 15:37:41,734][mdl.fnn][INFO] - Early stopping triggered at epoch: 25\n",
            "[2025-10-25 15:37:41,737][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.pt\n",
            "[2025-10-25 15:37:41,748][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[94mTrain Loss: 54.7810\u001b[0m\n",
            "[2025-10-25 15:37:41,748][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[95mValid Loss: 57.4886\u001b[0m\n",
            "[2025-10-25 15:37:41,751][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e0.pt\n",
            "[2025-10-25 15:37:41,751][mdl.fnn][INFO] - Validation loss decreased (inf --> 57.488632)\n",
            "[2025-10-25 15:37:41,761][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[94mTrain Loss: 54.7522\u001b[0m\n",
            "[2025-10-25 15:37:41,761][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[95mValid Loss: 56.9629\u001b[0m\n",
            "[2025-10-25 15:37:41,762][mdl.fnn][INFO] - Validation loss decreased (57.488632 --> 56.962887)\n",
            "[2025-10-25 15:37:41,772][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[94mTrain Loss: 54.0770\u001b[0m\n",
            "[2025-10-25 15:37:41,772][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[95mValid Loss: 57.7038\u001b[0m\n",
            "[2025-10-25 15:37:41,776][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e2.pt\n",
            "[2025-10-25 15:37:41,776][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,786][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[94mTrain Loss: 54.3484\u001b[0m\n",
            "[2025-10-25 15:37:41,787][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[95mValid Loss: 56.9704\u001b[0m\n",
            "[2025-10-25 15:37:41,787][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:41,797][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[94mTrain Loss: 53.8592\u001b[0m\n",
            "[2025-10-25 15:37:41,797][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[95mValid Loss: 56.6893\u001b[0m\n",
            "[2025-10-25 15:37:41,798][mdl.fnn][INFO] - Validation loss decreased (56.962887 --> 56.689297)\n",
            "[2025-10-25 15:37:41,808][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[94mTrain Loss: 53.5943\u001b[0m\n",
            "[2025-10-25 15:37:41,808][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[95mValid Loss: 57.1859\u001b[0m\n",
            "[2025-10-25 15:37:41,812][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e5.pt\n",
            "[2025-10-25 15:37:41,812][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,824][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[94mTrain Loss: 53.6844\u001b[0m\n",
            "[2025-10-25 15:37:41,825][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[95mValid Loss: 56.5434\u001b[0m\n",
            "[2025-10-25 15:37:41,825][mdl.fnn][INFO] - Validation loss decreased (56.689297 --> 56.543392)\n",
            "[2025-10-25 15:37:41,836][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[94mTrain Loss: 53.5197\u001b[0m\n",
            "[2025-10-25 15:37:41,836][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[95mValid Loss: 56.2402\u001b[0m\n",
            "[2025-10-25 15:37:41,836][mdl.fnn][INFO] - Validation loss decreased (56.543392 --> 56.240242)\n",
            "[2025-10-25 15:37:41,846][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[94mTrain Loss: 53.2509\u001b[0m\n",
            "[2025-10-25 15:37:41,847][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[95mValid Loss: 56.0766\u001b[0m\n",
            "[2025-10-25 15:37:41,850][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e8.pt\n",
            "[2025-10-25 15:37:41,850][mdl.fnn][INFO] - Validation loss decreased (56.240242 --> 56.076565)\n",
            "[2025-10-25 15:37:41,861][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[94mTrain Loss: 53.3092\u001b[0m\n",
            "[2025-10-25 15:37:41,862][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[95mValid Loss: 56.5757\u001b[0m\n",
            "[2025-10-25 15:37:41,862][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,873][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[94mTrain Loss: 53.0044\u001b[0m\n",
            "[2025-10-25 15:37:41,873][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[95mValid Loss: 56.0600\u001b[0m\n",
            "[2025-10-25 15:37:41,873][mdl.fnn][INFO] - Validation loss decreased (56.076565 --> 56.059963)\n",
            "[2025-10-25 15:37:41,884][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[94mTrain Loss: 53.0029\u001b[0m\n",
            "[2025-10-25 15:37:41,884][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[95mValid Loss: 56.1187\u001b[0m\n",
            "[2025-10-25 15:37:41,887][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e11.pt\n",
            "[2025-10-25 15:37:41,888][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,898][mdl.fnn][INFO] - Fold 2/2, Epoch 12, \u001b[94mTrain Loss: 53.0313\u001b[0m\n",
            "[2025-10-25 15:37:41,898][mdl.fnn][INFO] - Fold 2/2, Epoch 12, \u001b[95mValid Loss: 55.5317\u001b[0m\n",
            "[2025-10-25 15:37:41,898][mdl.fnn][INFO] - Validation loss decreased (56.059963 --> 55.531677)\n",
            "[2025-10-25 15:37:41,910][mdl.fnn][INFO] - Fold 2/2, Epoch 13, \u001b[94mTrain Loss: 52.8177\u001b[0m\n",
            "[2025-10-25 15:37:41,910][mdl.fnn][INFO] - Fold 2/2, Epoch 13, \u001b[95mValid Loss: 56.0350\u001b[0m\n",
            "[2025-10-25 15:37:41,911][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,921][mdl.fnn][INFO] - Fold 2/2, Epoch 14, \u001b[94mTrain Loss: 52.7721\u001b[0m\n",
            "[2025-10-25 15:37:41,922][mdl.fnn][INFO] - Fold 2/2, Epoch 14, \u001b[95mValid Loss: 55.4759\u001b[0m\n",
            "[2025-10-25 15:37:41,925][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e14.pt\n",
            "[2025-10-25 15:37:41,925][mdl.fnn][INFO] - Validation loss decreased (55.531677 --> 55.475929)\n",
            "[2025-10-25 15:37:41,935][mdl.fnn][INFO] - Fold 2/2, Epoch 15, \u001b[94mTrain Loss: 52.8636\u001b[0m\n",
            "[2025-10-25 15:37:41,935][mdl.fnn][INFO] - Fold 2/2, Epoch 15, \u001b[95mValid Loss: 55.6114\u001b[0m\n",
            "[2025-10-25 15:37:41,936][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:41,947][mdl.fnn][INFO] - Fold 2/2, Epoch 16, \u001b[94mTrain Loss: 52.7980\u001b[0m\n",
            "[2025-10-25 15:37:41,947][mdl.fnn][INFO] - Fold 2/2, Epoch 16, \u001b[95mValid Loss: 55.5690\u001b[0m\n",
            "[2025-10-25 15:37:41,948][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:41,958][mdl.fnn][INFO] - Fold 2/2, Epoch 17, \u001b[94mTrain Loss: 52.5881\u001b[0m\n",
            "[2025-10-25 15:37:41,958][mdl.fnn][INFO] - Fold 2/2, Epoch 17, \u001b[95mValid Loss: 55.7257\u001b[0m\n",
            "[2025-10-25 15:37:41,962][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.e17.pt\n",
            "[2025-10-25 15:37:41,962][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 15:37:41,972][mdl.fnn][INFO] - Fold 2/2, Epoch 18, \u001b[94mTrain Loss: 52.8473\u001b[0m\n",
            "[2025-10-25 15:37:41,972][mdl.fnn][INFO] - Fold 2/2, Epoch 18, \u001b[95mValid Loss: 55.5387\u001b[0m\n",
            "[2025-10-25 15:37:41,973][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 15:37:41,983][mdl.fnn][INFO] - Fold 2/2, Epoch 19, \u001b[94mTrain Loss: 52.7851\u001b[0m\n",
            "[2025-10-25 15:37:41,983][mdl.fnn][INFO] - Fold 2/2, Epoch 19, \u001b[95mValid Loss: 55.7392\u001b[0m\n",
            "[2025-10-25 15:37:41,984][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 15:37:41,984][mdl.fnn][INFO] - Early stopping triggered at epoch: 19\n",
            "[2025-10-25 15:37:41,987][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.pt\n",
            "[2025-10-25 15:37:41,987][__main__][INFO] - \u001b[92mTesting team recommender instance mdl.fnn.Fnn ... \u001b[0m\n",
            "/content/opentf/src/mdl/fnn.py:187: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.load_state_dict(Ntf.torch.load(modelfile, map_location=self.device)['model_state_dict'])\n",
            "[2025-10-25 15:37:41,993][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.pred\n",
            "[2025-10-25 15:37:41,998][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e0.pred\n",
            "[2025-10-25 15:37:42,002][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e2.pred\n",
            "[2025-10-25 15:37:42,007][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e5.pred\n",
            "[2025-10-25 15:37:42,011][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e8.pred\n",
            "[2025-10-25 15:37:42,016][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e11.pred\n",
            "[2025-10-25 15:37:42,020][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e14. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e14.pred\n",
            "[2025-10-25 15:37:42,024][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e17. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e17.pred\n",
            "[2025-10-25 15:37:42,029][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold0.test.e20. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e20.pred\n",
            "[2025-10-25 15:37:42,035][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.pred\n",
            "[2025-10-25 15:37:42,039][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e0.pred\n",
            "[2025-10-25 15:37:42,044][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e2.pred\n",
            "[2025-10-25 15:37:42,048][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e5.pred\n",
            "[2025-10-25 15:37:42,053][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e8.pred\n",
            "[2025-10-25 15:37:42,057][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e11.pred\n",
            "[2025-10-25 15:37:42,062][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e14. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e14.pred\n",
            "[2025-10-25 15:37:42,067][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e17. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e17.pred\n",
            "[2025-10-25 15:37:42,071][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e20. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e20.pred\n",
            "[2025-10-25 15:37:42,075][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold1.test.e23. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e23.pred\n",
            "[2025-10-25 15:37:42,081][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.pred\n",
            "[2025-10-25 15:37:42,085][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e0.pred\n",
            "[2025-10-25 15:37:42,091][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e2.pred\n",
            "[2025-10-25 15:37:42,096][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e5.pred\n",
            "[2025-10-25 15:37:42,101][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e8.pred\n",
            "[2025-10-25 15:37:42,105][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e11.pred\n",
            "[2025-10-25 15:37:42,110][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e14. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e14.pred\n",
            "[2025-10-25 15:37:42,118][mdl.fnn][INFO] - /fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b model predictions for fold2.test.e17. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e17.pred\n",
            "[2025-10-25 15:37:42,118][__main__][INFO] - \u001b[95mEvaluating team recommender instance mdl.fnn.Fnn ... \u001b[0m\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,126][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,127][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,131][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3100.92it/s]\n",
            "[2025-10-25 15:37:42,135][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,138][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 284.30it/s]\n",
            "[2025-10-25 15:37:42,162][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,164][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,165][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,169][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4134.76it/s]\n",
            "[2025-10-25 15:37:42,172][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,175][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 289.73it/s]\n",
            "[2025-10-25 15:37:42,198][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,200][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,200][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,205][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3930.19it/s]\n",
            "[2025-10-25 15:37:42,208][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,211][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 258.61it/s]\n",
            "[2025-10-25 15:37:42,237][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,238][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,239][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,243][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4422.51it/s]\n",
            "[2025-10-25 15:37:42,246][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,249][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 290.67it/s]\n",
            "[2025-10-25 15:37:42,271][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,273][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,274][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,278][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3841.64it/s]\n",
            "[2025-10-25 15:37:42,282][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,286][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 162.60it/s]\n",
            "[2025-10-25 15:37:42,326][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,328][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,329][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,333][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3989.26it/s]\n",
            "[2025-10-25 15:37:42,337][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,340][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 281.83it/s]\n",
            "[2025-10-25 15:37:42,363][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e11.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,365][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e14.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,366][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,370][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3919.91it/s]\n",
            "[2025-10-25 15:37:42,373][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,376][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 280.06it/s]\n",
            "[2025-10-25 15:37:42,400][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e14.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,401][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e17.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,402][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,408][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3814.39it/s]\n",
            "[2025-10-25 15:37:42,411][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,414][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 290.16it/s]\n",
            "[2025-10-25 15:37:42,437][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e17.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,439][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e20.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,440][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,443][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3838.83it/s]\n",
            "[2025-10-25 15:37:42,446][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,449][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 286.48it/s]\n",
            "[2025-10-25 15:37:42,472][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f0.test.e20.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,474][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,475][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,479][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3963.62it/s]\n",
            "[2025-10-25 15:37:42,482][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,485][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 282.32it/s]\n",
            "[2025-10-25 15:37:42,509][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,511][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,511][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,516][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3677.92it/s]\n",
            "[2025-10-25 15:37:42,519][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,522][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 275.50it/s]\n",
            "[2025-10-25 15:37:42,546][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,547][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,548][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,552][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4088.02it/s]\n",
            "[2025-10-25 15:37:42,555][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,558][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 287.32it/s]\n",
            "[2025-10-25 15:37:42,581][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,582][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,583][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,587][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3958.38it/s]\n",
            "[2025-10-25 15:37:42,590][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,593][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 283.67it/s]\n",
            "[2025-10-25 15:37:42,617][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,619][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,620][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,626][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2595.16it/s]\n",
            "[2025-10-25 15:37:42,631][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,634][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 283.53it/s]\n",
            "[2025-10-25 15:37:42,657][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,658][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,659][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,663][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4041.53it/s]\n",
            "[2025-10-25 15:37:42,666][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,669][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 294.85it/s]\n",
            "[2025-10-25 15:37:42,692][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e11.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,693][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e14.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,694][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,698][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3950.93it/s]\n",
            "[2025-10-25 15:37:42,701][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,704][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 283.70it/s]\n",
            "[2025-10-25 15:37:42,727][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e14.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,728][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e17.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,729][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,733][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4129.88it/s]\n",
            "[2025-10-25 15:37:42,736][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,738][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 282.07it/s]\n",
            "[2025-10-25 15:37:42,762][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e17.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,763][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e20.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,764][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,767][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4290.41it/s]\n",
            "[2025-10-25 15:37:42,770][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,773][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 291.77it/s]\n",
            "[2025-10-25 15:37:42,796][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e20.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,797][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e23.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,798][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,802][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3976.40it/s]\n",
            "[2025-10-25 15:37:42,805][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,808][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 209.62it/s]\n",
            "[2025-10-25 15:37:42,837][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f1.test.e23.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,840][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,840][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,844][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4060.31it/s]\n",
            "[2025-10-25 15:37:42,847][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,850][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 291.94it/s]\n",
            "[2025-10-25 15:37:42,873][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,874][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,875][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,879][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4029.11it/s]\n",
            "[2025-10-25 15:37:42,882][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,885][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 269.30it/s]\n",
            "[2025-10-25 15:37:42,909][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,911][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,911][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,916][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3105.05it/s]\n",
            "[2025-10-25 15:37:42,919][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,922][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 268.33it/s]\n",
            "[2025-10-25 15:37:42,946][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,947][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,948][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,952][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4001.43it/s]\n",
            "[2025-10-25 15:37:42,955][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,958][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 286.37it/s]\n",
            "[2025-10-25 15:37:42,981][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:42,983][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:42,983][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:42,987][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3892.99it/s]\n",
            "[2025-10-25 15:37:42,991][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:42,993][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 286.70it/s]\n",
            "[2025-10-25 15:37:43,016][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:43,018][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:43,018][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:43,022][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4072.14it/s]\n",
            "[2025-10-25 15:37:43,025][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:43,028][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 287.97it/s]\n",
            "[2025-10-25 15:37:43,051][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e11.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:43,053][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e14.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:43,053][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:43,057][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4224.72it/s]\n",
            "[2025-10-25 15:37:43,060][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:43,063][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 289.31it/s]\n",
            "[2025-10-25 15:37:43,086][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e14.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:43,087][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e17.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:43,088][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:43,092][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3839.53it/s]\n",
            "[2025-10-25 15:37:43,095][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:43,097][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 256.51it/s]\n",
            "[2025-10-25 15:37:43,124][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/f2.test.e17.pred.eval.mean.csv\n",
            "[2025-10-25 15:37:43,129][mdl.ntf][INFO] - Saving mean evaluation file over 3 folds as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/fnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b/test.pred.eval.mean.csv\n",
            "[2025-10-25 15:37:43,145][__main__][INFO] - \u001b[94mTraining team recommender instance mdl.bnn.Bnn ... \u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/content/opentf/src/mdl/fnn.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.unigram = Ntf.torch.tensor(y.sum(axis=0) / y.shape[0]).to(self.device)  # frequency of each expert in a batch\n",
            "[2025-10-25 15:37:43,162][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[94mTrain Loss: 55.8699\u001b[0m\n",
            "[2025-10-25 15:37:43,163][mdl.fnn][INFO] - Fold 0/2, Epoch 0, \u001b[95mValid Loss: 56.7096\u001b[0m\n",
            "[2025-10-25 15:37:43,166][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e0.pt\n",
            "[2025-10-25 15:37:43,166][mdl.fnn][INFO] - Validation loss decreased (inf --> 56.709644)\n",
            "[2025-10-25 15:37:43,179][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[94mTrain Loss: 55.9380\u001b[0m\n",
            "[2025-10-25 15:37:43,180][mdl.fnn][INFO] - Fold 0/2, Epoch 1, \u001b[95mValid Loss: 56.2262\u001b[0m\n",
            "[2025-10-25 15:37:43,180][mdl.fnn][INFO] - Validation loss decreased (56.709644 --> 56.226158)\n",
            "[2025-10-25 15:37:43,193][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[94mTrain Loss: 55.8123\u001b[0m\n",
            "[2025-10-25 15:37:43,193][mdl.fnn][INFO] - Fold 0/2, Epoch 2, \u001b[95mValid Loss: 56.1281\u001b[0m\n",
            "[2025-10-25 15:37:43,196][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e2.pt\n",
            "[2025-10-25 15:37:43,196][mdl.fnn][INFO] - Validation loss decreased (56.226158 --> 56.128094)\n",
            "[2025-10-25 15:37:43,209][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[94mTrain Loss: 55.2799\u001b[0m\n",
            "[2025-10-25 15:37:43,209][mdl.fnn][INFO] - Fold 0/2, Epoch 3, \u001b[95mValid Loss: 55.9876\u001b[0m\n",
            "[2025-10-25 15:37:43,210][mdl.fnn][INFO] - Validation loss decreased (56.128094 --> 55.987579)\n",
            "[2025-10-25 15:37:43,223][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[94mTrain Loss: 55.6912\u001b[0m\n",
            "[2025-10-25 15:37:43,223][mdl.fnn][INFO] - Fold 0/2, Epoch 4, \u001b[95mValid Loss: 56.2795\u001b[0m\n",
            "[2025-10-25 15:37:43,223][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:43,238][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[94mTrain Loss: 55.4871\u001b[0m\n",
            "[2025-10-25 15:37:43,238][mdl.fnn][INFO] - Fold 0/2, Epoch 5, \u001b[95mValid Loss: 55.6443\u001b[0m\n",
            "[2025-10-25 15:37:43,242][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e5.pt\n",
            "[2025-10-25 15:37:43,242][mdl.fnn][INFO] - Validation loss decreased (55.987579 --> 55.644329)\n",
            "[2025-10-25 15:37:43,254][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[94mTrain Loss: 55.3050\u001b[0m\n",
            "[2025-10-25 15:37:43,255][mdl.fnn][INFO] - Fold 0/2, Epoch 6, \u001b[95mValid Loss: 55.7185\u001b[0m\n",
            "[2025-10-25 15:37:43,255][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:43,268][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[94mTrain Loss: 55.2790\u001b[0m\n",
            "[2025-10-25 15:37:43,268][mdl.fnn][INFO] - Fold 0/2, Epoch 7, \u001b[95mValid Loss: 55.9072\u001b[0m\n",
            "[2025-10-25 15:37:43,269][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:43,281][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[94mTrain Loss: 54.8306\u001b[0m\n",
            "[2025-10-25 15:37:43,281][mdl.fnn][INFO] - Fold 0/2, Epoch 8, \u001b[95mValid Loss: 55.7106\u001b[0m\n",
            "[2025-10-25 15:37:43,285][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e8.pt\n",
            "[2025-10-25 15:37:43,285][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 15:37:43,298][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[94mTrain Loss: 54.9492\u001b[0m\n",
            "[2025-10-25 15:37:43,298][mdl.fnn][INFO] - Fold 0/2, Epoch 9, \u001b[95mValid Loss: 56.2660\u001b[0m\n",
            "[2025-10-25 15:37:43,299][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 15:37:43,312][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[94mTrain Loss: 55.0732\u001b[0m\n",
            "[2025-10-25 15:37:43,312][mdl.fnn][INFO] - Fold 0/2, Epoch 10, \u001b[95mValid Loss: 55.6022\u001b[0m\n",
            "[2025-10-25 15:37:43,312][mdl.fnn][INFO] - Validation loss decreased (55.644329 --> 55.602226)\n",
            "[2025-10-25 15:37:43,347][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[94mTrain Loss: 54.8042\u001b[0m\n",
            "[2025-10-25 15:37:43,347][mdl.fnn][INFO] - Fold 0/2, Epoch 11, \u001b[95mValid Loss: 55.7355\u001b[0m\n",
            "[2025-10-25 15:37:43,353][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e11.pt\n",
            "[2025-10-25 15:37:43,353][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:43,367][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[94mTrain Loss: 55.0498\u001b[0m\n",
            "[2025-10-25 15:37:43,367][mdl.fnn][INFO] - Fold 0/2, Epoch 12, \u001b[95mValid Loss: 55.5379\u001b[0m\n",
            "[2025-10-25 15:37:43,367][mdl.fnn][INFO] - Validation loss decreased (55.602226 --> 55.537910)\n",
            "[2025-10-25 15:37:43,380][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[94mTrain Loss: 55.3867\u001b[0m\n",
            "[2025-10-25 15:37:43,380][mdl.fnn][INFO] - Fold 0/2, Epoch 13, \u001b[95mValid Loss: 55.2177\u001b[0m\n",
            "[2025-10-25 15:37:43,381][mdl.fnn][INFO] - Validation loss decreased (55.537910 --> 55.217693)\n",
            "[2025-10-25 15:37:43,394][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[94mTrain Loss: 54.5639\u001b[0m\n",
            "[2025-10-25 15:37:43,394][mdl.fnn][INFO] - Fold 0/2, Epoch 14, \u001b[95mValid Loss: 55.6992\u001b[0m\n",
            "[2025-10-25 15:37:43,397][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e14.pt\n",
            "[2025-10-25 15:37:43,398][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:43,412][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[94mTrain Loss: 54.5846\u001b[0m\n",
            "[2025-10-25 15:37:43,413][mdl.fnn][INFO] - Fold 0/2, Epoch 15, \u001b[95mValid Loss: 55.3301\u001b[0m\n",
            "[2025-10-25 15:37:43,413][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:43,426][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[94mTrain Loss: 54.8063\u001b[0m\n",
            "[2025-10-25 15:37:43,427][mdl.fnn][INFO] - Fold 0/2, Epoch 16, \u001b[95mValid Loss: 55.4990\u001b[0m\n",
            "[2025-10-25 15:37:43,427][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 15:37:43,441][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[94mTrain Loss: 54.5938\u001b[0m\n",
            "[2025-10-25 15:37:43,441][mdl.fnn][INFO] - Fold 0/2, Epoch 17, \u001b[95mValid Loss: 56.1086\u001b[0m\n",
            "[2025-10-25 15:37:43,444][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.e17.pt\n",
            "[2025-10-25 15:37:43,445][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 15:37:43,458][mdl.fnn][INFO] - Fold 0/2, Epoch 18, \u001b[94mTrain Loss: 54.5526\u001b[0m\n",
            "[2025-10-25 15:37:43,458][mdl.fnn][INFO] - Fold 0/2, Epoch 18, \u001b[95mValid Loss: 55.3335\u001b[0m\n",
            "[2025-10-25 15:37:43,458][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 15:37:43,458][mdl.fnn][INFO] - Early stopping triggered at epoch: 18\n",
            "[2025-10-25 15:37:43,463][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.pt\n",
            "[2025-10-25 15:37:43,483][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[94mTrain Loss: 56.2187\u001b[0m\n",
            "[2025-10-25 15:37:43,483][mdl.fnn][INFO] - Fold 1/2, Epoch 0, \u001b[95mValid Loss: 55.8349\u001b[0m\n",
            "[2025-10-25 15:37:43,486][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e0.pt\n",
            "[2025-10-25 15:37:43,486][mdl.fnn][INFO] - Validation loss decreased (inf --> 55.834946)\n",
            "[2025-10-25 15:37:43,500][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[94mTrain Loss: 56.5845\u001b[0m\n",
            "[2025-10-25 15:37:43,500][mdl.fnn][INFO] - Fold 1/2, Epoch 1, \u001b[95mValid Loss: 54.6991\u001b[0m\n",
            "[2025-10-25 15:37:43,501][mdl.fnn][INFO] - Validation loss decreased (55.834946 --> 54.699120)\n",
            "[2025-10-25 15:37:43,514][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[94mTrain Loss: 56.0198\u001b[0m\n",
            "[2025-10-25 15:37:43,514][mdl.fnn][INFO] - Fold 1/2, Epoch 2, \u001b[95mValid Loss: 55.2755\u001b[0m\n",
            "[2025-10-25 15:37:43,517][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e2.pt\n",
            "[2025-10-25 15:37:43,517][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:43,534][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[94mTrain Loss: 56.3215\u001b[0m\n",
            "[2025-10-25 15:37:43,534][mdl.fnn][INFO] - Fold 1/2, Epoch 3, \u001b[95mValid Loss: 55.3733\u001b[0m\n",
            "[2025-10-25 15:37:43,534][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:43,548][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[94mTrain Loss: 55.9023\u001b[0m\n",
            "[2025-10-25 15:37:43,548][mdl.fnn][INFO] - Fold 1/2, Epoch 4, \u001b[95mValid Loss: 55.0186\u001b[0m\n",
            "[2025-10-25 15:37:43,549][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 15:37:43,562][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[94mTrain Loss: 56.1089\u001b[0m\n",
            "[2025-10-25 15:37:43,562][mdl.fnn][INFO] - Fold 1/2, Epoch 5, \u001b[95mValid Loss: 54.4789\u001b[0m\n",
            "[2025-10-25 15:37:43,566][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e5.pt\n",
            "[2025-10-25 15:37:43,566][mdl.fnn][INFO] - Validation loss decreased (54.699120 --> 54.478939)\n",
            "[2025-10-25 15:37:43,579][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[94mTrain Loss: 55.6965\u001b[0m\n",
            "[2025-10-25 15:37:43,579][mdl.fnn][INFO] - Fold 1/2, Epoch 6, \u001b[95mValid Loss: 54.7984\u001b[0m\n",
            "[2025-10-25 15:37:43,579][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:43,592][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[94mTrain Loss: 55.6870\u001b[0m\n",
            "[2025-10-25 15:37:43,593][mdl.fnn][INFO] - Fold 1/2, Epoch 7, \u001b[95mValid Loss: 54.3168\u001b[0m\n",
            "[2025-10-25 15:37:43,593][mdl.fnn][INFO] - Validation loss decreased (54.478939 --> 54.316780)\n",
            "[2025-10-25 15:37:43,606][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[94mTrain Loss: 56.4392\u001b[0m\n",
            "[2025-10-25 15:37:43,606][mdl.fnn][INFO] - Fold 1/2, Epoch 8, \u001b[95mValid Loss: 54.4878\u001b[0m\n",
            "[2025-10-25 15:37:43,610][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e8.pt\n",
            "[2025-10-25 15:37:43,610][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:43,623][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[94mTrain Loss: 55.7026\u001b[0m\n",
            "[2025-10-25 15:37:43,623][mdl.fnn][INFO] - Fold 1/2, Epoch 9, \u001b[95mValid Loss: 55.0580\u001b[0m\n",
            "[2025-10-25 15:37:43,623][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:43,636][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[94mTrain Loss: 55.8184\u001b[0m\n",
            "[2025-10-25 15:37:43,637][mdl.fnn][INFO] - Fold 1/2, Epoch 10, \u001b[95mValid Loss: 54.1445\u001b[0m\n",
            "[2025-10-25 15:37:43,637][mdl.fnn][INFO] - Validation loss decreased (54.316780 --> 54.144478)\n",
            "[2025-10-25 15:37:43,651][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[94mTrain Loss: 55.8001\u001b[0m\n",
            "[2025-10-25 15:37:43,651][mdl.fnn][INFO] - Fold 1/2, Epoch 11, \u001b[95mValid Loss: 54.7832\u001b[0m\n",
            "[2025-10-25 15:37:43,655][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e11.pt\n",
            "[2025-10-25 15:37:43,655][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:43,668][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[94mTrain Loss: 55.9865\u001b[0m\n",
            "[2025-10-25 15:37:43,668][mdl.fnn][INFO] - Fold 1/2, Epoch 12, \u001b[95mValid Loss: 54.5986\u001b[0m\n",
            "[2025-10-25 15:37:43,669][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:43,683][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[94mTrain Loss: 55.5947\u001b[0m\n",
            "[2025-10-25 15:37:43,684][mdl.fnn][INFO] - Fold 1/2, Epoch 13, \u001b[95mValid Loss: 55.0731\u001b[0m\n",
            "[2025-10-25 15:37:43,684][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 15:37:43,697][mdl.fnn][INFO] - Fold 1/2, Epoch 14, \u001b[94mTrain Loss: 55.7173\u001b[0m\n",
            "[2025-10-25 15:37:43,697][mdl.fnn][INFO] - Fold 1/2, Epoch 14, \u001b[95mValid Loss: 54.6146\u001b[0m\n",
            "[2025-10-25 15:37:43,701][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.e14.pt\n",
            "[2025-10-25 15:37:43,701][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 15:37:43,713][mdl.fnn][INFO] - Fold 1/2, Epoch 15, \u001b[94mTrain Loss: 56.3928\u001b[0m\n",
            "[2025-10-25 15:37:43,714][mdl.fnn][INFO] - Fold 1/2, Epoch 15, \u001b[95mValid Loss: 54.6889\u001b[0m\n",
            "[2025-10-25 15:37:43,714][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 15:37:43,714][mdl.fnn][INFO] - Early stopping triggered at epoch: 15\n",
            "[2025-10-25 15:37:43,717][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.pt\n",
            "[2025-10-25 15:37:43,737][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[94mTrain Loss: 55.4082\u001b[0m\n",
            "[2025-10-25 15:37:43,737][mdl.fnn][INFO] - Fold 2/2, Epoch 0, \u001b[95mValid Loss: 58.0916\u001b[0m\n",
            "[2025-10-25 15:37:43,744][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.e0.pt\n",
            "[2025-10-25 15:37:43,744][mdl.fnn][INFO] - Validation loss decreased (inf --> 58.091587)\n",
            "[2025-10-25 15:37:43,762][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[94mTrain Loss: 55.1100\u001b[0m\n",
            "[2025-10-25 15:37:43,763][mdl.fnn][INFO] - Fold 2/2, Epoch 1, \u001b[95mValid Loss: 57.4678\u001b[0m\n",
            "[2025-10-25 15:37:43,763][mdl.fnn][INFO] - Validation loss decreased (58.091587 --> 57.467751)\n",
            "[2025-10-25 15:37:43,776][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[94mTrain Loss: 55.1349\u001b[0m\n",
            "[2025-10-25 15:37:43,776][mdl.fnn][INFO] - Fold 2/2, Epoch 2, \u001b[95mValid Loss: 57.7490\u001b[0m\n",
            "[2025-10-25 15:37:43,780][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.e2.pt\n",
            "[2025-10-25 15:37:43,780][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:43,793][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[94mTrain Loss: 54.5135\u001b[0m\n",
            "[2025-10-25 15:37:43,793][mdl.fnn][INFO] - Fold 2/2, Epoch 3, \u001b[95mValid Loss: 56.9044\u001b[0m\n",
            "[2025-10-25 15:37:43,793][mdl.fnn][INFO] - Validation loss decreased (57.467751 --> 56.904366)\n",
            "[2025-10-25 15:37:43,807][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[94mTrain Loss: 54.2709\u001b[0m\n",
            "[2025-10-25 15:37:43,807][mdl.fnn][INFO] - Fold 2/2, Epoch 4, \u001b[95mValid Loss: 57.6934\u001b[0m\n",
            "[2025-10-25 15:37:43,807][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:43,821][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[94mTrain Loss: 54.5239\u001b[0m\n",
            "[2025-10-25 15:37:43,821][mdl.fnn][INFO] - Fold 2/2, Epoch 5, \u001b[95mValid Loss: 57.4714\u001b[0m\n",
            "[2025-10-25 15:37:43,824][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.e5.pt\n",
            "[2025-10-25 15:37:43,824][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:43,838][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[94mTrain Loss: 54.3981\u001b[0m\n",
            "[2025-10-25 15:37:43,838][mdl.fnn][INFO] - Fold 2/2, Epoch 6, \u001b[95mValid Loss: 57.6087\u001b[0m\n",
            "[2025-10-25 15:37:43,838][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 15:37:43,851][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[94mTrain Loss: 54.3081\u001b[0m\n",
            "[2025-10-25 15:37:43,852][mdl.fnn][INFO] - Fold 2/2, Epoch 7, \u001b[95mValid Loss: 57.9233\u001b[0m\n",
            "[2025-10-25 15:37:43,852][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 15:37:43,865][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[94mTrain Loss: 53.8749\u001b[0m\n",
            "[2025-10-25 15:37:43,865][mdl.fnn][INFO] - Fold 2/2, Epoch 8, \u001b[95mValid Loss: 56.8240\u001b[0m\n",
            "[2025-10-25 15:37:43,868][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.e8.pt\n",
            "[2025-10-25 15:37:43,869][mdl.fnn][INFO] - Validation loss decreased (56.904366 --> 56.823997)\n",
            "[2025-10-25 15:37:43,881][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[94mTrain Loss: 54.0046\u001b[0m\n",
            "[2025-10-25 15:37:43,881][mdl.fnn][INFO] - Fold 2/2, Epoch 9, \u001b[95mValid Loss: 57.4810\u001b[0m\n",
            "[2025-10-25 15:37:43,881][mdl.fnn][INFO] - EarlyStopping counter: 1 out of 5\n",
            "[2025-10-25 15:37:43,894][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[94mTrain Loss: 54.0000\u001b[0m\n",
            "[2025-10-25 15:37:43,894][mdl.fnn][INFO] - Fold 2/2, Epoch 10, \u001b[95mValid Loss: 57.3392\u001b[0m\n",
            "[2025-10-25 15:37:43,895][mdl.fnn][INFO] - EarlyStopping counter: 2 out of 5\n",
            "[2025-10-25 15:37:43,908][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[94mTrain Loss: 54.3159\u001b[0m\n",
            "[2025-10-25 15:37:43,908][mdl.fnn][INFO] - Fold 2/2, Epoch 11, \u001b[95mValid Loss: 56.8328\u001b[0m\n",
            "[2025-10-25 15:37:43,911][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.e11.pt\n",
            "[2025-10-25 15:37:43,911][mdl.fnn][INFO] - EarlyStopping counter: 3 out of 5\n",
            "[2025-10-25 15:37:43,924][mdl.fnn][INFO] - Fold 2/2, Epoch 12, \u001b[94mTrain Loss: 54.2377\u001b[0m\n",
            "[2025-10-25 15:37:43,925][mdl.fnn][INFO] - Fold 2/2, Epoch 12, \u001b[95mValid Loss: 57.1624\u001b[0m\n",
            "[2025-10-25 15:37:43,925][mdl.fnn][INFO] - EarlyStopping counter: 4 out of 5\n",
            "[2025-10-25 15:37:43,939][mdl.fnn][INFO] - Fold 2/2, Epoch 13, \u001b[94mTrain Loss: 54.5491\u001b[0m\n",
            "[2025-10-25 15:37:43,940][mdl.fnn][INFO] - Fold 2/2, Epoch 13, \u001b[95mValid Loss: 57.7939\u001b[0m\n",
            "[2025-10-25 15:37:43,940][mdl.fnn][INFO] - EarlyStopping counter: 5 out of 5\n",
            "[2025-10-25 15:37:43,940][mdl.fnn][INFO] - Early stopping triggered at epoch: 13\n",
            "[2025-10-25 15:37:43,943][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model with b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.pt\n",
            "[2025-10-25 15:37:43,944][__main__][INFO] - \u001b[92mTesting team recommender instance mdl.bnn.Bnn ... \u001b[0m\n",
            "/content/opentf/src/mdl/fnn.py:187: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.load_state_dict(Ntf.torch.load(modelfile, map_location=self.device)['model_state_dict'])\n",
            "[2025-10-25 15:37:43,954][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.pred\n",
            "[2025-10-25 15:37:43,963][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e0.pred\n",
            "[2025-10-25 15:37:43,972][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e2.pred\n",
            "[2025-10-25 15:37:43,980][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e5.pred\n",
            "[2025-10-25 15:37:43,989][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e8.pred\n",
            "[2025-10-25 15:37:43,998][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e11.pred\n",
            "[2025-10-25 15:37:44,007][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e14. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e14.pred\n",
            "[2025-10-25 15:37:44,016][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold0.test.e17. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e17.pred\n",
            "[2025-10-25 15:37:44,025][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.pred\n",
            "[2025-10-25 15:37:44,040][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e0.pred\n",
            "[2025-10-25 15:37:44,051][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e2.pred\n",
            "[2025-10-25 15:37:44,060][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e5.pred\n",
            "[2025-10-25 15:37:44,068][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e8.pred\n",
            "[2025-10-25 15:37:44,076][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e11.pred\n",
            "[2025-10-25 15:37:44,085][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold1.test.e14. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e14.pred\n",
            "[2025-10-25 15:37:44,094][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.pred\n",
            "[2025-10-25 15:37:44,102][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e0. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e0.pred\n",
            "[2025-10-25 15:37:44,110][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e2. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e2.pred\n",
            "[2025-10-25 15:37:44,120][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e5. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e5.pred\n",
            "[2025-10-25 15:37:44,129][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e8. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e8.pred\n",
            "[2025-10-25 15:37:44,138][mdl.fnn][INFO] - /bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10 model predictions for fold2.test.e11. has saved at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e11.pred\n",
            "[2025-10-25 15:37:44,138][__main__][INFO] - \u001b[95mEvaluating team recommender instance mdl.bnn.Bnn ... \u001b[0m\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,143][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,144][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,148][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3898.05it/s]\n",
            "[2025-10-25 15:37:44,151][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,154][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 294.85it/s]\n",
            "[2025-10-25 15:37:44,176][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,178][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,179][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,184][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4304.50it/s]\n",
            "[2025-10-25 15:37:44,186][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,189][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 213.00it/s]\n",
            "[2025-10-25 15:37:44,218][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,219][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,220][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,224][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4295.68it/s]\n",
            "[2025-10-25 15:37:44,230][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,232][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 292.36it/s]\n",
            "[2025-10-25 15:37:44,255][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,256][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,257][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,261][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3431.77it/s]\n",
            "[2025-10-25 15:37:44,264][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,267][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 298.85it/s]\n",
            "[2025-10-25 15:37:44,289][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,290][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,291][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,295][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4407.63it/s]\n",
            "[2025-10-25 15:37:44,297][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,300][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 302.51it/s]\n",
            "[2025-10-25 15:37:44,322][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,323][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,324][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,328][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2478.32it/s]\n",
            "[2025-10-25 15:37:44,333][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,337][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 146.92it/s]\n",
            "[2025-10-25 15:37:44,380][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e11.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,382][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e14.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,383][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,387][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4208.61it/s]\n",
            "[2025-10-25 15:37:44,390][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,393][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 308.23it/s]\n",
            "[2025-10-25 15:37:44,414][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e14.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,416][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e17.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,416][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,420][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4417.85it/s]\n",
            "[2025-10-25 15:37:44,423][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,426][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 299.10it/s]\n",
            "[2025-10-25 15:37:44,448][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f0.test.e17.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,450][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,451][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,455][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3769.82it/s]\n",
            "[2025-10-25 15:37:44,458][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,461][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 285.18it/s]\n",
            "[2025-10-25 15:37:44,484][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,486][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,487][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,491][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4135.58it/s]\n",
            "[2025-10-25 15:37:44,493][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,498][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 220.83it/s]\n",
            "[2025-10-25 15:37:44,529][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,530][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,531][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,539][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 2175.47it/s]\n",
            "[2025-10-25 15:37:44,544][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,548][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 248.54it/s]\n",
            "[2025-10-25 15:37:44,575][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,576][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,577][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,581][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4338.34it/s]\n",
            "[2025-10-25 15:37:44,584][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,586][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 299.61it/s]\n",
            "[2025-10-25 15:37:44,608][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,609][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,610][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,614][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3911.87it/s]\n",
            "[2025-10-25 15:37:44,617][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,620][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 294.69it/s]\n",
            "[2025-10-25 15:37:44,642][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,643][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,644][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,648][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3922.84it/s]\n",
            "[2025-10-25 15:37:44,651][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,654][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 281.05it/s]\n",
            "[2025-10-25 15:37:44,679][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e11.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,680][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e14.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,680][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,684][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4314.24it/s]\n",
            "[2025-10-25 15:37:44,687][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,690][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 282.30it/s]\n",
            "[2025-10-25 15:37:44,713][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f1.test.e14.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,715][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,716][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,720][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3977.15it/s]\n",
            "[2025-10-25 15:37:44,723][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,726][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 195.28it/s]\n",
            "[2025-10-25 15:37:44,759][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,762][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e0.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,763][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,767][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3956.14it/s]\n",
            "[2025-10-25 15:37:44,770][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,773][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 195.82it/s]\n",
            "[2025-10-25 15:37:44,805][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e0.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,806][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e2.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,807][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,811][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3965.87it/s]\n",
            "[2025-10-25 15:37:44,814][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,816][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 275.13it/s]\n",
            "[2025-10-25 15:37:44,841][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e2.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,842][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e5.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,843][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,847][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3997.62it/s]\n",
            "[2025-10-25 15:37:44,850][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,853][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 283.95it/s]\n",
            "[2025-10-25 15:37:44,876][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e5.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,877][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e8.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,878][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,882][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 4003.73it/s]\n",
            "[2025-10-25 15:37:44,885][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,888][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 275.62it/s]\n",
            "[2025-10-25 15:37:44,911][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e8.pred.eval.mean.csv\n",
            "/content/opentf/src/mdl/ntf.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  Y_ = Ntf.torch.load(predfile, map_location='cpu')['y_pred']\n",
            "[2025-10-25 15:37:44,913][mdl.ntf][INFO] - Evaluating predictions at ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e11.pred ... for {'trec': ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'], 'other': ['skill_coverage_2,5,10', 'aucroc']}\n",
            "[2025-10-25 15:37:44,914][mdl.ntf][INFO] - ['P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'success_2,5,10'] ...\n",
            "[2025-10-25 15:37:44,918][evl.metric][INFO] - Building pytrec_eval input for 5 instances ...\n",
            "100% 5/5 [00:00<00:00, 3852.93it/s]\n",
            "[2025-10-25 15:37:44,921][mdl.ntf][INFO] - ['aucroc'] ...\n",
            "[2025-10-25 15:37:44,923][mdl.ntf][INFO] - ['skill_coverage_2,5,10'] ...\n",
            "100% 5/5 [00:00<00:00, 252.75it/s]\n",
            "[2025-10-25 15:37:44,949][mdl.ntf][INFO] - Saving file per fold as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/f2.test.e11.pred.eval.mean.csv\n",
            "[2025-10-25 15:37:44,953][mdl.ntf][INFO] - Saving mean evaluation file over 3 folds as ../output/dblp/toy.dblp.v12.json/splits.f3.r0.85/bnn.b1000.e100.ns5.lr0.001.es5.h[128].spe3.lbce.tpw10.tnw1.nsdunigram_b.nmc10/test.pred.eval.mean.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Appendices**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ukte4M25AAkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Sample OpeNTF Commands for Different Datasets (`Unit Tests`)**\n",
        "\n",
        "- Datasests Preprocessing: [`OpeNTF/.github/workflows/inclusive-tests-preps-toys-main.yml`](https://github.com/fani-lab/OpeNTF/blob/main/.github/workflows/inclusive-tests-preps-toys-main.yml)\n",
        "- Models Train-Test-Eval: [`OpeNTF/.github/workflows/inclusive-tests-models-toys-main.yml`](https://github.com/fani-lab/OpeNTF/blob/main/.github/workflows/inclusive-tests-models-toys-main.yml)\n",
        "- Embedding and Gnn-based Models: [`OpeNTF/.github/workflows/inclusive-tests-embs-toys-main.yml`](https://github.com/fani-lab/OpeNTF/blob/main/.github/workflows/inclusive-tests-embs-toys-main.yml)"
      ],
      "metadata": {
        "id": "Jf6qKaVrBfxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Datasets**"
      ],
      "metadata": {
        "id": "X3Hh3UqoGamp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dblp"
      ],
      "metadata": {
        "id": "ia7rn1gcIG4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get install --assume-yes p7zip-full\n",
        "#!wget -O ../data/raw/dblp/dblp.v12.7z https://originalstatic.aminer.cn/misc/dblp.v12.7z\n",
        "#!7z e ../data/raw/dblp/dblp.v12.7z -o../data/raw/dblp/"
      ],
      "metadata": {
        "id": "RBZJO6ROGZ3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "imdb"
      ],
      "metadata": {
        "id": "fym1KH8HIJwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get install --assume-yes p7zip-full\n",
        "#!wget -O ../data/raw/imdb/name.basics.tsv.gz https://datasets.imdbws.com/name.basics.tsv.gz\n",
        "#!wget -O ../data/raw/imdb/title.basics.tsv.gz https://datasets.imdbws.com/title.basics.tsv.gz\n",
        "#!wget -O ../data/raw/imdb/title.principals.tsv.gz https://datasets.imdbws.com/title.principals.tsv.gz\n",
        "#!7z e ../data/raw/imdb/name.basics.tsv.gz -o../data/raw/imdb/\n",
        "#!mv ../data/raw/imdb/data.tsv ../data/raw/imdb/name.basics.tsv\n",
        "#!7z e ../data/raw/imdb/title.basics.tsv.gz -o../data/raw/imdb/\n",
        "#!mv ../data/raw/imdb/data.tsv ../data/raw/imdb/title.basics.tsv\n",
        "#!7z e ../data/raw/imdb/title.principals.tsv.gz -o../data/raw/imdb/\n",
        "#!mv ../data/raw/imdb/data.tsv ../data/raw/imdb/title.principals.tsv"
      ],
      "metadata": {
        "id": "inLPKBgwIOjt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}