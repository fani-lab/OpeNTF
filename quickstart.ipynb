{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quickstart.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fani-lab/OpeNTF/blob/main/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
	{
      "cell_type": "markdown",
      "source": [
        "**Setup Python 3.8 on Colab Environment.**"
      ],
      "metadata": {
        "id": "hsO795wNk9WL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "yzuvvMImFFWg",
        "outputId": "8cfdaaae-89c8-4402-d6cd-5c92ef9334ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Waiting for header\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Waiting for header\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Waiting for header\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Waiting for header\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Waiting for header\r0% [Release.gpg gpgv 564 B] [Connecting to archive.ubuntu.com] [Waiting for hea\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "\r0% [Release.gpg gpgv 564 B] [Connecting to archive.ubuntu.com] [Waiting for hea\r                                                                               \rGet:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [945 kB]\n",
            "Get:13 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [80.8 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,484 kB]\n",
            "Get:17 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,262 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,660 kB]\n",
            "Hit:20 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,098 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,830 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [937 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 13.7 MB in 4s (3,185 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8 python3.8-minimal\n",
            "0 upgraded, 4 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 4,676 kB of archives.\n",
            "After this operation, 18.5 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.8-minimal amd64 3.8.13-1+bionic1 [762 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.8-minimal amd64 3.8.13-1+bionic1 [1,824 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.8-stdlib amd64 3.8.13-1+bionic1 [1,656 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.8 amd64 3.8.13-1+bionic1 [434 kB]\n",
            "Fetched 4,676 kB in 5s (1,004 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../libpython3.8-minimal_3.8.13-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.13-1+bionic1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../python3.8-minimal_3.8.13-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.13-1+bionic1) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../libpython3.8-stdlib_3.8.13-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.13-1+bionic1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../python3.8_3.8.13-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.13-1+bionic1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.13-1+bionic1) ...\n",
            "Setting up python3.8-minimal (3.8.13-1+bionic1) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.13-1+bionic1) ...\n",
            "Setting up python3.8 (3.8.13-1+bionic1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in auto mode\n",
            "Python 3.8.13\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pkg-resources python3-secretstorage python3-setuptools python3-six\n",
            "  python3-wheel python3-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python3-cryptography-vectors\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0\n",
            "  python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-asn1crypto python3-cffi-backend python3-crypto\n",
            "  python3-cryptography python3-idna python3-keyring python3-keyrings.alt\n",
            "  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools\n",
            "  python3-six python3-wheel python3-xdg\n",
            "0 upgraded, 15 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 2,882 kB of archives.\n",
            "After this operation, 8,886 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.5 [1,653 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-asn1crypto all 0.24.0-1 [72.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-cffi-backend amd64 1.11.5-1 [64.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-cryptography amd64 2.1.4-1ubuntu1.4 [220 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-secretstorage all 2.3.1-2 [12.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyring all 10.6.0-1 [26.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-keyrings.alt all 3.0-1 [16.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-pip all 9.0.1-2.3~ubuntu1.18.04.5 [114 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-setuptools all 39.0.1-2 [248 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-wheel all 0.30.0-0.2 [36.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-xdg all 0.25-4ubuntu1.1 [31.3 kB]\n",
            "Fetched 2,882 kB in 1s (2,788 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 15.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 156829 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-asn1crypto.\n",
            "Preparing to unpack .../01-python3-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python3-cffi-backend.\n",
            "Preparing to unpack .../02-python3-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python3-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python3-crypto.\n",
            "Preparing to unpack .../03-python3-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python3-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../04-python3-idna_2.6-1_all.deb ...\n",
            "Unpacking python3-idna (2.6-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../05-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-cryptography.\n",
            "Preparing to unpack .../06-python3-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python3-secretstorage.\n",
            "Preparing to unpack .../07-python3-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python3-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python3-keyring.\n",
            "Preparing to unpack .../08-python3-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python3-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python3-keyrings.alt.\n",
            "Preparing to unpack .../09-python3-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python3-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../10-python3-pip_9.0.1-2.3~ubuntu1.18.04.5_all.deb ...\n",
            "Unpacking python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../11-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../12-python3-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python3-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../13-python3-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python3-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python3-xdg.\n",
            "Preparing to unpack .../14-python3-xdg_0.25-4ubuntu1.1_all.deb ...\n",
            "Unpacking python3-xdg (0.25-4ubuntu1.1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "Setting up python3-cffi-backend (1.11.5-1) ...\n",
            "Setting up python3-crypto (2.6.1-8ubuntu2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-idna (2.6-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-xdg (0.25-4ubuntu1.1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-wheel (0.30.0-0.2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-asn1crypto (0.24.0-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-pip (9.0.1-2.3~ubuntu1.18.04.5) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-setuptools (39.0.1-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-keyrings.alt (3.0-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-secretstorage (2.3.1-2) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Setting up python3-keyring (10.6.0-1) ...\n",
            "/usr/lib/python3.8/subprocess.py:842: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
            "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pip\n",
            "  Downloading https://files.pythonhosted.org/packages/4d/16/0a14ca596f30316efd412a60bdfac02a7259bf8673d4d917dc60b9a21812/pip-22.0.4-py3-none-any.whl (2.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.1MB 554kB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 9.0.1\n",
            "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
            "Successfully installed pip-22.0.4\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.9.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB)\n",
            "Collecting jupyter-client<8.0\n",
            "  Downloading jupyter_client-7.1.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython>=7.23.1\n",
            "  Downloading ipython-8.2.0-py3-none-any.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.7/750.7 KB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-5.9.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.8/283.8 KB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado<7.0,>=4.2\n",
            "  Downloading tornado-6.1-cp38-cp38-manylinux2010_x86_64.whl (427 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.5/427.5 KB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitlets<6.0,>=5.1.0\n",
            "  Downloading traitlets-5.1.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.0/102.0 KB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting debugpy<2.0,>=1.0.0\n",
            "  Downloading debugpy-1.6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline<0.2.0,>=0.1.0\n",
            "  Downloading matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython>=7.23.1->ipykernel) (39.0.1)\n",
            "Collecting stack-data\n",
            "  Downloading stack_data-0.2.0-py3-none-any.whl (21 kB)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pygments>=2.4.0\n",
            "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.28-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.2/380.2 KB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting python-dateutil>=2.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 KB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-core>=4.6.0\n",
            "  Downloading jupyter_core-4.9.2-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzmq>=13\n",
            "  Downloading pyzmq-22.3.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel) (1.11.0)\n",
            "Collecting asttokens\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Collecting executing\n",
            "  Downloading executing-0.8.3-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: wcwidth, pure-eval, ptyprocess, pickleshare, executing, backcall, traitlets, tornado, pyzmq, python-dateutil, pygments, psutil, prompt-toolkit, pexpect, parso, nest-asyncio, entrypoints, decorator, debugpy, asttokens, stack-data, matplotlib-inline, jupyter-core, jedi, jupyter-client, ipython, ipykernel\n",
            "Successfully installed asttokens-2.0.5 backcall-0.2.0 debugpy-1.6.0 decorator-5.1.1 entrypoints-0.4 executing-0.8.3 ipykernel-6.9.2 ipython-8.2.0 jedi-0.18.1 jupyter-client-7.1.2 jupyter-core-4.9.2 matplotlib-inline-0.1.3 nest-asyncio-1.5.4 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.28 psutil-5.9.0 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.11.2 python-dateutil-2.8.2 pyzmq-22.3.0 stack-data-0.2.0 tornado-6.1 traitlets-5.1.1 wcwidth-0.2.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "jupyter_core",
                  "pexpect",
                  "pickleshare",
                  "traitlets",
                  "wcwidth",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2\n",
        "!python --version\n",
        "!sudo apt-get install python3-pip\n",
        "!python -m pip install --upgrade pip\n",
        "!pip install ipykernel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing OpeNTF**"
      ],
      "metadata": {
        "id": "6tKkPogYlQxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -R opentf/\n",
        "!git clone https://github.com/fani-lab/opentf\n",
        "%cd opentf/\n",
        "!pip install -r requirements.txt\n",
        "%cd src/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fwIEGOF9FT4U",
        "outputId": "9164641d-552e-44b4-d843-ddb62593d8d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'opentf/': No such file or directory\n",
            "Cloning into 'opentf'...\n",
            "remote: Enumerating objects: 3286, done.\u001b[K\n",
            "remote: Counting objects: 100% (3286/3286), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2321/2321), done.\u001b[K\n",
            "remote: Total 3286 (delta 1465), reused 2553 (delta 921), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3286/3286), 35.00 MiB | 15.75 MiB/s, done.\n",
            "Resolving deltas: 100% (1465/1465), done.\n",
            "/content/opentf\n",
            "Collecting torch>=1.6.0\n",
            "  Downloading torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.6.3\n",
            "  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.20.3\n",
            "  Downloading numpy-1.20.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.60.0\n",
            "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML==5.4\n",
            "  Downloading PyYAML-5.4-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.2/662.2 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==0.24.2\n",
            "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.3.3\n",
            "  Downloading pandas-1.3.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytrec-eval-terrier==0.5.2\n",
            "  Downloading pytrec_eval_terrier-0.5.2-cp38-cp38-manylinux2010_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.4.2\n",
            "  Downloading matplotlib-3.4.2-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3.3->-r requirements.txt (line 7)) (2.8.2)\n",
            "Collecting pytz>=2017.3\n",
            "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.5/503.5 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open>=1.8.1\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/lib/python3/dist-packages (from gensim==3.8.3->-r requirements.txt (line 8)) (1.11.0)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.0/98.0 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pytz, typing-extensions, tqdm, threadpoolctl, smart-open, PyYAML, pytrec-eval-terrier, pyparsing, pillow, numpy, kiwisolver, joblib, cycler, torch, scipy, pandas, matplotlib, scikit_learn, gensim\n",
            "Successfully installed PyYAML-5.4 cycler-0.11.0 gensim-3.8.3 joblib-1.1.0 kiwisolver-1.4.1 matplotlib-3.4.2 numpy-1.20.3 pandas-1.3.3 pillow-9.0.1 pyparsing-3.0.7 pytrec-eval-terrier-0.5.2 pytz-2022.1 scikit_learn-0.24.2 scipy-1.6.3 smart-open-5.2.1 threadpoolctl-3.1.0 torch-1.11.0 tqdm-4.60.0 typing-extensions-4.1.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/opentf/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download Datasets**"
      ],
      "metadata": {
        "id": "X3Hh3UqoGamp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dblp"
      ],
      "metadata": {
        "id": "ia7rn1gcIG4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get install --assume-yes p7zip-full\n",
        "#!wget -O ../data/raw/dblp/dblp.v12.7z https://originalstatic.aminer.cn/misc/dblp.v12.7z\n",
        "#!7z e ../data/raw/dblp/dblp.v12.7z -o../data/raw/dblp/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBZJO6ROGZ3U",
        "outputId": "bc898113-a4ac-4801-b9f0-f8d69da94afd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan ../data/raw/dblp/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 2727161612 bytes (2601 MiB)\n",
            "\n",
            "Extracting archive: ../data/raw/dblp/dblp.v12.7z\n",
            "--\n",
            "Path = ../data/raw/dblp/dblp.v12.7z\n",
            "Type = 7z\n",
            "Physical Size = 2727161612\n",
            "Headers Size = 130\n",
            "Method = LZMA2:25\n",
            "Solid = -\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% - dblp.v12.json\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% - dblp.v12.json"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "imdb"
      ],
      "metadata": {
        "id": "fym1KH8HIJwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get install --assume-yes p7zip-full\n",
        "#!wget -O ../data/raw/imdb/name.basics.tsv.gz https://datasets.imdbws.com/name.basics.tsv.gz\n",
        "#!wget -O ../data/raw/imdb/title.basics.tsv.gz https://datasets.imdbws.com/title.basics.tsv.gz\n",
        "#!wget -O ../data/raw/imdb/title.principals.tsv.gz https://datasets.imdbws.com/title.principals.tsv.gz\n",
        "#!7z e ../data/raw/imdb/name.basics.tsv.gz -o../data/raw/imdb/\n",
        "#!mv ../data/raw/imdb/data.tsv ../data/raw/imdb/name.basics.tsv\n",
        "#!7z e ../data/raw/imdb/title.basics.tsv.gz -o../data/raw/imdb/\n",
        "#!mv ../data/raw/imdb/data.tsv ../data/raw/imdb/title.basics.tsv\n",
        "#!7z e ../data/raw/imdb/title.principals.tsv.gz -o../data/raw/imdb/\n",
        "#!mv ../data/raw/imdb/data.tsv ../data/raw/imdb/title.principals.tsv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "inLPKBgwIOjt",
        "outputId": "998be23b-661e-4425-ea32-f73bc9355691"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan ../data/raw/imdb/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 225213583 bytes (215 MiB)\n",
            "\n",
            "Extracting archive: ../data/raw/imdb/name.basics.tsv.gz\n",
            "--\n",
            "Path = ../data/raw/imdb/name.basics.tsv.gz\n",
            "Type = gzip\n",
            "Headers Size = 19\n",
            "\n",
            "  0% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Size:       689139542\n",
            "Compressed: 225213583\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan ../data/raw/imdb/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 153981157 bytes (147 MiB)\n",
            "\n",
            "Extracting archive: ../data/raw/imdb/title.basics.tsv.gz\n",
            "--\n",
            "Path = ../data/raw/imdb/title.basics.tsv.gz\n",
            "Type = gzip\n",
            "Headers Size = 19\n",
            "\n",
            "  0% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Size:       752708571\n",
            "Compressed: 153981157\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan ../data/raw/imdb/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 393203021 bytes (375 MiB)\n",
            "\n",
            "Extracting archive: ../data/raw/imdb/title.principals.tsv.gz\n",
            "--\n",
            "Path = ../data/raw/imdb/title.principals.tsv.gz\n",
            "Type = gzip\n",
            "Headers Size = 19\n",
            "\n",
            "  0% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% - data.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Size:       2183970048\n",
            "Compressed: 393203021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "uspt"
      ],
      "metadata": {
        "id": "9JDO5dgPILXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Default Hyperparameters**"
      ],
      "metadata": {
        "id": "a4G4Omoolyvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat param.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG0nCDddl5w6",
        "outputId": "515b3202-0dd3-4f68-e56a-66660b633d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import random\n",
            "import torch\n",
            "import numpy as np\n",
            "\n",
            "random.seed(0)\n",
            "torch.manual_seed(0)\n",
            "torch.cuda.manual_seed_all(0)\n",
            "\n",
            "np.random.seed(0)\n",
            "\n",
            "settings = {\n",
            "    'model':{\n",
            "        'baseline': {\n",
            "            'random': {\n",
            "                'b': 4096\n",
            "            },\n",
            "            'fnn':{\n",
            "                'l': [100],  # list of number of nodes in each layer\n",
            "                'lr': 0.1,  # learning rate\n",
            "                'b': 4096,  # batch size\n",
            "                'e': 20,  # epoch\n",
            "                'nns': None,  # number of negative samples\n",
            "                'ns': None,  # 'uniform', 'unigram', 'unigram_b'\n",
            "            },\n",
            "            'bnn':{\n",
            "                'l': [100],  # list of number of nodes in each layer\n",
            "                'lr': 0.1,  # learning rate\n",
            "                'b': 4096,  # batch size\n",
            "                'e': 20,  # epoch\n",
            "                'nns': None,  # number of negative samples\n",
            "                'ns': None,  # 'uniform', 'unigram', 'unigram_b'\n",
            "                's': 1  # # sample_elbo for bnn\n",
            "            },\n",
            "            'emb':{\n",
            "                'd': 100,# embedding dimension\n",
            "                'e': 100,# epoch\n",
            "                'dm': 1,# training algorithm. 1: distributed memory (PV-DM), 0: distributed bag of words (PV-DBOW)\n",
            "                'w': 1 #cooccurrence window\n",
            "            }\n",
            "        },\n",
            "        'cmd': ['train', 'test', 'eval', 'plot'],  # 'train', 'test', 'eval'\n",
            "        'nfolds': 3,\n",
            "        'train_test_split': 0.85\n",
            "    },\n",
            "    'data':{\n",
            "        'domain': {\n",
            "            'dblp':{},\n",
            "            'uspt':{},\n",
            "            'imdb':{},\n",
            "        },\n",
            "        'filter': {\n",
            "            'min_nteam': 75,\n",
            "            'min_team_size': 3,\n",
            "        },\n",
            "        'parallel': 1,\n",
            "        'ncore': 0,# <= 0 for all\n",
            "        'bucket_size': 500\n",
            "    },\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change Hyperparameters, e.g., Negative Sampling Heuristics and Number of Negative Samples**\n",
        "```\n",
        "settings['model']['baseline']['fnn']['ns'] = 'uniform'\n",
        "settings['model']['baseline']['fnn']['nns'] = 1\n",
        "settings['model']['baseline']['bnn']['ns'] = 'unigram_b'\n",
        "settings['model']['baseline']['bnn']['nns'] = 2\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DbBMkT-2GUyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile param.py \n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "settings = {\n",
        "    'model':{\n",
        "        'baseline': {\n",
        "            'random': {\n",
        "                'b': 4096\n",
        "            },\n",
        "            'fnn':{\n",
        "                'l': [100],  # list of number of nodes in each layer\n",
        "                'lr': 0.1,  # learning rate\n",
        "                'b': 4096,  # batch size\n",
        "                'e': 20,  # epoch\n",
        "                'nns': 1,  # number of negative samples\n",
        "                'ns': 'uniform',  # 'uniform', 'unigram', 'unigram_b'\n",
        "            },\n",
        "            'bnn':{\n",
        "                'l': [100],  # list of number of nodes in each layer\n",
        "                'lr': 0.1,  # learning rate\n",
        "                'b': 4096,  # batch size\n",
        "                'e': 20,  # epoch\n",
        "                'nns': 2,  # number of negative samples\n",
        "                'ns': 'unigram_b',  # 'uniform', 'unigram', 'unigram_b'\n",
        "                's': 1  # # sample_elbo for bnn\n",
        "            },\n",
        "            'emb':{\n",
        "                'd': 100,# embedding dimension\n",
        "                'e': 100,# epoch\n",
        "                'dm': 1,# training algorithm. 1: distributed memory (PV-DM), 0: distributed bag of words (PV-DBOW)\n",
        "                'w': 1 #cooccurrence window\n",
        "            }\n",
        "        },\n",
        "        'cmd': ['train', 'test', 'eval', 'plot'],  # 'train', 'test', 'eval'\n",
        "        'nfolds': 3,\n",
        "        'train_test_split': 0.85\n",
        "    },\n",
        "    'data':{\n",
        "        'domain': {\n",
        "            'dblp':{},\n",
        "            'uspt':{},\n",
        "            'imdb':{},\n",
        "        },\n",
        "        'filter': {\n",
        "            'min_nteam': 75,\n",
        "            'min_team_size': 3,\n",
        "        },\n",
        "        'parallel': 1,\n",
        "        'ncore': 0,# <= 0 for all\n",
        "        'bucket_size': 500\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "e_IpSujJGUgX",
        "outputId": "5e673d4c-3955-4570-d8ad-e1b5b54a320b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting param.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clearing Cache Pickles for Teams Sparse Matrix if Exist`(Optional)`**"
      ],
      "metadata": {
        "id": "a-hr8hQxVS64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -R ../data/preprocessed/dblp/toy.dblp.v12.json/\n",
        "!rm -R ../data/preprocessed/imdb/toy.title.basics.tsv/"
      ],
      "metadata": {
        "id": "xR1R1nUpVSLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benchmark on Toy subsets of DBLP and IMDB for non-Bayesian Feedforward (fnn) and Bayesian (bnn) Models as well as Random Baseline**"
      ],
      "metadata": {
        "id": "o41hWOnFoiVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -data ../data/raw/dblp/toy.dblp.v12.json ../data/raw/imdb/toy.title.basics.tsv -domain dblp imdb -model fnn fnn_emb bnn bnn_emb random\n",
        "#!python main.py -data ../data/raw/dblp/dblp.v12.json ../data/raw/imdb/title.basics.tsv -domain dblp imdb -model fnn fnn_emb bnn bnn_emb random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBUkUAFyIXAD",
        "outputId": "eb42da1c-f69a-4dbb-dea4-3163e403ee52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "File not found! Generating the sparse matrices ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "Pickles not found! Reading raw data from ../data/raw/dblp/toy.dblp.v12.json (progress in bytes) ...\n",
            "\r  0% 0/46630 [00:00<?, ?it/s]JSONDecodeError: There has been error in loading json line `[\n",
            "`!\n",
            "Expecting value: line 2 column 1 (char 2)\n",
            "JSONDecodeError: There has been error in loading json line `]`!\n",
            "Expecting value: line 1 column 1 (char 0)\n",
            "\r100% 46606/46630 [00:00<00:00, 8782053.65it/s]\n",
            "It took 0.00823354721069336 seconds to pickle the data into ./../data/preprocessed/dblp/toy.dblp.v12.json\n",
            "It took 0.07705211639404297 seconds to generate and store the sparse matrices of size (31, 25) at ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "It took 0.00011539459228515625 seconds to load from the pickles.\n",
            "It took 0.0004639625549316406 seconds to load the sparse matrices.\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 37.86146926879883, Time 0.008354902267456055, Overall 0.010493993759155273 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 2.2271452511058136, Time 0.008457660675048828, Overall 0.010595321655273438 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 14.891037940979004, Time 0.011717557907104492, Overall 0.013856172561645508 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 1.6545597712198894, Time 0.011817216873168945, Overall 0.013955354690551758 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 23.78317642211914, Time 0.017432212829589844, Overall 0.019571542739868164 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 1.3990103777717142, Time 0.01760101318359375, Overall 0.019739389419555664 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 20.005701065063477, Time 0.020586013793945312, Overall 0.02272510528564453 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 2.2228556738959417, Time 0.02067422866821289, Overall 0.0228118896484375 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 23.718902587890625, Time 0.026769399642944336, Overall 0.02890777587890625 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 1.3952295639935661, Time 0.02683544158935547, Overall 0.028972864151000977 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 16.789087295532227, Time 0.02929973602294922, Overall 0.031438350677490234 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 1.8654541439480252, Time 0.029389142990112305, Overall 0.031526803970336914 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 33.599205017089844, Time 0.036060333251953125, Overall 0.03819918632507324 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 1.9764238245346968, Time 0.03613400459289551, Overall 0.03827166557312012 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 31.076480865478516, Time 0.03839468955993652, Overall 0.040532827377319336 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 3.452942318386502, Time 0.03851795196533203, Overall 0.04065513610839844 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 35.348628997802734, Time 0.04557609558105469, Overall 0.047714948654174805 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 2.0793311175178077, Time 0.045662641525268555, Overall 0.047800540924072266 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 19.456682205200195, Time 0.048902034759521484, Overall 0.0510411262512207 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 2.1618535783555775, Time 0.04899311065673828, Overall 0.051131248474121094 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 29.4737606048584, Time 0.05600595474243164, Overall 0.05814504623413086 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 1.7337506238151998, Time 0.056180477142333984, Overall 0.0583188533782959 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 11.545722961425781, Time 0.059029579162597656, Overall 0.06116819381713867 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 1.2828581068250868, Time 0.059114933013916016, Overall 0.061252593994140625 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 27.596233367919922, Time 0.06531310081481934, Overall 0.06745123863220215 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 1.6233078451717602, Time 0.06537652015686035, Overall 0.06751394271850586 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 11.056278228759766, Time 0.0721275806427002, Overall 0.07426643371582031 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 1.228475358751085, Time 0.07222962379455566, Overall 0.07436776161193848 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 13.543466567993164, Time 0.07897210121154785, Overall 0.08111071586608887 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 0.7966745039995979, Time 0.07906270027160645, Overall 0.08120107650756836 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 10.917153358459473, Time 0.08231353759765625, Overall 0.08445215225219727 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 1.2130170398288302, Time 0.08240294456481934, Overall 0.08454060554504395 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 17.589384078979492, Time 0.08882832527160645, Overall 0.09096646308898926 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 1.034669651704676, Time 0.08889412879943848, Overall 0.09103131294250488 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 8.745837211608887, Time 0.09120321273803711, Overall 0.09334182739257812 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 0.9717596901787652, Time 0.09131145477294922, Overall 0.09344959259033203 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 17.77884292602539, Time 0.09723138809204102, Overall 0.09937000274658203 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 1.0458142897661995, Time 0.09733104705810547, Overall 0.09946894645690918 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 9.140935897827148, Time 0.10032105445861816, Overall 0.10246014595031738 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 1.0156595442030165, Time 0.10040712356567383, Overall 0.10254526138305664 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 18.186370849609375, Time 0.11316180229187012, Overall 0.11530089378356934 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 1.0697865205652572, Time 0.11435508728027344, Overall 0.11649394035339355 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 15.474249839782715, Time 0.11823010444641113, Overall 0.12036871910095215 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 1.7193610933091905, Time 0.12185239791870117, Overall 0.12399125099182129 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 15.932472229003906, Time 0.13512706756591797, Overall 0.1372663974761963 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 0.9372042487649357, Time 0.13524436950683594, Overall 0.13738203048706055 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 12.187929153442383, Time 0.14741063117980957, Overall 0.1495494842529297 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 1.354214350382487, Time 0.14757156372070312, Overall 0.14971017837524414 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 19.43343162536621, Time 0.15485405921936035, Overall 0.15699338912963867 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 1.1431430367862476, Time 0.15494441986083984, Overall 0.15708231925964355 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 20.418760299682617, Time 0.15815067291259766, Overall 0.16028952598571777 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 2.2687511444091797, Time 0.15824365615844727, Overall 0.16038179397583008 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 16.49360466003418, Time 0.1650257110595703, Overall 0.16716456413269043 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 0.97021203882554, Time 0.16510891914367676, Overall 0.16724658012390137 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 16.367244720458984, Time 0.1681067943572998, Overall 0.17024588584899902 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 1.818582746717665, Time 0.16820764541625977, Overall 0.17034554481506348 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 6.436985015869141, Time 0.1748509407043457, Overall 0.17698955535888672 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 0.3786461774040671, Time 0.1749255657196045, Overall 0.1770634651184082 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 12.831171989440918, Time 0.1778876781463623, Overall 0.18002605438232422 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 1.4256857766045465, Time 0.17797327041625977, Overall 0.18011116981506348 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 12.266948699951172, Time 0.1844797134399414, Overall 0.18661832809448242 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 0.7215852176441866, Time 0.18456530570983887, Overall 0.18670344352722168 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 35.58440399169922, Time 0.18752813339233398, Overall 0.189666748046875 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 3.9538226657443576, Time 0.18761062622070312, Overall 0.18974852561950684 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 7.625566482543945, Time 0.19441533088684082, Overall 0.19655370712280273 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 0.4485627342672909, Time 0.19449663162231445, Overall 0.19663405418395996 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 26.74018096923828, Time 0.1976795196533203, Overall 0.19981837272644043 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 2.9711312188042536, Time 0.20740818977355957, Overall 0.2095475196838379 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 14.600028991699219, Time 0.22327041625976562, Overall 0.22540950775146484 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 0.8588252348058364, Time 0.22337126731872559, Overall 0.2255091667175293 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 22.46853256225586, Time 0.22652816772460938, Overall 0.2286672592163086 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 2.496503618028429, Time 0.2333676815032959, Overall 0.23550677299499512 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 13.877779006958008, Time 0.24509191513061523, Overall 0.24723124504089355 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 0.8163399415857652, Time 0.2532947063446045, Overall 0.2554337978363037 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 21.672000885009766, Time 0.2581779956817627, Overall 0.2603168487548828 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 2.4080000983344183, Time 0.2583189010620117, Overall 0.26045703887939453 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 21.064477920532227, Time 0.28073644638061523, Overall 0.28287553787231445 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 1.2390869365018957, Time 0.28084754943847656, Overall 0.2829854488372803 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 32.01314926147461, Time 0.2900846004486084, Overall 0.2922239303588867 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 3.5570165846082897, Time 0.2902042865753174, Overall 0.292341947555542 \n",
            "Epoch    20: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 39.01165771484375, Time 0.010544061660766602, Overall 0.30587005615234375 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 2.294803394990809, Time 0.010641813278198242, Overall 0.3059666156768799 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 13.698541641235352, Time 0.013698577880859375, Overall 0.3090243339538574 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 1.5220601823594835, Time 0.013789176940917969, Overall 0.3091139793395996 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 17.73072052001953, Time 0.020339250564575195, Overall 0.31566500663757324 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 1.042983560001149, Time 0.020428180694580078, Overall 0.3157532215118408 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 21.09904670715332, Time 0.02359604835510254, Overall 0.3189220428466797 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 2.3443385230170355, Time 0.023685693740844727, Overall 0.31901001930236816 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 33.79732894897461, Time 0.046630859375, Overall 0.34195685386657715 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 1.9880781734690947, Time 0.04674196243286133, Overall 0.34206652641296387 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 23.00370216369629, Time 0.04981851577758789, Overall 0.34514403343200684 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 2.5559669070773654, Time 0.04991865158081055, Overall 0.345242977142334 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 31.71915054321289, Time 0.0566408634185791, Overall 0.35196614265441895 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 1.865832384894876, Time 0.0567319393157959, Overall 0.35205602645874023 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 21.647552490234375, Time 0.060640573501586914, Overall 0.35596609115600586 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 2.4052836100260415, Time 0.06073260307312012, Overall 0.35605740547180176 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 31.458934783935547, Time 0.07293033599853516, Overall 0.3682563304901123 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 1.8505255755256205, Time 0.07303047180175781, Overall 0.36835479736328125 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 16.17344093322754, Time 0.07643890380859375, Overall 0.3717646598815918 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 1.7970489925808377, Time 0.07653188705444336, Overall 0.3718564510345459 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 21.895902633666992, Time 0.08342409133911133, Overall 0.3787500858306885 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 1.2879942725686466, Time 0.08352136611938477, Overall 0.3788456916809082 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 15.711454391479492, Time 0.08679866790771484, Overall 0.3821239471435547 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 1.7457171546088324, Time 0.08688950538635254, Overall 0.3822140693664551 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 17.225852966308594, Time 0.09367990493774414, Overall 0.389005184173584 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 1.013285468606388, Time 0.09376311302185059, Overall 0.3890876770019531 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 20.505477905273438, Time 0.09673714637756348, Overall 0.3920624256134033 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 2.278386433919271, Time 0.09682273864746094, Overall 0.3921473026275635 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 11.575553894042969, Time 0.1031191349029541, Overall 0.39844465255737305 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 0.680914934943704, Time 0.1031951904296875, Overall 0.39851975440979004 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 22.8320255279541, Time 0.10591793060302734, Overall 0.4012434482574463 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 2.5368917253282337, Time 0.10599994659423828, Overall 0.4013242721557617 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 15.148372650146484, Time 0.11245369911193848, Overall 0.4077787399291992 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 0.8910807441262638, Time 0.1125340461730957, Overall 0.40785861015319824 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 27.96910858154297, Time 0.11541247367858887, Overall 0.4107377529144287 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 3.1076787312825522, Time 0.11549663543701172, Overall 0.41082143783569336 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 24.934354782104492, Time 0.12182760238647461, Overall 0.41715312004089355 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 1.4667267518884994, Time 0.12190747261047363, Overall 0.41723155975341797 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 25.725738525390625, Time 0.12485265731811523, Overall 0.4201779365539551 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 2.8584153917100696, Time 0.1249382495880127, Overall 0.42026305198669434 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 16.5440616607666, Time 0.13124704360961914, Overall 0.4265727996826172 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 0.9731800976921531, Time 0.13132405281066895, Overall 0.4266488552093506 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 25.816396713256836, Time 0.13427281379699707, Overall 0.4295980930328369 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 2.868488523695204, Time 0.1343543529510498, Overall 0.42967867851257324 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 10.933533668518066, Time 0.1406567096710205, Overall 0.43598222732543945 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 0.6431490393245921, Time 0.14073562622070312, Overall 0.43606066703796387 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 24.94062614440918, Time 0.1437208652496338, Overall 0.43904614448547363 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 2.771180682712131, Time 0.14380383491516113, Overall 0.43912839889526367 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 17.77134132385254, Time 0.15033364295959473, Overall 0.4456593990325928 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 1.0453730190501493, Time 0.15040874481201172, Overall 0.44573259353637695 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 27.7435302734375, Time 0.1542372703552246, Overall 0.44956231117248535 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 3.082614474826389, Time 0.15431809425354004, Overall 0.4496424198150635 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 15.44445514678955, Time 0.1707456111907959, Overall 0.46607136726379395 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 0.9084973615758559, Time 0.17653846740722656, Overall 0.4718644618988037 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 26.507089614868164, Time 0.18119168281555176, Overall 0.4765172004699707 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 2.945232179429796, Time 0.18129515647888184, Overall 0.4766197204589844 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 8.678986549377441, Time 0.18827533721923828, Overall 0.48360109329223633 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 0.5105286205516142, Time 0.18836712837219238, Overall 0.4836916923522949 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 20.79279136657715, Time 0.1914045810699463, Overall 0.48673009872436523 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 2.3103101518419056, Time 0.1914963722229004, Overall 0.48682117462158203 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 20.18438720703125, Time 0.20854878425598145, Overall 0.5038743019104004 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 1.18731689453125, Time 0.20994853973388672, Overall 0.5052738189697266 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 29.019813537597656, Time 0.21231865882873535, Overall 0.5076441764831543 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 3.2244237263997397, Time 0.21241426467895508, Overall 0.5077388286590576 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 14.726350784301758, Time 0.21917510032653809, Overall 0.5145003795623779 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 0.8662559284883387, Time 0.21926093101501465, Overall 0.5145857334136963 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 26.67388343811035, Time 0.22224020957946777, Overall 0.5175657272338867 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 2.9637648264567056, Time 0.22232913970947266, Overall 0.5176534652709961 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 9.888810157775879, Time 0.22890639305114746, Overall 0.5242316722869873 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 0.581694715163287, Time 0.2289876937866211, Overall 0.5243120193481445 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 31.700288772583008, Time 0.2320537567138672, Overall 0.527379035949707 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 3.522254308064779, Time 0.23215317726135254, Overall 0.5274777412414551 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 19.917728424072266, Time 0.23878097534179688, Overall 0.5341064929962158 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 1.1716310837689567, Time 0.23885536193847656, Overall 0.5341796875 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 27.64093780517578, Time 0.24184918403625488, Overall 0.5371739864349365 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 3.0712153116861978, Time 0.24193835258483887, Overall 0.5372631549835205 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 17.39653968811035, Time 0.24858331680297852, Overall 0.5439085960388184 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 1.0233258640064913, Time 0.24866318702697754, Overall 0.543987512588501 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 25.235610961914062, Time 0.2517232894897461, Overall 0.5470483303070068 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 2.803956773546007, Time 0.25180673599243164, Overall 0.5471315383911133 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 39.833526611328125, Time 0.006697654724121094, Overall 0.5565426349639893 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 2.21297370062934, Time 0.006802558898925781, Overall 0.5566468238830566 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 14.265080451965332, Time 0.010136842727661133, Overall 0.5599818229675293 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 1.7831350564956665, Time 0.010227203369140625, Overall 0.5600719451904297 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 27.03237533569336, Time 0.017683982849121094, Overall 0.5675289630889893 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 1.5017986297607422, Time 0.017769336700439453, Overall 0.5676138401031494 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 13.877972602844238, Time 0.020828962326049805, Overall 0.5706744194030762 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 1.7347465753555298, Time 0.020925521850585938, Overall 0.570770263671875 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 34.163230895996094, Time 0.02794504165649414, Overall 0.5777900218963623 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 1.897957271999783, Time 0.02802586555480957, Overall 0.5778703689575195 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 11.389960289001465, Time 0.030834436416625977, Overall 0.580679178237915 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 1.423745036125183, Time 0.030929088592529297, Overall 0.5807733535766602 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 19.460546493530273, Time 0.038120269775390625, Overall 0.587965726852417 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 1.081141471862793, Time 0.03820300102233887, Overall 0.5880470275878906 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 9.32742977142334, Time 0.04083418846130371, Overall 0.590679407119751 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 1.1659287214279175, Time 0.04091811180114746, Overall 0.5907626152038574 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 25.02311134338379, Time 0.047183990478515625, Overall 0.5970292091369629 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 1.3901728524102106, Time 0.04727458953857422, Overall 0.5971190929412842 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 12.692828178405762, Time 0.05014443397521973, Overall 0.599989652633667 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 1.5866035223007202, Time 0.05023956298828125, Overall 0.6000843048095703 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 18.3701114654541, Time 0.05724358558654785, Overall 0.607088565826416 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 1.0205617480807834, Time 0.05732917785644531, Overall 0.6071734428405762 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 15.438636779785156, Time 0.05998396873474121, Overall 0.6098287105560303 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 1.9298295974731445, Time 0.06007027626037598, Overall 0.6099145412445068 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 29.105789184570312, Time 0.06670737266540527, Overall 0.6165521144866943 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 1.616988288031684, Time 0.06679415702819824, Overall 0.61663818359375 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 9.14268684387207, Time 0.06949853897094727, Overall 0.6193437576293945 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 1.1428358554840088, Time 0.0695955753326416, Overall 0.6194398403167725 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 21.94902229309082, Time 0.07626557350158691, Overall 0.6261105537414551 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 1.2193901273939345, Time 0.07634758949279785, Overall 0.6261916160583496 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 16.285934448242188, Time 0.0789797306060791, Overall 0.6288242340087891 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 2.0357418060302734, Time 0.07906508445739746, Overall 0.6289093494415283 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 22.07121467590332, Time 0.08681631088256836, Overall 0.6366612911224365 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 1.22617859310574, Time 0.08690333366394043, Overall 0.6367475986480713 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 13.723642349243164, Time 0.08966565132141113, Overall 0.6395106315612793 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 1.7154552936553955, Time 0.08974957466125488, Overall 0.6395938396453857 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 29.75107192993164, Time 0.09625983238220215, Overall 0.6461050510406494 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 1.6528373294406467, Time 0.096343994140625, Overall 0.6461880207061768 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 13.574429512023926, Time 0.09903669357299805, Overall 0.6488816738128662 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 1.6968036890029907, Time 0.09912467002868652, Overall 0.6489689350128174 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 20.292335510253906, Time 0.10556864738464355, Overall 0.6554133892059326 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 1.1273519727918837, Time 0.10564804077148438, Overall 0.6554923057556152 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 16.984228134155273, Time 0.10832786560058594, Overall 0.658172607421875 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 2.123028516769409, Time 0.10842084884643555, Overall 0.6582655906677246 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 14.872281074523926, Time 0.11510682106018066, Overall 0.6649520397186279 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 0.8262378374735514, Time 0.11519241333007812, Overall 0.6650369167327881 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 18.542652130126953, Time 0.11800742149353027, Overall 0.6678524017333984 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 2.317831516265869, Time 0.11809349060058594, Overall 0.6679377555847168 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 12.868351936340332, Time 0.12897825241088867, Overall 0.6788234710693359 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 0.7149084409077963, Time 0.12907862663269043, Overall 0.6789231300354004 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 20.975900650024414, Time 0.13204193115234375, Overall 0.6818869113922119 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 2.6219875812530518, Time 0.13213610649108887, Overall 0.6819803714752197 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 18.926834106445312, Time 0.1392076015472412, Overall 0.6890528202056885 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 1.0514907836914062, Time 0.13929224014282227, Overall 0.6891367435455322 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 18.249217987060547, Time 0.14210748672485352, Overall 0.6919522285461426 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 2.2811522483825684, Time 0.14219284057617188, Overall 0.6920371055603027 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 8.537834167480469, Time 0.15604472160339355, Overall 0.7058906555175781 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 0.4743241204155816, Time 0.1561441421508789, Overall 0.7059879302978516 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 16.220916748046875, Time 0.15889716148376465, Overall 0.7087419033050537 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 2.0276145935058594, Time 0.15899181365966797, Overall 0.7088356018066406 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 11.39267349243164, Time 0.17312073707580566, Overall 0.722966194152832 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 0.6329263051350912, Time 0.1732158660888672, Overall 0.7230596542358398 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 15.783859252929688, Time 0.1889336109161377, Overall 0.7387793064117432 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 1.972982406616211, Time 0.18905091285705566, Overall 0.7388958930969238 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 22.586193084716797, Time 0.19929170608520508, Overall 0.7491371631622314 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 1.2547885047064886, Time 0.19938158988952637, Overall 0.7492256164550781 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 13.648416519165039, Time 0.2018725872039795, Overall 0.7517173290252686 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 1.7060520648956299, Time 0.20196056365966797, Overall 0.7518045902252197 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 13.022741317749023, Time 0.2241652011871338, Overall 0.7740108966827393 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 0.7234856287638346, Time 0.22767233848571777, Overall 0.7775180339813232 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 15.730463027954102, Time 0.23067522048950195, Overall 0.7805204391479492 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 1.9663078784942627, Time 0.23077082633972168, Overall 0.7806148529052734 \n",
            "Epoch    18: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 16.776182174682617, Time 0.23990440368652344, Overall 0.7897498607635498 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 0.932010120815701, Time 0.2400059700012207, Overall 0.7898504734039307 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 28.756132125854492, Time 0.24317383766174316, Overall 0.7930185794830322 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 3.5945165157318115, Time 0.24325895309448242, Overall 0.7931032180786133 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 7.911396026611328, Time 0.2499525547027588, Overall 0.7997970581054688 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 0.43952200147840714, Time 0.250032901763916, Overall 0.7998769283294678 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 15.108732223510742, Time 0.252108097076416, Overall 0.8019523620605469 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 1.8885915279388428, Time 0.252178430557251, Overall 0.8020224571228027 \n",
            "It took 0.8029751777648926 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "It took 9.107589721679688e-05 seconds to load from the pickles.\n",
            "It took 0.00043010711669921875 seconds to load the sparse matrices.\n",
            "/content/opentf/src/mdl/fnn.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  neg_idx = torch.nonzero(torch.tensor(neg_rands), as_tuple=True)[0]\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 444.0578308105469, Time 0.024172067642211914, Overall 0.02649688720703125 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 26.12104887120864, Time 0.024288177490234375, Overall 0.026611328125 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 183.30967712402344, Time 0.03742170333862305, Overall 0.03974652290344238 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 20.36774190266927, Time 0.03757977485656738, Overall 0.03990340232849121 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 439.3744201660156, Time 0.07271385192871094, Overall 0.07503867149353027 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 25.845554127412683, Time 0.07283425331115723, Overall 0.07515764236450195 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 188.16502380371094, Time 0.08335709571838379, Overall 0.08568143844604492 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 20.907224867078995, Time 0.08347678184509277, Overall 0.0857999324798584 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 386.7190856933594, Time 0.1021122932434082, Overall 0.10443663597106934 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 22.74818151137408, Time 0.10223269462585449, Overall 0.10455584526062012 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 152.74217224121094, Time 0.11208128929138184, Overall 0.11440610885620117 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 16.97135247124566, Time 0.11221170425415039, Overall 0.11453509330749512 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 471.7853088378906, Time 0.13073039054870605, Overall 0.1330549716949463 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 27.752076990464154, Time 0.13084125518798828, Overall 0.1331641674041748 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 232.11781311035156, Time 0.14214515686035156, Overall 0.1444699764251709 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 25.790868123372395, Time 0.1422741413116455, Overall 0.14459729194641113 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 418.7845153808594, Time 0.1704564094543457, Overall 0.17278146743774414 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 24.63438325769761, Time 0.1705946922302246, Overall 0.17291760444641113 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 206.76895141601562, Time 0.1806354522705078, Overall 0.18296027183532715 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 22.974327935112846, Time 0.18076634407043457, Overall 0.1830897331237793 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 397.6075744628906, Time 0.22261285781860352, Overall 0.22493767738342285 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 23.388680850758274, Time 0.22274422645568848, Overall 0.2250669002532959 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 98.0854721069336, Time 0.2335524559020996, Overall 0.23587703704833984 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 10.898385789659288, Time 0.23369288444519043, Overall 0.23601627349853516 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 312.71258544921875, Time 0.2645130157470703, Overall 0.26685285568237305 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 18.3948579676011, Time 0.2646491527557373, Overall 0.26697230339050293 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 193.82550048828125, Time 0.2754952907562256, Overall 0.2778201103210449 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 21.53616672092014, Time 0.27564287185668945, Overall 0.2779667377471924 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 489.03302001953125, Time 0.2948603630065918, Overall 0.29718494415283203 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 28.766648236443014, Time 0.29498982429504395, Overall 0.2973134517669678 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 200.54112243652344, Time 0.3051009178161621, Overall 0.30742502212524414 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 22.282346937391495, Time 0.3052239418029785, Overall 0.30754733085632324 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 461.4981994628906, Time 0.3294563293457031, Overall 0.33178091049194336 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 27.146952909581803, Time 0.32958126068115234, Overall 0.33190441131591797 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 178.0887908935547, Time 0.3545846939086914, Overall 0.35690927505493164 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 19.787643432617188, Time 0.3547353744506836, Overall 0.3570587635040283 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 394.8896179199219, Time 0.38172173500061035, Overall 0.3840463161468506 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 23.228801054113053, Time 0.38182759284973145, Overall 0.38415074348449707 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 152.54820251464844, Time 0.390949010848999, Overall 0.39327406883239746 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 16.94980027940538, Time 0.39107322692871094, Overall 0.39339661598205566 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 323.6602783203125, Time 0.4215402603149414, Overall 0.42386484146118164 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 19.03883990119485, Time 0.4216642379760742, Overall 0.42398786544799805 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 219.97418212890625, Time 0.438704252243042, Overall 0.44102907180786133 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 24.441575792100693, Time 0.43885111808776855, Overall 0.4411747455596924 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 259.73046875, Time 0.46863865852355957, Overall 0.4709634780883789 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 15.278262867647058, Time 0.4687516689300537, Overall 0.47107505798339844 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 215.02435302734375, Time 0.4791903495788574, Overall 0.48151493072509766 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 23.89159478081597, Time 0.4793055057525635, Overall 0.4816286563873291 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 414.3712463378906, Time 0.5090107917785645, Overall 0.5113348960876465 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 24.37477919634651, Time 0.509108304977417, Overall 0.5114309787750244 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 194.34837341308594, Time 0.5301353931427002, Overall 0.5324594974517822 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 21.594263712565105, Time 0.5302748680114746, Overall 0.5325980186462402 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 284.9128112792969, Time 0.5604376792907715, Overall 0.5627703666687012 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 16.759577134076288, Time 0.5605835914611816, Overall 0.5629067420959473 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 186.376708984375, Time 0.5708599090576172, Overall 0.5731844902038574 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 20.70852322048611, Time 0.5710453987121582, Overall 0.573369026184082 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 363.0026550292969, Time 0.5946898460388184, Overall 0.5970141887664795 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 21.353097354664524, Time 0.5948066711425781, Overall 0.597130537033081 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 138.9038543701172, Time 0.6059885025024414, Overall 0.6083123683929443 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 15.433761596679688, Time 0.6060957908630371, Overall 0.6084184646606445 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 308.4321594238281, Time 0.6250956058502197, Overall 0.62742018699646 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 18.143068201401654, Time 0.6252131462097168, Overall 0.6275360584259033 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 164.6736297607422, Time 0.6364572048187256, Overall 0.6387815475463867 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 18.297069973415798, Time 0.6365959644317627, Overall 0.6389195919036865 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 345.9830017089844, Time 0.6575887203216553, Overall 0.6599130630493164 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 20.35194127699908, Time 0.6576943397521973, Overall 0.660017728805542 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 167.69879150390625, Time 0.6673789024353027, Overall 0.669703483581543 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 18.633199055989582, Time 0.6675012111663818, Overall 0.6698243618011475 \n",
            "Epoch    17: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 268.4657897949219, Time 0.6867866516113281, Overall 0.689110517501831 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 15.792105282054228, Time 0.686873197555542, Overall 0.6891956329345703 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 234.05714416503906, Time 0.6965773105621338, Overall 0.6989016532897949 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 26.006349351671005, Time 0.6966888904571533, Overall 0.699012041091919 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 373.646484375, Time 0.7169108390808105, Overall 0.7192361354827881 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 21.979204963235293, Time 0.7171018123626709, Overall 0.7194256782531738 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 169.95465087890625, Time 0.7384033203125, Overall 0.7407279014587402 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 18.88385009765625, Time 0.7385685443878174, Overall 0.7408919334411621 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 278.0062255859375, Time 0.7794404029846191, Overall 0.7817752361297607 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 16.353307387408087, Time 0.779592752456665, Overall 0.7819161415100098 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 152.7782745361328, Time 0.7950606346130371, Overall 0.7973859310150146 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 16.97536383734809, Time 0.795196533203125, Overall 0.7975199222564697 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 465.07659912109375, Time 0.01675868034362793, Overall 0.8190631866455078 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 27.357447007123163, Time 0.019385814666748047, Overall 0.8216896057128906 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 198.44020080566406, Time 0.030150175094604492, Overall 0.8324549198150635 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 22.04891120062934, Time 0.030275583267211914, Overall 0.8325791358947754 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 388.5081481933594, Time 0.05964946746826172, Overall 0.8619539737701416 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 22.853420481962317, Time 0.059764862060546875, Overall 0.8620686531066895 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 162.8468780517578, Time 0.07034826278686523, Overall 0.872652530670166 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 18.094097561306423, Time 0.07047247886657715, Overall 0.8727757930755615 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 337.01348876953125, Time 0.08931183815002441, Overall 0.8916161060333252 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 19.824322868795957, Time 0.0894172191619873, Overall 0.8917200565338135 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 167.82943725585938, Time 0.10114097595214844, Overall 0.9034454822540283 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 18.647715250651043, Time 0.10126733779907227, Overall 0.9035706520080566 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 314.2102966308594, Time 0.12393665313720703, Overall 0.9262421131134033 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 18.48295862534467, Time 0.12405180931091309, Overall 0.9263548851013184 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 179.9540252685547, Time 0.14645719528198242, Overall 0.9487719535827637 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 19.994891696506077, Time 0.14661288261413574, Overall 0.9489161968231201 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 265.60589599609375, Time 0.16658782958984375, Overall 0.9688920974731445 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 15.623876235064339, Time 0.16669726371765137, Overall 0.9690005779266357 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 177.8440399169922, Time 0.17778635025024414, Overall 0.9800915718078613 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 19.760448879665798, Time 0.17790770530700684, Overall 0.9802112579345703 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 285.5304260253906, Time 0.202955961227417, Overall 1.0052602291107178 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 16.795907413258274, Time 0.20308542251586914, Overall 1.0053889751434326 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 133.6238250732422, Time 0.21440434455871582, Overall 1.0167090892791748 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 14.847091674804688, Time 0.21456599235534668, Overall 1.0168695449829102 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 268.36602783203125, Time 0.2346792221069336, Overall 1.0369834899902344 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 15.786236931295957, Time 0.23478436470031738, Overall 1.0370872020721436 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 138.31454467773438, Time 0.24482488632202148, Overall 1.0471296310424805 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 15.368282741970486, Time 0.24494385719299316, Overall 1.0472471714019775 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 292.20928955078125, Time 0.2662923336029053, Overall 1.068596601486206 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 17.18878173828125, Time 0.26639795303344727, Overall 1.0687010288238525 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 172.33636474609375, Time 0.2758033275604248, Overall 1.0781073570251465 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 19.148484971788193, Time 0.2759122848510742, Overall 1.0782158374786377 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 261.9287109375, Time 0.29608869552612305, Overall 1.098393201828003 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 15.407571231617647, Time 0.2962055206298828, Overall 1.0985090732574463 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 163.60223388671875, Time 0.3068809509277344, Overall 1.1091852188110352 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 18.178025987413193, Time 0.30707216262817383, Overall 1.1093759536743164 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 277.6723937988281, Time 0.3244748115539551, Overall 1.1267800331115723 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 16.333670223460476, Time 0.3245985507965088, Overall 1.1269018650054932 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 207.78041076660156, Time 0.33463335037231445, Overall 1.1369373798370361 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 23.086712307400173, Time 0.3347349166870117, Overall 1.1370375156402588 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 327.6777038574219, Time 0.3628854751586914, Overall 1.1651899814605713 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 19.27515905043658, Time 0.36299943923950195, Overall 1.1653029918670654 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 206.8218536376953, Time 0.3731405735015869, Overall 1.1754448413848877 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 22.980205959743923, Time 0.37326836585998535, Overall 1.1755716800689697 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 377.64874267578125, Time 0.3922910690307617, Overall 1.1945955753326416 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 22.21463192210478, Time 0.3923985958099365, Overall 1.1947016716003418 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 153.68678283691406, Time 0.4019784927368164, Overall 1.2042827606201172 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 17.076309204101562, Time 0.4021029472351074, Overall 1.204406499862671 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 303.3511657714844, Time 0.42005228996276855, Overall 1.2223570346832275 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 17.844186221852024, Time 0.4201633930206299, Overall 1.2224664688110352 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 180.25315856933594, Time 0.43849921226501465, Overall 1.2408034801483154 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 20.028128729926216, Time 0.4386460781097412, Overall 1.2409489154815674 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 235.48985290527344, Time 0.4778110980987549, Overall 1.2801156044006348 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 13.852344288545495, Time 0.47792983055114746, Overall 1.2802331447601318 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 156.06129455566406, Time 0.48934102058410645, Overall 1.2916464805603027 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 17.34014383951823, Time 0.4894742965698242, Overall 1.2917780876159668 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 318.3157043457031, Time 0.5071408748626709, Overall 1.3094456195831299 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 18.724453196806067, Time 0.5072593688964844, Overall 1.3095626831054688 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 166.56936645507812, Time 0.5238723754882812, Overall 1.3261775970458984 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 18.507707383897568, Time 0.5240252017974854, Overall 1.3263287544250488 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 318.32012939453125, Time 0.5431058406829834, Overall 1.345409631729126 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 18.724713493795957, Time 0.5432133674621582, Overall 1.3455162048339844 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 126.9662857055664, Time 0.5584936141967773, Overall 1.360797643661499 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 14.107365078396267, Time 0.5586192607879639, Overall 1.3609223365783691 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 318.4023132324219, Time 0.5772597789764404, Overall 1.379563808441162 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 18.729547837201288, Time 0.5773634910583496, Overall 1.3796665668487549 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 194.16529846191406, Time 0.5883908271789551, Overall 1.3906950950622559 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 21.573922051323784, Time 0.5885260105133057, Overall 1.3908298015594482 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 332.21563720703125, Time 0.6090087890625, Overall 1.4113130569458008 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 19.542096306295957, Time 0.6091153621673584, Overall 1.4114184379577637 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 166.63233947753906, Time 0.6200351715087891, Overall 1.4223401546478271 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 18.51470438639323, Time 0.6201562881469727, Overall 1.4224600791931152 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 263.25689697265625, Time 0.6562271118164062, Overall 1.4585318565368652 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 15.485699821920957, Time 0.6563434600830078, Overall 1.4586470127105713 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 235.64627075195312, Time 0.666724443435669, Overall 1.4690284729003906 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 26.182918972439236, Time 0.6668515205383301, Overall 1.4691545963287354 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 304.781005859375, Time 0.6936063766479492, Overall 1.495910406112671 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 17.928294462316178, Time 0.6937253475189209, Overall 1.4960289001464844 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 194.240478515625, Time 0.7062444686889648, Overall 1.5085492134094238 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 21.582275390625, Time 0.7063806056976318, Overall 1.5086839199066162 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 351.1201171875, Time 0.020023584365844727, Overall 1.546452522277832 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 19.506673177083332, Time 0.02013421058654785, Overall 1.5465617179870605 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 148.72805786132812, Time 0.030562639236450195, Overall 1.5569915771484375 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 18.591007232666016, Time 0.030683517456054688, Overall 1.5571115016937256 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 380.013427734375, Time 0.0542147159576416, Overall 1.5806431770324707 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 21.111857096354168, Time 0.05433058738708496, Overall 1.5807583332061768 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 213.19680786132812, Time 0.06459569931030273, Overall 1.5910241603851318 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 26.649600982666016, Time 0.0647134780883789, Overall 1.5911405086517334 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 455.5800476074219, Time 0.0859839916229248, Overall 1.6124117374420166 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 25.31000264485677, Time 0.08607721328735352, Overall 1.612504005432129 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 118.19065856933594, Time 0.09571456909179688, Overall 1.622143268585205 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 14.773832321166992, Time 0.09584784507751465, Overall 1.6222751140594482 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 416.10980224609375, Time 0.12162399291992188, Overall 1.6480534076690674 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 23.117211235894096, Time 0.12174654006958008, Overall 1.648174524307251 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 180.1134033203125, Time 0.14249587059020996, Overall 1.6689250469207764 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 22.514175415039062, Time 0.14264249801635742, Overall 1.6690702438354492 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 361.49139404296875, Time 0.16135787963867188, Overall 1.6877870559692383 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 20.082855224609375, Time 0.1614854335784912, Overall 1.687913179397583 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 136.699951171875, Time 0.17856788635253906, Overall 1.7049977779388428 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 17.087493896484375, Time 0.17872381210327148, Overall 1.7051515579223633 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 393.2778625488281, Time 0.2203366756439209, Overall 1.746765375137329 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 21.848770141601562, Time 0.22047662734985352, Overall 1.746903657913208 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 193.2274627685547, Time 0.2308027744293213, Overall 1.7572314739227295 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 24.153432846069336, Time 0.23093199729919434, Overall 1.757359266281128 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 234.37515258789062, Time 0.26221799850463867, Overall 1.7886466979980469 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 13.020841810438368, Time 0.26233696937561035, Overall 1.7887647151947021 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 192.13473510742188, Time 0.27214717864990234, Overall 1.7985756397247314 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 24.016841888427734, Time 0.27226758003234863, Overall 1.7986950874328613 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 357.72442626953125, Time 0.2929091453552246, Overall 1.8193373680114746 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 19.873579237196182, Time 0.2930176258087158, Overall 1.8194446563720703 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 98.43081665039062, Time 0.31271815299987793, Overall 1.8391461372375488 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 12.303852081298828, Time 0.31284546852111816, Overall 1.8392724990844727 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 323.1580810546875, Time 0.342085599899292, Overall 1.8685142993927002 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 17.953226725260418, Time 0.34221363067626953, Overall 1.8686408996582031 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 124.89543914794922, Time 0.3512997627258301, Overall 1.8777284622192383 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 15.611929893493652, Time 0.3514363765716553, Overall 1.877863883972168 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 410.0848083496094, Time 0.37065792083740234, Overall 1.8970866203308105 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 22.782489352756077, Time 0.37076807022094727, Overall 1.89719557762146 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 166.34219360351562, Time 0.3812117576599121, Overall 1.9076404571533203 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 20.792774200439453, Time 0.3813631534576416, Overall 1.9077908992767334 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 321.18060302734375, Time 0.40259385108947754, Overall 1.929023265838623 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 17.843366834852432, Time 0.4027130603790283, Overall 1.929140329360962 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 172.16700744628906, Time 0.41361379623413086, Overall 1.94004225730896 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 21.520875930786133, Time 0.413745641708374, Overall 1.940173625946045 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 265.901123046875, Time 0.43566322326660156, Overall 1.9620921611785889 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 14.772284613715279, Time 0.43578648567199707, Overall 1.9622137546539307 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 114.57778930664062, Time 0.4460592269897461, Overall 1.9724879264831543 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 14.322223663330078, Time 0.4461836814880371, Overall 1.9726107120513916 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 310.7489929199219, Time 0.46566081047058105, Overall 1.9920895099639893 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 17.26383293999566, Time 0.46576905250549316, Overall 1.9921965599060059 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 207.89578247070312, Time 0.4756650924682617, Overall 2.00209379196167 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 25.98697280883789, Time 0.47579050064086914, Overall 2.002218246459961 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 411.0791931152344, Time 0.4950218200683594, Overall 2.0214502811431885 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 22.837732950846355, Time 0.49513959884643555, Overall 2.0215671062469482 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 166.44692993164062, Time 0.5052297115325928, Overall 2.031658172607422 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 20.805866241455078, Time 0.5053553581237793, Overall 2.031782627105713 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 264.334716796875, Time 0.5230488777160645, Overall 2.0494775772094727 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 14.685262044270834, Time 0.5231626033782959, Overall 2.0495896339416504 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 139.0541229248047, Time 0.5343255996704102, Overall 2.06075382232666 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 17.381765365600586, Time 0.534461259841919, Overall 2.0608890056610107 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 362.0979919433594, Time 0.5533685684204102, Overall 2.0797975063323975 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 20.11655510796441, Time 0.5535073280334473, Overall 2.07993483543396 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 207.94613647460938, Time 0.5638353824615479, Overall 2.090263605117798 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 25.993267059326172, Time 0.5639536380767822, Overall 2.0903818607330322 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 346.0018005371094, Time 0.583249568939209, Overall 2.109678268432617 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 19.22232225206163, Time 0.5833694934844971, Overall 2.1097970008850098 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 249.406005859375, Time 0.5931541919708252, Overall 2.119582414627075 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 31.175750732421875, Time 0.5933904647827148, Overall 2.1198179721832275 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 310.8369140625, Time 0.6152634620666504, Overall 2.1416921615600586 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 17.268717447916668, Time 0.6153819561004639, Overall 2.1418097019195557 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 154.38587951660156, Time 0.6282827854156494, Overall 2.1547110080718994 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 19.298234939575195, Time 0.6284396648406982, Overall 2.154867172241211 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 325.3382568359375, Time 0.654780387878418, Overall 2.181208848953247 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 18.07434760199653, Time 0.6548941135406494, Overall 2.181321382522583 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 158.91526794433594, Time 0.6657345294952393, Overall 2.1921627521514893 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 19.864408493041992, Time 0.6658542156219482, Overall 2.1922812461853027 \n",
            "Epoch    19: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 284.4574890136719, Time 0.6892890930175781, Overall 2.2157180309295654 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 15.803193834092882, Time 0.6894011497497559, Overall 2.2158284187316895 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 139.03341674804688, Time 0.6993052959442139, Overall 2.225733995437622 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 17.37917709350586, Time 0.6994690895080566, Overall 2.2258968353271484 \n",
            "It took 2.2284395694732666 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "It took 8.082389831542969e-05 seconds to load from the pickles.\n",
            "It took 0.000423431396484375 seconds to load the sparse matrices.\n",
            "Loading the skill embedding pickle ...\n",
            "2022-03-04 05:28:51,321 : INFO : loading Doc2Vec object from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl\n",
            "File not found! Learning skill.emb.d100.w1.dm1 embeddings from scratch ...\n",
            "Loading the skill documents pickle ...\n",
            "File not found! Generating skill documents ...\n",
            "#Documents with word type of skill have created: 31\n",
            "Saving the skill documents ...\n",
            "2022-03-04 05:28:51,385 : INFO : collecting all words and their counts\n",
            "2022-03-04 05:28:51,385 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "2022-03-04 05:28:51,386 : INFO : collected 11 word types and 31 unique tags from a corpus of 31 examples and 67 words\n",
            "2022-03-04 05:28:51,386 : INFO : Loading a fresh vocabulary\n",
            "2022-03-04 05:28:51,386 : INFO : effective_min_count=0 retains 11 unique words (100% of original 11, drops 0)\n",
            "2022-03-04 05:28:51,386 : INFO : effective_min_count=0 leaves 67 word corpus (100% of original 67, drops 0)\n",
            "2022-03-04 05:28:51,386 : INFO : deleting the raw counts dictionary of 11 items\n",
            "2022-03-04 05:28:51,386 : INFO : sample=0.001 downsamples 11 most-common words\n",
            "2022-03-04 05:28:51,386 : INFO : downsampling leaves estimated 7 word corpus (11.0% of prior 67)\n",
            "2022-03-04 05:28:51,387 : INFO : estimated required memory for 11 words and 100 dimensions: 32900 bytes\n",
            "2022-03-04 05:28:51,387 : INFO : resetting layer weights\n",
            "  0% 0/10 [00:00<?, ?it/s]2022-03-04 05:28:51,418 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,432 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,433 : INFO : EPOCH - 1 : training on 67 raw words (39 effective words) took 0.0s, 17307 effective words/s\n",
            "2022-03-04 05:28:51,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,483 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,483 : INFO : EPOCH - 2 : training on 67 raw words (37 effective words) took 0.0s, 16567 effective words/s\n",
            "2022-03-04 05:28:51,489 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,489 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,490 : INFO : EPOCH - 3 : training on 67 raw words (40 effective words) took 0.0s, 19483 effective words/s\n",
            "2022-03-04 05:28:51,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,526 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,526 : INFO : EPOCH - 4 : training on 67 raw words (36 effective words) took 0.0s, 17149 effective words/s\n",
            "2022-03-04 05:28:51,540 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,541 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,541 : INFO : EPOCH - 5 : training on 67 raw words (38 effective words) took 0.0s, 19635 effective words/s\n",
            "2022-03-04 05:28:51,541 : INFO : training on a 335 raw words (190 effective words) took 0.1s, 1635 effective words/s\n",
            "2022-03-04 05:28:51,541 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            " 10% 1/10 [00:00<00:01,  8.10it/s]2022-03-04 05:28:51,541 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,562 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,562 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,562 : INFO : EPOCH - 1 : training on 67 raw words (40 effective words) took 0.0s, 20355 effective words/s\n",
            "2022-03-04 05:28:51,604 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,604 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,604 : INFO : EPOCH - 2 : training on 67 raw words (36 effective words) took 0.0s, 17699 effective words/s\n",
            "2022-03-04 05:28:51,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,631 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,631 : INFO : EPOCH - 3 : training on 67 raw words (43 effective words) took 0.0s, 20388 effective words/s\n",
            "2022-03-04 05:28:51,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,642 : INFO : EPOCH - 4 : training on 67 raw words (40 effective words) took 0.0s, 19054 effective words/s\n",
            "2022-03-04 05:28:51,657 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,657 : INFO : EPOCH - 5 : training on 67 raw words (40 effective words) took 0.0s, 17256 effective words/s\n",
            "2022-03-04 05:28:51,657 : INFO : training on a 335 raw words (199 effective words) took 0.1s, 1717 effective words/s\n",
            "2022-03-04 05:28:51,657 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            " 20% 2/10 [00:00<00:00,  8.38it/s]2022-03-04 05:28:51,658 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,693 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,693 : INFO : EPOCH - 1 : training on 67 raw words (35 effective words) took 0.0s, 15992 effective words/s\n",
            "2022-03-04 05:28:51,698 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,699 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,699 : INFO : EPOCH - 2 : training on 67 raw words (36 effective words) took 0.0s, 16968 effective words/s\n",
            "2022-03-04 05:28:51,701 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,701 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,701 : INFO : EPOCH - 3 : training on 67 raw words (40 effective words) took 0.0s, 19277 effective words/s\n",
            "2022-03-04 05:28:51,708 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,708 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,708 : INFO : EPOCH - 4 : training on 67 raw words (37 effective words) took 0.0s, 17844 effective words/s\n",
            "2022-03-04 05:28:51,711 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,711 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,711 : INFO : EPOCH - 5 : training on 67 raw words (38 effective words) took 0.0s, 18119 effective words/s\n",
            "2022-03-04 05:28:51,712 : INFO : training on a 335 raw words (186 effective words) took 0.1s, 3463 effective words/s\n",
            "2022-03-04 05:28:51,712 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,712 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,714 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,715 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,715 : INFO : EPOCH - 1 : training on 67 raw words (41 effective words) took 0.0s, 19919 effective words/s\n",
            "2022-03-04 05:28:51,717 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,717 : INFO : EPOCH - 2 : training on 67 raw words (36 effective words) took 0.0s, 19875 effective words/s\n",
            "2022-03-04 05:28:51,724 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,724 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,724 : INFO : EPOCH - 3 : training on 67 raw words (40 effective words) took 0.0s, 19031 effective words/s\n",
            "2022-03-04 05:28:51,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,730 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,731 : INFO : EPOCH - 4 : training on 67 raw words (39 effective words) took 0.0s, 6725 effective words/s\n",
            "2022-03-04 05:28:51,734 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,735 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,735 : INFO : EPOCH - 5 : training on 67 raw words (40 effective words) took 0.0s, 21654 effective words/s\n",
            "2022-03-04 05:28:51,735 : INFO : training on a 335 raw words (196 effective words) took 0.0s, 8375 effective words/s\n",
            "2022-03-04 05:28:51,735 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,735 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,742 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,742 : INFO : EPOCH - 1 : training on 67 raw words (40 effective words) took 0.0s, 18966 effective words/s\n",
            "2022-03-04 05:28:51,746 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,746 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,746 : INFO : EPOCH - 2 : training on 67 raw words (36 effective words) took 0.0s, 19135 effective words/s\n",
            "2022-03-04 05:28:51,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,749 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,749 : INFO : EPOCH - 3 : training on 67 raw words (38 effective words) took 0.0s, 19934 effective words/s\n",
            "2022-03-04 05:28:51,751 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,751 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,751 : INFO : EPOCH - 4 : training on 67 raw words (35 effective words) took 0.0s, 19384 effective words/s\n",
            "2022-03-04 05:28:51,754 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,754 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,754 : INFO : EPOCH - 5 : training on 67 raw words (39 effective words) took 0.0s, 21053 effective words/s\n",
            "2022-03-04 05:28:51,754 : INFO : training on a 335 raw words (188 effective words) took 0.0s, 10094 effective words/s\n",
            "2022-03-04 05:28:51,754 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,754 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,757 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,757 : INFO : EPOCH - 1 : training on 67 raw words (35 effective words) took 0.0s, 18174 effective words/s\n",
            "2022-03-04 05:28:51,759 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,759 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,759 : INFO : EPOCH - 2 : training on 67 raw words (37 effective words) took 0.0s, 25325 effective words/s\n",
            "2022-03-04 05:28:51,762 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,762 : INFO : EPOCH - 3 : training on 67 raw words (37 effective words) took 0.0s, 19051 effective words/s\n",
            "2022-03-04 05:28:51,764 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,765 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,765 : INFO : EPOCH - 4 : training on 67 raw words (35 effective words) took 0.0s, 16478 effective words/s\n",
            "2022-03-04 05:28:51,767 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,770 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,770 : INFO : EPOCH - 5 : training on 67 raw words (38 effective words) took 0.0s, 8691 effective words/s\n",
            "2022-03-04 05:28:51,770 : INFO : training on a 335 raw words (182 effective words) took 0.0s, 11657 effective words/s\n",
            "2022-03-04 05:28:51,770 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            " 60% 6/10 [00:00<00:00, 20.39it/s]2022-03-04 05:28:51,770 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,772 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,773 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,773 : INFO : EPOCH - 1 : training on 67 raw words (37 effective words) took 0.0s, 22049 effective words/s\n",
            "2022-03-04 05:28:51,776 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,777 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,777 : INFO : EPOCH - 2 : training on 67 raw words (39 effective words) took 0.0s, 22959 effective words/s\n",
            "2022-03-04 05:28:51,779 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,780 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,780 : INFO : EPOCH - 3 : training on 67 raw words (37 effective words) took 0.0s, 17778 effective words/s\n",
            "2022-03-04 05:28:51,782 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,783 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,783 : INFO : EPOCH - 4 : training on 67 raw words (40 effective words) took 0.0s, 22206 effective words/s\n",
            "2022-03-04 05:28:51,790 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,790 : INFO : EPOCH - 5 : training on 67 raw words (40 effective words) took 0.0s, 10280 effective words/s\n",
            "2022-03-04 05:28:51,790 : INFO : training on a 335 raw words (193 effective words) took 0.0s, 9767 effective words/s\n",
            "2022-03-04 05:28:51,790 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,790 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,803 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,803 : INFO : EPOCH - 1 : training on 67 raw words (41 effective words) took 0.0s, 20304 effective words/s\n",
            "2022-03-04 05:28:51,811 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,812 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,812 : INFO : EPOCH - 2 : training on 67 raw words (39 effective words) took 0.0s, 17905 effective words/s\n",
            "2022-03-04 05:28:51,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,814 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,814 : INFO : EPOCH - 3 : training on 67 raw words (41 effective words) took 0.0s, 20301 effective words/s\n",
            "2022-03-04 05:28:51,817 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,817 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,817 : INFO : EPOCH - 4 : training on 67 raw words (36 effective words) took 0.0s, 17440 effective words/s\n",
            "2022-03-04 05:28:51,820 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,820 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,820 : INFO : EPOCH - 5 : training on 67 raw words (43 effective words) took 0.0s, 20817 effective words/s\n",
            "2022-03-04 05:28:51,820 : INFO : training on a 335 raw words (200 effective words) took 0.0s, 6687 effective words/s\n",
            "2022-03-04 05:28:51,820 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,820 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,823 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,823 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,823 : INFO : EPOCH - 1 : training on 67 raw words (39 effective words) took 0.0s, 18156 effective words/s\n",
            "2022-03-04 05:28:51,826 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,826 : INFO : EPOCH - 2 : training on 67 raw words (39 effective words) took 0.0s, 19794 effective words/s\n",
            "2022-03-04 05:28:51,834 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,834 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,834 : INFO : EPOCH - 3 : training on 67 raw words (39 effective words) took 0.0s, 5389 effective words/s\n",
            "2022-03-04 05:28:51,847 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,847 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,847 : INFO : EPOCH - 4 : training on 67 raw words (40 effective words) took 0.0s, 17485 effective words/s\n",
            "2022-03-04 05:28:51,850 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,850 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,850 : INFO : EPOCH - 5 : training on 67 raw words (40 effective words) took 0.0s, 19048 effective words/s\n",
            "2022-03-04 05:28:51,850 : INFO : training on a 335 raw words (197 effective words) took 0.0s, 6589 effective words/s\n",
            "2022-03-04 05:28:51,850 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:51,851 : INFO : training model with 2 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:51,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,853 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,853 : INFO : EPOCH - 1 : training on 67 raw words (41 effective words) took 0.0s, 20342 effective words/s\n",
            "2022-03-04 05:28:51,865 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,865 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,865 : INFO : EPOCH - 2 : training on 67 raw words (38 effective words) took 0.0s, 16759 effective words/s\n",
            "2022-03-04 05:28:51,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,868 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,868 : INFO : EPOCH - 3 : training on 67 raw words (35 effective words) took 0.0s, 16645 effective words/s\n",
            "2022-03-04 05:28:51,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,899 : INFO : EPOCH - 4 : training on 67 raw words (37 effective words) took 0.0s, 14820 effective words/s\n",
            "2022-03-04 05:28:51,901 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:51,902 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:51,903 : INFO : EPOCH - 5 : training on 67 raw words (35 effective words) took 0.0s, 9977 effective words/s\n",
            "2022-03-04 05:28:51,903 : INFO : training on a 335 raw words (186 effective words) took 0.1s, 3534 effective words/s\n",
            "2022-03-04 05:28:51,903 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100% 10/10 [00:00<00:00, 20.58it/s]\n",
            "Saving model for skill.emb.d100.w1.dm1 under directory ./../data/preprocessed/dblp/toy.dblp.v12.json ...\n",
            "2022-03-04 05:28:51,904 : INFO : saving Doc2Vec object under ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl, separately None\n",
            "2022-03-04 05:28:51,905 : INFO : saved ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 39.28938293457031, Time 0.2170703411102295, Overall 0.21887946128845215 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 2.311140172621783, Time 0.21718335151672363, Overall 0.21899104118347168 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 17.608112335205078, Time 0.2194974422454834, Overall 0.22130537033081055 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 1.9564569261338975, Time 0.21959948539733887, Overall 0.2214066982269287 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 34.10918426513672, Time 0.23760533332824707, Overall 0.23941421508789062 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 2.0064226038315716, Time 0.23772072792053223, Overall 0.23952817916870117 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 16.468996047973633, Time 0.24399423599243164, Overall 0.2458035945892334 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 1.829888449774848, Time 0.24413442611694336, Overall 0.2459418773651123 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 26.197040557861328, Time 0.24971747398376465, Overall 0.2515256404876709 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 1.5410023857565487, Time 0.24982953071594238, Overall 0.25163698196411133 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 19.816923141479492, Time 0.2520608901977539, Overall 0.25386905670166016 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 2.201880349053277, Time 0.2521517276763916, Overall 0.25395894050598145 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 32.29713439941406, Time 0.25724029541015625, Overall 0.2590484619140625 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 1.8998314352596508, Time 0.25733351707458496, Overall 0.2591407299041748 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 26.74020767211914, Time 0.25943660736083984, Overall 0.261244535446167 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 2.9711341857910156, Time 0.25952625274658203, Overall 0.2613332271575928 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 34.45058059692383, Time 0.2660400867462158, Overall 0.26784801483154297 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 2.0265047409955192, Time 0.26613497734069824, Overall 0.2679421901702881 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 21.350526809692383, Time 0.26845669746398926, Overall 0.2702648639678955 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 2.372280756632487, Time 0.2685585021972656, Overall 0.27036571502685547 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 29.383352279663086, Time 0.2738926410675049, Overall 0.27570080757141113 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 1.728432487039005, Time 0.27398180961608887, Overall 0.2757892608642578 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 17.27570152282715, Time 0.27605223655700684, Overall 0.2778604030609131 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 1.9195223914252386, Time 0.2761387825012207, Overall 0.27794528007507324 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 26.99698829650879, Time 0.28134799003601074, Overall 0.2831563949584961 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 1.5880581350887524, Time 0.2814371585845947, Overall 0.28324437141418457 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 20.577354431152344, Time 0.2837038040161133, Overall 0.28551173210144043 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 2.2863727145724826, Time 0.28380870819091797, Overall 0.2856159210205078 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 33.457027435302734, Time 0.2923614978790283, Overall 0.29416990280151367 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 1.968060437370749, Time 0.29246997833251953, Overall 0.2942774295806885 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 15.447563171386719, Time 0.29482340812683105, Overall 0.2966318130493164 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 1.7163959079318576, Time 0.2949404716491699, Overall 0.29674768447875977 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 24.19440269470215, Time 0.30208420753479004, Overall 0.3038921356201172 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 1.4232001585118912, Time 0.30217647552490234, Overall 0.3039839267730713 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 17.524883270263672, Time 0.30431580543518066, Overall 0.3061239719390869 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 1.9472092522515192, Time 0.3044118881225586, Overall 0.30621933937072754 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 25.123722076416016, Time 0.31137633323669434, Overall 0.3131847381591797 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 1.4778660044950598, Time 0.31241798400878906, Overall 0.3142263889312744 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 15.839691162109375, Time 0.31473374366760254, Overall 0.3165419101715088 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 1.7599656846788194, Time 0.3148312568664551, Overall 0.316638708114624 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 27.82807159423828, Time 0.3200337886810303, Overall 0.3218419551849365 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 1.6369453878963696, Time 0.3201162815093994, Overall 0.32192325592041016 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 13.623557090759277, Time 0.32224202156066895, Overall 0.324049711227417 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 1.5137285656399198, Time 0.3223421573638916, Overall 0.32414913177490234 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 33.65329360961914, Time 0.3273921012878418, Overall 0.32920026779174805 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 1.9796055064481848, Time 0.3274822235107422, Overall 0.32928967475891113 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 17.095060348510742, Time 0.32957911491394043, Overall 0.3313872814178467 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 1.899451149834527, Time 0.3296666145324707, Overall 0.33147382736206055 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 24.2404842376709, Time 0.3347444534301758, Overall 0.33655261993408203 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 1.4259108375100529, Time 0.3348386287689209, Overall 0.33664584159851074 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 18.14167022705078, Time 0.34410905838012695, Overall 0.3459179401397705 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 2.015741136338976, Time 0.34424638748168945, Overall 0.3460538387298584 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 30.325443267822266, Time 0.37453413009643555, Overall 0.3763427734375 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 1.783849603989545, Time 0.37465810775756836, Overall 0.3764650821685791 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 19.531070709228516, Time 0.3770480155944824, Overall 0.378856897354126 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 2.170118967692057, Time 0.37715768814086914, Overall 0.3789646625518799 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 25.105310440063477, Time 0.3935098648071289, Overall 0.39531850814819336 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 1.4767829670625574, Time 0.3936598300933838, Overall 0.39546728134155273 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 15.665833473205566, Time 0.39601922035217285, Overall 0.3978276252746582 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 1.7406481636895075, Time 0.3961176872253418, Overall 0.39792513847351074 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 27.28921890258789, Time 0.40863895416259766, Overall 0.4104475975036621 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 1.6052481707404642, Time 0.40874481201171875, Overall 0.4105520248413086 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 20.403976440429688, Time 0.41092371940612793, Overall 0.4127321243286133 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 2.2671084933810763, Time 0.4110236167907715, Overall 0.4128305912017822 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 25.508668899536133, Time 0.425645112991333, Overall 0.42745304107666016 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 1.5005099352668314, Time 0.42574596405029297, Overall 0.4275531768798828 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 15.518495559692383, Time 0.4309878349304199, Overall 0.4327962398529053 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 1.7242772844102647, Time 0.43110084533691406, Overall 0.432908296585083 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 29.27398681640625, Time 0.4364001750946045, Overall 0.43820810317993164 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 1.7219992244944853, Time 0.4365060329437256, Overall 0.43831348419189453 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 15.344001770019531, Time 0.4389915466308594, Overall 0.4407999515533447 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 1.7048890855577257, Time 0.4390883445739746, Overall 0.44089555740356445 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 27.60951042175293, Time 0.4443027973175049, Overall 0.44611072540283203 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 1.6240888483384077, Time 0.4443964958190918, Overall 0.44620370864868164 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 16.82895278930664, Time 0.453047513961792, Overall 0.45485639572143555 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 1.8698836432562933, Time 0.45318102836608887, Overall 0.4549891948699951 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 25.331932067871094, Time 0.46622252464294434, Overall 0.4680309295654297 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 1.4901136510512407, Time 0.46634578704833984, Overall 0.4681529998779297 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 16.208505630493164, Time 0.46881890296936035, Overall 0.4706273078918457 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 1.800945070054796, Time 0.4689362049102783, Overall 0.47074365615844727 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 37.123783111572266, Time 0.00496363639831543, Overall 0.478712797164917 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 2.183751947739545, Time 0.005049467086791992, Overall 0.47879815101623535 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 16.70228385925293, Time 0.006975412368774414, Overall 0.4807243347167969 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 1.8558093176947699, Time 0.007056236267089844, Overall 0.4808049201965332 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 30.700939178466797, Time 0.013499259948730469, Overall 0.48724842071533203 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 1.805937598733341, Time 0.013586282730102539, Overall 0.4873342514038086 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 13.250755310058594, Time 0.015560626983642578, Overall 0.48930954933166504 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 1.472306145562066, Time 0.01564311981201172, Overall 0.4893918037414551 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 27.49819564819336, Time 0.020164966583251953, Overall 0.4939141273498535 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 1.6175409204819624, Time 0.020247936248779297, Overall 0.49399614334106445 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 12.040948867797852, Time 0.022287607192993164, Overall 0.4960367679595947 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 1.3378832075330946, Time 0.022385358810424805, Overall 0.49613356590270996 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 29.84539794921875, Time 0.027250051498413086, Overall 0.5009994506835938 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 1.7556116440716911, Time 0.02734994888305664, Overall 0.5010983943939209 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 19.82787322998047, Time 0.029479026794433594, Overall 0.5032281875610352 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 2.2030970255533853, Time 0.0295717716217041, Overall 0.5033204555511475 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 33.587711334228516, Time 0.03460073471069336, Overall 0.5083498954772949 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 1.975747725542854, Time 0.03468966484069824, Overall 0.5084383487701416 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 12.740323066711426, Time 0.03732705116271973, Overall 0.5110762119293213 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 1.4155914518568251, Time 0.0374143123626709, Overall 0.511162519454956 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 28.246456146240234, Time 0.042455196380615234, Overall 0.5162043571472168 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 1.6615562438964844, Time 0.04254269599914551, Overall 0.5162911415100098 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 17.752071380615234, Time 0.04454231262207031, Overall 0.5182914733886719 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 1.972452375623915, Time 0.044631242752075195, Overall 0.5183796882629395 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 27.827817916870117, Time 0.049546003341674805, Overall 0.5232954025268555 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 1.6369304656982422, Time 0.04963088035583496, Overall 0.5233793258666992 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 10.741201400756836, Time 0.05757713317871094, Overall 0.5313270092010498 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 1.1934668223063152, Time 0.05768704414367676, Overall 0.5314357280731201 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 30.686832427978516, Time 0.06330227851867676, Overall 0.5370519161224365 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 1.8051077898810892, Time 0.06339859962463379, Overall 0.537146806716919 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 15.088050842285156, Time 0.06560540199279785, Overall 0.5393548011779785 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 1.6764500935872395, Time 0.06569361686706543, Overall 0.5394415855407715 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 24.01816177368164, Time 0.07074093818664551, Overall 0.5444900989532471 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 1.4128330455106848, Time 0.07084250450134277, Overall 0.5445914268493652 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 15.72756290435791, Time 0.07305097579956055, Overall 0.5468001365661621 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 1.7475069893731012, Time 0.07313919067382812, Overall 0.5468878746032715 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 25.323312759399414, Time 0.07821941375732422, Overall 0.5519688129425049 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 1.489606632905848, Time 0.0783071517944336, Overall 0.5520634651184082 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 19.48696517944336, Time 0.08045792579650879, Overall 0.5542070865631104 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 2.1652183532714844, Time 0.0805504322052002, Overall 0.5542991161346436 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 26.932004928588867, Time 0.10464835166931152, Overall 0.5783984661102295 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 1.5842355840346392, Time 0.104766845703125, Overall 0.5785155296325684 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 19.629817962646484, Time 0.11407756805419922, Overall 0.5878276824951172 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 2.181090884738498, Time 0.1141974925994873, Overall 0.5879456996917725 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 31.3636417388916, Time 0.12899136543273926, Overall 0.6027412414550781 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 1.8449201022877413, Time 0.1291038990020752, Overall 0.6028525829315186 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 15.630915641784668, Time 0.13140344619750977, Overall 0.6051530838012695 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 1.736768404642741, Time 0.131500244140625, Overall 0.6052486896514893 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 25.807598114013672, Time 0.15452814102172852, Overall 0.6282782554626465 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 1.5180940067066866, Time 0.15466046333312988, Overall 0.6284093856811523 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 15.223583221435547, Time 0.15952396392822266, Overall 0.6332736015319824 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 1.6915092468261719, Time 0.1596364974975586, Overall 0.633385419845581 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 27.435461044311523, Time 0.17031359672546387, Overall 0.6440632343292236 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 1.6138506496653837, Time 0.17708992958068848, Overall 0.6508400440216064 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 15.826635360717773, Time 0.17958378791809082, Overall 0.6533331871032715 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 1.7585150400797527, Time 0.17968249320983887, Overall 0.653430700302124 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 24.883529663085938, Time 0.185028076171875, Overall 0.6587774753570557 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 1.4637370390050553, Time 0.19157862663269043, Overall 0.6653282642364502 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 17.12472915649414, Time 0.19396519660949707, Overall 0.6677145957946777 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 1.9027476840549045, Time 0.19405674934387207, Overall 0.6678054332733154 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 23.546066284179688, Time 0.2174997329711914, Overall 0.6912493705749512 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 1.3850627225988053, Time 0.21849894523620605, Overall 0.6922485828399658 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 15.08640193939209, Time 0.22079896926879883, Overall 0.6945483684539795 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 1.6762668821546767, Time 0.2209017276763916, Overall 0.694650411605835 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 24.989303588867188, Time 0.22626662254333496, Overall 0.7000160217285156 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 1.4699590346392464, Time 0.2263636589050293, Overall 0.7001123428344727 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 19.7445011138916, Time 0.22868776321411133, Overall 0.7024374008178711 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 2.1938334570990667, Time 0.23378896713256836, Overall 0.707538366317749 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 27.377788543701172, Time 0.23921418190002441, Overall 0.7129635810852051 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 1.6104581496294808, Time 0.23931026458740234, Overall 0.7130587100982666 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 16.74555015563965, Time 0.24164795875549316, Overall 0.7153971195220947 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 1.860616683959961, Time 0.24174165725708008, Overall 0.7154905796051025 \n",
            "Epoch    18: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 28.749893188476562, Time 0.24774384498596191, Overall 0.7214932441711426 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 1.6911701875574447, Time 0.24784588813781738, Overall 0.7215943336486816 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 16.558860778808594, Time 0.25008583068847656, Overall 0.7238349914550781 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 1.8398734198676214, Time 0.2501797676086426, Overall 0.7239282131195068 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 18.338594436645508, Time 0.2554020881652832, Overall 0.7291514873504639 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 1.0787408492144417, Time 0.2554900646209717, Overall 0.7292385101318359 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 16.535921096801758, Time 0.25766682624816895, Overall 0.7314159870147705 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 1.8373245663113065, Time 0.25775623321533203, Overall 0.7315051555633545 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 39.133277893066406, Time 0.0044651031494140625, Overall 0.73897385597229 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 2.1740709940592446, Time 0.004547595977783203, Overall 0.7390551567077637 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 16.10224151611328, Time 0.006380558013916016, Overall 0.7408890724182129 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 2.01278018951416, Time 0.006469249725341797, Overall 0.7409765720367432 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 34.60878372192383, Time 0.011851072311401367, Overall 0.7463595867156982 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 1.922710206773546, Time 0.011929035186767578, Overall 0.746436595916748 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 15.243721961975098, Time 0.013697385787963867, Overall 0.7482054233551025 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 1.9054652452468872, Time 0.013788700103759766, Overall 0.7482964992523193 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 26.112159729003906, Time 0.019015789031982422, Overall 0.7535245418548584 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 1.450675540500217, Time 0.019108295440673828, Overall 0.7536163330078125 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 17.622987747192383, Time 0.02115321159362793, Overall 0.7556614875793457 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 2.202873468399048, Time 0.021262645721435547, Overall 0.7557699680328369 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 35.02808380126953, Time 0.026375293731689453, Overall 0.7608835697174072 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 1.946004655626085, Time 0.02645587921142578, Overall 0.7609632015228271 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 22.866439819335938, Time 0.028368234634399414, Overall 0.7628767490386963 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 2.858304977416992, Time 0.028454065322875977, Overall 0.7629618644714355 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 31.09764862060547, Time 0.03399181365966797, Overall 0.7685000896453857 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 1.7276471455891926, Time 0.03409075736999512, Overall 0.7685983180999756 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 17.40577507019043, Time 0.047425270080566406, Overall 0.7819347381591797 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 2.1757218837738037, Time 0.047559261322021484, Overall 0.782066822052002 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 28.3808650970459, Time 0.056626081466674805, Overall 0.7911357879638672 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 1.576714727613661, Time 0.06334805488586426, Overall 0.7978572845458984 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 17.41816520690918, Time 0.06592679023742676, Overall 0.8004350662231445 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 2.1772706508636475, Time 0.06603860855102539, Overall 0.8005461692810059 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 33.740840911865234, Time 0.07410836219787598, Overall 0.808617353439331 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 1.8744911617702908, Time 0.08031606674194336, Overall 0.8148248195648193 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 19.775989532470703, Time 0.08283019065856934, Overall 0.8173391819000244 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 2.471998691558838, Time 0.08293581008911133, Overall 0.8174436092376709 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 25.513078689575195, Time 0.10772156715393066, Overall 0.8422307968139648 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 1.4173932605319552, Time 0.1078345775604248, Overall 0.8423421382904053 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 18.36115074157715, Time 0.10987281799316406, Overall 0.84438157081604 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 2.2951438426971436, Time 0.1099705696105957, Overall 0.844477653503418 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 23.880020141601562, Time 0.11518430709838867, Overall 0.849693775177002 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 1.3266677856445312, Time 0.11527633666992188, Overall 0.8497841358184814 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 17.85411834716797, Time 0.11716794967651367, Overall 0.851693868637085 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 2.231764793395996, Time 0.11727762222290039, Overall 0.8517851829528809 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 26.8709659576416, Time 0.1224665641784668, Overall 0.8569746017456055 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 1.4928314420912001, Time 0.1225595474243164, Overall 0.8570666313171387 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 21.225614547729492, Time 0.12469005584716797, Overall 0.8591985702514648 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 2.6532018184661865, Time 0.1247866153717041, Overall 0.8592941761016846 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 28.720924377441406, Time 0.1302030086517334, Overall 0.8647110462188721 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 1.5956069098578558, Time 0.13029050827026367, Overall 0.8647980690002441 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 19.05063247680664, Time 0.13225340843200684, Overall 0.8667619228363037 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 2.38132905960083, Time 0.13234257698059082, Overall 0.8668498992919922 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 28.53203582763672, Time 0.13874578475952148, Overall 0.8732542991638184 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 1.5851131015353732, Time 0.13884186744689941, Overall 0.8733494281768799 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 13.546672821044922, Time 0.14090275764465332, Overall 0.8754105567932129 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 1.6933341026306152, Time 0.14099454879760742, Overall 0.8755025863647461 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 20.821565628051758, Time 0.1461174488067627, Overall 0.8806262016296387 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 1.1567536460028753, Time 0.14622163772583008, Overall 0.8807296752929688 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 17.680110931396484, Time 0.14820170402526855, Overall 0.8827102184295654 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 2.2100138664245605, Time 0.1482851505279541, Overall 0.8827927112579346 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 23.0064697265625, Time 0.15332722663879395, Overall 0.8878359794616699 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 1.27813720703125, Time 0.15341997146606445, Overall 0.8879275321960449 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 21.719863891601562, Time 0.15553665161132812, Overall 0.8900454044342041 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 2.7149829864501953, Time 0.15563154220581055, Overall 0.8901395797729492 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 21.658710479736328, Time 0.16079378128051758, Overall 0.8953022956848145 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 1.2032616933186848, Time 0.16087961196899414, Overall 0.8953871726989746 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 19.457012176513672, Time 0.162750244140625, Overall 0.897258996963501 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 2.432126522064209, Time 0.16283607482910156, Overall 0.8973431587219238 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 30.220840454101562, Time 0.18200039863586426, Overall 0.9165093898773193 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 1.67893558078342, Time 0.18350720405578613, Overall 0.9180161952972412 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 15.627473831176758, Time 0.1858506202697754, Overall 0.9203591346740723 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 1.9534342288970947, Time 0.1859447956085205, Overall 0.920452356338501 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 33.30281066894531, Time 0.1933128833770752, Overall 0.927821159362793 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 1.8501561482747395, Time 0.19339728355407715, Overall 0.9279050827026367 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 16.826139450073242, Time 0.19549822807312012, Overall 0.930006742477417 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 2.1032674312591553, Time 0.19559216499328613, Overall 0.9300994873046875 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 28.615325927734375, Time 0.2077035903930664, Overall 0.9422121047973633 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 1.5897403293185763, Time 0.20780348777770996, Overall 0.9423108100891113 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 25.50934410095215, Time 0.20981311798095703, Overall 0.9443213939666748 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 3.1886680126190186, Time 0.20990896224975586, Overall 0.9444165229797363 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 28.423120498657227, Time 0.21564602851867676, Overall 0.9501545429229736 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 1.5790622499254015, Time 0.21573710441589355, Overall 0.950244665145874 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 19.528335571289062, Time 0.21800732612609863, Overall 0.9525158405303955 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 2.441041946411133, Time 0.2181262969970703, Overall 0.952634334564209 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 26.901384353637695, Time 0.22394466400146484, Overall 0.9584534168243408 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 1.494521352979872, Time 0.2240438461303711, Overall 0.9585514068603516 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 17.908519744873047, Time 0.2260138988494873, Overall 0.9605224132537842 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 2.238564968109131, Time 0.22611331939697266, Overall 0.9606211185455322 \n",
            "It took 0.9620282649993896 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
            "It took 6.723403930664062e-05 seconds to load from the pickles.\n",
            "It took 0.0003409385681152344 seconds to load the sparse matrices.\n",
            "Loading the skill embedding pickle ...\n",
            "2022-03-04 05:28:53,864 : INFO : loading Doc2Vec object from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl\n",
            "2022-03-04 05:28:53,865 : INFO : loading vocabulary recursively from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl.vocabulary.* with mmap=None\n",
            "2022-03-04 05:28:53,866 : INFO : loading trainables recursively from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl.trainables.* with mmap=None\n",
            "2022-03-04 05:28:53,866 : INFO : loading wv recursively from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl.wv.* with mmap=None\n",
            "2022-03-04 05:28:53,866 : INFO : loading docvecs recursively from ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl.docvecs.* with mmap=None\n",
            "2022-03-04 05:28:53,866 : INFO : loaded ./../data/preprocessed/dblp/toy.dblp.v12.json/skill.emb.d100.w1.dm1.mdl\n",
            "/content/opentf/src/mdl/fnn.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  neg_idx = torch.nonzero(torch.tensor(neg_rands), as_tuple=True)[0]\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 324.1528015136719, Time 0.01065683364868164, Overall 0.012133598327636719 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 19.067811853745404, Time 0.010750293731689453, Overall 0.012225866317749023 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 197.55870056152344, Time 0.0169069766998291, Overall 0.018383502960205078 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 21.95096672905816, Time 0.017017364501953125, Overall 0.018493175506591797 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 377.5923156738281, Time 0.03297924995422363, Overall 0.03445577621459961 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 22.211312686695774, Time 0.033074378967285156, Overall 0.03455018997192383 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 131.8585968017578, Time 0.03943967819213867, Overall 0.04091596603393555 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 14.650955200195312, Time 0.039551496505737305, Overall 0.041027069091796875 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 400.5333251953125, Time 0.05060076713562012, Overall 0.052077293395996094 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 23.560783835018384, Time 0.050689697265625, Overall 0.05216550827026367 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 206.6090850830078, Time 0.05689501762390137, Overall 0.05837225914001465 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 22.95656500922309, Time 0.056989192962646484, Overall 0.058464765548706055 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 336.90313720703125, Time 0.06826400756835938, Overall 0.06974053382873535 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 19.8178316004136, Time 0.06837940216064453, Overall 0.0698549747467041 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 141.1392822265625, Time 0.07451677322387695, Overall 0.07599306106567383 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 15.682142469618055, Time 0.07462286949157715, Overall 0.07609868049621582 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 293.9031982421875, Time 0.08626937866210938, Overall 0.08774614334106445 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 17.28842342601103, Time 0.08637166023254395, Overall 0.08784723281860352 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 195.20584106445312, Time 0.09265446662902832, Overall 0.0941309928894043 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 21.689537896050346, Time 0.09277629852294922, Overall 0.09425210952758789 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 290.79083251953125, Time 0.10793471336364746, Overall 0.10941123962402344 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 17.105343089384192, Time 0.10805034637451172, Overall 0.1095266342163086 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 143.0269775390625, Time 0.11934971809387207, Overall 0.12082767486572266 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 15.891886393229166, Time 0.11948037147521973, Overall 0.1209564208984375 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 251.04562377929688, Time 0.13424372673034668, Overall 0.13572049140930176 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 14.767389634076286, Time 0.13434910774230957, Overall 0.13582468032836914 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 134.62142944335938, Time 0.1407334804534912, Overall 0.14220976829528809 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 14.957936604817709, Time 0.14084792137145996, Overall 0.14232349395751953 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 361.12115478515625, Time 0.15233087539672852, Overall 0.1538076400756836 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 21.242420869715072, Time 0.15243172645568848, Overall 0.15390753746032715 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 163.350341796875, Time 0.15863776206970215, Overall 0.16011428833007812 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 18.150037977430557, Time 0.15874409675598145, Overall 0.16021943092346191 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 186.6538543701172, Time 0.1701366901397705, Overall 0.17161321640014648 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 10.979638492359834, Time 0.17023706436157227, Overall 0.17171263694763184 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 180.49856567382812, Time 0.17638683319091797, Overall 0.17786312103271484 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 20.055396185980904, Time 0.17650961875915527, Overall 0.17798566818237305 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 317.1058044433594, Time 0.18766117095947266, Overall 0.18913769721984863 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 18.65328261431526, Time 0.18774890899658203, Overall 0.1892251968383789 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 180.5802764892578, Time 0.19379687309265137, Overall 0.19527292251586914 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 20.06447516547309, Time 0.193892240524292, Overall 0.19536805152893066 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 235.07386779785156, Time 0.20614385604858398, Overall 0.20762038230895996 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 13.82787457634421, Time 0.20623135566711426, Overall 0.20770692825317383 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 188.59988403320312, Time 0.2125861644744873, Overall 0.21406245231628418 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 20.955542670355904, Time 0.2126765251159668, Overall 0.21415233612060547 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 415.20697021484375, Time 0.22396564483642578, Overall 0.22544217109680176 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 24.423939424402572, Time 0.2240581512451172, Overall 0.22553348541259766 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 108.49039459228516, Time 0.23016667366027832, Overall 0.2316431999206543 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 12.054488288031685, Time 0.2302720546722412, Overall 0.23174738883972168 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 291.1599426269531, Time 0.241363525390625, Overall 0.24283957481384277 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 17.127055448644303, Time 0.241469144821167, Overall 0.24294471740722656 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 227.7084197998047, Time 0.24750995635986328, Overall 0.24898648262023926 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 25.30093553331163, Time 0.24760937690734863, Overall 0.2490849494934082 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 207.09613037109375, Time 0.25873804092407227, Overall 0.26021480560302734 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 12.182125315946692, Time 0.2588376998901367, Overall 0.2603135108947754 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 92.94046020507812, Time 0.26518964767456055, Overall 0.2666664123535156 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 10.326717800564236, Time 0.2653036117553711, Overall 0.26677918434143066 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 225.8187713623047, Time 0.2768893241882324, Overall 0.2783658504486084 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 13.283457138959099, Time 0.2769956588745117, Overall 0.2784714698791504 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 277.89532470703125, Time 0.2834029197692871, Overall 0.2848794460296631 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 30.87725830078125, Time 0.283538818359375, Overall 0.2850148677825928 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 260.0650634765625, Time 0.29481983184814453, Overall 0.2962963581085205 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 15.297944910386029, Time 0.2949202060699463, Overall 0.29639554023742676 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 220.3164825439453, Time 0.3011152744293213, Overall 0.30259203910827637 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 24.47960917154948, Time 0.3012220859527588, Overall 0.30269789695739746 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 412.61773681640625, Time 0.3123610019683838, Overall 0.31383705139160156 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 24.271631577435663, Time 0.31246232986450195, Overall 0.3139379024505615 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 195.1291961669922, Time 0.31851911544799805, Overall 0.3199954032897949 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 21.681021796332466, Time 0.3186171054840088, Overall 0.32009243965148926 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 296.8972473144531, Time 0.3336753845214844, Overall 0.33515286445617676 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 17.464543959673712, Time 0.33377814292907715, Overall 0.335254430770874 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 128.17813110351562, Time 0.3412761688232422, Overall 0.34275245666503906 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 14.242014567057291, Time 0.34137701988220215, Overall 0.3428528308868408 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 405.9588623046875, Time 0.3523521423339844, Overall 0.35382843017578125 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 23.879933076746322, Time 0.35244107246398926, Overall 0.3539164066314697 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 133.3762664794922, Time 0.35836172103881836, Overall 0.35983824729919434 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 14.819585164388021, Time 0.35845494270324707, Overall 0.3599374294281006 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 428.80364990234375, Time 0.36977219581604004, Overall 0.371248722076416 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 25.223744111902572, Time 0.36986327171325684, Overall 0.3713390827178955 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 264.41021728515625, Time 0.3758842945098877, Overall 0.37736034393310547 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 29.37891303168403, Time 0.37598252296447754, Overall 0.3774583339691162 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 253.13780212402344, Time 0.010341882705688477, Overall 0.3907918930053711 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 14.890458948471966, Time 0.010436058044433594, Overall 0.3908853530883789 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 122.18386840820312, Time 0.016543149948120117, Overall 0.39699363708496094 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 13.575985378689236, Time 0.01663994789123535, Overall 0.39708900451660156 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 221.7301483154297, Time 0.02781200408935547, Overall 0.4082624912261963 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 13.04294990090763, Time 0.02791118621826172, Overall 0.40836048126220703 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 206.91256713867188, Time 0.03456306457519531, Overall 0.41501450538635254 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 22.990285237630207, Time 0.034676313400268555, Overall 0.4151265621185303 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 376.6322021484375, Time 0.04876279830932617, Overall 0.429213285446167 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 22.154835420496322, Time 0.04885387420654297, Overall 0.4293034076690674 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 200.1957550048828, Time 0.054960012435913086, Overall 0.4354104995727539 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 22.243972778320312, Time 0.05506587028503418, Overall 0.4355154037475586 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 237.10154724121094, Time 0.06634688377380371, Overall 0.44679713249206543 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 13.94714983771829, Time 0.06644868850708008, Overall 0.4468979835510254 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 133.74107360839844, Time 0.07258033752441406, Overall 0.4530303478240967 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 14.860119289822048, Time 0.07268500328063965, Overall 0.45313429832458496 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 360.64520263671875, Time 0.08400106430053711, Overall 0.4644510746002197 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 21.214423684512866, Time 0.08409833908081055, Overall 0.46454763412475586 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 164.412841796875, Time 0.09020161628723145, Overall 0.47065162658691406 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 18.26809353298611, Time 0.09030437469482422, Overall 0.47075414657592773 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 331.41455078125, Time 0.10131311416625977, Overall 0.4817633628845215 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 19.49497357536765, Time 0.10140633583068848, Overall 0.4818558692932129 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 132.71542358398438, Time 0.10768580436706543, Overall 0.48813652992248535 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 14.746158175998264, Time 0.10778594017028809, Overall 0.4882352352142334 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 454.1573791503906, Time 0.11887359619140625, Overall 0.49932336807250977 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 26.715139950022976, Time 0.11897110939025879, Overall 0.4994204044342041 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 181.98793029785156, Time 0.12511634826660156, Overall 0.5055665969848633 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 20.22088114420573, Time 0.12521815299987793, Overall 0.5056676864624023 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 429.8935852050781, Time 0.13625621795654297, Overall 0.5167059898376465 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 25.28785795323989, Time 0.13634777069091797, Overall 0.5167973041534424 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 139.7830047607422, Time 0.14231204986572266, Overall 0.5227622985839844 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 15.531444973415798, Time 0.14240360260009766, Overall 0.522852897644043 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 297.4884033203125, Time 0.15359091758728027, Overall 0.534041166305542 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 17.499317842371322, Time 0.1536731719970703, Overall 0.5341224670410156 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 151.39764404296875, Time 0.15947461128234863, Overall 0.5399243831634521 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 16.82196044921875, Time 0.15958571434020996, Overall 0.5400354862213135 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 526.1587524414062, Time 0.17034435272216797, Overall 0.5507943630218506 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 30.950514849494486, Time 0.17042994499206543, Overall 0.5508794784545898 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 189.15927124023438, Time 0.17630839347839355, Overall 0.5567584037780762 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 21.017696804470486, Time 0.17639684677124023, Overall 0.5568466186523438 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 310.2640380859375, Time 0.18725848197937012, Overall 0.5677084922790527 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 18.25082576976103, Time 0.1873457431793213, Overall 0.5677952766418457 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 199.37289428710938, Time 0.19318795204162598, Overall 0.5736382007598877 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 22.152543809678818, Time 0.19328022003173828, Overall 0.5737297534942627 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 379.3507385253906, Time 0.20415902137756348, Overall 0.584608793258667 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 22.314749325022976, Time 0.2042536735534668, Overall 0.5847032070159912 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 146.3191680908203, Time 0.21046090126037598, Overall 0.5909111499786377 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 16.25768534342448, Time 0.21058320999145508, Overall 0.5910332202911377 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 298.45623779296875, Time 0.22343039512634277, Overall 0.6038804054260254 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 17.556249281939337, Time 0.2235422134399414, Overall 0.6039915084838867 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 230.83779907226562, Time 0.22969532012939453, Overall 0.6101455688476562 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 25.648644341362846, Time 0.2297956943511963, Overall 0.6102452278137207 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 381.82305908203125, Time 0.24084258079528809, Overall 0.6212928295135498 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 22.460179946001837, Time 0.24093270301818848, Overall 0.6213822364807129 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 182.1325225830078, Time 0.24781584739685059, Overall 0.6282670497894287 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 20.236946953667534, Time 0.2479093074798584, Overall 0.628359317779541 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 223.90679931640625, Time 0.2645692825317383, Overall 0.6450197696685791 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 13.170988195082721, Time 0.26465845108032227, Overall 0.6451077461242676 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 246.8092803955078, Time 0.2707390785217285, Overall 0.6511890888214111 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 27.423253377278645, Time 0.27083539962768555, Overall 0.6512846946716309 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 355.9542541503906, Time 0.2816758155822754, Overall 0.6621255874633789 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 20.938485538258274, Time 0.28175926208496094, Overall 0.6622087955474854 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 250.3579864501953, Time 0.2877674102783203, Overall 0.6682181358337402 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 27.817554050021702, Time 0.28786754608154297, Overall 0.6683175563812256 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 297.734375, Time 0.29891467094421387, Overall 0.6793649196624756 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 17.513786764705884, Time 0.29900383949279785, Overall 0.6794538497924805 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 202.0998077392578, Time 0.3049187660217285, Overall 0.685368537902832 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 22.45553419325087, Time 0.30501246452331543, Overall 0.6854619979858398 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 330.1881408691406, Time 0.3158681392669678, Overall 0.6963176727294922 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 19.422831815831803, Time 0.31595563888549805, Overall 0.6964046955108643 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 154.3441162109375, Time 0.3219766616821289, Overall 0.7024266719818115 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 17.14934624565972, Time 0.3220639228820801, Overall 0.7025132179260254 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 287.2308349609375, Time 0.3330080509185791, Overall 0.7134580612182617 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 16.895931468290442, Time 0.3330965042114258, Overall 0.7135457992553711 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 191.9844970703125, Time 0.339261531829834, Overall 0.7197117805480957 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 21.33161078559028, Time 0.3393571376800537, Overall 0.719806432723999 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 277.53436279296875, Time 0.3518366813659668, Overall 0.7322866916656494 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 16.325550752527572, Time 0.3519282341003418, Overall 0.7323777675628662 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 182.06211853027344, Time 0.359544038772583, Overall 0.739995002746582 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 20.229124281141495, Time 0.3596363067626953, Overall 0.7400858402252197 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 451.2745056152344, Time 0.010155439376831055, Overall 0.753138542175293 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 25.07080586751302, Time 0.010239601135253906, Overall 0.7532219886779785 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 164.009033203125, Time 0.015947341918945312, Overall 0.7589302062988281 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 20.501129150390625, Time 0.016058921813964844, Overall 0.7590410709381104 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 340.316650390625, Time 0.02680492401123047, Overall 0.7697880268096924 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 18.906480577256943, Time 0.026908159255981445, Overall 0.7698900699615479 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 122.51885223388672, Time 0.03279685974121094, Overall 0.7757794857025146 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 15.31485652923584, Time 0.03288841247558594, Overall 0.7758705615997314 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 306.09185791015625, Time 0.04382467269897461, Overall 0.7868075370788574 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 17.005103217230904, Time 0.04391193389892578, Overall 0.7868938446044922 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 180.60379028320312, Time 0.04974722862243652, Overall 0.7927296161651611 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 22.57547378540039, Time 0.049839019775390625, Overall 0.7928214073181152 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 341.3136901855469, Time 0.06084084510803223, Overall 0.803823709487915 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 18.961871676974827, Time 0.060927391052246094, Overall 0.8039095401763916 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 121.51146697998047, Time 0.06659197807312012, Overall 0.8095743656158447 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 15.188933372497559, Time 0.06668424606323242, Overall 0.809666633605957 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 302.5458984375, Time 0.07765913009643555, Overall 0.8206417560577393 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 16.80810546875, Time 0.0777437686920166, Overall 0.8207263946533203 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 187.67433166503906, Time 0.0834496021270752, Overall 0.8264319896697998 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 23.459291458129883, Time 0.08353686332702637, Overall 0.8265185356140137 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 415.2032775878906, Time 0.09484648704528809, Overall 0.8378291130065918 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 23.066848754882812, Time 0.09493446350097656, Overall 0.837916374206543 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 162.9917449951172, Time 0.10062885284423828, Overall 0.8436117172241211 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 20.37396812438965, Time 0.10072207450866699, Overall 0.8437042236328125 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 367.9454345703125, Time 0.11170625686645508, Overall 0.854689359664917 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 20.44141303168403, Time 0.11179041862487793, Overall 0.8547725677490234 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 167.7412567138672, Time 0.11788272857666016, Overall 0.8608660697937012 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 20.9676570892334, Time 0.11799502372741699, Overall 0.8609774112701416 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 320.9735412597656, Time 0.13024353981018066, Overall 0.8732266426086426 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 17.831863403320312, Time 0.13033485412597656, Overall 0.8733172416687012 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 177.60572814941406, Time 0.13605189323425293, Overall 0.8790347576141357 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 22.200716018676758, Time 0.13614320755004883, Overall 0.8791253566741943 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 348.7560119628906, Time 0.1473391056060791, Overall 0.8903219699859619 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 19.37533399793837, Time 0.14742732048034668, Overall 0.8904092311859131 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 233.74215698242188, Time 0.1531820297241211, Overall 0.8961646556854248 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 29.217769622802734, Time 0.1532740592956543, Overall 0.8962557315826416 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 412.3738708496094, Time 0.16446757316589355, Overall 0.9074504375457764 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 22.909659491644966, Time 0.16455793380737305, Overall 0.9075403213500977 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 196.48289489746094, Time 0.1704404354095459, Overall 0.9134230613708496 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 24.560361862182617, Time 0.1705493927001953, Overall 0.9135315418243408 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 386.8630065917969, Time 0.18188142776489258, Overall 0.9248645305633545 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 21.492389255099827, Time 0.1819934844970703, Overall 0.9249758720397949 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 211.52268981933594, Time 0.1895456314086914, Overall 0.9325292110443115 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 26.440336227416992, Time 0.1896533966064453, Overall 0.9326364994049072 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 395.6923828125, Time 0.20610499382019043, Overall 0.9490883350372314 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 21.98291015625, Time 0.20619773864746094, Overall 0.9491796493530273 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 210.5931854248047, Time 0.21214532852172852, Overall 0.9551281929016113 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 26.324148178100586, Time 0.21224379539489746, Overall 0.955225944519043 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 325.7163391113281, Time 0.2240896224975586, Overall 0.9670727252960205 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 18.095352172851562, Time 0.2241816520690918, Overall 0.9671638011932373 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 163.83560180664062, Time 0.23033928871154785, Overall 0.9733221530914307 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 20.479450225830078, Time 0.23044228553771973, Overall 0.9734244346618652 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 399.69915771484375, Time 0.2430109977722168, Overall 0.9859952926635742 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 22.205508761935764, Time 0.2431190013885498, Overall 0.9861016273498535 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 178.05410766601562, Time 0.2527732849121094, Overall 0.9957571029663086 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 22.256763458251953, Time 0.2529006004333496, Overall 0.9958832263946533 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 305.04620361328125, Time 0.26683759689331055, Overall 1.0098209381103516 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 16.947011311848957, Time 0.26692771911621094, Overall 1.0099101066589355 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 221.0592803955078, Time 0.2728240489959717, Overall 1.0158073902130127 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 27.632410049438477, Time 0.2729227542877197, Overall 1.0159049034118652 \n",
            "Epoch    15: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 423.1200256347656, Time 0.285463809967041, Overall 1.0284478664398193 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 23.506668090820312, Time 0.2855558395385742, Overall 1.028538465499878 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 236.1533660888672, Time 0.2929799556732178, Overall 1.0359766483306885 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 29.5191707611084, Time 0.2930893898010254, Overall 1.036071538925171 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 461.8120422363281, Time 0.30411195755004883, Overall 1.0470950603485107 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 25.656224568684895, Time 0.3041994571685791, Overall 1.0471813678741455 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 194.67724609375, Time 0.30994415283203125, Overall 1.0529272556304932 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 24.33465576171875, Time 0.3100595474243164, Overall 1.053041696548462 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 354.907470703125, Time 0.3212246894836426, Overall 1.0642073154449463 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 19.717081705729168, Time 0.3213183879852295, Overall 1.064300298690796 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 223.61825561523438, Time 0.32727527618408203, Overall 1.0702581405639648 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 27.952281951904297, Time 0.32737159729003906, Overall 1.0703539848327637 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 305.1754455566406, Time 0.33858537673950195, Overall 1.0815680027008057 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 16.95419141981337, Time 0.33867788314819336, Overall 1.0816600322723389 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 188.31553649902344, Time 0.34456443786621094, Overall 1.0875473022460938 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 23.53944206237793, Time 0.3446693420410156, Overall 1.0876519680023193 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 414.93292236328125, Time 0.3562800884246826, Overall 1.0992629528045654 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 23.051829020182293, Time 0.35637736320495605, Overall 1.0993595123291016 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 170.05374145507812, Time 0.362255334854126, Overall 1.1052379608154297 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 21.256717681884766, Time 0.36235642433166504, Overall 1.1053383350372314 \n",
            "It took 1.1070947647094727 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 5 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/imdb/toy.title.basics.tsv/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/imdb/toy.title.basics.tsv/indexes.pkl ...\n",
            "It took 0.000152587890625 seconds to load from the pickles.\n",
            "It took 0.0004761219024658203 seconds to load the sparse matrices.\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/imdb/toy.title.basics.tsv/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/imdb/toy.title.basics.tsv/indexes.pkl ...\n",
            "It took 0.00010538101196289062 seconds to load from the pickles.\n",
            "It took 0.0003178119659423828 seconds to load the sparse matrices.\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 21.549558639526367, Time 0.0023844242095947266, Overall 0.0035181045532226562 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 7.183186213175456, Time 0.0024776458740234375, Overall 0.0036106109619140625 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 17.319856643676758, Time 0.003537416458129883, Overall 0.004670858383178711 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 8.659928321838379, Time 0.0036242008209228516, Overall 0.00475764274597168 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 12.84377670288086, Time 0.006041049957275391, Overall 0.00717473030090332 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 4.281258900960286, Time 0.006125688552856445, Overall 0.00725865364074707 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 18.8310604095459, Time 0.00717616081237793, Overall 0.008309602737426758 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 9.41553020477295, Time 0.007266998291015625, Overall 0.00839996337890625 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 5.814655780792236, Time 0.009510993957519531, Overall 0.010644197463989258 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 1.938218593597412, Time 0.009598255157470703, Overall 0.010730981826782227 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 19.04481315612793, Time 0.010468721389770508, Overall 0.011601924896240234 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 9.522406578063965, Time 0.010548830032348633, Overall 0.011681556701660156 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 3.470761299133301, Time 0.012665987014770508, Overall 0.013799190521240234 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 1.1569204330444336, Time 0.012753963470458984, Overall 0.013887643814086914 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 27.950054168701172, Time 0.013596057891845703, Overall 0.014729499816894531 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 13.975027084350586, Time 0.013681411743164062, Overall 0.014814138412475586 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 2.0285208225250244, Time 0.015790939331054688, Overall 0.016924381256103516 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 0.6761736075083414, Time 0.01586294174194336, Overall 0.016995668411254883 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 36.90449523925781, Time 0.016753673553466797, Overall 0.017887592315673828 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 18.452247619628906, Time 0.01682305335998535, Overall 0.017955780029296875 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 3.86327862739563, Time 0.018901586532592773, Overall 0.0200345516204834 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 1.28775954246521, Time 0.01897263526916504, Overall 0.020105600357055664 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 39.61162185668945, Time 0.019819259643554688, Overall 0.020952463150024414 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 19.805810928344727, Time 0.019891023635864258, Overall 0.02102351188659668 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 16.111955642700195, Time 0.022264480590820312, Overall 0.023398637771606445 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 5.370651880900065, Time 0.022335290908813477, Overall 0.023468494415283203 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 35.28874206542969, Time 0.023358583450317383, Overall 0.02449178695678711 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 17.644371032714844, Time 0.023439645767211914, Overall 0.024572134017944336 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 23.150497436523438, Time 0.025480985641479492, Overall 0.02661442756652832 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 7.7168324788411455, Time 0.025554418563842773, Overall 0.0266878604888916 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 57.956180572509766, Time 0.02639174461364746, Overall 0.02752518653869629 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 28.978090286254883, Time 0.02646780014038086, Overall 0.027600526809692383 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 0.31891846656799316, Time 0.028481721878051758, Overall 0.029614686965942383 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 0.10630615552266438, Time 0.02855682373046875, Overall 0.029689550399780273 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 55.87533950805664, Time 0.029416561126708984, Overall 0.03054976463317871 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 27.93766975402832, Time 0.029494047164916992, Overall 0.030626535415649414 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 2.9751009941101074, Time 0.03150582313537598, Overall 0.032639265060424805 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 0.9917003313700358, Time 0.03157973289489746, Overall 0.03271293640136719 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 71.5157470703125, Time 0.03241300582885742, Overall 0.03354597091674805 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 35.75787353515625, Time 0.03249001502990723, Overall 0.03362274169921875 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 23.80497169494629, Time 0.03449821472167969, Overall 0.035631656646728516 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 7.934990564982097, Time 0.03457307815551758, Overall 0.035706520080566406 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 52.77552032470703, Time 0.03540682792663574, Overall 0.03654026985168457 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 26.387760162353516, Time 0.035486698150634766, Overall 0.036620140075683594 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 1.1355326175689697, Time 0.03752017021179199, Overall 0.03865337371826172 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 0.3785108725229899, Time 0.03759479522705078, Overall 0.03872823715209961 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 60.60572052001953, Time 0.03843951225280762, Overall 0.03957247734069824 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 30.302860260009766, Time 0.03851723670959473, Overall 0.03964972496032715 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 36.08270263671875, Time 0.04053831100463867, Overall 0.0416715145111084 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 12.027567545572916, Time 0.040610313415527344, Overall 0.04174375534057617 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 56.66070556640625, Time 0.04145979881286621, Overall 0.042592763900756836 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 28.330352783203125, Time 0.04153776168823242, Overall 0.04267072677612305 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 0.5495427846908569, Time 0.043523311614990234, Overall 0.04465627670288086 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 0.18318092823028564, Time 0.04359841346740723, Overall 0.04473137855529785 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 66.16078186035156, Time 0.04443097114562988, Overall 0.04556393623352051 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 33.08039093017578, Time 0.044507503509521484, Overall 0.04564023017883301 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 27.610605239868164, Time 0.04653811454772949, Overall 0.04767107963562012 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 9.203535079956055, Time 0.04661059379577637, Overall 0.047744035720825195 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 65.66681671142578, Time 0.04744362831115723, Overall 0.048577070236206055 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 32.83340835571289, Time 0.04752159118652344, Overall 0.04865407943725586 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 0.06741201877593994, Time 0.04951167106628418, Overall 0.050644636154174805 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 0.022470672925313313, Time 0.04958486557006836, Overall 0.050717830657958984 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 59.829437255859375, Time 0.05043745040893555, Overall 0.05157065391540527 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 29.914718627929688, Time 0.05051541328430176, Overall 0.05164813995361328 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 13.125578880310059, Time 0.05250978469848633, Overall 0.05364274978637695 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 4.375192960103353, Time 0.05258321762084961, Overall 0.05371594429016113 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 67.30813598632812, Time 0.053437232971191406, Overall 0.05457043647766113 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 33.65406799316406, Time 0.05351543426513672, Overall 0.054648399353027344 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 14.442712783813477, Time 0.055512189865112305, Overall 0.05664515495300293 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 4.814237594604492, Time 0.05558514595031738, Overall 0.05671834945678711 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 62.21708679199219, Time 0.05641913414001465, Overall 0.05755209922790527 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 31.108543395996094, Time 0.05649542808532715, Overall 0.05762815475463867 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 20.7673282623291, Time 0.05853462219238281, Overall 0.05966782569885254 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 6.9224427541097, Time 0.0586087703704834, Overall 0.059741973876953125 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 80.19715118408203, Time 0.059441566467285156, Overall 0.060575008392333984 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 40.098575592041016, Time 0.05952048301696777, Overall 0.0606532096862793 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 14.277054786682129, Time 0.06154608726501465, Overall 0.06267929077148438 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 4.759018262227376, Time 0.061620473861694336, Overall 0.06275415420532227 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 75.67807006835938, Time 0.062450408935546875, Overall 0.0635836124420166 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 37.83903503417969, Time 0.06252765655517578, Overall 0.0636606216430664 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 22.849224090576172, Time 0.0018334388732910156, Overall 0.06737542152404785 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 7.616408030192058, Time 0.0019180774688720703, Overall 0.0674598217010498 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 14.282303810119629, Time 0.002791881561279297, Overall 0.06833338737487793 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 7.1411519050598145, Time 0.002882242202758789, Overall 0.06842327117919922 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 15.817303657531738, Time 0.005029916763305664, Overall 0.0705714225769043 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 5.272434552510579, Time 0.005102634429931641, Overall 0.07064437866210938 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 16.168691635131836, Time 0.005959749221801758, Overall 0.07150077819824219 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 8.084345817565918, Time 0.0060384273529052734, Overall 0.0715794563293457 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 6.825645923614502, Time 0.008144378662109375, Overall 0.0736856460571289 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 2.2752153078715005, Time 0.008218050003051758, Overall 0.07375955581665039 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 18.185161590576172, Time 0.009079456329345703, Overall 0.07462072372436523 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 9.092580795288086, Time 0.009159088134765625, Overall 0.07470011711120605 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 6.271937847137451, Time 0.011210441589355469, Overall 0.0767519474029541 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 2.090645949045817, Time 0.01128530502319336, Overall 0.07682657241821289 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 17.93439292907715, Time 0.012103796005249023, Overall 0.07764506340026855 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 8.967196464538574, Time 0.012195825576782227, Overall 0.07773685455322266 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 5.2647223472595215, Time 0.01423025131225586, Overall 0.07977175712585449 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 1.754907449086507, Time 0.014310836791992188, Overall 0.07985210418701172 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 23.216163635253906, Time 0.015133857727050781, Overall 0.08067512512207031 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 11.608081817626953, Time 0.015212774276733398, Overall 0.08075356483459473 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 2.168821096420288, Time 0.017231225967407227, Overall 0.08277249336242676 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 0.7229403654734293, Time 0.01731133460998535, Overall 0.08285212516784668 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 28.299907684326172, Time 0.018137216567993164, Overall 0.0836782455444336 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 14.149953842163086, Time 0.01821422576904297, Overall 0.0837547779083252 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 2.2640042304992676, Time 0.020196199417114258, Overall 0.08573722839355469 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 0.7546680768330892, Time 0.02026963233947754, Overall 0.08581018447875977 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 27.19229507446289, Time 0.021109819412231445, Overall 0.08665108680725098 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 13.596147537231445, Time 0.021188974380493164, Overall 0.08672976493835449 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 12.445605278015137, Time 0.02317976951599121, Overall 0.08872127532958984 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 4.148535092671712, Time 0.023253202438354492, Overall 0.08879470825195312 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 24.297956466674805, Time 0.02408742904663086, Overall 0.08962869644165039 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 12.148978233337402, Time 0.024164199829101562, Overall 0.08970499038696289 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 0.12712672352790833, Time 0.02637314796447754, Overall 0.09191417694091797 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 0.04237557450930277, Time 0.026439666748046875, Overall 0.0919806957244873 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 39.11021423339844, Time 0.02724742889404297, Overall 0.0927884578704834 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 19.55510711669922, Time 0.027352333068847656, Overall 0.09289407730102539 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 8.562207221984863, Time 0.02967381477355957, Overall 0.09521603584289551 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 2.8540690739949546, Time 0.029752254486083984, Overall 0.09529376029968262 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 42.699928283691406, Time 0.030805587768554688, Overall 0.09634685516357422 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 21.349964141845703, Time 0.03088212013244629, Overall 0.09642267227172852 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 7.240756511688232, Time 0.032932281494140625, Overall 0.09847378730773926 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 2.4135855038960776, Time 0.033003807067871094, Overall 0.09854459762573242 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 29.49982452392578, Time 0.03386378288269043, Overall 0.09940481185913086 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 14.74991226196289, Time 0.033937931060791016, Overall 0.09947872161865234 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 1.5851658582687378, Time 0.03594326972961426, Overall 0.10148453712463379 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 0.5283886194229126, Time 0.036012887954711914, Overall 0.10155344009399414 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 31.133630752563477, Time 0.03687024116516113, Overall 0.10241127014160156 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 15.566815376281738, Time 0.03694510459899902, Overall 0.10248589515686035 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 11.26675033569336, Time 0.03901243209838867, Overall 0.1045536994934082 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 3.7555834452311196, Time 0.039084672927856445, Overall 0.10462617874145508 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 45.554054260253906, Time 0.03996014595031738, Overall 0.10550141334533691 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 22.777027130126953, Time 0.040039777755737305, Overall 0.10558056831359863 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 7.569538116455078, Time 0.042029380798339844, Overall 0.10757064819335938 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 2.523179372151693, Time 0.04210329055786133, Overall 0.10764479637145996 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 47.188053131103516, Time 0.042936086654663086, Overall 0.10847759246826172 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 23.594026565551758, Time 0.04301285743713379, Overall 0.10855388641357422 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 18.124364852905273, Time 0.04500865936279297, Overall 0.1105499267578125 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 6.041454950968425, Time 0.04508161544799805, Overall 0.11062288284301758 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 42.532047271728516, Time 0.04592442512512207, Overall 0.1114656925201416 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 21.266023635864258, Time 0.04600119590759277, Overall 0.1115419864654541 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 1.1948556900024414, Time 0.048003196716308594, Overall 0.11354446411132812 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 0.3982852300008138, Time 0.04807734489440918, Overall 0.1136178970336914 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 32.01362991333008, Time 0.048918962478637695, Overall 0.11446022987365723 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 16.00681495666504, Time 0.04899716377258301, Overall 0.11453771591186523 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 1.2694764137268066, Time 0.05097603797912598, Overall 0.1165170669555664 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 0.42315880457560223, Time 0.051050662994384766, Overall 0.1165916919708252 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 31.314542770385742, Time 0.05190777778625488, Overall 0.11744904518127441 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 15.657271385192871, Time 0.058295488357543945, Overall 0.12383794784545898 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 1.5945760011672974, Time 0.061124324798583984, Overall 0.12666606903076172 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 0.5315253337224325, Time 0.06118607521057129, Overall 0.12672662734985352 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 41.06740951538086, Time 0.06206488609313965, Overall 0.12760639190673828 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 20.53370475769043, Time 0.06212973594665527, Overall 0.1276702880859375 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 5.185311317443848, Time 0.06418919563293457, Overall 0.1297307014465332 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 1.728437105814616, Time 0.06424570083618164, Overall 0.12978649139404297 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 38.36845016479492, Time 0.06509017944335938, Overall 0.1306314468383789 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 19.18422508239746, Time 0.06515359878540039, Overall 0.13069415092468262 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 2.556353807449341, Time 0.06716227531433105, Overall 0.1327037811279297 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 0.8521179358164469, Time 0.06722021102905273, Overall 0.13276124000549316 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 34.34358215332031, Time 0.06804728507995605, Overall 0.1335887908935547 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 17.171791076660156, Time 0.06811046600341797, Overall 0.1336512565612793 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 28.77434730529785, Time 0.0017480850219726562, Overall 0.1371471881866455 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 7.193586826324463, Time 0.0018084049224853516, Overall 0.1372063159942627 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 7.894406318664551, Time 0.0025234222412109375, Overall 0.13792181015014648 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 7.894406318664551, Time 0.0025873184204101562, Overall 0.1379852294921875 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 16.219764709472656, Time 0.0047266483306884766, Overall 0.14012527465820312 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 4.054941177368164, Time 0.00478363037109375, Overall 0.1401815414428711 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 8.232234954833984, Time 0.0054056644439697266, Overall 0.14080381393432617 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 8.232234954833984, Time 0.005491018295288086, Overall 0.14088916778564453 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 8.356008529663086, Time 0.007619619369506836, Overall 0.14301800727844238 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 2.0890021324157715, Time 0.007676362991333008, Overall 0.14307403564453125 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 8.4896240234375, Time 0.008294105529785156, Overall 0.1436924934387207 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 8.4896240234375, Time 0.008354663848876953, Overall 0.1437525749206543 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 5.124468803405762, Time 0.01042318344116211, Overall 0.14582180976867676 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 1.2811172008514404, Time 0.010523080825805664, Overall 0.1459212303161621 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 16.661941528320312, Time 0.011153936386108398, Overall 0.14655232429504395 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 16.661941528320312, Time 0.0112152099609375, Overall 0.14661312103271484 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 21.52109146118164, Time 0.013282299041748047, Overall 0.1486806869506836 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 5.38027286529541, Time 0.013339757919311523, Overall 0.14873790740966797 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 11.181884765625, Time 0.013973474502563477, Overall 0.14937186241149902 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 11.181884765625, Time 0.014034509658813477, Overall 0.14943265914916992 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 9.296154975891113, Time 0.0161893367767334, Overall 0.15158796310424805 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 2.3240387439727783, Time 0.01624584197998047, Overall 0.1516437530517578 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 14.583809852600098, Time 0.01689910888671875, Overall 0.1522974967956543 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 14.583809852600098, Time 0.01696038246154785, Overall 0.1523582935333252 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 10.436346054077148, Time 0.019052505493164062, Overall 0.1544508934020996 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 2.609086513519287, Time 0.01910853385925293, Overall 0.15450596809387207 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 25.316360473632812, Time 0.019761323928833008, Overall 0.15515995025634766 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 25.316360473632812, Time 0.019822359085083008, Overall 0.15522003173828125 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 12.479909896850586, Time 0.022061824798583984, Overall 0.15745997428894043 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 3.1199774742126465, Time 0.02211904525756836, Overall 0.1575169563293457 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 23.25408172607422, Time 0.022813081741333008, Overall 0.15821146965026855 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 23.25408172607422, Time 0.022875547409057617, Overall 0.15827322006225586 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 26.651689529418945, Time 0.02498340606689453, Overall 0.16038203239440918 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 6.662922382354736, Time 0.025040626525878906, Overall 0.16043853759765625 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 24.07669448852539, Time 0.02569746971130371, Overall 0.16109561920166016 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 24.07669448852539, Time 0.025758981704711914, Overall 0.16115665435791016 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 2.6523587703704834, Time 0.027895212173461914, Overall 0.16329383850097656 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 0.6630896925926208, Time 0.027953624725341797, Overall 0.16335105895996094 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 19.084426879882812, Time 0.028609037399291992, Overall 0.16400718688964844 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 19.084426879882812, Time 0.028670310974121094, Overall 0.16406822204589844 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 2.201409339904785, Time 0.03083205223083496, Overall 0.1662306785583496 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 0.5503523349761963, Time 0.03088998794555664, Overall 0.16628742218017578 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 17.998289108276367, Time 0.031531333923339844, Overall 0.1669297218322754 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 17.998289108276367, Time 0.03159141540527344, Overall 0.16698884963989258 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 12.52488899230957, Time 0.03369879722595215, Overall 0.1690969467163086 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 3.1312222480773926, Time 0.03375554084777832, Overall 0.16915321350097656 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 25.060405731201172, Time 0.034375667572021484, Overall 0.16977405548095703 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 25.060405731201172, Time 0.03443574905395508, Overall 0.16983342170715332 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 2.3573803901672363, Time 0.036627769470214844, Overall 0.1720263957977295 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 0.5893450975418091, Time 0.036684513092041016, Overall 0.17208218574523926 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 22.731204986572266, Time 0.037351131439208984, Overall 0.17274951934814453 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 22.731204986572266, Time 0.037413597106933594, Overall 0.17281126976013184 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 7.320591926574707, Time 0.03966045379638672, Overall 0.17505884170532227 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 1.8301479816436768, Time 0.03971695899963379, Overall 0.17511487007141113 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 24.599180221557617, Time 0.04033327102661133, Overall 0.17573142051696777 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 24.599180221557617, Time 0.04039478302001953, Overall 0.17579245567321777 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 8.771195411682129, Time 0.04282569885253906, Overall 0.1782238483428955 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 2.1927988529205322, Time 0.042882442474365234, Overall 0.17828035354614258 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 19.01167106628418, Time 0.04353189468383789, Overall 0.17893028259277344 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 19.01167106628418, Time 0.04359269142150879, Overall 0.17899036407470703 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 13.674346923828125, Time 0.045679330825805664, Overall 0.1810777187347412 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 3.4185867309570312, Time 0.045735836029052734, Overall 0.18113350868225098 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 22.794742584228516, Time 0.04635143280029297, Overall 0.18174982070922852 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 22.794742584228516, Time 0.04641389846801758, Overall 0.18181180953979492 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 6.138021945953369, Time 0.048563480377197266, Overall 0.1839618682861328 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 1.5345054864883423, Time 0.04862070083618164, Overall 0.18401837348937988 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 17.067283630371094, Time 0.04922795295715332, Overall 0.18462634086608887 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 17.067283630371094, Time 0.04928898811340332, Overall 0.18468642234802246 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 9.792823791503906, Time 0.051377058029174805, Overall 0.18677592277526855 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 2.4482059478759766, Time 0.0514369010925293, Overall 0.18683481216430664 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 19.074249267578125, Time 0.05208945274353027, Overall 0.18748784065246582 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 19.074249267578125, Time 0.05214953422546387, Overall 0.1875472068786621 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 2.4587903022766113, Time 0.05423545837402344, Overall 0.18963408470153809 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 0.6146975755691528, Time 0.05429267883300781, Overall 0.18969011306762695 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 20.532434463500977, Time 0.05497479438781738, Overall 0.19037318229675293 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 20.532434463500977, Time 0.05503654479980469, Overall 0.19043445587158203 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 12.736185073852539, Time 0.05712103843688965, Overall 0.1925191879272461 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 3.1840462684631348, Time 0.057178497314453125, Overall 0.19257640838623047 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 17.52637481689453, Time 0.05781388282775879, Overall 0.19321227073669434 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 17.52637481689453, Time 0.057874441146850586, Overall 0.19327235221862793 \n",
            "It took 0.19401812553405762 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/imdb/toy.title.basics.tsv/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/imdb/toy.title.basics.tsv/indexes.pkl ...\n",
            "It took 6.914138793945312e-05 seconds to load from the pickles.\n",
            "It took 0.0002598762512207031 seconds to load the sparse matrices.\n",
            "/content/opentf/src/mdl/fnn.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  neg_idx = torch.nonzero(torch.tensor(neg_rands), as_tuple=True)[0]\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 223.563232421875, Time 0.007948637008666992, Overall 0.00933527946472168 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 74.52107747395833, Time 0.008021116256713867, Overall 0.009406805038452148 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 175.42575073242188, Time 0.012685060501098633, Overall 0.014071941375732422 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 87.71287536621094, Time 0.012767314910888672, Overall 0.014153003692626953 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 183.82264709472656, Time 0.021719932556152344, Overall 0.023107528686523438 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 61.27421569824219, Time 0.021800518035888672, Overall 0.023186445236206055 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 114.09405517578125, Time 0.027779817581176758, Overall 0.02916717529296875 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 57.047027587890625, Time 0.02787017822265625, Overall 0.029256105422973633 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 160.5645294189453, Time 0.036516666412353516, Overall 0.0379033088684082 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 53.5215098063151, Time 0.03659391403198242, Overall 0.0379796028137207 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 105.30533599853516, Time 0.04124164581298828, Overall 0.04262852668762207 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 52.65266799926758, Time 0.04132437705993652, Overall 0.042710065841674805 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 137.5637664794922, Time 0.049633026123046875, Overall 0.051020145416259766 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 45.8545888264974, Time 0.049742698669433594, Overall 0.05112862586975098 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 115.51200103759766, Time 0.05446934700012207, Overall 0.05585622787475586 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 57.75600051879883, Time 0.05456733703613281, Overall 0.055953264236450195 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 161.4525146484375, Time 0.06335997581481934, Overall 0.06474685668945312 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 53.8175048828125, Time 0.0634453296661377, Overall 0.06483101844787598 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 144.90286254882812, Time 0.06805014610290527, Overall 0.06943702697753906 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 72.45143127441406, Time 0.0681300163269043, Overall 0.06951594352722168 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 131.20765686035156, Time 0.07623982429504395, Overall 0.07762670516967773 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 43.73588562011719, Time 0.07631087303161621, Overall 0.07769656181335449 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 128.22256469726562, Time 0.08098340034484863, Overall 0.08237004280090332 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 64.11128234863281, Time 0.08106064796447754, Overall 0.08244657516479492 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 136.79833984375, Time 0.08948540687561035, Overall 0.09087204933166504 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 45.599446614583336, Time 0.08957791328430176, Overall 0.09096384048461914 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 128.74884033203125, Time 0.09419441223144531, Overall 0.0955812931060791 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 64.37442016601562, Time 0.09427690505981445, Overall 0.09566259384155273 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 187.93748474121094, Time 0.10233497619628906, Overall 0.10372185707092285 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 62.64582824707031, Time 0.10240650177001953, Overall 0.10379219055175781 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 174.080322265625, Time 0.10704159736633301, Overall 0.1084280014038086 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 87.0401611328125, Time 0.10711789131164551, Overall 0.10850358009338379 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 214.4874267578125, Time 0.11512517929077148, Overall 0.11651206016540527 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 71.49580891927083, Time 0.11519765853881836, Overall 0.11658358573913574 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 152.5611114501953, Time 0.1198122501373291, Overall 0.12119913101196289 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 76.28055572509766, Time 0.11989164352416992, Overall 0.1212773323059082 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 118.44998168945312, Time 0.12833404541015625, Overall 0.12972140312194824 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 39.48332722981771, Time 0.12841320037841797, Overall 0.12979912757873535 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 164.81179809570312, Time 0.1331648826599121, Overall 0.1345515251159668 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 82.40589904785156, Time 0.13325119018554688, Overall 0.13463687896728516 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 126.58779907226562, Time 0.14149022102355957, Overall 0.14288640022277832 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 42.19593302408854, Time 0.14158987998962402, Overall 0.1429755687713623 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 152.9593505859375, Time 0.1463327407836914, Overall 0.147719144821167 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 76.47967529296875, Time 0.14642596244812012, Overall 0.1478116512298584 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 91.72357940673828, Time 0.15494894981384277, Overall 0.15633559226989746 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 30.57452646891276, Time 0.1550276279449463, Overall 0.15641355514526367 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 139.39529418945312, Time 0.15985989570617676, Overall 0.16124749183654785 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 69.69764709472656, Time 0.1599593162536621, Overall 0.1613461971282959 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 132.22328186035156, Time 0.1682722568511963, Overall 0.16965866088867188 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 44.07442728678385, Time 0.16835689544677734, Overall 0.16974306106567383 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 141.31890869140625, Time 0.17294621467590332, Overall 0.1743326187133789 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 70.65945434570312, Time 0.1730341911315918, Overall 0.17442035675048828 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 117.78421783447266, Time 0.18105268478393555, Overall 0.18243956565856934 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 39.26140594482422, Time 0.18113303184509277, Overall 0.18251895904541016 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 197.3934783935547, Time 0.18567395210266113, Overall 0.18706202507019043 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 98.69673919677734, Time 0.18576407432556152, Overall 0.1871500015258789 \n",
            "Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 103.27717590332031, Time 0.1938467025756836, Overall 0.19523358345031738 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 34.42572530110677, Time 0.19393229484558105, Overall 0.19531822204589844 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 203.55067443847656, Time 0.19846343994140625, Overall 0.19985008239746094 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 101.77533721923828, Time 0.1985633373260498, Overall 0.1999492645263672 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 99.66838073730469, Time 0.20656442642211914, Overall 0.20795106887817383 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 33.22279357910156, Time 0.20664548873901367, Overall 0.20803165435791016 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 213.87713623046875, Time 0.21123147010803223, Overall 0.21261811256408691 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 106.93856811523438, Time 0.2113208770751953, Overall 0.2127068042755127 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 42.244197845458984, Time 0.21936702728271484, Overall 0.22075366973876953 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 14.081399281819662, Time 0.2194530963897705, Overall 0.2208390235900879 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 208.06825256347656, Time 0.22404789924621582, Overall 0.2254347801208496 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 104.03412628173828, Time 0.22413921356201172, Overall 0.2255253791809082 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 111.34632110595703, Time 0.23215508460998535, Overall 0.23354172706604004 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 37.115440368652344, Time 0.2322402000427246, Overall 0.2336258888244629 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 169.78610229492188, Time 0.23708844184875488, Overall 0.23847508430480957 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 84.89305114746094, Time 0.2371835708618164, Overall 0.2385694980621338 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 97.50737762451172, Time 0.24518418312072754, Overall 0.24657106399536133 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 32.50245920817057, Time 0.24526667594909668, Overall 0.24665284156799316 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 208.03208923339844, Time 0.24985909461975098, Overall 0.25124573707580566 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 104.01604461669922, Time 0.24994397163391113, Overall 0.2513298988342285 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 125.17135620117188, Time 0.2578105926513672, Overall 0.2591972351074219 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 41.723785400390625, Time 0.25789546966552734, Overall 0.2592813968658447 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 221.89404296875, Time 0.26407623291015625, Overall 0.26546406745910645 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 110.947021484375, Time 0.26418375968933105, Overall 0.26557040214538574 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 191.80320739746094, Time 0.01056814193725586, Overall 0.28041791915893555 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 63.93440246582031, Time 0.010655879974365234, Overall 0.2805047035217285 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 157.88970947265625, Time 0.015403985977172852, Overall 0.28525352478027344 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 78.94485473632812, Time 0.015492677688598633, Overall 0.2853415012359619 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 224.49916076660156, Time 0.023557662963867188, Overall 0.2934072017669678 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 74.83305358886719, Time 0.023644208908081055, Overall 0.29349327087402344 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 166.262939453125, Time 0.028184175491333008, Overall 0.2980337142944336 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 83.1314697265625, Time 0.028293609619140625, Overall 0.298142671585083 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 183.52755737304688, Time 0.036757707595825195, Overall 0.3066074848175049 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 61.17585245768229, Time 0.03684091567993164, Overall 0.3066897392272949 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 73.18004608154297, Time 0.04157376289367676, Overall 0.31142330169677734 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 36.590023040771484, Time 0.04166150093078613, Overall 0.3115103244781494 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 176.6120147705078, Time 0.049536943435668945, Overall 0.31938672065734863 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 58.87067159016927, Time 0.049620866775512695, Overall 0.3194699287414551 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 160.71755981445312, Time 0.054083824157714844, Overall 0.32393336296081543 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 80.35877990722656, Time 0.054167747497558594, Overall 0.3240163326263428 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 135.58554077148438, Time 0.06200718879699707, Overall 0.33185672760009766 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 45.19518025716146, Time 0.06209754943847656, Overall 0.33194661140441895 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 86.30998229980469, Time 0.06653523445129395, Overall 0.33638429641723633 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 43.154991149902344, Time 0.06662416458129883, Overall 0.3364732265472412 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 206.01968383789062, Time 0.07464480400085449, Overall 0.344494104385376 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 68.67322794596355, Time 0.07473039627075195, Overall 0.34457945823669434 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 126.5046615600586, Time 0.07927322387695312, Overall 0.3491227626800537 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 63.2523307800293, Time 0.07935929298400879, Overall 0.34920811653137207 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 122.04036712646484, Time 0.08725786209106445, Overall 0.35710740089416504 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 40.68012237548828, Time 0.08733892440795898, Overall 0.35718798637390137 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 119.27583312988281, Time 0.09244704246520996, Overall 0.36229729652404785 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 59.637916564941406, Time 0.09253811836242676, Overall 0.36238718032836914 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 111.05253601074219, Time 0.10132837295532227, Overall 0.37117815017700195 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 37.01751200358073, Time 0.10140848159790039, Overall 0.37125730514526367 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 155.16494750976562, Time 0.10585546493530273, Overall 0.3757050037384033 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 77.58247375488281, Time 0.10594582557678223, Overall 0.3757946491241455 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 124.92613220214844, Time 0.11402416229248047, Overall 0.38387393951416016 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 41.64204406738281, Time 0.11411547660827637, Overall 0.38396453857421875 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 215.34762573242188, Time 0.11862945556640625, Overall 0.38847875595092773 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 107.67381286621094, Time 0.11871623992919922, Overall 0.3885653018951416 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 141.239013671875, Time 0.12677907943725586, Overall 0.39662885665893555 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 47.079671223958336, Time 0.1268634796142578, Overall 0.3967125415802002 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 111.20625305175781, Time 0.13137388229370117, Overall 0.40122318267822266 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 55.603126525878906, Time 0.13145899772644043, Overall 0.4013080596923828 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 125.02149963378906, Time 0.1394493579864502, Overall 0.4092986583709717 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 41.67383321126302, Time 0.13953280448913574, Overall 0.4093818664550781 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 169.03916931152344, Time 0.1440107822418213, Overall 0.4138600826263428 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 84.51958465576172, Time 0.1441054344177246, Overall 0.4139542579650879 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 69.76956176757812, Time 0.15198373794555664, Overall 0.4218332767486572 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 23.256520589192707, Time 0.15207219123840332, Overall 0.4219212532043457 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 111.99064636230469, Time 0.15800189971923828, Overall 0.4278526306152344 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 55.995323181152344, Time 0.15812039375305176, Overall 0.42797040939331055 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 111.181396484375, Time 0.16604375839233398, Overall 0.43589353561401367 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 37.060465494791664, Time 0.1661367416381836, Overall 0.4359855651855469 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 179.35977172851562, Time 0.17060351371765137, Overall 0.44045329093933105 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 89.67988586425781, Time 0.17069005966186523, Overall 0.4405388832092285 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 100.52783966064453, Time 0.17863225936889648, Overall 0.44848155975341797 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 33.50927988688151, Time 0.17871785163879395, Overall 0.44856691360473633 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 144.32284545898438, Time 0.18315434455871582, Overall 0.4530036449432373 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 72.16142272949219, Time 0.1832578182220459, Overall 0.4531064033508301 \n",
            "Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 141.27816772460938, Time 0.19116735458374023, Overall 0.4610168933868408 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 47.09272257486979, Time 0.19126367568969727, Overall 0.46111249923706055 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 135.0758056640625, Time 0.1961350440979004, Overall 0.4659848213195801 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 67.53790283203125, Time 0.19623899459838867, Overall 0.46608805656433105 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 102.73765563964844, Time 0.20461392402648926, Overall 0.47446370124816895 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 34.24588521321615, Time 0.20470452308654785, Overall 0.47455334663391113 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 102.89509582519531, Time 0.209228515625, Overall 0.4790782928466797 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 51.447547912597656, Time 0.20931577682495117, Overall 0.47916483879089355 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 40.0707893371582, Time 0.2173161506652832, Overall 0.4871656894683838 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 13.356929779052734, Time 0.21739935874938965, Overall 0.48724818229675293 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 97.90495300292969, Time 0.2219247817993164, Overall 0.491774320602417 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 48.952476501464844, Time 0.22201871871948242, Overall 0.4918680191040039 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 111.7119140625, Time 0.23013758659362793, Overall 0.4999873638153076 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 37.2373046875, Time 0.23025846481323242, Overall 0.5001075267791748 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 184.9722442626953, Time 0.23493409156799316, Overall 0.5047836303710938 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 92.48612213134766, Time 0.23502826690673828, Overall 0.5048768520355225 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 83.71971893310547, Time 0.24335145950317383, Overall 0.5132014751434326 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 27.906572977701824, Time 0.2434406280517578, Overall 0.5132894515991211 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 183.54420471191406, Time 0.24811911582946777, Overall 0.5179684162139893 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 91.77210235595703, Time 0.2482316493988037, Overall 0.518080472946167 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 121.26172637939453, Time 0.2566208839416504, Overall 0.526470422744751 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 40.42057545979818, Time 0.25670719146728516, Overall 0.5265562534332275 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 188.73724365234375, Time 0.26144862174987793, Overall 0.5312981605529785 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 94.36862182617188, Time 0.2615523338317871, Overall 0.5314013957977295 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 342.1708679199219, Time 0.0075740814208984375, Overall 0.5418665409088135 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 85.54271697998047, Time 0.00767207145690918, Overall 0.5419631004333496 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 70.71479034423828, Time 0.012093544006347656, Overall 0.5463852882385254 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 70.71479034423828, Time 0.012198686599731445, Overall 0.5464897155761719 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 253.0639190673828, Time 0.020786762237548828, Overall 0.5550796985626221 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 63.2659797668457, Time 0.020891189575195312, Overall 0.5551824569702148 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 100.64994049072266, Time 0.02527618408203125, Overall 0.559567928314209 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 100.64994049072266, Time 0.02537846565246582, Overall 0.5596692562103271 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 230.55616760253906, Time 0.0365605354309082, Overall 0.5708532333374023 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 57.639041900634766, Time 0.03666567802429199, Overall 0.5709571838378906 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 92.85443115234375, Time 0.04343891143798828, Overall 0.5777316093444824 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 92.85443115234375, Time 0.04354548454284668, Overall 0.5778372287750244 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 240.92034912109375, Time 0.05615711212158203, Overall 0.5904498100280762 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 60.23008728027344, Time 0.05625772476196289, Overall 0.5905489921569824 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 98.10147857666016, Time 0.06084942817687988, Overall 0.5951414108276367 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 98.10147857666016, Time 0.060950279235839844, Overall 0.5952413082122803 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 231.92315673828125, Time 0.06952118873596191, Overall 0.6038131713867188 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 57.98078918457031, Time 0.06961822509765625, Overall 0.6039092540740967 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 69.79515075683594, Time 0.0741875171661377, Overall 0.6084792613983154 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 69.79515075683594, Time 0.07426571846008301, Overall 0.6085565090179443 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 171.85232543945312, Time 0.08317923545837402, Overall 0.6174709796905518 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 42.96308135986328, Time 0.08328723907470703, Overall 0.6175782680511475 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 95.57527923583984, Time 0.08777761459350586, Overall 0.6220693588256836 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 95.57527923583984, Time 0.08787703514099121, Overall 0.6221678256988525 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 185.23826599121094, Time 0.09657669067382812, Overall 0.6308684349060059 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 46.309566497802734, Time 0.09667515754699707, Overall 0.6309661865234375 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 89.84111022949219, Time 0.1011054515838623, Overall 0.63539719581604 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 89.84111022949219, Time 0.10120415687561035, Overall 0.6354949474334717 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 118.62872314453125, Time 0.10967779159545898, Overall 0.6439692974090576 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 29.657180786132812, Time 0.10978269577026367, Overall 0.6440744400024414 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 83.56624603271484, Time 0.11414694786071777, Overall 0.6484382152557373 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 83.56624603271484, Time 0.1142425537109375, Overall 0.6485335826873779 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 145.08612060546875, Time 0.1227104663848877, Overall 0.6570019721984863 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 36.27153015136719, Time 0.12282133102416992, Overall 0.6571128368377686 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 65.85070037841797, Time 0.12715601921081543, Overall 0.6614475250244141 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 65.85070037841797, Time 0.12725090980529785, Overall 0.6615417003631592 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 174.36474609375, Time 0.13650226593017578, Overall 0.6707940101623535 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 43.5911865234375, Time 0.13659071922302246, Overall 0.6708812713623047 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 60.84980392456055, Time 0.14091205596923828, Overall 0.6752033233642578 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 60.84980392456055, Time 0.14100384712219238, Overall 0.6752948760986328 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 83.6169662475586, Time 0.1515483856201172, Overall 0.6858398914337158 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 20.90424156188965, Time 0.15162348747253418, Overall 0.6859142780303955 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 76.42691040039062, Time 0.15590119361877441, Overall 0.690192699432373 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 76.42691040039062, Time 0.15598440170288086, Overall 0.6902751922607422 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 139.4669952392578, Time 0.1665809154510498, Overall 0.7008733749389648 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 34.86674880981445, Time 0.16667604446411133, Overall 0.7009677886962891 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 97.53953552246094, Time 0.17135834693908691, Overall 0.7056496143341064 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 97.53953552246094, Time 0.17143726348876953, Overall 0.7057280540466309 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 118.6475830078125, Time 0.17965149879455566, Overall 0.7139427661895752 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 29.661895751953125, Time 0.17972016334533691, Overall 0.7140107154846191 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 132.29519653320312, Time 0.18391823768615723, Overall 0.7182092666625977 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 132.29519653320312, Time 0.18399310111999512, Overall 0.7182838916778564 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 133.2755126953125, Time 0.19230318069458008, Overall 0.7265949249267578 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 33.318878173828125, Time 0.19237828254699707, Overall 0.7266688346862793 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 111.74742889404297, Time 0.19657301902770996, Overall 0.7308647632598877 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 111.74742889404297, Time 0.19664883613586426, Overall 0.7309393882751465 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 123.55662536621094, Time 0.20490097999572754, Overall 0.7391924858093262 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 30.889156341552734, Time 0.20497703552246094, Overall 0.7392675876617432 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 61.79773712158203, Time 0.2093207836151123, Overall 0.7436120510101318 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 61.79773712158203, Time 0.20940136909484863, Overall 0.7436923980712891 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 125.20948028564453, Time 0.21773767471313477, Overall 0.7520289421081543 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 31.302370071411133, Time 0.21784067153930664, Overall 0.752131462097168 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 83.2917251586914, Time 0.2221050262451172, Overall 0.7563965320587158 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 83.2917251586914, Time 0.22218871116638184, Overall 0.7564792633056641 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 85.35384368896484, Time 0.2305457592010498, Overall 0.7648375034332275 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 21.33846092224121, Time 0.23062682151794434, Overall 0.7649178504943848 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 111.56222534179688, Time 0.23551297187805176, Overall 0.7698049545288086 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 111.56222534179688, Time 0.23560285568237305, Overall 0.7698934078216553 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 125.2991714477539, Time 0.24751853942871094, Overall 0.7818119525909424 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 31.324792861938477, Time 0.24763154983520508, Overall 0.7819230556488037 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 125.3450927734375, Time 0.25508570671081543, Overall 0.7893786430358887 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 125.3450927734375, Time 0.25522947311401367, Overall 0.7895214557647705 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 83.94950103759766, Time 0.26452207565307617, Overall 0.7988142967224121 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 20.987375259399414, Time 0.26460838317871094, Overall 0.7988989353179932 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 76.9488296508789, Time 0.26911091804504395, Overall 0.8034026622772217 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 76.9488296508789, Time 0.26920413970947266, Overall 0.803494930267334 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 111.50602722167969, Time 0.27797722816467285, Overall 0.8122692108154297 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 27.876506805419922, Time 0.278059720993042, Overall 0.8123505115509033 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 111.63041687011719, Time 0.28272533416748047, Overall 0.8170173168182373 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 111.63041687011719, Time 0.28284502029418945, Overall 0.817136287689209 \n",
            "It took 0.8189888000488281 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/imdb/toy.title.basics.tsv/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/imdb/toy.title.basics.tsv/indexes.pkl ...\n",
            "It took 8.487701416015625e-05 seconds to load from the pickles.\n",
            "It took 0.0003039836883544922 seconds to load the sparse matrices.\n",
            "Loading the skill embedding pickle ...\n",
            "2022-03-04 05:28:58,616 : INFO : loading Doc2Vec object from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl\n",
            "File not found! Learning skill.emb.d100.w1.dm1 embeddings from scratch ...\n",
            "Loading the skill documents pickle ...\n",
            "File not found! Generating skill documents ...\n",
            "#Documents with word type of skill have created: 6\n",
            "Saving the skill documents ...\n",
            "2022-03-04 05:28:58,620 : INFO : collecting all words and their counts\n",
            "2022-03-04 05:28:58,621 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
            "2022-03-04 05:28:58,621 : INFO : collected 7 word types and 6 unique tags from a corpus of 6 examples and 10 words\n",
            "2022-03-04 05:28:58,621 : INFO : Loading a fresh vocabulary\n",
            "2022-03-04 05:28:58,621 : INFO : effective_min_count=0 retains 7 unique words (100% of original 7, drops 0)\n",
            "2022-03-04 05:28:58,621 : INFO : effective_min_count=0 leaves 10 word corpus (100% of original 10, drops 0)\n",
            "2022-03-04 05:28:58,621 : INFO : deleting the raw counts dictionary of 7 items\n",
            "2022-03-04 05:28:58,621 : INFO : sample=0.001 downsamples 7 most-common words\n",
            "2022-03-04 05:28:58,621 : INFO : downsampling leaves estimated 0 word corpus (8.7% of prior 10)\n",
            "2022-03-04 05:28:58,621 : INFO : estimated required memory for 7 words and 100 dimensions: 12700 bytes\n",
            "2022-03-04 05:28:58,621 : INFO : resetting layer weights\n",
            "  0% 0/10 [00:00<?, ?it/s]2022-03-04 05:28:58,624 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,626 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,626 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,626 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 9596 effective words/s\n",
            "2022-03-04 05:28:58,627 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,627 : INFO : EPOCH - 2 : training on 10 raw words (8 effective words) took 0.0s, 13766 effective words/s\n",
            "2022-03-04 05:28:58,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,628 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,628 : INFO : EPOCH - 3 : training on 10 raw words (6 effective words) took 0.0s, 11013 effective words/s\n",
            "2022-03-04 05:28:58,629 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,629 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,629 : INFO : EPOCH - 4 : training on 10 raw words (6 effective words) took 0.0s, 11950 effective words/s\n",
            "2022-03-04 05:28:58,630 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,630 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,630 : INFO : EPOCH - 5 : training on 10 raw words (8 effective words) took 0.0s, 15559 effective words/s\n",
            "2022-03-04 05:28:58,630 : INFO : training on a 50 raw words (34 effective words) took 0.0s, 5633 effective words/s\n",
            "2022-03-04 05:28:58,630 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,631 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,632 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,632 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,632 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 11271 effective words/s\n",
            "2022-03-04 05:28:58,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,633 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,633 : INFO : EPOCH - 2 : training on 10 raw words (7 effective words) took 0.0s, 12623 effective words/s\n",
            "2022-03-04 05:28:58,634 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,634 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,634 : INFO : EPOCH - 3 : training on 10 raw words (7 effective words) took 0.0s, 12384 effective words/s\n",
            "2022-03-04 05:28:58,635 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,635 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,635 : INFO : EPOCH - 4 : training on 10 raw words (7 effective words) took 0.0s, 13594 effective words/s\n",
            "2022-03-04 05:28:58,636 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,636 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,636 : INFO : EPOCH - 5 : training on 10 raw words (6 effective words) took 0.0s, 12051 effective words/s\n",
            "2022-03-04 05:28:58,636 : INFO : training on a 50 raw words (33 effective words) took 0.0s, 5704 effective words/s\n",
            "2022-03-04 05:28:58,636 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,637 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,638 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,638 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,638 : INFO : EPOCH - 1 : training on 10 raw words (7 effective words) took 0.0s, 12820 effective words/s\n",
            "2022-03-04 05:28:58,639 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,639 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,639 : INFO : EPOCH - 2 : training on 10 raw words (6 effective words) took 0.0s, 11130 effective words/s\n",
            "2022-03-04 05:28:58,640 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,640 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,640 : INFO : EPOCH - 3 : training on 10 raw words (9 effective words) took 0.0s, 15520 effective words/s\n",
            "2022-03-04 05:28:58,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,641 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,641 : INFO : EPOCH - 4 : training on 10 raw words (8 effective words) took 0.0s, 15198 effective words/s\n",
            "2022-03-04 05:28:58,642 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,642 : INFO : EPOCH - 5 : training on 10 raw words (8 effective words) took 0.0s, 15783 effective words/s\n",
            "2022-03-04 05:28:58,642 : INFO : training on a 50 raw words (38 effective words) took 0.0s, 6579 effective words/s\n",
            "2022-03-04 05:28:58,642 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,643 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,644 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,644 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,644 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 11957 effective words/s\n",
            "2022-03-04 05:28:58,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,645 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,645 : INFO : EPOCH - 2 : training on 10 raw words (7 effective words) took 0.0s, 13043 effective words/s\n",
            "2022-03-04 05:28:58,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,646 : INFO : EPOCH - 3 : training on 10 raw words (6 effective words) took 0.0s, 11108 effective words/s\n",
            "2022-03-04 05:28:58,647 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,647 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,647 : INFO : EPOCH - 4 : training on 10 raw words (6 effective words) took 0.0s, 8668 effective words/s\n",
            "2022-03-04 05:28:58,648 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,648 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,648 : INFO : EPOCH - 5 : training on 10 raw words (6 effective words) took 0.0s, 12028 effective words/s\n",
            "2022-03-04 05:28:58,648 : INFO : training on a 50 raw words (31 effective words) took 0.0s, 5297 effective words/s\n",
            "2022-03-04 05:28:58,649 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,649 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,650 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,650 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,650 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 11375 effective words/s\n",
            "2022-03-04 05:28:58,651 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,651 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,651 : INFO : EPOCH - 2 : training on 10 raw words (8 effective words) took 0.0s, 14776 effective words/s\n",
            "2022-03-04 05:28:58,652 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,652 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,652 : INFO : EPOCH - 3 : training on 10 raw words (7 effective words) took 0.0s, 12341 effective words/s\n",
            "2022-03-04 05:28:58,653 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,653 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,653 : INFO : EPOCH - 4 : training on 10 raw words (7 effective words) took 0.0s, 13046 effective words/s\n",
            "2022-03-04 05:28:58,654 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,654 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,654 : INFO : EPOCH - 5 : training on 10 raw words (6 effective words) took 0.0s, 12121 effective words/s\n",
            "2022-03-04 05:28:58,654 : INFO : training on a 50 raw words (34 effective words) took 0.0s, 5972 effective words/s\n",
            "2022-03-04 05:28:58,654 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,654 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,656 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,656 : INFO : EPOCH - 1 : training on 10 raw words (8 effective words) took 0.0s, 15625 effective words/s\n",
            "2022-03-04 05:28:58,657 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,657 : INFO : EPOCH - 2 : training on 10 raw words (8 effective words) took 0.0s, 13888 effective words/s\n",
            "2022-03-04 05:28:58,658 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,658 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,658 : INFO : EPOCH - 3 : training on 10 raw words (7 effective words) took 0.0s, 12938 effective words/s\n",
            "2022-03-04 05:28:58,659 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,659 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,659 : INFO : EPOCH - 4 : training on 10 raw words (6 effective words) took 0.0s, 10732 effective words/s\n",
            "2022-03-04 05:28:58,660 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,660 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,660 : INFO : EPOCH - 5 : training on 10 raw words (7 effective words) took 0.0s, 9963 effective words/s\n",
            "2022-03-04 05:28:58,660 : INFO : training on a 50 raw words (36 effective words) took 0.0s, 6031 effective words/s\n",
            "2022-03-04 05:28:58,661 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,661 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,662 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,662 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,662 : INFO : EPOCH - 1 : training on 10 raw words (7 effective words) took 0.0s, 12902 effective words/s\n",
            "2022-03-04 05:28:58,663 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,663 : INFO : EPOCH - 2 : training on 10 raw words (7 effective words) took 0.0s, 12692 effective words/s\n",
            "2022-03-04 05:28:58,664 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,664 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,664 : INFO : EPOCH - 3 : training on 10 raw words (6 effective words) took 0.0s, 8836 effective words/s\n",
            "2022-03-04 05:28:58,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,665 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,665 : INFO : EPOCH - 4 : training on 10 raw words (6 effective words) took 0.0s, 12102 effective words/s\n",
            "2022-03-04 05:28:58,666 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,666 : INFO : EPOCH - 5 : training on 10 raw words (7 effective words) took 0.0s, 13890 effective words/s\n",
            "2022-03-04 05:28:58,667 : INFO : training on a 50 raw words (33 effective words) took 0.0s, 5640 effective words/s\n",
            "2022-03-04 05:28:58,667 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,667 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,668 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,668 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 11381 effective words/s\n",
            "2022-03-04 05:28:58,669 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,669 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,669 : INFO : EPOCH - 2 : training on 10 raw words (7 effective words) took 0.0s, 12754 effective words/s\n",
            "2022-03-04 05:28:58,670 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,670 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,670 : INFO : EPOCH - 3 : training on 10 raw words (9 effective words) took 0.0s, 12500 effective words/s\n",
            "2022-03-04 05:28:58,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,671 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,671 : INFO : EPOCH - 4 : training on 10 raw words (7 effective words) took 0.0s, 13420 effective words/s\n",
            "2022-03-04 05:28:58,672 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,673 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,673 : INFO : EPOCH - 5 : training on 10 raw words (6 effective words) took 0.0s, 12625 effective words/s\n",
            "2022-03-04 05:28:58,673 : INFO : training on a 50 raw words (35 effective words) took 0.0s, 6018 effective words/s\n",
            "2022-03-04 05:28:58,673 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,673 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,674 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,674 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,674 : INFO : EPOCH - 1 : training on 10 raw words (6 effective words) took 0.0s, 11898 effective words/s\n",
            "2022-03-04 05:28:58,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,675 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,675 : INFO : EPOCH - 2 : training on 10 raw words (7 effective words) took 0.0s, 13781 effective words/s\n",
            "2022-03-04 05:28:58,676 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,676 : INFO : EPOCH - 3 : training on 10 raw words (7 effective words) took 0.0s, 13054 effective words/s\n",
            "2022-03-04 05:28:58,677 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,677 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,677 : INFO : EPOCH - 4 : training on 10 raw words (6 effective words) took 0.0s, 7365 effective words/s\n",
            "2022-03-04 05:28:58,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,721 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,721 : INFO : EPOCH - 5 : training on 10 raw words (6 effective words) took 0.0s, 140 effective words/s\n",
            "2022-03-04 05:28:58,721 : INFO : training on a 50 raw words (32 effective words) took 0.0s, 660 effective words/s\n",
            "2022-03-04 05:28:58,721 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "2022-03-04 05:28:58,722 : INFO : training model with 2 workers on 7 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
            "2022-03-04 05:28:58,724 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,724 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,724 : INFO : EPOCH - 1 : training on 10 raw words (8 effective words) took 0.0s, 11698 effective words/s\n",
            "2022-03-04 05:28:58,725 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,726 : INFO : EPOCH - 2 : training on 10 raw words (10 effective words) took 0.0s, 17240 effective words/s\n",
            "2022-03-04 05:28:58,727 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,727 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,727 : INFO : EPOCH - 3 : training on 10 raw words (6 effective words) took 0.0s, 7302 effective words/s\n",
            "2022-03-04 05:28:58,730 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,730 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,730 : INFO : EPOCH - 4 : training on 10 raw words (7 effective words) took 0.0s, 12894 effective words/s\n",
            "2022-03-04 05:28:58,732 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2022-03-04 05:28:58,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2022-03-04 05:28:58,732 : INFO : EPOCH - 5 : training on 10 raw words (8 effective words) took 0.0s, 13262 effective words/s\n",
            "2022-03-04 05:28:58,732 : INFO : training on a 50 raw words (39 effective words) took 0.0s, 3794 effective words/s\n",
            "2022-03-04 05:28:58,732 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "100% 10/10 [00:00<00:00, 92.68it/s]\n",
            "Saving model for skill.emb.d100.w1.dm1 under directory ./../data/preprocessed/imdb/toy.title.basics.tsv ...\n",
            "2022-03-04 05:28:58,732 : INFO : saving Doc2Vec object under ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl, separately None\n",
            "2022-03-04 05:28:58,733 : INFO : saved ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 20.89476776123047, Time 0.002061128616333008, Overall 0.0032889842987060547 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 6.964922587076823, Time 0.0021347999572753906, Overall 0.0033617019653320312 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 15.67884349822998, Time 0.0029821395874023438, Overall 0.004209756851196289 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 7.83942174911499, Time 0.0030519962310791016, Overall 0.004278898239135742 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 16.935617446899414, Time 0.0053195953369140625, Overall 0.006548166275024414 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 5.645205815633138, Time 0.005401134490966797, Overall 0.006627798080444336 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 15.893596649169922, Time 0.006142139434814453, Overall 0.007369518280029297 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 7.946798324584961, Time 0.006207704544067383, Overall 0.0074346065521240234 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 11.834761619567871, Time 0.008309125900268555, Overall 0.0095367431640625 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 3.944920539855957, Time 0.008369922637939453, Overall 0.009596586227416992 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 17.236940383911133, Time 0.009076833724975586, Overall 0.010304450988769531 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 8.618470191955566, Time 0.009141206741333008, Overall 0.010368108749389648 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 6.85523796081543, Time 0.011214733123779297, Overall 0.012442350387573242 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 2.28507932027181, Time 0.011275291442871094, Overall 0.012502193450927734 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 16.59016227722168, Time 0.011975526809692383, Overall 0.013203620910644531 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 8.29508113861084, Time 0.012041568756103516, Overall 0.013268470764160156 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 7.202470302581787, Time 0.014084577560424805, Overall 0.015311956405639648 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 2.400823434193929, Time 0.014146089553833008, Overall 0.015372753143310547 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 18.503576278686523, Time 0.014856338500976562, Overall 0.01608419418334961 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 9.251788139343262, Time 0.014921188354492188, Overall 0.016147851943969727 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 15.47766399383545, Time 0.016865015029907227, Overall 0.01809239387512207 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 5.159221331278483, Time 0.016923904418945312, Overall 0.018150806427001953 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 22.997556686401367, Time 0.017645835876464844, Overall 0.018872976303100586 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 11.498778343200684, Time 0.017710447311401367, Overall 0.01893758773803711 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 7.586587905883789, Time 0.019732952117919922, Overall 0.02096104621887207 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 2.528862635294596, Time 0.019821643829345703, Overall 0.02104926109313965 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 27.344085693359375, Time 0.02057027816772461, Overall 0.021797895431518555 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 13.672042846679688, Time 0.020647764205932617, Overall 0.02187490463256836 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 11.254692077636719, Time 0.022660017013549805, Overall 0.02388787269592285 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 3.7515640258789062, Time 0.022736787796020508, Overall 0.02396416664123535 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 29.239416122436523, Time 0.02346205711364746, Overall 0.024689674377441406 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 14.619708061218262, Time 0.023540258407592773, Overall 0.024766921997070312 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 6.819766044616699, Time 0.025517940521240234, Overall 0.02674555778503418 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 2.2732553482055664, Time 0.025593042373657227, Overall 0.02682018280029297 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 38.22959899902344, Time 0.026326894760131836, Overall 0.02755451202392578 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 19.11479949951172, Time 0.026402711868286133, Overall 0.027629852294921875 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 11.993060111999512, Time 0.028311491012573242, Overall 0.029539108276367188 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 3.9976867039998374, Time 0.02838587760925293, Overall 0.029613018035888672 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 39.81480407714844, Time 0.02908921241760254, Overall 0.030316829681396484 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 19.90740203857422, Time 0.029165267944335938, Overall 0.030392169952392578 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 1.0248712301254272, Time 0.03110647201538086, Overall 0.032334089279174805 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 0.3416237433751424, Time 0.031183481216430664, Overall 0.03241086006164551 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 27.39421844482422, Time 0.03190946578979492, Overall 0.03313708305358887 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 13.69710922241211, Time 0.03198814392089844, Overall 0.03321480751037598 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 1.065588116645813, Time 0.033937692642211914, Overall 0.03516507148742676 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 0.3551960388819377, Time 0.034010887145996094, Overall 0.035237789154052734 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 35.0877685546875, Time 0.03474020957946777, Overall 0.035967350006103516 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 17.54388427734375, Time 0.03482675552368164, Overall 0.03605365753173828 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 7.7620849609375, Time 0.03687143325805664, Overall 0.03809857368469238 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 2.5873616536458335, Time 0.03694510459899902, Overall 0.038172006607055664 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 29.870519638061523, Time 0.037660837173461914, Overall 0.03888845443725586 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 14.935259819030762, Time 0.03773999214172363, Overall 0.03896665573120117 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 9.307663917541504, Time 0.0396878719329834, Overall 0.04091501235961914 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 3.1025546391805015, Time 0.039763450622558594, Overall 0.040990352630615234 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 33.38908386230469, Time 0.04052424430847168, Overall 0.04175162315368652 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 16.694541931152344, Time 0.04059910774230957, Overall 0.04182624816894531 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 16.438919067382812, Time 0.04256582260131836, Overall 0.0437929630279541 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 5.4796396891276045, Time 0.04263949394226074, Overall 0.043866872787475586 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 29.96393394470215, Time 0.04335975646972656, Overall 0.044586896896362305 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 14.981966972351074, Time 0.04343461990356445, Overall 0.044661521911621094 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 7.338017463684082, Time 0.04539966583251953, Overall 0.046627044677734375 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 2.4460058212280273, Time 0.045472145080566406, Overall 0.04669976234436035 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 40.022727966308594, Time 0.046175479888916016, Overall 0.04740285873413086 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 20.011363983154297, Time 0.046254634857177734, Overall 0.047481536865234375 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 1.5313664674758911, Time 0.0481867790222168, Overall 0.04941439628601074 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 0.5104554891586304, Time 0.0482635498046875, Overall 0.04949069023132324 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 36.87295150756836, Time 0.04898977279663086, Overall 0.050217390060424805 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 18.43647575378418, Time 0.04906964302062988, Overall 0.050296783447265625 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 0.3642873466014862, Time 0.05102133750915527, Overall 0.052248239517211914 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 0.12142911553382874, Time 0.051097869873046875, Overall 0.05232501029968262 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 36.68831253051758, Time 0.051824331283569336, Overall 0.05305194854736328 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 18.34415626525879, Time 0.051900625228881836, Overall 0.05312752723693848 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 11.25161075592041, Time 0.05396723747253418, Overall 0.055194854736328125 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 3.7505369186401367, Time 0.05404162406921387, Overall 0.055268287658691406 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 33.49126434326172, Time 0.05478692054748535, Overall 0.0560145378112793 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 16.74563217163086, Time 0.054871320724487305, Overall 0.056098222732543945 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 12.398804664611816, Time 0.056809186935424805, Overall 0.05803656578063965 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 4.1329348882039385, Time 0.05689239501953125, Overall 0.05811929702758789 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 35.37033462524414, Time 0.05761361122131348, Overall 0.05884075164794922 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 17.68516731262207, Time 0.05769228935241699, Overall 0.05891919136047363 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 22.583873748779297, Time 0.0015101432800292969, Overall 0.06236720085144043 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 7.527957916259766, Time 0.0017457008361816406, Overall 0.06258773803710938 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 14.683688163757324, Time 0.0025458335876464844, Overall 0.06338691711425781 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 7.341844081878662, Time 0.002634286880493164, Overall 0.06347465515136719 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 20.920425415039062, Time 0.004632711410522461, Overall 0.06547355651855469 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 6.9734751383463545, Time 0.004724979400634766, Overall 0.06556534767150879 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 15.167448043823242, Time 0.005422115325927734, Overall 0.06626296043395996 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 7.583724021911621, Time 0.0054972171783447266, Overall 0.06633710861206055 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 15.470659255981445, Time 0.007471561431884766, Overall 0.06831192970275879 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 5.1568864186604815, Time 0.007546663284301758, Overall 0.06838703155517578 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 17.41344451904297, Time 0.008264303207397461, Overall 0.06910490989685059 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 8.706722259521484, Time 0.008341073989868164, Overall 0.06918144226074219 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 12.0974760055542, Time 0.010243415832519531, Overall 0.07108426094055176 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 4.032492001851399, Time 0.010315656661987305, Overall 0.07115578651428223 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 15.773385047912598, Time 0.0110321044921875, Overall 0.07187294960021973 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 7.886692523956299, Time 0.011114120483398438, Overall 0.07195472717285156 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 7.61578369140625, Time 0.012991189956665039, Overall 0.07383179664611816 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 2.5385945638020835, Time 0.013065576553344727, Overall 0.07390594482421875 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 19.649751663208008, Time 0.013766288757324219, Overall 0.07460737228393555 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 9.824875831604004, Time 0.013839483261108398, Overall 0.07468008995056152 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 4.4168477058410645, Time 0.015747547149658203, Overall 0.07658815383911133 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 1.4722825686136882, Time 0.015820026397705078, Overall 0.07666015625 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 21.22811508178711, Time 0.01649761199951172, Overall 0.07733798027038574 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 10.614057540893555, Time 0.016573667526245117, Overall 0.07741379737854004 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 6.123331069946289, Time 0.018433332443237305, Overall 0.07927417755126953 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 2.041110356648763, Time 0.018507003784179688, Overall 0.07934737205505371 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 27.269987106323242, Time 0.019257068634033203, Overall 0.08009767532348633 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 13.634993553161621, Time 0.029869794845581055, Overall 0.0907125473022461 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 1.3229196071624756, Time 0.03348731994628906, Overall 0.0943291187286377 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 0.4409732023874919, Time 0.03358006477355957, Overall 0.0944209098815918 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 32.64762878417969, Time 0.03482627868652344, Overall 0.09566807746887207 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 16.323814392089844, Time 0.034920692443847656, Overall 0.09576153755187988 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 1.8833765983581543, Time 0.0379638671875, Overall 0.09880542755126953 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 0.6277921994527181, Time 0.03804373741149902, Overall 0.09888410568237305 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 36.68771743774414, Time 0.03919792175292969, Overall 0.10004878044128418 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 18.34385871887207, Time 0.039290666580200195, Overall 0.10013198852539062 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 1.0939708948135376, Time 0.04221320152282715, Overall 0.10305476188659668 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 0.3646569649378459, Time 0.04228949546813965, Overall 0.10313010215759277 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 34.89491653442383, Time 0.04323720932006836, Overall 0.10407876968383789 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 17.447458267211914, Time 0.04331564903259277, Overall 0.1041562557220459 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 3.513800859451294, Time 0.04604053497314453, Overall 0.10688185691833496 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 1.1712669531504314, Time 0.04611802101135254, Overall 0.10695886611938477 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 48.71968078613281, Time 0.04706263542175293, Overall 0.10790419578552246 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 24.359840393066406, Time 0.04714202880859375, Overall 0.10798311233520508 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 5.770809173583984, Time 0.04989123344421387, Overall 0.1107325553894043 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 1.9236030578613281, Time 0.049963951110839844, Overall 0.11080503463745117 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 53.82622528076172, Time 0.05089235305786133, Overall 0.11173391342163086 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 26.91311264038086, Time 0.050971269607543945, Overall 0.11181235313415527 \n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 19.72037124633789, Time 0.0537567138671875, Overall 0.11459827423095703 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 6.57345708211263, Time 0.0538330078125, Overall 0.11467361450195312 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 66.85899353027344, Time 0.05477404594421387, Overall 0.1156156063079834 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 33.42949676513672, Time 0.05484914779663086, Overall 0.11568999290466309 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 27.232532501220703, Time 0.05757284164428711, Overall 0.11841416358947754 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 9.077510833740234, Time 0.0576481819152832, Overall 0.11848902702331543 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 57.6411018371582, Time 0.05856823921203613, Overall 0.11940956115722656 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 28.8205509185791, Time 0.05864739418029785, Overall 0.11948823928833008 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 21.036672592163086, Time 0.061331748962402344, Overall 0.12217330932617188 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 7.012224197387695, Time 0.06141090393066406, Overall 0.12225198745727539 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 57.419158935546875, Time 0.06234908103942871, Overall 0.12319064140319824 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 28.709579467773438, Time 0.06259799003601074, Overall 0.12343907356262207 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 9.536870002746582, Time 0.06531906127929688, Overall 0.1261608600616455 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 3.178956667582194, Time 0.06539678573608398, Overall 0.1262376308441162 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 59.75401306152344, Time 0.06634068489074707, Overall 0.1271822452545166 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 29.87700653076172, Time 0.06641936302185059, Overall 0.1272599697113037 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 12.584416389465332, Time 0.06905794143676758, Overall 0.129899263381958 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 4.19480546315511, Time 0.06913113594055176, Overall 0.12997126579284668 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 48.65335464477539, Time 0.06999945640563965, Overall 0.13084053993225098 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 24.326677322387695, Time 0.07007479667663574, Overall 0.13091516494750977 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 35.70063781738281, Time 0.07286524772644043, Overall 0.13370633125305176 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 11.900212605794271, Time 0.07294845581054688, Overall 0.1337893009185791 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 59.10893630981445, Time 0.07393813133239746, Overall 0.1347792148590088 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 29.554468154907227, Time 0.07404112815856934, Overall 0.13488197326660156 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 0.12711110711097717, Time 0.07701587677001953, Overall 0.13785719871520996 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 0.04237036903699239, Time 0.07710123062133789, Overall 0.13794159889221191 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 59.45218276977539, Time 0.078125, Overall 0.13896656036376953 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 29.726091384887695, Time 0.07821989059448242, Overall 0.13906097412109375 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 0.5067961812019348, Time 0.08120894432067871, Overall 0.14205074310302734 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 0.16893206040064493, Time 0.0812838077545166, Overall 0.14212369918823242 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 58.49680709838867, Time 0.08208203315734863, Overall 0.14292263984680176 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 29.248403549194336, Time 0.08215951919555664, Overall 0.14299941062927246 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 29.68310546875, Time 0.0016489028930664062, Overall 0.14674615859985352 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 7.4207763671875, Time 0.001725912094116211, Overall 0.1468219757080078 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 8.177983283996582, Time 0.002328157424926758, Overall 0.14742445945739746 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 8.177983283996582, Time 0.0024073123931884766, Overall 0.14750385284423828 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 27.368253707885742, Time 0.004532575607299805, Overall 0.1496288776397705 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 6.8420634269714355, Time 0.0046062469482421875, Overall 0.1497020721435547 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 8.26734733581543, Time 0.005201816558837891, Overall 0.1502981185913086 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 8.26734733581543, Time 0.005280256271362305, Overall 0.1503760814666748 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 19.435958862304688, Time 0.0073163509368896484, Overall 0.15241289138793945 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 4.858989715576172, Time 0.007391929626464844, Overall 0.15248775482177734 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 8.700787544250488, Time 0.008001327514648438, Overall 0.15309762954711914 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 8.700787544250488, Time 0.008078813552856445, Overall 0.15317440032958984 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 14.1765775680542, Time 0.010095357894897461, Overall 0.15519142150878906 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 3.54414439201355, Time 0.010173559188842773, Overall 0.15526962280273438 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 9.42677116394043, Time 0.01077127456665039, Overall 0.1558678150177002 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 9.42677116394043, Time 0.010846853256225586, Overall 0.1559429168701172 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 14.108482360839844, Time 0.012883663177490234, Overall 0.15797972679138184 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 3.527120590209961, Time 0.012966156005859375, Overall 0.15806221961975098 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 7.344514846801758, Time 0.013582706451416016, Overall 0.15867924690246582 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 7.344514846801758, Time 0.013660192489624023, Overall 0.15875625610351562 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 9.944671630859375, Time 0.015685558319091797, Overall 0.1607820987701416 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 2.4861679077148438, Time 0.015758514404296875, Overall 0.16085433959960938 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 11.793458938598633, Time 0.01634383201599121, Overall 0.16144013404846191 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 11.793458938598633, Time 0.016437292098999023, Overall 0.16153335571289062 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 7.9289751052856445, Time 0.018417835235595703, Overall 0.1635303497314453 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 1.9822437763214111, Time 0.018504858016967773, Overall 0.16360092163085938 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 12.551904678344727, Time 0.01908707618713379, Overall 0.1641833782196045 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 12.551904678344727, Time 0.01916193962097168, Overall 0.16425776481628418 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 7.125901699066162, Time 0.021160125732421875, Overall 0.16625690460205078 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 1.7814754247665405, Time 0.021235227584838867, Overall 0.16633152961730957 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 14.289322853088379, Time 0.021825551986694336, Overall 0.16692161560058594 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 14.289322853088379, Time 0.02190232276916504, Overall 0.16699814796447754 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 7.452751636505127, Time 0.02408885955810547, Overall 0.16918540000915527 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 1.8631879091262817, Time 0.02416253089904785, Overall 0.16925811767578125 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 12.100137710571289, Time 0.024784564971923828, Overall 0.16988086700439453 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 12.100137710571289, Time 0.024860620498657227, Overall 0.16995620727539062 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 21.408519744873047, Time 0.02688431739807129, Overall 0.1719803810119629 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 5.352129936218262, Time 0.026965618133544922, Overall 0.17206144332885742 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 9.878581047058105, Time 0.027588605880737305, Overall 0.1726851463317871 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 9.878581047058105, Time 0.027663707733154297, Overall 0.1727597713470459 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 8.557249069213867, Time 0.029638290405273438, Overall 0.17473483085632324 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 2.139312267303467, Time 0.02971363067626953, Overall 0.17480993270874023 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 15.772207260131836, Time 0.030299901962280273, Overall 0.17539620399475098 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 15.772207260131836, Time 0.030378341674804688, Overall 0.1754746437072754 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 20.26165199279785, Time 0.03237462043762207, Overall 0.17747092247009277 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 5.065412998199463, Time 0.03246569633483887, Overall 0.17756152153015137 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 17.312129974365234, Time 0.03305315971374512, Overall 0.17814946174621582 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 17.312129974365234, Time 0.03313136100769043, Overall 0.17822718620300293 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 0.6246523857116699, Time 0.03507113456726074, Overall 0.18016719818115234 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 0.15616309642791748, Time 0.03514385223388672, Overall 0.18023920059204102 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 16.662796020507812, Time 0.03575730323791504, Overall 0.18085360527038574 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 16.662796020507812, Time 0.035837650299072266, Overall 0.18093347549438477 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 16.27337074279785, Time 0.03783679008483887, Overall 0.18293309211730957 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 4.068342685699463, Time 0.037912845611572266, Overall 0.18300914764404297 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 18.453947067260742, Time 0.03852081298828125, Overall 0.18361735343933105 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 18.453947067260742, Time 0.03859543800354004, Overall 0.18369150161743164 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 17.39864158630371, Time 0.040613651275634766, Overall 0.18570995330810547 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 4.349660396575928, Time 0.04068875312805176, Overall 0.18578481674194336 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 11.397185325622559, Time 0.04127860069274902, Overall 0.18637490272521973 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 11.397185325622559, Time 0.041356563568115234, Overall 0.18645238876342773 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 16.983680725097656, Time 0.04331064224243164, Overall 0.18840694427490234 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 4.245920181274414, Time 0.043387413024902344, Overall 0.18848323822021484 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 15.353394508361816, Time 0.0439915657043457, Overall 0.1890876293182373 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 15.353394508361816, Time 0.044066667556762695, Overall 0.1891629695892334 \n",
            "Epoch    16: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 19.571727752685547, Time 0.04646873474121094, Overall 0.19156575202941895 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 4.892931938171387, Time 0.04653811454772949, Overall 0.1916344165802002 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 16.733802795410156, Time 0.04738140106201172, Overall 0.19247865676879883 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 16.733802795410156, Time 0.04749011993408203, Overall 0.19258713722229004 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 12.509761810302734, Time 0.04955339431762695, Overall 0.19464969635009766 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 3.1274404525756836, Time 0.049631357192993164, Overall 0.19472765922546387 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 16.245176315307617, Time 0.05024218559265137, Overall 0.19533872604370117 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 16.245176315307617, Time 0.05032157897949219, Overall 0.19541716575622559 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 10.59842586517334, Time 0.052324771881103516, Overall 0.19742131233215332 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 2.649606466293335, Time 0.052399635314941406, Overall 0.1974954605102539 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 14.011007308959961, Time 0.05301403999328613, Overall 0.19811010360717773 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 14.011007308959961, Time 0.05309104919433594, Overall 0.19818663597106934 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 10.42996883392334, Time 0.05519509315490723, Overall 0.20029115676879883 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 2.607492208480835, Time 0.05527186393737793, Overall 0.20036840438842773 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 13.532951354980469, Time 0.05587434768676758, Overall 0.20097041130065918 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 13.532951354980469, Time 0.05596041679382324, Overall 0.20105648040771484 \n",
            "It took 0.20196771621704102 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n",
            "Loading sparse matrices from ./../data/preprocessed/imdb/toy.title.basics.tsv/teamsvecs.pkl ...\n",
            "Loading indexes pickle from ./../data/preprocessed/imdb/toy.title.basics.tsv/indexes.pkl ...\n",
            "It took 8.392333984375e-05 seconds to load from the pickles.\n",
            "It took 0.0002994537353515625 seconds to load the sparse matrices.\n",
            "Loading the skill embedding pickle ...\n",
            "2022-03-04 05:28:59,722 : INFO : loading Doc2Vec object from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl\n",
            "2022-03-04 05:28:59,722 : INFO : loading vocabulary recursively from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl.vocabulary.* with mmap=None\n",
            "2022-03-04 05:28:59,722 : INFO : loading trainables recursively from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl.trainables.* with mmap=None\n",
            "2022-03-04 05:28:59,723 : INFO : loading wv recursively from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl.wv.* with mmap=None\n",
            "2022-03-04 05:28:59,723 : INFO : loading docvecs recursively from ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl.docvecs.* with mmap=None\n",
            "2022-03-04 05:28:59,723 : INFO : loaded ./../data/preprocessed/imdb/toy.title.basics.tsv/skill.emb.d100.w1.dm1.mdl\n",
            "/content/opentf/src/mdl/fnn.py:98: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  neg_idx = torch.nonzero(torch.tensor(neg_rands), as_tuple=True)[0]\n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 177.44537353515625, Time 0.011749744415283203, Overall 0.013112783432006836 \n",
            "Fold 0/2, Epoch 0/19, Running Loss train 59.148457845052086, Time 0.011878013610839844, Overall 0.013239860534667969 \n",
            "Fold 0/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 104.9969253540039, Time 0.020729780197143555, Overall 0.022092103958129883 \n",
            "Fold 0/2, Epoch 0/19, Running Loss valid 52.49846267700195, Time 0.020830392837524414, Overall 0.022191286087036133 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 116.69597625732422, Time 0.029870271682739258, Overall 0.031232118606567383 \n",
            "Fold 0/2, Epoch 1/19, Running Loss train 38.898658752441406, Time 0.029957294464111328, Overall 0.03131818771362305 \n",
            "Fold 0/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 106.08340454101562, Time 0.035085201263427734, Overall 0.03644728660583496 \n",
            "Fold 0/2, Epoch 1/19, Running Loss valid 53.04170227050781, Time 0.03517723083496094, Overall 0.036538124084472656 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 142.20498657226562, Time 0.043784141540527344, Overall 0.04514622688293457 \n",
            "Fold 0/2, Epoch 2/19, Running Loss train 47.40166219075521, Time 0.0438687801361084, Overall 0.04522991180419922 \n",
            "Fold 0/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 81.33821868896484, Time 0.04893803596496582, Overall 0.050299882888793945 \n",
            "Fold 0/2, Epoch 2/19, Running Loss valid 40.66910934448242, Time 0.04903459548950195, Overall 0.05039572715759277 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 137.81874084472656, Time 0.05742359161376953, Overall 0.05878496170043945 \n",
            "Fold 0/2, Epoch 3/19, Running Loss train 45.93958028157552, Time 0.057505130767822266, Overall 0.05886697769165039 \n",
            "Fold 0/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 112.0657958984375, Time 0.06216621398925781, Overall 0.06352758407592773 \n",
            "Fold 0/2, Epoch 3/19, Running Loss valid 56.03289794921875, Time 0.06225252151489258, Overall 0.0636134147644043 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 107.39189910888672, Time 0.07061219215393066, Overall 0.07197380065917969 \n",
            "Fold 0/2, Epoch 4/19, Running Loss train 35.79729970296224, Time 0.07068920135498047, Overall 0.07205009460449219 \n",
            "Fold 0/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 88.29478454589844, Time 0.0753786563873291, Overall 0.07674002647399902 \n",
            "Fold 0/2, Epoch 4/19, Running Loss valid 44.14739227294922, Time 0.07546830177307129, Overall 0.0768289566040039 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 94.01165008544922, Time 0.0838620662689209, Overall 0.08522367477416992 \n",
            "Fold 0/2, Epoch 5/19, Running Loss train 31.33721669514974, Time 0.08395218849182129, Overall 0.08531332015991211 \n",
            "Fold 0/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 144.73338317871094, Time 0.08872008323669434, Overall 0.09008169174194336 \n",
            "Fold 0/2, Epoch 5/19, Running Loss valid 72.36669158935547, Time 0.08881068229675293, Overall 0.09017157554626465 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 153.01698303222656, Time 0.09780454635620117, Overall 0.0991661548614502 \n",
            "Fold 0/2, Epoch 6/19, Running Loss train 51.00566101074219, Time 0.09790921211242676, Overall 0.09927010536193848 \n",
            "Fold 0/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 193.7552947998047, Time 0.1033484935760498, Overall 0.10471105575561523 \n",
            "Fold 0/2, Epoch 6/19, Running Loss valid 96.87764739990234, Time 0.10346484184265137, Overall 0.10482621192932129 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 87.720703125, Time 0.11575722694396973, Overall 0.11712026596069336 \n",
            "Fold 0/2, Epoch 7/19, Running Loss train 29.240234375, Time 0.11585712432861328, Overall 0.1172177791595459 \n",
            "Fold 0/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 120.17443084716797, Time 0.12088561058044434, Overall 0.12224745750427246 \n",
            "Fold 0/2, Epoch 7/19, Running Loss valid 60.087215423583984, Time 0.12098193168640137, Overall 0.12234306335449219 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 25.979341506958008, Time 0.1298673152923584, Overall 0.13123726844787598 \n",
            "Fold 0/2, Epoch 8/19, Running Loss train 8.659780502319336, Time 0.12996768951416016, Overall 0.13132882118225098 \n",
            "Fold 0/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 179.7688751220703, Time 0.1348865032196045, Overall 0.13624835014343262 \n",
            "Fold 0/2, Epoch 8/19, Running Loss valid 89.88443756103516, Time 0.13498258590698242, Overall 0.13634371757507324 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 74.29985046386719, Time 0.14371132850646973, Overall 0.14507317543029785 \n",
            "Fold 0/2, Epoch 9/19, Running Loss train 24.766616821289062, Time 0.14380121231079102, Overall 0.14516234397888184 \n",
            "Fold 0/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 147.40487670898438, Time 0.1488628387451172, Overall 0.1502244472503662 \n",
            "Fold 0/2, Epoch 9/19, Running Loss valid 73.70243835449219, Time 0.14896464347839355, Overall 0.15032577514648438 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 42.73161697387695, Time 0.1577739715576172, Overall 0.1591355800628662 \n",
            "Fold 0/2, Epoch 10/19, Running Loss train 14.24387232462565, Time 0.15786194801330566, Overall 0.15922331809997559 \n",
            "Fold 0/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 183.22549438476562, Time 0.16309642791748047, Overall 0.1644585132598877 \n",
            "Fold 0/2, Epoch 10/19, Running Loss valid 91.61274719238281, Time 0.1631927490234375, Overall 0.16455388069152832 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 29.381481170654297, Time 0.17173504829406738, Overall 0.1730971336364746 \n",
            "Fold 0/2, Epoch 11/19, Running Loss train 9.793827056884766, Time 0.17182183265686035, Overall 0.17318272590637207 \n",
            "Fold 0/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 184.6741943359375, Time 0.17658591270446777, Overall 0.1779472827911377 \n",
            "Fold 0/2, Epoch 11/19, Running Loss valid 92.33709716796875, Time 0.17667031288146973, Overall 0.17803144454956055 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 30.559093475341797, Time 0.1850452423095703, Overall 0.18640685081481934 \n",
            "Fold 0/2, Epoch 12/19, Running Loss train 10.1863644917806, Time 0.18513774871826172, Overall 0.18649888038635254 \n",
            "Fold 0/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 220.49916076660156, Time 0.18985724449157715, Overall 0.19121861457824707 \n",
            "Fold 0/2, Epoch 12/19, Running Loss valid 110.24958038330078, Time 0.1899425983428955, Overall 0.19130349159240723 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 48.30070114135742, Time 0.19870853424072266, Overall 0.20007085800170898 \n",
            "Fold 0/2, Epoch 13/19, Running Loss train 16.10023371378581, Time 0.19879770278930664, Overall 0.20015883445739746 \n",
            "Fold 0/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 184.85479736328125, Time 0.20366740226745605, Overall 0.20502877235412598 \n",
            "Fold 0/2, Epoch 13/19, Running Loss valid 92.42739868164062, Time 0.20375680923461914, Overall 0.20511770248413086 \n",
            "Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 56.572113037109375, Time 0.21291589736938477, Overall 0.2142772674560547 \n",
            "Fold 0/2, Epoch 14/19, Running Loss train 18.857371012369793, Time 0.2129981517791748, Overall 0.21435880661010742 \n",
            "Fold 0/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 168.908935546875, Time 0.21773195266723633, Overall 0.21909356117248535 \n",
            "Fold 0/2, Epoch 14/19, Running Loss valid 84.4544677734375, Time 0.2178189754486084, Overall 0.21918010711669922 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 60.33464431762695, Time 0.2263014316558838, Overall 0.2276628017425537 \n",
            "Fold 0/2, Epoch 15/19, Running Loss train 20.111548105875652, Time 0.22639250755310059, Overall 0.2277534008026123 \n",
            "Fold 0/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 150.388427734375, Time 0.2312605381011963, Overall 0.23262238502502441 \n",
            "Fold 0/2, Epoch 15/19, Running Loss valid 75.1942138671875, Time 0.23135805130004883, Overall 0.23273372650146484 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 33.725685119628906, Time 0.23995637893676758, Overall 0.2413179874420166 \n",
            "Fold 0/2, Epoch 16/19, Running Loss train 11.241895039876303, Time 0.24004459381103516, Overall 0.24140596389770508 \n",
            "Fold 0/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 186.1919708251953, Time 0.2448256015777588, Overall 0.2461869716644287 \n",
            "Fold 0/2, Epoch 16/19, Running Loss valid 93.09598541259766, Time 0.2449204921722412, Overall 0.24628114700317383 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 84.26667785644531, Time 0.2566952705383301, Overall 0.2580573558807373 \n",
            "Fold 0/2, Epoch 17/19, Running Loss train 28.088892618815105, Time 0.2567896842956543, Overall 0.2581510543823242 \n",
            "Fold 0/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 167.1018829345703, Time 0.2643861770629883, Overall 0.2657489776611328 \n",
            "Fold 0/2, Epoch 17/19, Running Loss valid 83.55094146728516, Time 0.26450014114379883, Overall 0.26586174964904785 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 67.44584655761719, Time 0.27431249618530273, Overall 0.27567410469055176 \n",
            "Fold 0/2, Epoch 18/19, Running Loss train 22.481948852539062, Time 0.274397611618042, Overall 0.2757585048675537 \n",
            "Fold 0/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 226.41604614257812, Time 0.279371976852417, Overall 0.2807333469390869 \n",
            "Fold 0/2, Epoch 18/19, Running Loss valid 113.20802307128906, Time 0.2794632911682129, Overall 0.2808244228363037 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 56.681732177734375, Time 0.28797364234924316, Overall 0.2893350124359131 \n",
            "Fold 0/2, Epoch 19/19, Running Loss train 18.893910725911457, Time 0.2880728244781494, Overall 0.28943419456481934 \n",
            "Fold 0/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 193.0804901123047, Time 0.2933981418609619, Overall 0.29476046562194824 \n",
            "Fold 0/2, Epoch 19/19, Running Loss valid 96.54024505615234, Time 0.29352283477783203, Overall 0.2948949337005615 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 134.6439666748047, Time 0.007748603820800781, Overall 0.30573272705078125 \n",
            "Fold 1/2, Epoch 0/19, Running Loss train 44.8813222249349, Time 0.007847785949707031, Overall 0.3058319091796875 \n",
            "Fold 1/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 119.81596374511719, Time 0.013702154159545898, Overall 0.31168699264526367 \n",
            "Fold 1/2, Epoch 0/19, Running Loss valid 59.907981872558594, Time 0.013804912567138672, Overall 0.31178903579711914 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 179.365478515625, Time 0.02835679054260254, Overall 0.3263416290283203 \n",
            "Fold 1/2, Epoch 1/19, Running Loss train 59.788492838541664, Time 0.02845144271850586, Overall 0.326434850692749 \n",
            "Fold 1/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 146.49461364746094, Time 0.03553462028503418, Overall 0.33351874351501465 \n",
            "Fold 1/2, Epoch 1/19, Running Loss valid 73.24730682373047, Time 0.035640716552734375, Overall 0.33362412452697754 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 182.90762329101562, Time 0.044545650482177734, Overall 0.3425302505493164 \n",
            "Fold 1/2, Epoch 2/19, Running Loss train 60.969207763671875, Time 0.04463768005371094, Overall 0.3426210880279541 \n",
            "Fold 1/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 108.89891052246094, Time 0.04935097694396973, Overall 0.3473348617553711 \n",
            "Fold 1/2, Epoch 2/19, Running Loss valid 54.44945526123047, Time 0.04943990707397461, Overall 0.3474233150482178 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 211.67120361328125, Time 0.05833792686462402, Overall 0.3563220500946045 \n",
            "Fold 1/2, Epoch 3/19, Running Loss train 70.55706787109375, Time 0.05843186378479004, Overall 0.3564152717590332 \n",
            "Fold 1/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 144.79859924316406, Time 0.06440401077270508, Overall 0.36238765716552734 \n",
            "Fold 1/2, Epoch 3/19, Running Loss valid 72.39929962158203, Time 0.06449151039123535, Overall 0.3624746799468994 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 126.98641967773438, Time 0.07312512397766113, Overall 0.3711094856262207 \n",
            "Fold 1/2, Epoch 4/19, Running Loss train 42.32880655924479, Time 0.07321476936340332, Overall 0.3711977005004883 \n",
            "Fold 1/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 150.51803588867188, Time 0.07803225517272949, Overall 0.37601613998413086 \n",
            "Fold 1/2, Epoch 4/19, Running Loss valid 75.25901794433594, Time 0.07812738418579102, Overall 0.3761107921600342 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 98.41445922851562, Time 0.0866246223449707, Overall 0.38460850715637207 \n",
            "Fold 1/2, Epoch 5/19, Running Loss train 32.80481974283854, Time 0.0867166519165039, Overall 0.38470005989074707 \n",
            "Fold 1/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 96.48518371582031, Time 0.0917813777923584, Overall 0.38976526260375977 \n",
            "Fold 1/2, Epoch 5/19, Running Loss valid 48.242591857910156, Time 0.09192061424255371, Overall 0.3899040222167969 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 60.15469741821289, Time 0.1003568172454834, Overall 0.39834094047546387 \n",
            "Fold 1/2, Epoch 6/19, Running Loss train 20.051565806070965, Time 0.10044097900390625, Overall 0.3984243869781494 \n",
            "Fold 1/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 143.73614501953125, Time 0.10512328147888184, Overall 0.4031074047088623 \n",
            "Fold 1/2, Epoch 6/19, Running Loss valid 71.86807250976562, Time 0.1052093505859375, Overall 0.40319299697875977 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 91.19586181640625, Time 0.11461019515991211, Overall 0.4125940799713135 \n",
            "Fold 1/2, Epoch 7/19, Running Loss train 30.39862060546875, Time 0.1146993637084961, Overall 0.41268253326416016 \n",
            "Fold 1/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 172.74203491210938, Time 0.11964035034179688, Overall 0.41762423515319824 \n",
            "Fold 1/2, Epoch 7/19, Running Loss valid 86.37101745605469, Time 0.11973166465759277, Overall 0.41771483421325684 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 65.93112182617188, Time 0.12839531898498535, Overall 0.4263789653778076 \n",
            "Fold 1/2, Epoch 8/19, Running Loss train 21.977040608723957, Time 0.12848424911499023, Overall 0.4264676570892334 \n",
            "Fold 1/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 126.44061279296875, Time 0.13334321975708008, Overall 0.43132758140563965 \n",
            "Fold 1/2, Epoch 8/19, Running Loss valid 63.220306396484375, Time 0.13343238830566406, Overall 0.4314157962799072 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 112.19284057617188, Time 0.14332890510559082, Overall 0.4413132667541504 \n",
            "Fold 1/2, Epoch 9/19, Running Loss train 37.397613525390625, Time 0.14346694946289062, Overall 0.4414513111114502 \n",
            "Fold 1/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 176.4554443359375, Time 0.14946937561035156, Overall 0.44745326042175293 \n",
            "Fold 1/2, Epoch 9/19, Running Loss valid 88.22772216796875, Time 0.149566650390625, Overall 0.44755005836486816 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 89.25654602050781, Time 0.15837907791137695, Overall 0.4563636779785156 \n",
            "Fold 1/2, Epoch 10/19, Running Loss train 29.752182006835938, Time 0.15845966339111328, Overall 0.45644307136535645 \n",
            "Fold 1/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 134.22323608398438, Time 0.16327500343322754, Overall 0.461259126663208 \n",
            "Fold 1/2, Epoch 10/19, Running Loss valid 67.11161804199219, Time 0.16336512565612793, Overall 0.461348295211792 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 47.97418975830078, Time 0.17189836502075195, Overall 0.4698824882507324 \n",
            "Fold 1/2, Epoch 11/19, Running Loss train 15.99139658610026, Time 0.17200851440429688, Overall 0.46999192237854004 \n",
            "Fold 1/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 154.2019500732422, Time 0.1769418716430664, Overall 0.47492527961730957 \n",
            "Fold 1/2, Epoch 11/19, Running Loss valid 77.1009750366211, Time 0.17703652381896973, Overall 0.4750196933746338 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 70.27954864501953, Time 0.18562102317810059, Overall 0.48360514640808105 \n",
            "Fold 1/2, Epoch 12/19, Running Loss train 23.42651621500651, Time 0.18571019172668457, Overall 0.48369359970092773 \n",
            "Fold 1/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 201.6096954345703, Time 0.19057273864746094, Overall 0.4885568618774414 \n",
            "Fold 1/2, Epoch 12/19, Running Loss valid 100.80484771728516, Time 0.19066834449768066, Overall 0.4886512756347656 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 60.53083419799805, Time 0.19928956031799316, Overall 0.49727368354797363 \n",
            "Fold 1/2, Epoch 13/19, Running Loss train 20.176944732666016, Time 0.19937539100646973, Overall 0.4973585605621338 \n",
            "Fold 1/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 191.0591583251953, Time 0.20429515838623047, Overall 0.5022788047790527 \n",
            "Fold 1/2, Epoch 13/19, Running Loss valid 95.52957916259766, Time 0.20438265800476074, Overall 0.5023660659790039 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 42.816402435302734, Time 0.21306204795837402, Overall 0.5110471248626709 \n",
            "Fold 1/2, Epoch 14/19, Running Loss train 14.272134145100912, Time 0.21314787864685059, Overall 0.511131763458252 \n",
            "Fold 1/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 180.95375061035156, Time 0.21816706657409668, Overall 0.516150951385498 \n",
            "Fold 1/2, Epoch 14/19, Running Loss valid 90.47687530517578, Time 0.21827220916748047, Overall 0.5162553787231445 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 42.84201431274414, Time 0.22690033912658691, Overall 0.5249021053314209 \n",
            "Fold 1/2, Epoch 15/19, Running Loss train 14.28067143758138, Time 0.22700929641723633, Overall 0.5249924659729004 \n",
            "Fold 1/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 180.3522186279297, Time 0.23192477226257324, Overall 0.5299086570739746 \n",
            "Fold 1/2, Epoch 15/19, Running Loss valid 90.17610931396484, Time 0.23201823234558105, Overall 0.5300014019012451 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 73.51598358154297, Time 0.2405698299407959, Overall 0.5385537147521973 \n",
            "Fold 1/2, Epoch 16/19, Running Loss train 24.505327860514324, Time 0.24065470695495605, Overall 0.5386381149291992 \n",
            "Fold 1/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 156.46229553222656, Time 0.24542689323425293, Overall 0.5434107780456543 \n",
            "Fold 1/2, Epoch 16/19, Running Loss valid 78.23114776611328, Time 0.2455143928527832, Overall 0.5434978008270264 \n",
            "Epoch    17: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 70.57200622558594, Time 0.2540273666381836, Overall 0.5520110130310059 \n",
            "Fold 1/2, Epoch 17/19, Running Loss train 23.524002075195312, Time 0.2541072368621826, Overall 0.552091121673584 \n",
            "Fold 1/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 174.23965454101562, Time 0.2588791847229004, Overall 0.5568628311157227 \n",
            "Fold 1/2, Epoch 17/19, Running Loss valid 87.11982727050781, Time 0.2589848041534424, Overall 0.5569684505462646 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 56.78665542602539, Time 0.2673652172088623, Overall 0.5653491020202637 \n",
            "Fold 1/2, Epoch 18/19, Running Loss train 18.928885142008465, Time 0.2674527168273926, Overall 0.5654358863830566 \n",
            "Fold 1/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 162.47628784179688, Time 0.2721850872039795, Overall 0.5701689720153809 \n",
            "Fold 1/2, Epoch 18/19, Running Loss valid 81.23814392089844, Time 0.2722785472869873, Overall 0.5702614784240723 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 77.61183166503906, Time 0.28069543838500977, Overall 0.5786795616149902 \n",
            "Fold 1/2, Epoch 19/19, Running Loss train 25.87061055501302, Time 0.28078460693359375, Overall 0.5787689685821533 \n",
            "Fold 1/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 264.0872497558594, Time 0.28557252883911133, Overall 0.5835564136505127 \n",
            "Fold 1/2, Epoch 19/19, Running Loss valid 132.0436248779297, Time 0.2856612205505371, Overall 0.5836443901062012 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase train, Running Loss train 172.86056518554688, Time 0.007709503173828125, Overall 0.5943076610565186 \n",
            "Fold 2/2, Epoch 0/19, Running Loss train 43.21514129638672, Time 0.0077991485595703125, Overall 0.5943965911865234 \n",
            "Fold 2/2, Epoch 0/19, Minibatch 0/0, Phase valid, Running Loss valid 61.495513916015625, Time 0.012599468231201172, Overall 0.5991973876953125 \n",
            "Fold 2/2, Epoch 0/19, Running Loss valid 61.495513916015625, Time 0.0126953125, Overall 0.599292516708374 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase train, Running Loss train 238.7032928466797, Time 0.021565914154052734, Overall 0.6081638336181641 \n",
            "Fold 2/2, Epoch 1/19, Running Loss train 59.67582321166992, Time 0.021657943725585938, Overall 0.60825514793396 \n",
            "Fold 2/2, Epoch 1/19, Minibatch 0/0, Phase valid, Running Loss valid 56.358272552490234, Time 0.027092695236206055, Overall 0.6136915683746338 \n",
            "Fold 2/2, Epoch 1/19, Running Loss valid 56.358272552490234, Time 0.027199506759643555, Overall 0.6137971878051758 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase train, Running Loss train 164.607666015625, Time 0.04201769828796387, Overall 0.6286163330078125 \n",
            "Fold 2/2, Epoch 2/19, Running Loss train 41.15191650390625, Time 0.042128801345825195, Overall 0.6287269592285156 \n",
            "Fold 2/2, Epoch 2/19, Minibatch 0/0, Phase valid, Running Loss valid 56.020172119140625, Time 0.04725456237792969, Overall 0.6338522434234619 \n",
            "Fold 2/2, Epoch 2/19, Running Loss valid 56.020172119140625, Time 0.04735445976257324, Overall 0.6339516639709473 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase train, Running Loss train 232.95985412597656, Time 0.056397438049316406, Overall 0.6429951190948486 \n",
            "Fold 2/2, Epoch 3/19, Running Loss train 58.23996353149414, Time 0.05648159980773926, Overall 0.6430785655975342 \n",
            "Fold 2/2, Epoch 3/19, Minibatch 0/0, Phase valid, Running Loss valid 57.229835510253906, Time 0.061031341552734375, Overall 0.6476292610168457 \n",
            "Fold 2/2, Epoch 3/19, Running Loss valid 57.229835510253906, Time 0.06112217903137207, Overall 0.647719144821167 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase train, Running Loss train 153.38121032714844, Time 0.06999349594116211, Overall 0.6565914154052734 \n",
            "Fold 2/2, Epoch 4/19, Running Loss train 38.34530258178711, Time 0.07007479667663574, Overall 0.6566720008850098 \n",
            "Fold 2/2, Epoch 4/19, Minibatch 0/0, Phase valid, Running Loss valid 74.46890258789062, Time 0.07467222213745117, Overall 0.6612699031829834 \n",
            "Fold 2/2, Epoch 4/19, Running Loss valid 74.46890258789062, Time 0.07475519180297852, Overall 0.6613521575927734 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase train, Running Loss train 150.65771484375, Time 0.08335018157958984, Overall 0.6699488162994385 \n",
            "Fold 2/2, Epoch 5/19, Running Loss train 37.6644287109375, Time 0.08343505859375, Overall 0.6700325012207031 \n",
            "Fold 2/2, Epoch 5/19, Minibatch 0/0, Phase valid, Running Loss valid 56.64616775512695, Time 0.08795404434204102, Overall 0.6745519638061523 \n",
            "Fold 2/2, Epoch 5/19, Running Loss valid 56.64616775512695, Time 0.088043212890625, Overall 0.6746406555175781 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase train, Running Loss train 144.879150390625, Time 0.0966649055480957, Overall 0.6832630634307861 \n",
            "Fold 2/2, Epoch 6/19, Running Loss train 36.21978759765625, Time 0.09675216674804688, Overall 0.6833498477935791 \n",
            "Fold 2/2, Epoch 6/19, Minibatch 0/0, Phase valid, Running Loss valid 75.64248657226562, Time 0.10123085975646973, Overall 0.687828779220581 \n",
            "Fold 2/2, Epoch 6/19, Running Loss valid 75.64248657226562, Time 0.10133552551269531, Overall 0.6879332065582275 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase train, Running Loss train 86.31511688232422, Time 0.1099545955657959, Overall 0.6965525150299072 \n",
            "Fold 2/2, Epoch 7/19, Running Loss train 21.578779220581055, Time 0.11004233360290527, Overall 0.6966400146484375 \n",
            "Fold 2/2, Epoch 7/19, Minibatch 0/0, Phase valid, Running Loss valid 89.75019836425781, Time 0.11455035209655762, Overall 0.7011487483978271 \n",
            "Fold 2/2, Epoch 7/19, Running Loss valid 89.75019836425781, Time 0.11465048789978027, Overall 0.7012476921081543 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase train, Running Loss train 84.934326171875, Time 0.12347817420959473, Overall 0.710075855255127 \n",
            "Fold 2/2, Epoch 8/19, Running Loss train 21.23358154296875, Time 0.1235649585723877, Overall 0.7101619243621826 \n",
            "Fold 2/2, Epoch 8/19, Minibatch 0/0, Phase valid, Running Loss valid 78.14482116699219, Time 0.12877392768859863, Overall 0.7153720855712891 \n",
            "Fold 2/2, Epoch 8/19, Running Loss valid 78.14482116699219, Time 0.12886953353881836, Overall 0.7154667377471924 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase train, Running Loss train 163.0548095703125, Time 0.13803434371948242, Overall 0.724632978439331 \n",
            "Fold 2/2, Epoch 9/19, Running Loss train 40.763702392578125, Time 0.1381361484527588, Overall 0.7247335910797119 \n",
            "Fold 2/2, Epoch 9/19, Minibatch 0/0, Phase valid, Running Loss valid 128.84295654296875, Time 0.14391517639160156, Overall 0.7305145263671875 \n",
            "Fold 2/2, Epoch 9/19, Running Loss valid 128.84295654296875, Time 0.1440131664276123, Overall 0.7306110858917236 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase train, Running Loss train 81.20283508300781, Time 0.1533198356628418, Overall 0.739917516708374 \n",
            "Fold 2/2, Epoch 10/19, Running Loss train 20.300708770751953, Time 0.15339875221252441, Overall 0.7399961948394775 \n",
            "Fold 2/2, Epoch 10/19, Minibatch 0/0, Phase valid, Running Loss valid 74.84832763671875, Time 0.1578834056854248, Overall 0.744481086730957 \n",
            "Fold 2/2, Epoch 10/19, Running Loss valid 74.84832763671875, Time 0.15797066688537598, Overall 0.7445681095123291 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase train, Running Loss train 77.09957885742188, Time 0.1666395664215088, Overall 0.7532377243041992 \n",
            "Fold 2/2, Epoch 11/19, Running Loss train 19.27489471435547, Time 0.16672706604003906, Overall 0.7533245086669922 \n",
            "Fold 2/2, Epoch 11/19, Minibatch 0/0, Phase valid, Running Loss valid 71.31852722167969, Time 0.17195439338684082, Overall 0.7585532665252686 \n",
            "Fold 2/2, Epoch 11/19, Running Loss valid 71.31852722167969, Time 0.17206048965454102, Overall 0.7586586475372314 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase train, Running Loss train 119.45675659179688, Time 0.1818249225616455, Overall 0.7684226036071777 \n",
            "Fold 2/2, Epoch 12/19, Running Loss train 29.86418914794922, Time 0.1819162368774414, Overall 0.7685132026672363 \n",
            "Fold 2/2, Epoch 12/19, Minibatch 0/0, Phase valid, Running Loss valid 87.80877685546875, Time 0.1865828037261963, Overall 0.7731807231903076 \n",
            "Fold 2/2, Epoch 12/19, Running Loss valid 87.80877685546875, Time 0.18668341636657715, Overall 0.7732808589935303 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase train, Running Loss train 94.174560546875, Time 0.1955738067626953, Overall 0.7821717262268066 \n",
            "Fold 2/2, Epoch 13/19, Running Loss train 23.54364013671875, Time 0.19567179679870605, Overall 0.7822697162628174 \n",
            "Fold 2/2, Epoch 13/19, Minibatch 0/0, Phase valid, Running Loss valid 125.71942138671875, Time 0.20022797584533691, Overall 0.7868256568908691 \n",
            "Fold 2/2, Epoch 13/19, Running Loss valid 125.71942138671875, Time 0.2003321647644043, Overall 0.7869293689727783 \n",
            "Epoch    14: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase train, Running Loss train 95.54637145996094, Time 0.20910954475402832, Overall 0.7957074642181396 \n",
            "Fold 2/2, Epoch 14/19, Running Loss train 23.886592864990234, Time 0.20919370651245117, Overall 0.7957911491394043 \n",
            "Fold 2/2, Epoch 14/19, Minibatch 0/0, Phase valid, Running Loss valid 97.98548126220703, Time 0.21367573738098145, Overall 0.8002736568450928 \n",
            "Fold 2/2, Epoch 14/19, Running Loss valid 97.98548126220703, Time 0.21376490592956543, Overall 0.8003625869750977 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase train, Running Loss train 78.5185546875, Time 0.2225637435913086, Overall 0.8091614246368408 \n",
            "Fold 2/2, Epoch 15/19, Running Loss train 19.629638671875, Time 0.22265100479125977, Overall 0.8092482089996338 \n",
            "Fold 2/2, Epoch 15/19, Minibatch 0/0, Phase valid, Running Loss valid 98.54474639892578, Time 0.22751355171203613, Overall 0.8141114711761475 \n",
            "Fold 2/2, Epoch 15/19, Running Loss valid 98.54474639892578, Time 0.2276015281677246, Overall 0.8141987323760986 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase train, Running Loss train 82.19507598876953, Time 0.23624110221862793, Overall 0.8228390216827393 \n",
            "Fold 2/2, Epoch 16/19, Running Loss train 20.548768997192383, Time 0.23633766174316406, Overall 0.8229351043701172 \n",
            "Fold 2/2, Epoch 16/19, Minibatch 0/0, Phase valid, Running Loss valid 95.62377166748047, Time 0.24085712432861328, Overall 0.8274550437927246 \n",
            "Fold 2/2, Epoch 16/19, Running Loss valid 95.62377166748047, Time 0.24094843864440918, Overall 0.8275458812713623 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase train, Running Loss train 71.4222412109375, Time 0.24972891807556152, Overall 0.8363265991210938 \n",
            "Fold 2/2, Epoch 17/19, Running Loss train 17.855560302734375, Time 0.2498188018798828, Overall 0.8364160060882568 \n",
            "Fold 2/2, Epoch 17/19, Minibatch 0/0, Phase valid, Running Loss valid 112.08317565917969, Time 0.25433778762817383, Overall 0.8409357070922852 \n",
            "Fold 2/2, Epoch 17/19, Running Loss valid 112.08317565917969, Time 0.2544248104095459, Overall 0.8410220146179199 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase train, Running Loss train 44.908870697021484, Time 0.26312732696533203, Overall 0.8497254848480225 \n",
            "Fold 2/2, Epoch 18/19, Running Loss train 11.227217674255371, Time 0.2632172107696533, Overall 0.8498144149780273 \n",
            "Fold 2/2, Epoch 18/19, Minibatch 0/0, Phase valid, Running Loss valid 69.69280242919922, Time 0.267864465713501, Overall 0.8544621467590332 \n",
            "Fold 2/2, Epoch 18/19, Running Loss valid 69.69280242919922, Time 0.26795387268066406, Overall 0.8545513153076172 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase train, Running Loss train 84.4041976928711, Time 0.2767188549041748, Overall 0.8633167743682861 \n",
            "Fold 2/2, Epoch 19/19, Running Loss train 21.101049423217773, Time 0.2768058776855469, Overall 0.8634033203125 \n",
            "Fold 2/2, Epoch 19/19, Minibatch 0/0, Phase valid, Running Loss valid 123.36332702636719, Time 0.28158140182495117, Overall 0.8681802749633789 \n",
            "Fold 2/2, Epoch 19/19, Running Loss valid 123.36332702636719, Time 0.28169727325439453, Overall 0.8682947158813477 \n",
            "It took 0.8701348304748535 to train the model.\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Building pytrec_eval input for 1 instances ...\n",
            "Evaluating {'P_2,5,10', 'recall_2,5,10', 'ndcg_cut_2,5,10', 'map_cut_2,5,10'} ...\n",
            "Averaging ...\n",
            "Figure(640x480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benchmark Output Folder on `dblp` and `imdb` for Baselines**"
      ],
      "metadata": {
        "id": "-Q06TnofpXeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/toy.dblp.v12.json/\n",
        "!ls ../output/toy.title.basics.tsv/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ion5hv6viDa2",
        "outputId": "1f781217-4f15-491a-99e9-73aa2c123414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bnn  bnn_emb  fnn  fnn_emb  random\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's look at the Bayesian (bnn) Results for `dblp`**\n",
        "\n",
        "```\n",
        "#team:31, #skills:11, #members:13\n",
        "layers:[100], learning rate:0.1, batch size:4096, epoch:20, \n",
        "#negative samples:2, negative sampling: unigram_b, elbo samples:1\n",
        "```"
      ],
      "metadata": {
        "id": "AMe6O86CpuPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ../output/toy.dblp.v12.json/bnn/t31.s11.m13.l[100].lr0.1.b4096.e20.nns2.nsunigram_b.s1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5P-YCCFkAkg",
        "outputId": "44544bd3-b696-46db-b4f1-fdcb7d89e097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f0.test.pred\t\t    state_dict_model.f1.e15.pt\n",
            "f0.test.pred.eval.mean.csv  state_dict_model.f1.e16.pt\n",
            "f0.test.pred.eval.roc.pkl   state_dict_model.f1.e17.pt\n",
            "f0.train_valid_loss.png     state_dict_model.f1.e18.pt\n",
            "f1.test.pred\t\t    state_dict_model.f1.e19.pt\n",
            "f1.test.pred.eval.mean.csv  state_dict_model.f1.e1.pt\n",
            "f1.test.pred.eval.roc.pkl   state_dict_model.f1.e2.pt\n",
            "f1.train_valid_loss.png     state_dict_model.f1.e3.pt\n",
            "f2.test.pred\t\t    state_dict_model.f1.e4.pt\n",
            "f2.test.pred.eval.mean.csv  state_dict_model.f1.e5.pt\n",
            "f2.test.pred.eval.roc.pkl   state_dict_model.f1.e6.pt\n",
            "f2.train_valid_loss.png     state_dict_model.f1.e7.pt\n",
            "state_dict_model.f0.e0.pt   state_dict_model.f1.e8.pt\n",
            "state_dict_model.f0.e10.pt  state_dict_model.f1.e9.pt\n",
            "state_dict_model.f0.e11.pt  state_dict_model_f1.pt\n",
            "state_dict_model.f0.e12.pt  state_dict_model.f2.e0.pt\n",
            "state_dict_model.f0.e13.pt  state_dict_model.f2.e10.pt\n",
            "state_dict_model.f0.e14.pt  state_dict_model.f2.e11.pt\n",
            "state_dict_model.f0.e15.pt  state_dict_model.f2.e12.pt\n",
            "state_dict_model.f0.e16.pt  state_dict_model.f2.e13.pt\n",
            "state_dict_model.f0.e17.pt  state_dict_model.f2.e14.pt\n",
            "state_dict_model.f0.e18.pt  state_dict_model.f2.e15.pt\n",
            "state_dict_model.f0.e19.pt  state_dict_model.f2.e16.pt\n",
            "state_dict_model.f0.e1.pt   state_dict_model.f2.e17.pt\n",
            "state_dict_model.f0.e2.pt   state_dict_model.f2.e18.pt\n",
            "state_dict_model.f0.e3.pt   state_dict_model.f2.e19.pt\n",
            "state_dict_model.f0.e4.pt   state_dict_model.f2.e1.pt\n",
            "state_dict_model.f0.e5.pt   state_dict_model.f2.e2.pt\n",
            "state_dict_model.f0.e6.pt   state_dict_model.f2.e3.pt\n",
            "state_dict_model.f0.e7.pt   state_dict_model.f2.e4.pt\n",
            "state_dict_model.f0.e8.pt   state_dict_model.f2.e5.pt\n",
            "state_dict_model.f0.e9.pt   state_dict_model.f2.e6.pt\n",
            "state_dict_model_f0.pt\t    state_dict_model.f2.e7.pt\n",
            "state_dict_model.f1.e0.pt   state_dict_model.f2.e8.pt\n",
            "state_dict_model.f1.e10.pt  state_dict_model.f2.e9.pt\n",
            "state_dict_model.f1.e11.pt  state_dict_model_f2.pt\n",
            "state_dict_model.f1.e12.pt  test.pred.eval.mean.csv\n",
            "state_dict_model.f1.e13.pt  test.roc.png\n",
            "state_dict_model.f1.e14.pt  train_valid_loss.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC Plot for 3-Fold Cross-Validated Models on Test Set**"
      ],
      "metadata": {
        "id": "KhtwppXbrEEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('../output/toy.dblp.v12.json/bnn/t31.s11.m13.l[100].lr0.1.b4096.e20.nns2.nsunigram_b.s1/test.roc.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "-75NPqckkbGm",
        "outputId": "b543bb82-7a68-4bc9-a509-34efc1f5667e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('../output/toy.dblp.v12.json/bnn/t31.s11.m13.l[100].lr0.1.b4096.e20.nns2.nsunigram_b.s1/test.pred.eval.mean.csv', index_col = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "bdooeMNexjjl",
        "outputId": "3e070546-d40e-4efa-ce94-5a85abaa08a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6833bc74-df16-45bd-9f0d-55d43cec74a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>P_2</th>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_5</th>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P_10</th>\n",
              "      <td>0.233333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_2</th>\n",
              "      <td>0.072222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_5</th>\n",
              "      <td>0.388889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall_10</th>\n",
              "      <td>0.877778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_2</th>\n",
              "      <td>0.077371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_5</th>\n",
              "      <td>0.253334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ndcg_cut_10</th>\n",
              "      <td>0.464721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_2</th>\n",
              "      <td>0.036111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_5</th>\n",
              "      <td>0.143426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>map_cut_10</th>\n",
              "      <td>0.279246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aucroc</th>\n",
              "      <td>0.631657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6833bc74-df16-45bd-9f0d-55d43cec74a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6833bc74-df16-45bd-9f0d-55d43cec74a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6833bc74-df16-45bd-9f0d-55d43cec74a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 mean\n",
              "P_2          0.100000\n",
              "P_5          0.200000\n",
              "P_10         0.233333\n",
              "recall_2     0.072222\n",
              "recall_5     0.388889\n",
              "recall_10    0.877778\n",
              "ndcg_cut_2   0.077371\n",
              "ndcg_cut_5   0.253334\n",
              "ndcg_cut_10  0.464721\n",
              "map_cut_2    0.036111\n",
              "map_cut_5    0.143426\n",
              "map_cut_10   0.279246\n",
              "aucroc       0.631657"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}