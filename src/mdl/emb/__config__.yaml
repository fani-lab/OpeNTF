dim: 128 # embedding dim. it matters for skill vectors if the skill set is small (e.g., in imdb or gith) or large (e.g., in dblp or uspt)

model:
  batch_size: 1000 # batch_size for loaders
  epochs: 100 # num max epochs
  ns: 5 # number of negative samples for each positive sample
  lr: 0.001 #learning rate
  es: 5 # earlystopping's patience. to bypass, set it to a higher value than epoch
  spe: # will be overriden dynamically in ./src/main.py from root ./config.yml

  # Quoc V. Le, Tomás Mikolov: Distributed Representations of Sentences and Documents. ICML 2014: 1188-1196
  d2v: # we use gensim
    embtype: skill # skill, member, skillmember, skilltime
    dm: 1 # training algorithm. 1: distributed memory (PV-DM), 0: distributed bag of words (PV-DBOW)
    # NOTE: As the input is a skill subset, so either the sum/avg of skill vectors individually >> embtype = 'skill' or 'joint' and  dbow_words = True
    # OR the team vecs when the words are only skills. So, embtype = 'skill' and  dbow_words = False
    # let's remove this and do for always
    # dbow_words: True # train word-vectors in skip-gram fashion; 0: no (default, faster), 1: yes.
    w: 5 # cooccurrence window. In OpeNTF (for teams), depends on the average team size (n_members) plus n_skills per teams
    d: ${dim}
    e: ${model.epochs}
    lr: ${model.lr}
    spe: ${model.spe}

  gnn:
    graph:
      structure: #hydra doesn't understand tuple. So, inside code, explicit cast to tuple(...)
        #[[[member, to, member]], m] # looks like hetero but homo to have consistent pipleline for both types
        #[[[skill, to, member]], sm] #hetero
        [[[skill, to, team], [member, to, team]], stm]
        #[[[skill, to, team], [member, to, team], [loc, to, team]], stml]
        #[[[skill, to, skill], [skill, to, team], [member, to, team], [loc, to, team]], sstml]

      dup_edge: #https://pytorch-geometric.readthedocs.io/en/2.6.1/generated/torch_geometric.transforms.ToUndirected.html
        # if not set, keep the duplicates, else: merged by 'add', 'mean', 'min', 'max', or 'mul' >> for now, a single edge feature of value 1, so, mean, max, min should have all same effect
        add
        #mean
        #min
        #max
        #mul
      pre: # if set, use pretrained D2v vectors as initial node features of graph data
        #d2v.d8.e100.w10.dm1.skillmember  # skill, member, team
        #d2v.d8.e100.w10.dm1.skill  # skill, team
        #d2v.d9.e100.w10.dm1.skill  # if not exists, train from scratch!

    pytorch: #will be overriden dynamically in ./src/main.py from root ./__config__.yaml
    model: #dummy tag as placeholder. don't worry or touch it.

    #Grover, Aditya, and Jure Leskovec. "node2vec: Scalable feature learning for networks." Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 2016.
    #p: Return parameter, controls likelihood of revisiting the previous node. high p → discourages going back, low p → encourages backtracking
    #q: In-out (exploration) parameter, controls likelihood of visiting distant vs nearby nodes. high q → BFS-like (stick to local neighborhood), low q → DFS-like (explore outward)
    #p q	Behavior
    #1 1	Unbiased random walk (vanilla DeepWalk)
    #1 0.5	DFS-like (explore outward, communities)
    #1 2	BFS-like (stay local, structural roles)
    #0.2 4	Very local walks
    #4 0.25	Very exploratory
    n2v:
      d:  ${dim}
      w:  ${model.d2v.w}
      e:  ${model.epochs}
      b:  ${model.batch_size}
      lr: ${model.lr}
      es: ${model.es}
      ns: ${model.ns}
      spe: ${model.spe}
      wl: 5  #walk_length
      wn: 10 #walks_per_node
      p:  1.0
      q:  1.0

    #Dong, Chawla, Swami. "metapath2vec: Scalable representation learning for heterogeneous networks." SIGKDD 2017.
    m2v:
      metapath_name: # to have an embedding for a node type, it should be part of the metapath, e.g., for locations
        ##member → skill → member → skill, recommend skills to members, for sm graph structure
        #[[[member, rev_to, skill], [skill, to, member], [member, rev_to, skill]], msm]

        ##team → skill → team → member for stm. Given a team, rank likely members, recommend members to a team
        [[[team, rev_to, skill], [skill, to, team ], [team, rev_to, member]], tstm]
        ## member → team → skill → team for stm. Given a member, recommend likely teams
        #[[[member, to, team], [team, rev_to, skill], [skill, to, team], mtst]

        ##stml (member → team → location → team) Members worked on teams in the same location as the target team. Recommending teams to members or ranking likely team assignments for new members
        #[[[member, to, team], [team, rev_to, loc], [loc, to, team]], mtlt]

        ##Combines skill and location similarity (similar domain and location) to find members from teams that share skills and location with the target team. Location is important (e.g., for co-location constraints) and to reflect real-world assignment feasibility
        #[[[team, rev_to, skill], [skill, to, team], [team, rev_to, loc], [loc, to, team], [team, rev_to, member]], tstlt]
        ## (member → team → location → team), Member to similar teams in area, Teams near where member has worked
        #[[member, to, team], [team, rev_to, loc], [loc, to, team], mtlt]
        ## (team → location → team → member), Recommend local team members, Members in geographically close teams
        #[[team, rev_to, loc], [loc, to, team], [team, rev_to, member]], tltm]

      d:  ${dim}
      w:  4 #${model.d2v.w} ## assert walk_length + 1 >= context_size
      e:  ${model.epochs}
      b:  ${model.batch_size}
      lr: ${model.lr}
      es: ${model.es}
      ns: ${model.gnn.n2v.ns}
      spe: ${model.spe}
      wl: 3 #${model.gnn.n2v.wl} #walk_length AttributeError: The 'walk_length' is longer than the given 'metapath', but the 'metapath' does not denote a cycle
      wn: ${model.gnn.n2v.wn} #walks_per_node

    #Thomas N. Kipf, Max Welling: Semi-Supervised Classification with Graph Convolutional Networks. ICLR (Poster) 2017
    gcn:
      d: ${dim}
      e: ${model.epochs}
      b: ${model.batch_size}
      lr: ${model.lr}
      es: ${model.es}
      ns: ${model.ns}
      spe: ${model.spe}
      h: # hidden dimension, if empty, means 1-hop: [${dim}, ${dim}], otherwise means len(hd)+1 hop: [${dim}, hd[0], hd[1], ..., ${dim}]
        - ${dim} # hydra cannot interpolate in a list like [${dim}]. So, each item per line
      nn: [30, 20] # number of neighbors in each hop ([20, 10] -> 20 neighbors in 1-hop, 10 neighbors in 2-hop). Should match hd
      supervision_edge_types: # if not set, all edge_types as supervision edges.
        - ['member', 'to', 'team']
        - ['team', 'rev_to', 'member']

    #Hamilton, Will, Zhitao Ying, and Jure Leskovec. "Inductive representation learning on large graphs." NIPS (2017).
    gs: ${model.gnn.gcn}
      #d: ${dim}
      #e: ${model.epochs}
      #b: ${model.batch_size}
      #lr: ${model.lr}
      #es: ${model.es}
      #ns: ${model.ns}
      #spe: ${model.spe}
      #h: # hidden dimension, if empty, means 1-hop: [${dim}, ${dim}], otherwise means len(hd)+1 hop: [${dim}, hd[0], hd[1], ..., ${dim}]
      #  - ${dim} # hydra cannot interpolate in a list like [${dim}]. So, each item per line
      #nn: [ 30, 20 ] # number of neighbors in each hop ([20, 10] -> 20 neighbors in 1-hop, 10 neighbors in 2-hop). Should match hd
      #supervision_edge_types:
      # - ['member', 'to', 'team'] # if not set, all edge_types as supervision edges.

    gin: ${model.gnn.gcn}

    gat:
      d: ${dim}
      e: ${model.epochs}
      b: ${model.batch_size}
      lr: ${model.lr}
      es: ${model.es}
      ns: ${model.ns}
      spe: ${model.spe}
      h: # hidden dimension, if empty, means 1-hop: [${dim}, ${dim}], otherwise means len(hd)+1 hop: [${dim}, hd[0], hd[1], ..., ${dim}]
        - ${dim} # hydra cannot interpolate in a list like [${dim}]. So, each item per line
      nn: [30, 20] # number of neighbors in each hop ([20, 10] -> 20 neighbors in 1-hop, 10 neighbors in 2-hop). Should match hd
      supervision_edge_types: # if not set, all edge_types as supervision edges.
        #([('member', 'to', 'team')], 'stm')
      ah: 2 # number of attention heads (if applicable)
      cat: True # multi-head attention aggregation, True: concat, False: mean

    gatv2: ${model.gnn.gat}



#  'gnn.han': {
#      'e': 100,
#      'b': 128,
#      'd': 8,
#      'ns' : 5,
#      'h': 2,
#      'nn': [30, 20],
#      'graph_types': 'stm',
#      'agg': 'mean',
#      'dir': False,
#      'metapaths':{
#          'sm': [[('skill', 'to', 'member'), ('member', 'rev_to', 'skill')]],
#          'stm': [
#              [('member', 'to', 'team'), ('team', 'rev_to', 'skill'), ('skill', 'to', 'team'), ('team', 'rev_to', 'member')],
#              [('skill', 'to', 'team'), ('team', 'rev_to', 'member'), ('member', 'to', 'team'), ('team', 'rev_to', 'skill')],
#              [('member', 'to', 'team'), ('team', 'rev_to', 'member')],
#              [('skill', 'to', 'team'), ('team', 'rev_to', 'skill')],
#          ],
#          'stml': [
#              [('member', 'to', 'team'), ('team', 'rev_to', 'loc'), ('loc', 'to', 'team'), ('team', 'rev_to', 'member')],
#              [('skill', 'to', 'team'), ('team', 'rev_to', 'member'), ('member', 'to', 'team'), ('team', 'rev_to', 'skill')],
#              [('member', 'to', 'team'), ('team', 'rev_to', 'member')],
#              [('skill', 'to', 'team'), ('team', 'rev_to', 'skill')],
#          ],
#          # added one extra e-e connection in the middle
#          # 'sm.en': [[('skill', 'to', 'skill'), ('skill', 'to', 'member'), ('member', 'to', 'member'), ('member', 'rev_to', 'skill'), ('skill', 'to', 'skill')]],
#          'sm.en': [[('skill', 'to', 'skill'), ('skill', 'to', 'member'), ('member', 'rev_to', 'skill'), ('skill', 'to', 'skill')]],
#          'stm.en': [
#              [('member', 'to', 'team'), ('team', 'rev_to', 'skill'), ('skill', 'to', 'team'), ('team', 'rev_to', 'member')],
#              [('skill', 'to', 'team'), ('team', 'rev_to', 'member'), ('member', 'to', 'team'), ('team', 'rev_to', 'skill')],
#              [('member', 'to', 'team'), ('team', 'rev_to', 'member')],
#              [('skill', 'to', 'team'), ('team', 'rev_to', 'skill')],
#              # repeating the same set of metapaths with additional s-s or e-e connections
#              # [('member', 'to', 'member'), ('member', 'to', 'team'), ('team', 'rev_to', 'skill'), ('skill', 'to', 'team'), ('team', 'rev_to', 'member'), ('member', 'to', 'member')],
#              # [('skill', 'to', 'skill'), ('skill', 'to', 'team'), ('team', 'rev_to', 'member'), ('member', 'to', 'team'), ('team', 'rev_to', 'skill'), ('skill', 'to', 'skill')],
#              # [('member', 'to', 'member'), ('member', 'to', 'team'), ('team', 'rev_to', 'member'), ('member', 'to', 'member')],
#              # [('skill', 'to', 'skill'), ('skill', 'to', 'team'), ('team', 'rev_to', 'skill'), ('skill', 'to', 'skill')],
#          ]
#      }
#  },

#  'gnn.lant': {
#      'e': 100,
#      'b': 128,
#      'd': 8,
#      'ns' : 5,
#      'h': 2,
#      'nn': [30, 20],
#      'graph_types': 'stm',
#      'agg': 'mean',
#      'dir': False,
#  },

#},
