#defaults:
#  - mdl/emb/config

hydra:
  output_subdir: null
  run:
    dir: . #unix or macos
    #dir: /dev/null # windows
pytorch: torch==2.2.2 #--index-url https://download.pytorch.org/whl/cu124

cmd:
  prep 
  #train
  #test
  #eval
  #plot
  #agg
  #fair
data: #required for 'prep' step
  domain:
    #cmn.publication.Publication
    #cmn.movie.Movie
    #cmn.repository.Repository
    cmn.patent.Patent
  source:
    #../data/dblp/toy.dblp.v12.json
    #../data/imdb/toy.title.basics.tsv
    #../data/gith/toy.repos.csv
    ../data/uspt/toy.patent.tsv
  #these are folders or will be created as folders
  output:
    #../output/dblp/toy.dblp.v12.json
    #../output/imdb/toy.title.basics.tsv
    #../output/gith/toy.repos.csv
    ../output/uspt/toy.patent.tsv

  filter:
    min_nteam: 10 # as this may yield empty teams, min_team_size should be set to at least 1
    min_team_size: 2 #no filter -> no key 'filter' or ~data.filter in the command line
  location: 'venue' #should be one of 'city', 'state', 'country', represents the *location of team members*, or 'venue' represents the location of team members as replica of the location of team like in dblp
  acceleration: 'cpu' #cpu for all cores, cpu:3 for 3 cores, 'cuda' for all gpus, 'cuda:1,3' for gpu1 and gpu3
  bucket_size: 1000
  embedding: #if not set, will be skipped
    config: ./mdl/emb/config.yml
    class_method: # the name directs to the correct part of the embedding config file
      #mdl.emb.d2v.D2v_d2v #Doc2Vec
      #mdl.emb.gnn.Gnn_n2v #Node2Vec
      mdl.emb.gnn.Gnn_m2v  #Metapath2Vec

model:
    baseline:
        random:
            b: 128

train:
  nfolds: 3
  train_test_split: 0.85
  step_ahead: 2 #for now, it means that whatever are in the last [step_ahead] time interval will be the test set!