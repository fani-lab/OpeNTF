{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is OpeNTF?\n",
    "OpeNTF is an open-source framework hosting large-scale training datasets and canonical neural team formation models that are trained using fairness-aware and time-sensitive methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite for OpeNTF\n",
    "Before using OpeNTF, the following libraries are needed as a prerequisite, in addition to the libraries in `requirements.txt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install torch==1.9.0\n",
    "pip install pytrec-eval-terrier==0.5.2\n",
    "pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "git clone --recursive https://github.com/Fani-Lab/opentf\n",
    "cd opentf\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart on OpeNTF\n",
    "\n",
    "OpeNTF has the following required arguments:\n",
    "\n",
    "- `-data`: the path of the input datasets.\n",
    "- `-domain`: the domain the input dataset belongs in.\n",
    "- `-model`: the neural team formation models to be used in the run.\n",
    "\n",
    "As well, other optional arguments include:\n",
    "- `-attribute`: the set of our sensitive attributes (e.g., popularity).\n",
    "- `-fairness`: fairness metrics for reranking algorithms, used to minimize different bias.\n",
    "- `-np-ratio`: desired ratio of non-popular experts after reranking.\n",
    "- `-k_max`: cutoff for the reranking algorithms.\n",
    "- `-filter`: remove outliers, if needed.\n",
    "- `-future`: predict future, if needed.\n",
    "- `-exp_id`: ID of the experiment.\n",
    "- `-output`: path of the baseline output.\n",
    "\n",
    "The following is a sample run of the OpeNTF codebase using a toy dataset `toy.dblp.v12.json`, which is modelled after the DBLP dataset: a dataset consisting of authorship and skill information on more than 4 million Computer Science research publications. Two neural models (`feedforward` and `Bayesian`) are used in this quickstart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tea-n_\\Documents\\GitHub\\OpeNTF framework\\OpeNTF\\src\n",
      "Loading sparse matrices from ./../data/preprocessed/dblp/toy.dblp.v12.json/teamsvecs.pkl ...\n",
      "Loading indexes pickle from ./../data/preprocessed/dblp/toy.dblp.v12.json/indexes.pkl ...\n",
      "It took 0.010999202728271484 seconds to load from the pickles.\n",
      "It took 0.021991729736328125 seconds to load the sparse matrices.\n",
      "Running for (dataset, model): (dblp, fnn) ... \n",
      "Fold 0/2, Epoch 0/9, Minibatch 0/0, Phase train, Running Loss train 0.6056249141693115, Time 0.0599970817565918, Overall 4.238657712936401 \n",
      "Fold 0/2, Epoch 0/9, Running Loss train 0.03562499495113597, Time 0.0599970817565918, Overall 4.238657712936401 \n",
      "Fold 0/2, Epoch 0/9, Minibatch 0/0, Phase valid, Running Loss valid 0.5972533226013184, Time 0.06499719619750977, Overall 4.243657827377319 \n",
      "Fold 0/2, Epoch 0/9, Running Loss valid 0.06636148028903538, Time 0.06499719619750977, Overall 4.243657827377319 \n",
      "Fold 0/2, Epoch 1/9, Minibatch 0/0, Phase train, Running Loss train 0.5991436243057251, Time 0.096099853515625, Overall 4.274760484695435 \n",
      "Fold 0/2, Epoch 1/9, Running Loss train 0.035243742606219125, Time 0.096099853515625, Overall 4.274760484695435 \n",
      "Fold 0/2, Epoch 1/9, Minibatch 0/0, Phase valid, Running Loss valid 0.592308521270752, Time 0.10408306121826172, Overall 4.282743692398071 \n",
      "Fold 0/2, Epoch 1/9, Running Loss valid 0.06581205791897243, Time 0.10508513450622559, Overall 4.283745765686035 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 0/2, Epoch 2/9, Minibatch 0/0, Phase train, Running Loss train 0.592818021774292, Time 0.12507987022399902, Overall 4.303740501403809 \n",
      "Fold 0/2, Epoch 2/9, Running Loss train 0.03487164833966423, Time 0.12507987022399902, Overall 4.303740501403809 \n",
      "Fold 0/2, Epoch 2/9, Minibatch 0/0, Phase valid, Running Loss valid 0.5874701738357544, Time 0.13108086585998535, Overall 4.309741497039795 \n",
      "Fold 0/2, Epoch 2/9, Running Loss valid 0.06527446375952826, Time 0.13108086585998535, Overall 4.309741497039795 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 0/2, Epoch 3/9, Minibatch 0/0, Phase train, Running Loss train 0.5866307020187378, Time 0.14908242225646973, Overall 4.327743053436279 \n",
      "Fold 0/2, Epoch 3/9, Running Loss train 0.0345076883540434, Time 0.1500844955444336, Overall 4.328745126724243 \n",
      "Fold 0/2, Epoch 3/9, Minibatch 0/0, Phase valid, Running Loss valid 0.5827431082725525, Time 0.15508055686950684, Overall 4.333741188049316 \n",
      "Fold 0/2, Epoch 3/9, Running Loss valid 0.06474923425250584, Time 0.15508055686950684, Overall 4.333741188049316 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Fold 0/2, Epoch 4/9, Minibatch 0/0, Phase train, Running Loss train 0.5805637240409851, Time 0.1710801124572754, Overall 4.349740743637085 \n",
      "Fold 0/2, Epoch 4/9, Running Loss train 0.034150807296528536, Time 0.1710801124572754, Overall 4.349740743637085 \n",
      "Fold 0/2, Epoch 4/9, Minibatch 0/0, Phase valid, Running Loss valid 0.5781247019767761, Time 0.1750807762145996, Overall 4.353741407394409 \n",
      "Fold 0/2, Epoch 4/9, Running Loss valid 0.06423607799741957, Time 0.1750807762145996, Overall 4.353741407394409 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Fold 0/2, Epoch 5/9, Minibatch 0/0, Phase train, Running Loss train 0.574617326259613, Time 0.1890864372253418, Overall 4.367747068405151 \n",
      "Fold 0/2, Epoch 5/9, Running Loss train 0.03380101919174194, Time 0.1890864372253418, Overall 4.367747068405151 \n",
      "Fold 0/2, Epoch 5/9, Minibatch 0/0, Phase valid, Running Loss valid 0.5736306309700012, Time 0.1940782070159912, Overall 4.372738838195801 \n",
      "Fold 0/2, Epoch 5/9, Running Loss valid 0.06373673677444458, Time 0.1940782070159912, Overall 4.372738838195801 \n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early Stopping Triggered at epoch: 5\n",
      "Fold 1/2, Epoch 0/9, Minibatch 0/0, Phase train, Running Loss train 0.6933990716934204, Time 0.017998456954956055, Overall 4.400743246078491 \n",
      "Fold 1/2, Epoch 0/9, Running Loss train 0.04078818068784826, Time 0.017998456954956055, Overall 4.400743246078491 \n",
      "Fold 1/2, Epoch 0/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6659319996833801, Time 0.02700352668762207, Overall 4.409748315811157 \n",
      "Fold 1/2, Epoch 0/9, Running Loss valid 0.07399244440926446, Time 0.02700352668762207, Overall 4.409748315811157 \n",
      "Fold 1/2, Epoch 1/9, Minibatch 0/0, Phase train, Running Loss train 0.6839163899421692, Time 0.04999852180480957, Overall 4.432743310928345 \n",
      "Fold 1/2, Epoch 1/9, Running Loss train 0.040230375878951126, Time 0.04999852180480957, Overall 4.432743310928345 \n",
      "Fold 1/2, Epoch 1/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6573002338409424, Time 0.054996490478515625, Overall 4.437741279602051 \n",
      "Fold 1/2, Epoch 1/9, Running Loss valid 0.07303335931566027, Time 0.054996490478515625, Overall 4.437741279602051 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 1/2, Epoch 2/9, Minibatch 0/0, Phase train, Running Loss train 0.6747457981109619, Time 0.06899642944335938, Overall 4.4517412185668945 \n",
      "Fold 1/2, Epoch 2/9, Running Loss train 0.03969092930064482, Time 0.06899642944335938, Overall 4.4517412185668945 \n",
      "Fold 1/2, Epoch 2/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6489450335502625, Time 0.07399749755859375, Overall 4.456742286682129 \n",
      "Fold 1/2, Epoch 2/9, Running Loss valid 0.07210500372780694, Time 0.07399749755859375, Overall 4.456742286682129 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 1/2, Epoch 3/9, Minibatch 0/0, Phase train, Running Loss train 0.6658795475959778, Time 0.08699870109558105, Overall 4.469743490219116 \n",
      "Fold 1/2, Epoch 3/9, Running Loss train 0.03916938515270457, Time 0.08699870109558105, Overall 4.469743490219116 \n",
      "Fold 1/2, Epoch 3/9, Minibatch 0/0, Phase valid, Running Loss valid 0.640863835811615, Time 0.09400057792663574, Overall 4.476745367050171 \n",
      "Fold 1/2, Epoch 3/9, Running Loss valid 0.07120709286795722, Time 0.09400057792663574, Overall 4.476745367050171 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Fold 1/2, Epoch 4/9, Minibatch 0/0, Phase train, Running Loss train 0.6573038697242737, Time 0.10799622535705566, Overall 4.490741014480591 \n",
      "Fold 1/2, Epoch 4/9, Running Loss train 0.03866493351319257, Time 0.10799622535705566, Overall 4.490741014480591 \n",
      "Fold 1/2, Epoch 4/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6330206394195557, Time 0.11299729347229004, Overall 4.495742082595825 \n",
      "Fold 1/2, Epoch 4/9, Running Loss valid 0.07033562660217285, Time 0.11299729347229004, Overall 4.495742082595825 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Fold 1/2, Epoch 5/9, Minibatch 0/0, Phase train, Running Loss train 0.6490036845207214, Time 0.12999939918518066, Overall 4.512744188308716 \n",
      "Fold 1/2, Epoch 5/9, Running Loss train 0.03817668732474832, Time 0.12999939918518066, Overall 4.512744188308716 \n",
      "Fold 1/2, Epoch 5/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6254642009735107, Time 0.13500189781188965, Overall 4.517746686935425 \n",
      "Fold 1/2, Epoch 5/9, Running Loss valid 0.06949602233039008, Time 0.13599538803100586, Overall 4.518740177154541 \n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early Stopping Triggered at epoch: 5\n",
      "Fold 2/2, Epoch 0/9, Minibatch 0/0, Phase train, Running Loss train 0.6977599263191223, Time 0.012998342514038086, Overall 4.539742946624756 \n",
      "Fold 2/2, Epoch 0/9, Running Loss train 0.03876444035106235, Time 0.012998342514038086, Overall 4.539742946624756 \n",
      "Fold 2/2, Epoch 0/9, Minibatch 0/0, Phase valid, Running Loss valid 0.7054514288902283, Time 0.019999027252197266, Overall 4.546743631362915 \n",
      "Fold 2/2, Epoch 0/9, Running Loss valid 0.08818142861127853, Time 0.019999027252197266, Overall 4.546743631362915 \n",
      "Fold 2/2, Epoch 1/9, Minibatch 0/0, Phase train, Running Loss train 0.687987744808197, Time 0.04099678993225098, Overall 4.567741394042969 \n",
      "Fold 2/2, Epoch 1/9, Running Loss train 0.038221541378233165, Time 0.04199409484863281, Overall 4.568738698959351 \n",
      "Fold 2/2, Epoch 1/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6971001029014587, Time 0.04499387741088867, Overall 4.5717384815216064 \n",
      "Fold 2/2, Epoch 1/9, Running Loss valid 0.08713751286268234, Time 0.04499387741088867, Overall 4.5717384815216064 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 2/2, Epoch 2/9, Minibatch 0/0, Phase train, Running Loss train 0.678523600101471, Time 0.058997392654418945, Overall 4.585741996765137 \n",
      "Fold 2/2, Epoch 2/9, Running Loss train 0.03769575556119283, Time 0.05999469757080078, Overall 4.5867393016815186 \n",
      "Fold 2/2, Epoch 2/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6890474557876587, Time 0.06599593162536621, Overall 4.592740535736084 \n",
      "Fold 2/2, Epoch 2/9, Running Loss valid 0.08613093197345734, Time 0.06599593162536621, Overall 4.592740535736084 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 2/2, Epoch 3/9, Minibatch 0/0, Phase train, Running Loss train 0.6693738698959351, Time 0.08299565315246582, Overall 4.609740257263184 \n",
      "Fold 2/2, Epoch 3/9, Running Loss train 0.037187437216440834, Time 0.08299565315246582, Overall 4.609740257263184 \n",
      "Fold 2/2, Epoch 3/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6812991499900818, Time 0.09099721908569336, Overall 4.617741823196411 \n",
      "Fold 2/2, Epoch 3/9, Running Loss valid 0.08516239374876022, Time 0.09099721908569336, Overall 4.617741823196411 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Fold 2/2, Epoch 4/9, Minibatch 0/0, Phase train, Running Loss train 0.6605099439620972, Time 0.10500240325927734, Overall 4.631747007369995 \n",
      "Fold 2/2, Epoch 4/9, Running Loss train 0.036694996886783175, Time 0.10500240325927734, Overall 4.631747007369995 \n",
      "Fold 2/2, Epoch 4/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6738382577896118, Time 0.10999512672424316, Overall 4.636739730834961 \n",
      "Fold 2/2, Epoch 4/9, Running Loss valid 0.08422978222370148, Time 0.10999512672424316, Overall 4.636739730834961 \n",
      "EarlyStopping counter: 4 out of 5\n",
      "Fold 2/2, Epoch 5/9, Minibatch 0/0, Phase train, Running Loss train 0.6519139409065247, Time 0.1269981861114502, Overall 4.653742790222168 \n",
      "Fold 2/2, Epoch 5/9, Running Loss train 0.036217441161473594, Time 0.1269981861114502, Overall 4.653742790222168 \n",
      "Fold 2/2, Epoch 5/9, Minibatch 0/0, Phase valid, Running Loss valid 0.6666646599769592, Time 0.13199806213378906, Overall 4.658742666244507 \n",
      "Fold 2/2, Epoch 5/9, Running Loss valid 0.0833330824971199, Time 0.13199806213378906, Overall 4.658742666244507 \n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early Stopping Triggered at epoch: 5\n",
      "It took 4.666749000549316 to train the model.\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
      "Averaging ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
      "Averaging ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
      "Averaging ...\n",
      "####################################################################################################\n",
      "Reranking for the baseline ../output/toy.dblp.v12.json/fnn/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/f0.test.pred ...\n",
      "Loading popularity labels ...\n",
      "Loading popularity labels failed! Generating popularity labels at ../output/toy.dblp.v12.json/fnn/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/rerank/stats.pkl ...\n",
      "Loading reranking results ...\n",
      "Loading re-ranking results failed! Reranking the predictions based on popularity with det_greedy for top-None ...\n",
      "Loading fairness evaluation results before and after reranking ...\n",
      "Loading fairness results failed! Evaluating fairness metric {'ndkl'} ...\n",
      "Loading utility metric evaluation results before and after reranking ...\n",
      " Loading utility metric results failed! Evaluating utility metric {'map_cut_2,5,10'} ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10'} ...\n",
      "Averaging ...\n",
      "Pipeline for the baseline ../output/toy.dblp.v12.json/fnn/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/f0.test.pred completed by <_MainProcess name='MainProcess' parent=None started>! 0.20600175857543945\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "Reranking for the baseline ../output/toy.dblp.v12.json/fnn/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/f1.test.pred ...\n",
      "Loading popularity labels ...\n",
      "Loading reranking results ...\n",
      "Loading re-ranking results failed! Reranking the predictions based on popularity with det_greedy for top-None ...\n",
      "Loading fairness evaluation results before and after reranking ...\n",
      "Loading fairness results failed! Evaluating fairness metric {'ndkl'} ...\n",
      "Loading utility metric evaluation results before and after reranking ...\n",
      " Loading utility metric results failed! Evaluating utility metric {'map_cut_2,5,10'} ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10'} ...\n",
      "Averaging ...\n",
      "Pipeline for the baseline ../output/toy.dblp.v12.json/fnn/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/f1.test.pred completed by <_MainProcess name='MainProcess' parent=None started>! 0.14999842643737793\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "Reranking for the baseline ../output/toy.dblp.v12.json/fnn/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/f2.test.pred ...\n",
      "Loading popularity labels ...\n",
      "Loading reranking results ...\n",
      "Loading re-ranking results failed! Reranking the predictions based on popularity with det_greedy for top-None ...\n",
      "Loading fairness evaluation results before and after reranking ...\n",
      "Loading fairness results failed! Evaluating fairness metric {'ndkl'} ...\n",
      "Loading utility metric evaluation results before and after reranking ...\n",
      " Loading utility metric results failed! Evaluating utility metric {'map_cut_2,5,10'} ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10'} ...\n",
      "Averaging ...\n",
      "Pipeline for the baseline ../output/toy.dblp.v12.json/fnn/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/t31.s10.m13.l[100].lr0.001.b128.e10.nns3.nsnone.lossSL/f2.test.pred completed by <_MainProcess name='MainProcess' parent=None started>! 0.14599990844726562\n",
      "####################################################################################################\n",
      "Running for (dataset, model): (dblp, bnn) ... \n",
      "Fold 0/2, Epoch 0/4, Minibatch 0/0, Phase train, Running Loss train 9.701826095581055, Time 0.028998851776123047, Overall 0.03300189971923828 \n",
      "Fold 0/2, Epoch 0/4, Running Loss train 0.5706956526812386, Time 0.028998851776123047, Overall 0.03300189971923828 \n",
      "Fold 0/2, Epoch 0/4, Minibatch 0/0, Phase valid, Running Loss valid 6.872168064117432, Time 0.042000770568847656, Overall 0.04600381851196289 \n",
      "Fold 0/2, Epoch 0/4, Running Loss valid 0.7635742293463813, Time 0.042000770568847656, Overall 0.04600381851196289 \n",
      "Fold 0/2, Epoch 1/4, Minibatch 0/0, Phase train, Running Loss train 7.5233869552612305, Time 0.08099865913391113, Overall 0.08500170707702637 \n",
      "Fold 0/2, Epoch 1/4, Running Loss train 0.4425521738388959, Time 0.08099865913391113, Overall 0.08500170707702637 \n",
      "Fold 0/2, Epoch 1/4, Minibatch 0/0, Phase valid, Running Loss valid 5.3721466064453125, Time 0.0919952392578125, Overall 0.09599828720092773 \n",
      "Fold 0/2, Epoch 1/4, Running Loss valid 0.5969051784939237, Time 0.0919952392578125, Overall 0.09599828720092773 \n",
      "Fold 0/2, Epoch 2/4, Minibatch 0/0, Phase train, Running Loss train 8.192795753479004, Time 0.11699771881103516, Overall 0.12100076675415039 \n",
      "Fold 0/2, Epoch 2/4, Running Loss train 0.48192916196935315, Time 0.11699771881103516, Overall 0.12100076675415039 \n",
      "Fold 0/2, Epoch 2/4, Minibatch 0/0, Phase valid, Running Loss valid 3.359665632247925, Time 0.13300728797912598, Overall 0.1370103359222412 \n",
      "Fold 0/2, Epoch 2/4, Running Loss valid 0.37329618136088055, Time 0.13300728797912598, Overall 0.1370103359222412 \n",
      "Fold 0/2, Epoch 3/4, Minibatch 0/0, Phase train, Running Loss train 8.646369934082031, Time 0.1640021800994873, Overall 0.16800522804260254 \n",
      "Fold 0/2, Epoch 3/4, Running Loss train 0.5086099961224724, Time 0.1640021800994873, Overall 0.16800522804260254 \n",
      "Fold 0/2, Epoch 3/4, Minibatch 0/0, Phase valid, Running Loss valid 10.325803756713867, Time 0.1759958267211914, Overall 0.17999887466430664 \n",
      "Fold 0/2, Epoch 3/4, Running Loss valid 1.147311528523763, Time 0.1759958267211914, Overall 0.17999887466430664 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 0/2, Epoch 4/4, Minibatch 0/0, Phase train, Running Loss train 8.802574157714844, Time 0.20200133323669434, Overall 0.20600438117980957 \n",
      "Fold 0/2, Epoch 4/4, Running Loss train 0.517798479865579, Time 0.2030174732208252, Overall 0.20702052116394043 \n",
      "Fold 0/2, Epoch 4/4, Minibatch 0/0, Phase valid, Running Loss valid 6.550690650939941, Time 0.21699738502502441, Overall 0.22100043296813965 \n",
      "Fold 0/2, Epoch 4/4, Running Loss valid 0.7278545167711046, Time 0.21699738502502441, Overall 0.22100043296813965 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 1/2, Epoch 0/4, Minibatch 0/0, Phase train, Running Loss train 8.19212818145752, Time 0.024997949600219727, Overall 0.25800156593322754 \n",
      "Fold 1/2, Epoch 0/4, Running Loss train 0.48188989302691293, Time 0.024997949600219727, Overall 0.25800156593322754 \n",
      "Fold 1/2, Epoch 0/4, Minibatch 0/0, Phase valid, Running Loss valid 10.479596138000488, Time 0.043000221252441406, Overall 0.2760038375854492 \n",
      "Fold 1/2, Epoch 0/4, Running Loss valid 1.1643995708889432, Time 0.043000221252441406, Overall 0.2760038375854492 \n",
      "Fold 1/2, Epoch 1/4, Minibatch 0/0, Phase train, Running Loss train 7.664950370788574, Time 0.07799887657165527, Overall 0.3110024929046631 \n",
      "Fold 1/2, Epoch 1/4, Running Loss train 0.45087943357579846, Time 0.07799887657165527, Overall 0.3110024929046631 \n",
      "Fold 1/2, Epoch 1/4, Minibatch 0/0, Phase valid, Running Loss valid 5.143964767456055, Time 0.09299850463867188, Overall 0.3260021209716797 \n",
      "Fold 1/2, Epoch 1/4, Running Loss valid 0.5715516408284506, Time 0.09299850463867188, Overall 0.3260021209716797 \n",
      "Fold 1/2, Epoch 2/4, Minibatch 0/0, Phase train, Running Loss train 7.0461907386779785, Time 0.12600040435791016, Overall 0.35900402069091797 \n",
      "Fold 1/2, Epoch 2/4, Running Loss train 0.41448180815752816, Time 0.12600040435791016, Overall 0.35900402069091797 \n",
      "Fold 1/2, Epoch 2/4, Minibatch 0/0, Phase valid, Running Loss valid 5.6814775466918945, Time 0.14249062538146973, Overall 0.37549424171447754 \n",
      "Fold 1/2, Epoch 2/4, Running Loss valid 0.6312752829657661, Time 0.1430361270904541, Overall 0.3760397434234619 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 1/2, Epoch 3/4, Minibatch 0/0, Phase train, Running Loss train 9.323131561279297, Time 0.17501211166381836, Overall 0.40801572799682617 \n",
      "Fold 1/2, Epoch 3/4, Running Loss train 0.5484195036046645, Time 0.17501211166381836, Overall 0.40801572799682617 \n",
      "Fold 1/2, Epoch 3/4, Minibatch 0/0, Phase valid, Running Loss valid 5.848703384399414, Time 0.1910104751586914, Overall 0.4240140914916992 \n",
      "Fold 1/2, Epoch 3/4, Running Loss valid 0.6498559315999349, Time 0.19200706481933594, Overall 0.42501068115234375 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 1/2, Epoch 4/4, Minibatch 0/0, Phase train, Running Loss train 8.630220413208008, Time 0.22302532196044922, Overall 0.45602893829345703 \n",
      "Fold 1/2, Epoch 4/4, Running Loss train 0.5076600243063534, Time 0.22400856018066406, Overall 0.4570121765136719 \n",
      "Fold 1/2, Epoch 4/4, Minibatch 0/0, Phase valid, Running Loss valid 6.053482532501221, Time 0.24556422233581543, Overall 0.47856783866882324 \n",
      "Fold 1/2, Epoch 4/4, Running Loss valid 0.6726091702779134, Time 0.24611186981201172, Overall 0.47911548614501953 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "Fold 2/2, Epoch 0/4, Minibatch 0/0, Phase train, Running Loss train 13.120939254760742, Time 0.028215885162353516, Overall 0.5213377475738525 \n",
      "Fold 2/2, Epoch 0/4, Running Loss train 0.7289410697089301, Time 0.028757095336914062, Overall 0.5218789577484131 \n",
      "Fold 2/2, Epoch 0/4, Minibatch 0/0, Phase valid, Running Loss valid 7.2940826416015625, Time 0.05135083198547363, Overall 0.5444726943969727 \n",
      "Fold 2/2, Epoch 0/4, Running Loss valid 0.9117603302001953, Time 0.05135083198547363, Overall 0.5444726943969727 \n",
      "Fold 2/2, Epoch 1/4, Minibatch 0/0, Phase train, Running Loss train 6.706620693206787, Time 0.09486913681030273, Overall 0.5879909992218018 \n",
      "Fold 2/2, Epoch 1/4, Running Loss train 0.3725900385114882, Time 0.09587502479553223, Overall 0.5889968872070312 \n",
      "Fold 2/2, Epoch 1/4, Minibatch 0/0, Phase valid, Running Loss valid 5.9946818351745605, Time 0.11588263511657715, Overall 0.6090044975280762 \n",
      "Fold 2/2, Epoch 1/4, Running Loss valid 0.7493352293968201, Time 0.11687278747558594, Overall 0.609994649887085 \n",
      "Fold 2/2, Epoch 2/4, Minibatch 0/0, Phase train, Running Loss train 6.208798408508301, Time 0.16187167167663574, Overall 0.6549935340881348 \n",
      "Fold 2/2, Epoch 2/4, Running Loss train 0.34493324491712785, Time 0.16187167167663574, Overall 0.6549935340881348 \n",
      "Fold 2/2, Epoch 2/4, Minibatch 0/0, Phase valid, Running Loss valid 6.477299213409424, Time 0.17587566375732422, Overall 0.6689975261688232 \n",
      "Fold 2/2, Epoch 2/4, Running Loss valid 0.809662401676178, Time 0.17587566375732422, Overall 0.6689975261688232 \n",
      "EarlyStopping counter: 1 out of 5\n",
      "Fold 2/2, Epoch 3/4, Minibatch 0/0, Phase train, Running Loss train 6.142394065856934, Time 0.2244253158569336, Overall 0.7175471782684326 \n",
      "Fold 2/2, Epoch 3/4, Running Loss train 0.34124411476982963, Time 0.2244253158569336, Overall 0.7175471782684326 \n",
      "Fold 2/2, Epoch 3/4, Minibatch 0/0, Phase valid, Running Loss valid 6.238161563873291, Time 0.24743247032165527, Overall 0.7405543327331543 \n",
      "Fold 2/2, Epoch 3/4, Running Loss valid 0.7797701954841614, Time 0.24849271774291992, Overall 0.741614580154419 \n",
      "EarlyStopping counter: 2 out of 5\n",
      "Fold 2/2, Epoch 4/4, Minibatch 0/0, Phase train, Running Loss train 5.8609395027160645, Time 0.29543328285217285, Overall 0.7885551452636719 \n",
      "Fold 2/2, Epoch 4/4, Running Loss train 0.3256077501508925, Time 0.29543328285217285, Overall 0.7885551452636719 \n",
      "Fold 2/2, Epoch 4/4, Minibatch 0/0, Phase valid, Running Loss valid 6.935448169708252, Time 0.32242488861083984, Overall 0.8155467510223389 \n",
      "Fold 2/2, Epoch 4/4, Running Loss valid 0.8669310212135315, Time 0.3234236240386963, Overall 0.8165454864501953 \n",
      "EarlyStopping counter: 3 out of 5\n",
      "It took 0.8275489807128906 to train the model.\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
      "Averaging ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
      "Averaging ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'ndcg_cut_2,5,10', 'map_cut_2,5,10', 'P_2,5,10', 'recall_2,5,10'} ...\n",
      "Averaging ...\n",
      "####################################################################################################\n",
      "Reranking for the baseline ../output/toy.dblp.v12.json/bnn/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/f0.test.pred ...\n",
      "Loading popularity labels ...\n",
      "Loading popularity labels failed! Generating popularity labels at ../output/toy.dblp.v12.json/bnn/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/rerank/stats.pkl ...\n",
      "Loading reranking results ...\n",
      "Loading re-ranking results failed! Reranking the predictions based on popularity with det_greedy for top-None ...\n",
      "Loading fairness evaluation results before and after reranking ...\n",
      "Loading fairness results failed! Evaluating fairness metric {'ndkl'} ...\n",
      "Loading utility metric evaluation results before and after reranking ...\n",
      " Loading utility metric results failed! Evaluating utility metric {'map_cut_2,5,10'} ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10'} ...\n",
      "Averaging ...\n",
      "Pipeline for the baseline ../output/toy.dblp.v12.json/bnn/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/f0.test.pred completed by <_MainProcess name='MainProcess' parent=None started>! 0.1805408000946045\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "Reranking for the baseline ../output/toy.dblp.v12.json/bnn/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/f1.test.pred ...\n",
      "Loading popularity labels ...\n",
      "Loading reranking results ...\n",
      "Loading re-ranking results failed! Reranking the predictions based on popularity with det_greedy for top-None ...\n",
      "Loading fairness evaluation results before and after reranking ...\n",
      "Loading fairness results failed! Evaluating fairness metric {'ndkl'} ...\n",
      "Loading utility metric evaluation results before and after reranking ...\n",
      " Loading utility metric results failed! Evaluating utility metric {'map_cut_2,5,10'} ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10'} ...\n",
      "Averaging ...\n",
      "Pipeline for the baseline ../output/toy.dblp.v12.json/bnn/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/f1.test.pred completed by <_MainProcess name='MainProcess' parent=None started>! 0.21157193183898926\n",
      "####################################################################################################\n",
      "####################################################################################################\n",
      "Reranking for the baseline ../output/toy.dblp.v12.json/bnn/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/f2.test.pred ...\n",
      "Loading popularity labels ...\n",
      "Loading reranking results ...\n",
      "Loading re-ranking results failed! Reranking the predictions based on popularity with det_greedy for top-None ...\n",
      "Loading fairness evaluation results before and after reranking ...\n",
      "Loading fairness results failed! Evaluating fairness metric {'ndkl'} ...\n",
      "Loading utility metric evaluation results before and after reranking ...\n",
      " Loading utility metric results failed! Evaluating utility metric {'map_cut_2,5,10'} ...\n",
      "Building pytrec_eval input for 5 instances ...\n",
      "Evaluating {'map_cut_2,5,10'} ...\n",
      "Averaging ...\n",
      "Pipeline for the baseline ../output/toy.dblp.v12.json/bnn/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/t31.s10.m13.l[128].lr0.1.b128.e5.nns3.nsunigram_b.s1.lossSL/f2.test.pred completed by <_MainProcess name='MainProcess' parent=None started>! 0.18742156028747559\n",
      "####################################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tea-n_\\anaconda3\\envs\\opentf\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 54.35it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2498.99it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 61.73it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2505.86it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 60.97it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 4987.28it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1662.43it/s]\n",
      "c:\\Users\\tea-n_\\anaconda3\\envs\\opentf\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 55.56it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2498.39it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 40.98it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 40.65it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 9173.89it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1660.32it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 47.62it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 47.17it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 5000.36it/s]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1245.78it/s]\n"
     ]
    }
   ],
   "source": [
    "%cd src\n",
    "!python -u main.py -data ../data/raw/dblp/toy.dblp.v12.json -domain dblp -model fnn bnn -fairness det_greedy -attribute popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Setting Hyperparameters\n",
    "OpeNTF's codebase offers the following hyperparameter to be set for each neural team formation methods:\n",
    "\n",
    "### `model`\n",
    "- Contains the baseline hyperparameters in the form of `'model-name' : { params }`, which allows the models to be integrated into the baseline with their unique parameters.\n",
    "- Allows the customization of which stages of the system to be executed through `cmd`.\n",
    "- Contains other training parameter for the models.\n",
    "\n",
    "### `data`\n",
    "- Contains parameters for manipulating datasets, including dataset filters (e.g., minimum team size) and bucket size for sparse matrix parallel generation.\n",
    "\n",
    "### `fair`\n",
    "- Contains parameters for the fairness metrics used in consideration during team formation.\n",
    "\n",
    "A snippet of the parameters used in `param.py` is displayed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "settings = {\n",
    "    'model':{\n",
    "        'baseline': {\n",
    "            'random': {\n",
    "                'b': 128\n",
    "            },\n",
    "            'fnn':{\n",
    "                'l': [100],  # list of number of nodes in each layer\n",
    "                'lr': 0.001,  # learning rate\n",
    "                'b': 128,  # batch size\n",
    "                'e': 10,  # epoch\n",
    "                'nns': 3,  # number of negative samples\n",
    "                'ns': 'none',  # 'none', 'uniform', 'unigram', 'unigram_b'\n",
    "                'loss': 'SL',  # 'SL'-> superloss, 'DP' -> Data Parameters, 'normal' -> Binary Cross Entropy\n",
    "            },\n",
    "            'bnn':{\n",
    "                'l': [128],  # list of number of nodes in each layer\n",
    "                'lr': 0.1,  # learning rate\n",
    "                'b': 128,  # batch size\n",
    "                'e': 5,  # epoch\n",
    "                'nns': 3,  # number of negative samples\n",
    "                'ns': 'unigram_b',  # 'uniform', 'unigram', 'unigram_b'\n",
    "                's': 1,  # # sample_elbo for bnn\n",
    "                'loss': 'SL',  # 'SL'-> superloss, 'DP' -> Data Parameters, 'normal' -> Binary Cross Entropy\n",
    "            },\n",
    "        },\n",
    "        'cmd': ['train', 'test', 'eval', 'fair'],  # 'train', 'test', 'eval', 'plot', 'agg', 'fair'\n",
    "        'nfolds': 3,\n",
    "        'train_test_split': 0.85,\n",
    "        'step_ahead': 2,#for now, it means that whatever are in the last [step_ahead] time interval will be the test set!\n",
    "    },\n",
    "    'data':{\n",
    "        'domain': {\n",
    "            'dblp':{},\n",
    "            'uspt':{},\n",
    "            'imdb':{},\n",
    "        },\n",
    "        'location_type': 'country', #should be one of 'city', 'state', 'country' and represents the location of members in teams (not the location of teams)\n",
    "        'filter': {\n",
    "            'min_nteam': 5,\n",
    "            'min_team_size': 2,\n",
    "        },\n",
    "        'parallel': 1,\n",
    "        'ncore': 0,# <= 0 for all\n",
    "        'bucket_size': 1000\n",
    "    },\n",
    "    'fair': {'np_ratio': None,\n",
    "              'fairness': ['det_greedy',],\n",
    "              'k_max': None,\n",
    "              'fairness_metrics': {'ndkl'},\n",
    "              'utility_metrics': {'map_cut_2,5,10'},\n",
    "              'eq_op': False,\n",
    "              'mode': 0,\n",
    "              'core': -1,\n",
    "              'attribute': ['gender', 'popularity']},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure and Inheritance\n",
    "\n",
    "### Dataset Structure\n",
    "<p align=\"center\"><img src='./src/cmn/dataset_hierarchy.png' width=\"500\" ></p>\n",
    "\n",
    "To integrate a new dataset into the baseline, follow the structure of the `team` class. Additional fields can be added, like its derived classes. Ideally, only the `read_data()` function should be overriden.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "[\n",
    "  {\n",
    "    \"id\": 1,\n",
    "    \"reviewers\": [\n",
    "      { \"name\": \"Ada\", \"id\": 1, \"expertise\": \"Multimedia mining\" },\n",
    "      { \"name\": \"Bob\", \"id\": 11, \"expertise\": \"Image Captioning\" },\n",
    "      { \"name\": \"Cameron\", \"id\": 12, \"expertise\": \"Image Classification\" }\n",
    "    ],\n",
    "    \"fos\": [\"Image Captioning\"],\n",
    "    \"title\": \"A Comprehensive Review of Domain-specific Image Captioning\",\n",
    "    \"year\": 2000,\n",
    "  },\n",
    "  {\n",
    "    \"id\": 2,\n",
    "    \"reviewers\": [\n",
    "      { \"name\": \"Ada\", \"id\": 1, \"expertise\": \"Multimedia mining\" },\n",
    "      { \"name\": \"David\", \"id\": 9, \"expertise\": \"Video Classification\" },\n",
    "      { \"name\": \"Cameron\", \"id\": 12, \"expertise\": \"Image Classification\" }\n",
    "    ],\n",
    "    \"fos\": [\"Machine Learning\", \"Image Segmentation\"],\n",
    "    \"title\": \"A methodology for the physically accurate visualisation of medical imaging\",\n",
    "    \"year\": 1999,\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from cmn.member import Member\n",
    "from cmn.team import Team\n",
    "\n",
    "class Review(Team):\n",
    "    def _init_(self, id, title, year, fos, reviewers):\n",
    "        super().__init__(id, reviewers, fos, year)\n",
    "        self.title = title\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_data(datapath, output, index, filter, settings):\n",
    "        try:\n",
    "            return super(Review, Review).load_data(output, index)\n",
    "        except (FileNotFoundError, EOFError) as e:\n",
    "            print(f\"Pickles not found! Reading raw data from {datapath} (progress in bytes) ...\")\n",
    "            teams = {}; candidates = {}\n",
    "\n",
    "            with open(datapath, \"r\", encoding='utf-8') as jf:\n",
    "                for line in jf:\n",
    "                    try:\n",
    "                        if not line: break\n",
    "                        jsonline = json.loads(line.lower().lstrip(\",\"))\n",
    "                        id = jsonline['id']\n",
    "                        title = jsonline['title']\n",
    "                        year = jsonline['year']\n",
    "\n",
    "                        # a team must have skills and members\n",
    "                        try: fos = jsonline['fos']\n",
    "                        except: continue\n",
    "                        try: reviewers = jsonline['reviewers']\n",
    "                        except: continue\n",
    "\n",
    "                        members = []\n",
    "                        for reviewer in reviewers:\n",
    "                            member_id = reviewer['id']\n",
    "                            member_name = reviewer['name'].replace(\" \", \"_\")\n",
    "                            if (idname := f'{member_id}_{member_name}') not in candidates:\n",
    "                                candidates[idname] = Member(member_id, member_name)\n",
    "                                candidates[idname].skills.update(set(reviewer['expertise']))\n",
    "                            members.append(candidates[idname])\n",
    "                            \n",
    "                        team = Review(id, title, year, fos, members)\n",
    "                        teams[team.id] = team\n",
    "                    except json.JSONDecodeError as e:  # ideally should happen only for the last line ']'\n",
    "                        print(f'JSONDecodeError: There has been error in loading json line `{line}`!\\n{e}')\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        raise e\n",
    "            return super(Review, Review).read_data(teams, output, filter, settings)\n",
    "        except Exception as e: raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Structure\n",
    "![Class Diagram of the Model baseline.](./new-class-diagram.png)\n",
    "\n",
    "To integrate a new model into the baseline, follow the `Ntf` class. Ideally, only the `learn()` method should be overriden, with `eval()` remaining the same for fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "from mdl.ntf import Ntf\n",
    "from mdl.cds import TFDataset\n",
    "from cmn.team import Team\n",
    "from cmn.tools import merge_teams_by_skills\n",
    "from mdl.cds import SuperlossDataset\n",
    "from mdl.superloss import SuperLoss\n",
    "\n",
    "class Random(Ntf):\n",
    "    def __init__(self):\n",
    "        super(Random, self).__init__()\n",
    "    \n",
    "    def init(self):\n",
    "        self.model = keras.Sequential()\n",
    "\n",
    "    def learn(self, splits, indexes, vecs, params, prev_model, output):\n",
    "        input_size = vecs['skill'].shape[1]\n",
    "        output_size = len(indexes['i2c'])\n",
    "\n",
    "        for foldidx in splits['folds'].keys():\n",
    "            self.init(input_size=input_size, output_size=output_size)\n",
    "            if prev_model: keras.saving.load_model((prev_model[foldidx]))\n",
    "            \n",
    "            keras.saving.save_model(self.model, f\"{output}/state_dict_model.f{foldidx}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opentf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
