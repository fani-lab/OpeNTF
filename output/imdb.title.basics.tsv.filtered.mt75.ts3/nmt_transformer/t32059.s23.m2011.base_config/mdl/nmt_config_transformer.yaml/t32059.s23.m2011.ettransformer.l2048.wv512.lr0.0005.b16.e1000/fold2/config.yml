batch_size: 16
data:
  corpus_1:
    path_src: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer/t32059.s23.m2011.base_config./mdl/nmt_config_transformer.yaml/t32059.s23.m2011.ettransformer.l2048.wv512.lr0.0005.b16.e1000/fold2/src-train.txt
    path_tgt: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer/t32059.s23.m2011.base_config./mdl/nmt_config_transformer.yaml/t32059.s23.m2011.ettransformer.l2048.wv512.lr0.0005.b16.e1000/fold2/tgt-train.txt
  valid:
    path_src: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer/t32059.s23.m2011.base_config./mdl/nmt_config_transformer.yaml/t32059.s23.m2011.ettransformer.l2048.wv512.lr0.0005.b16.e1000/fold2/src-valid.txt
    path_tgt: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer/t32059.s23.m2011.base_config./mdl/nmt_config_transformer.yaml/t32059.s23.m2011.ettransformer.l2048.wv512.lr0.0005.b16.e1000/fold2/tgt-valid.txt
decay_steps: 100
decoder_type: transformer
dropout: 0.3
encoder_type: transformer
gpu_ranks:
- 0
heads: 8
hidden_size: 512
keep_checkpoint: -1
layers: 6
learning_rate: 0.0005
learning_rate_decay: 0.95
optim: adam
overwrite: true
position_encoding: true
report_every: 1000
save_checkpoint_steps: 500
save_data: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer/t32059.s23.m2011.base_config./mdl/nmt_config_transformer.yaml/t32059.s23.m2011.ettransformer.l2048.wv512.lr0.0005.b16.e1000/fold2/
save_model: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer/t32059.s23.m2011.base_config./mdl/nmt_config_transformer.yaml/t32059.s23.m2011.ettransformer.l2048.wv512.lr0.0005.b16.e1000/fold2/model
seed: 0
src_vocab: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer/t32059.s23.m2011.base_config./mdl/nmt_config_transformer.yaml/t32059.s23.m2011.ettransformer.l2048.wv512.lr0.0005.b16.e1000/fold2/vocab.src
start_decay_steps: 100
tgt_vocab: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer/t32059.s23.m2011.base_config./mdl/nmt_config_transformer.yaml/t32059.s23.m2011.ettransformer.l2048.wv512.lr0.0005.b16.e1000/fold2/vocab.tgt
train_steps: 1000
transformer_ff: 2048
valid_steps: 1000
word_vec_size: 512
world_size: 1
