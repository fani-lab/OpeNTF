accum_steps:
- 0
adam_beta2: 0.998
attention_dropout:
- 0.2
batch_size: 512
batch_type: tokens
beam_size: 5
bucket_size: 262144
data:
  corpus_1:
    path_src: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer-model3/t32059.s23.m2011.ettransformer.l3072.wv512.lr0.0005.b512.e300000/fold1/src-train.txt
    path_tgt: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer-model3/t32059.s23.m2011.ettransformer.l3072.wv512.lr0.0005.b512.e300000/fold1/tgt-train.txt
    weight: 1
  valid:
    path_src: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer-model3/t32059.s23.m2011.ettransformer.l3072.wv512.lr0.0005.b512.e300000/fold1/src-valid.txt
    path_tgt: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer-model3/t32059.s23.m2011.ettransformer.l3072.wv512.lr0.0005.b512.e300000/fold1/tgt-valid.txt
dec_layers: 4
decay_method: noam
decay_steps: 10000
decoder_type: transformer
dropout:
- 0.2
enc_layers: 4
encoder_type: transformer
gpu_ranks:
- 0
heads: 8
hidden_size: 512
label_smoothing: 0.05
learning_rate: 0.0005
learning_rate_decay: 0.8
length_penalty: 1.0
max_grad_norm: 0
max_relative_positions: 20
model_dtype: fp16
normalization: tokens
num_workers: 4
optim: adam
overwrite: true
param_init: 0
param_init_glorot: true
position_encoding: false
save_checkpoint_steps: 10000
save_data: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer-model3/t32059.s23.m2011.ettransformer.l3072.wv512.lr0.0005.b512.e300000/fold1/
save_model: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer-model3/t32059.s23.m2011.ettransformer.l3072.wv512.lr0.0005.b512.e300000/fold1/model
src_vocab: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer-model3/t32059.s23.m2011.ettransformer.l3072.wv512.lr0.0005.b512.e300000/fold1/vocab.src
tgt_vocab: ./../output/imdb.title.basics.tsv.filtered.mt75.ts3/nmt_transformer-model3/t32059.s23.m2011.ettransformer.l3072.wv512.lr0.0005.b512.e300000/fold1/vocab.tgt
train_steps: 300000
transformer_ff: 3072
valid_batch_size: 1024
valid_steps: 10000
warmup_steps: 16000
weight_decay: 0.0001
word_vec_size: 512
world_size: 1
